{"meta":{"title":"行路中.","subtitle":"脚踏实地","description":"笔记 随笔","author":"Sean10","url":"https://sean10.github.io","root":"/"},"pages":[{"title":"categories","date":"2016-04-15T07:04:50.000Z","updated":"2023-03-18T15:11:14.928Z","comments":true,"path":"categories/index.html","permalink":"https://sean10.github.io/categories/index.html","excerpt":"","text":""},{"title":"关于&&留言板","date":"2018-02-24T09:15:33.000Z","updated":"2023-03-18T15:11:14.907Z","comments":true,"path":"about/index.html","permalink":"https://sean10.github.io/about/index.html","excerpt":"","text":"主要记录专业、反思、读书小结、影评。 mail: sean10reborn@gmail.com"},{"title":"tags","date":"2016-04-15T06:15:46.000Z","updated":"2023-03-18T15:11:14.927Z","comments":false,"path":"tags/index.html","permalink":"https://sean10.github.io/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"浅读<Deploying User-space TCP at Cloud Scale with Luna>","slug":"浅读-Deploying-User-space-TCP-at-Cloud-Scale-with-Luna","date":"2025-02-07T09:50:20.000Z","updated":"2025-02-07T14:30:16.709Z","comments":true,"path":"2025/02/07/浅读-Deploying-User-space-TCP-at-Cloud-Scale-with-Luna/","link":"","permalink":"https://sean10.github.io/2025/02/07/%E6%B5%85%E8%AF%BB-Deploying-User-space-TCP-at-Cloud-Scale-with-Luna/","excerpt":"","text":"目前在个人的理解中, 在存储高带宽需求场景下, RDMA的RoCEv2方案, 在节省CPU, 使CPU用在提供更高的IOPS的处理能力上, 是显著优势了. 在不超过40Gbps的场景下, TCP还是可以用的. 按之前收集的论文数据, 大概是RDMA下, 1%的CPU消耗对比, TCP时100%+的CPU消耗, 在100Gbps以上时, CPU消耗10多个核, 对于主流服务器CPU单C超线程完也才32核, 在那个量级下, TCP从成本上基本完全不可用了. 内存带宽, TCP存在成倍的内核&lt;-&gt;用户态复制的开销, 在现在的内存通道情况下是没达到瓶颈, 但是也挺浪费. 虽然也有提到TCP spice方案, 但论文中觉得不是长期方案. 从下图可以看出，内核 TCP 的性能远未达到我们的 SLO。具体来说，图 2(a)表明内核 TCP 的基本 RPC 延迟中位数已经达到 50μs。相比之下，我们的高性能类 EBS 要求端到端响应延迟为 100μs[3]。图 2(b)进一步显示，单核上的内核网络堆栈只能提供最多 600Mbps 的吞吐量。此外，图 2(b)还表明，通过分配更多核心无法解决内核 TCP 的性能问题。可能的原因之一是随着 CPU 核心数量的增加，内核开销——如跨核竞争——也会增加。 DPDK则目前处在两者中间的感觉, 转换到用户态确实能节省一部分TCP协议自身的CPU损耗, 但是相比CPU压力卸载走来说, 就没什么优势了. 兼容性视角, 当然优势还是比较大的. 只不过在存储内网下, 无法与RDMA相提并论. TCP 仍然是许多现代大规模数据中心的核心协议。然而，随着硬件（例如，100Gbps 链路速度网络）和软件（例如，Intel DPDK 支持）性能要求的不断提高，基于内核的 TCP 堆栈已不再是一个理想的选择。在过去十年中，多个机构提出了各种用户堆栈 TCP 堆栈，提供与传统 TCP 支持相比具有显著性能改进的功能。不幸的是，我们发现这些提案在实际应用中可能无法很好地工作，尤其是在大规模部署时。 在本文中，我们介绍了 Luna，这是一种广泛部署在阿里云上的用户空间 TCP 堆栈。我们详细阐述了设计权衡，强调了线程、内存和流量模型中的三个独特特征。此外，我们分享了从现场部署中学到的经验教训。广泛的微基准评估和从生产系统收集的性能统计数据表明，L 在吞吐量方面比内核和其他用户空间解决方案高出 3.5 倍，并将延迟降低 53%。 看到本文时, 主要在内核与用户态方案的路径上, 有了以下的问题 从上述定位视角, 阿里的这套方案, 是否落地在了盘古引擎层? 还是哪个层级? 阿里的这套方案, 是否落地在了盘古引擎层? 还是哪个层级? 与RDMA RoCEv2的方案相比, 定位的差异, 是主打利旧硬件场景? 还是彻底PK的场景? 毕竟如果还是在用户态, 那就是和DPDK范畴相近的, CPU消耗还是不能卸载到网卡上去. 还是说引入新硬件? 在RDMA网卡之外提供了其他的能力? 结论: 定位在计算侧-&gt;存储端 中间的链路, 在计算客户端-&gt;块存储/对象存储/表格存储网关前 这条链路由于计算侧可能跨数据中心, 中间的链路就目前互联网状态, 无法使用RDMA, 因此需要在保障通用硬件兼容性的情况下, 提供高吞吐能力. 按照引文, 主要实现目标如下 业务核心价值: 针对目前整套的计算段-&gt;存储端的复杂网络架构下, 支持利旧硬件的情况下, 在相对CPU利用率较高的效果下可以让4K,512B等小IO跑满40Gbps-100Gbps的网卡, 相比之前的TCP吞吐量呈至多3.5倍的提升, 延时呈53%的降低. 而针对更高100Gbps等, 会引入类似RDMA硬件卸载CPU的DPU硬件, 来配合将CPU消耗等进一步优化. 在本文中，我们讨论了 LUNA 可以有效地利用 50Gpbs NIC。但是，对于更高的带宽（例如，200 到 400Gbps），LUNA 的运行到完成与浅缓冲区可能会导致 NIC 队列溢出和数据包丢弃。此外，当消息大小为 4KB 时，LUNA 至少需要 8 个内核才能使 100Gbps 网络带宽饱和。因此，为了采用高链接速度网络，我们认为利用硬件加速是必要的。此外，虽然 TCP 可以通过多路径 TCP 使用多路径传输，但 TCP 中的队头阻塞问题及其在故障恢复方面的限制仍然促使我们专门为高性能云存储设计了一种新协议。我们最近的工作称为 Solar [29]，它涉及使用与 DPU 共同设计的新传输层协议，这说明了这一点。 内部价值: 提高单核CPU可提供的吞吐量 解决TCP内存拷贝 解决TCP硬件中断多, 上下文切换多问题 降低TCP目前的长尾延时 支持跨可用区网络通信 对内存带宽的消耗放大减少 利旧, 新程序兼容旧服务器, 使其网卡同时响应传统TCP请求, 和本次新的流量 主要对比mTCP和IX, 如果不是公有云这种规模, 私有云场景按照这个对比, 可能基于mTCP和IX开发是个可行方案. 不过, 如果广域网的RDMA方案出来, 且成本下降到可接受时, 可能还是以RDMA为主流方案了. 主要核心技术 用户态Luna替换TCP TCP 堆栈。如第 3 节所述，LUNA 使用 TCP 作为传输层协议。LUNA 根据 RFC 实现 TCP [2801234]，并支持拥塞控制、流量控制、RTT 估计和 SACK。 类比xsky的RDMA的ECN拥塞控制等. LibOS模式运行 在此设置中，应用程序和 LUNA 在同一进程中运行并共享内存地址空间。或者，可以在单独的进程中运行网络堆栈，并通过共享内存进行通信.在这种情况下，如果每个服务器中只有一个网络进程来服务于不同的应用程序进程，则称为微内核模式（例如，Google Snap [27]）。另一种解决方案是为每个应用程序进程设置一个网络堆栈进程，称为 Sidecar 模式。 参考Irene Y. Zhang: 高层次内核绕过 I/O 抽象的案例 --- Irene Y. Zhang: The Case for a High-level Kernel-Bypass I/O Abstraction 可知, 如果缺失该环节, DPDK和RDMA均需要单独实现拥塞控制和流量控制, 在该环节, 则可进行一层抽象 提供易用性 提供可迁移性 提供灵活性 线程间 share nothing架构 run to complete模型 inline run to complete LUNA 也逐个处理数据包。但是，LUNA 避免将事件添加到事件队列中，而是立即调用已注册的回调函数，生成响应以及数据包的协议标头，然后将它们发送出去。简而言之，inline-r2c 将处理每个数据包直到完成。 显然，inline-r2c 消除了事件入队和出队的开销，并提高了缓存局部性，从而提供了更好的性能。但是，inline-r2c 还需要一个新的编程模型，并强制 upperlayer 应用程序使用类似 raw-packet 的零拷贝读 / 写接口。此外，inline-r2c 仅在 LibOS 模型中可用，因为应用层代码必须与网络堆栈位于同一位置 一般类比应该是用在高优先级请求上, 确保该请求的低延时 batch run to complete LUNA 通过 TCP/IP 堆栈一次处理一个接收到的数据包，然后为每个具有 TCP 有效负载的数据包向事件队列添加一个读取事件。在 LUNA 处理完本轮收到的所有数据包后，应用程序将立即处理这些读取事件。然后，RPC 框架调用注册到每个事件的回调函数，生成响应消息，并将消息发送到发送缓冲区。处理完所有事件后，LUNA 会在发送缓冲区中添加消息的协议标头，将它们转发到 NIC，然后开始下一轮。 batch-r2c 工作在更传统的类似 epoll 或类似 libev 的编程模型中，并且与传统的类似 BSD-Socket 的接口兼容。在实践中，我们在 EBS 等面向性能的服务上部署 inline-r2c，出于兼容性考虑，我们将 batch-r2c 用于对象存储等服务。 一般类比应该是用在正常优先级请求上, 确保整体延时保障 内存 零拷贝 LUNA 在接收端和发送端支持完整的数据路径零拷贝缓冲区，旨在最大限度地减少数据移动开销。LUNA 在用户空间 slab 子系统的帮助下实现了其全栈零拷贝。此子系统引入的开销很小，并维护传统的编程模型。 Zbuf 用户空间 slab 子系统。Zbuf 用作用户空间 slab 子系统，为用户预先分配内存块。图 6 显示了 Zbuf 的结构。我们可以看到 Zbuf 保留了从 DPDK 的内存地址空间分配的几个大页面，并将它们划分为多个 2MB 的内存区域。每个内存区域的标头记录元信息，例如物理地址。内存区进一步拆分为 OBJS，OBJ 可以直接由户（即应用程序）。objs 的元数据（在图 6 中表示为 ctx）与 objs 位于同一内存区中，紧跟在区域元数据之后。同一内存区中的所有 obj 共享相同的大小，但大小可能因内存区而异（例如，图 6 中的 2KB 与 4KB）。Obj 生命周期管理。Zbuf 使用引用计数器来管理每个 obj 的生命周期。初始化后，计数器设置为 1。之后，每当复制相应的 obj 时，计数器就会增加 1，每次释放 obj 时，计数器就会减少 1。一旦计数达到 0，obj 将被放回内存区的空闲列表。 DMA 通过 DMA 将数据包数据发送到 OBJ （（1））。网络堆栈使用网络协议 （（2）） 处理数据包，并将指向可读有效载荷的指针（在图 7 中标记为 ）通过 RPC 接口 （（3）） 传送到上层应用程序。应用程序可以在完成消息处理后直接释放有效负载 （（4））。Zbuf 将找到相关的 obj 并通过减少引用计数来释放它。 流量模型 NIC 多队列区分 内核/用户空间流量 将控制平面（即 ARP 表和路由表管理）留给内核，并使用 netlink 接口访问路由信息。 LUNA 使用 Flow Bifurcation 和 SR-IOV 支持，为用户空间流量保留一定的端口范围，这样就不会干扰内核流量。内核网络堆栈直接处理 ARP 请求和响应等控制平面消息，并管理控制平面 Flow Bifurcation SR-IOV 支持 DPDK轮询 用户空间流量 PMD轮询模式驱动程序 巨页管理 数据结构 哈希映射 mbuf 总结 大体上, 阿里这套方案在存算分离架构下的私有云的IaaS中, 计算侧网络可借鉴, 只不过工作量角度, 可能大幅复用DPDK/IX等方案, 存储侧走RDMA毋庸置疑. 对于如果没有此类复杂网络场景, 在具体核算成本TCO时, 也许有可能还是全套RDMA方案划得来?","categories":[{"name":"专业","slug":"pro","permalink":"https://sean10.github.io/categories/pro/"}],"tags":[{"name":"网络","slug":"网络","permalink":"https://sean10.github.io/tags/%E7%BD%91%E7%BB%9C/"},{"name":"TCP","slug":"TCP","permalink":"https://sean10.github.io/tags/TCP/"}]},{"title":"大模型使用初探","slug":"大模型使用初探","date":"2024-09-28T03:13:22.000Z","updated":"2024-10-07T06:10:45.349Z","comments":true,"path":"2024/09/28/大模型使用初探/","link":"","permalink":"https://sean10.github.io/2024/09/28/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E4%BD%BF%E7%94%A8%E5%88%9D%E6%8E%A2/","excerpt":"","text":"最近除了chat类以外, 尝试性折腾了几个大模型的工具, 大概有了一些个人使用场景下的认识, 简单抛砖引玉一下. 目前主要用的, chat类, 主要利用的是其结合搜索引擎 一个常用的是 腾讯的元宝. 主要原因是这些kimi等串联了搜索引擎的gpt应用里, 腾讯这个对接了公众号, 一些高质量的文章比较多. 也有人有同样看法. 有三类内容，近乎是微信公众号独占的： ❶许多券商研究报告，通过公众号免费分享； ❷ 类似《中国基金报》等官方微信号，往往会免费放出自家的核心内容，甚至还有微信小编会进一步整合一些内容。 ❸ 各类基金公司发布的投教类文章，其中也不乏深度文章。 知识库收集 目前来看, 一个关键点在于知识库信息的收集. 完全依赖搜索引擎在现在不太可靠了. 比如reddit/知乎不再应对搜索引擎的爬虫, 打包售卖数据内容. 即, 数据已经开始作为赢利点使用了. 其次, 诸多网站均关闭了非登录用户的访问权限, 比如知乎,github, 均需要个人注册的token方可查询到内容. 目前一个个人想法, 依托于rss订阅(目前主要是rsshub自定义网页抓取, 可能后续AI加持的follow), 除了订阅信息流外, 均需要具有持久化保存到知识库中能力. 这样, 避免像以前订阅的滴滴云博客等直接不再维护 导致的信息流丢失的情况. zotero支持feed订阅指定网站信息. 但是保存内容依旧需要人工.atom本身存储为markdown格式没啥问题 此时zotero中就能拥有完整内容了. 最好中间的workflow能经过一次AI处理, 输出一个订阅的总结.(这个程序可以接受单独部署, 然后通过邮件形式发送之类的) 实战 基于东方财富/公司财报/IDC分析等材料, 使大模型知识库提炼信息, 给出总结. 目前主要尝试过了dify/ragflow/auto-rag, 这几个知识库+低代码串联应用. 全文搜索能力还行. 但是响应速度, 可能是我的设备","categories":[{"name":"专业","slug":"pro","permalink":"https://sean10.github.io/categories/pro/"}],"tags":[{"name":"大模型","slug":"大模型","permalink":"https://sean10.github.io/tags/%E5%A4%A7%E6%A8%A1%E5%9E%8B/"},{"name":"AI","slug":"AI","permalink":"https://sean10.github.io/tags/AI/"}]},{"title":"开源分支如何与上游维持协作初探","slug":"开源分支如何与上游维持协作初探","date":"2024-03-10T06:26:12.000Z","updated":"2024-03-11T03:58:02.486Z","comments":true,"path":"2024/03/10/开源分支如何与上游维持协作初探/","link":"","permalink":"https://sean10.github.io/2024/03/10/%E5%BC%80%E6%BA%90%E5%88%86%E6%94%AF%E5%A6%82%E4%BD%95%E4%B8%8E%E4%B8%8A%E6%B8%B8%E7%BB%B4%E6%8C%81%E5%8D%8F%E4%BD%9C%E5%88%9D%E6%8E%A2/","excerpt":"","text":"上游做出了破坏性变更 上游出现了一个尚未修复的 BUG 上游缺乏本项目需要的功能特性 更新 沟通 贡献 思路 目前主要推荐的方案还是将自己二次开发的代码, 这部分因为是比较熟悉的. 进行重构, 尽可能让他对上游相关文件的修改小, 然后拆分成patch形式, 这里的一个点是由于我们不太可能合并到上游, 因此后续对上游的更新是必然要合入的. 这里有一个最大的冲突, 从维护成本角度, 合入上游最低. 只需要处理一次冲突. 因此我们的方案里, 除了核心代码的部分, 其实缺陷部分, 可能是推荐向上游合入的. 如何合入更新 此时就有两种选择 1. 我们作为patch, 使用高版本社区合入时, 处理我们的patch的冲突进行合入. 2. 社区的更新作为patch, 我们手动合入我们的. 这块的比较其实还是显而易见的,社区的更新人员远不止10多人, 每历经一批小版本提交的commit 远比我们多. 而且对commit的理解程度, 显然是维护人员更高. 我们去理解并合入社区的修改的工作量相当巨大. 反而还不如仅维护我们自己修改的patch部分. 社区其他人也是这么思考的, 我们作为下游, fork的人员, 开发人力是没有上游多的. 下一个问题, 我们的patch应该如何管理? 类似centos/openEuler下游社区那种, 创建单独的patch文件, 和社区版本的release版本压缩包放一起维护 那这个patch的生成是手动吗? 是否有办法批量生成patch? 从而减少维护成本? [没办法, 有冲突, 不存在批量] svn应该是可以基于commit拆分patch. 但是svn的commit提交是无法覆盖的, 那么我们做重构的动作, 也就没办法变成基于一个稳定的设备版本拉出的多条commit操作了. 要做这个动作, 就必须是基于git完全完成重构之后, 才能往svn合入了. 然后此时拉出patch. 而这个patch, 后续会在每次更新版本时, 需要重新处理一次. 那这样的话, 看着好像确实没必要单独维护一个svn来放源码了? 因为只是为了生成patch, 完全可以本地基于release版本初始化, 然后手动合入patch, 并修改. 修改后本地commit导出新的patch. 那重构的过程, 是否有必要初始化git? svn是否有帮助? (svn没有帮助, git merge有帮助) 重构的过程, 其实也可以svn. 只需要选择指定2个版本之间输出patch即可. 且最终这个分支就停止迭代了其实. 所以这个源码分支, 是可以类似git的branch那样, 持久保留的. 就是确实没有社区那种rebase的git log那么干净 如果需要, 倒也可以除了开发分支, 拉出一个重构完成后的干净分支. 这个比较推荐, 作为最终归档. 待确认效果: git merge具有比patch更强的处理冲突能力, 对于行定位错误, git merge的算法一定程度上可以处理成功. 因此, 我们在处理冲突时, 是需要有一个具有我们自己的修改的git分支的. 具体差异参考下文 修改开源软件以后仍保持更新同步_51CTO博客_软件源更新失败 (关键, 值得专项进行讨论设计)其中最重要的部分就是重构的解耦性了. 决定了后续每次冲突处理的共性基本代价. (社区重构引发的那种就没办法了), 其实和开源合规性的关联也比较大. 拆出独立库加载, 也刚好符合了LGPL约束. 测试先行? TODO: 找一条这个思路重构的? PR拆解成小PR的 RWL缓存实现 原始PR Sharded BlueStore - 3 - resharding tool by aclamk · Pull Request #29087 · ceph/ceph 拆解小PR rbd/cache: Replicated Write Log core codes part 1 by lixiaoy1 · Pull Request #31279 · ceph/ceph rbd/cache: Replicated Write Log core codes part 2 by yison · Pull Request #31963 · ceph/ceph backport的脚本做了些什么? 描述了backport所需遵守的规则 使用github token和trakcer.ceph.com token指定源PR和目标合入的里程碑分支版本, 自动化创建关联tracker issue单和PR 自动根据需要backport的PR拉出对应的backport用分支并开发cherry-pick 合入PR中的commit, 直到第一条冲突报错, 处理后继续调用会继续自动合入. ceph/SubmittingPatches-backports.rst 在 main ·ceph/ceph 我们似乎没有一个关联系统, 类似github的PR, 发起backport的PR, 关注进展. 对于考虑合入的点, 要保持和上游的沟通(话语权, 方案是否被上游接受挺考究上游社区对你的信任度) 开源产品的维护思路? 一般社区流程是, 基线分支 轻量开发分支(轻量级的, 短时存在, 需要临时处理的冲突一般较少) 长期特性开发分支 独立迭代, 分支内部评审合并轻量开发分支(这里的轻量开发分支指代的是个人branch, 因为一般有合并的权限管理) 定期合并上游的变更 稳定后合入基线分支 发布分支(长期, 后续只cherry-pick基线分支的一些关键必须得修改) ### ceph 像ceph, 基线开发, 然后到时间拉出分支, 后续如果有要合入的功能或缺陷修复, 通过backport进行合入, 此时负责人对代码进行微量重构. 相比我们的更新基础版本后需要做冲突处理, 他们是在提交时就进行了. 一般ceph在拉出新分支时, 一般这个版本要使用的功能应该 TODO: 看看squid分支上, 和master分支, 一些特性究竟谁先谁后? crimson: update seastar submodule to fix prometheus build error by athanatos · Pull Request #55878 · ceph/ceph squid: crimson: update seastar submodule to fix prometheus build error by idryomov · Pull Request #55907 · ceph/ceph 参考这两条, 从id上就很明显了, squid分支的提交是backport的 flink TiFlash Merge TiKV 6.0 into Proxy by CalvinNeo · Pull Request #55 · pingcap/tidb-engine-ext\u0000 android kernel trunk-&gt;LTS stage暂存进行测试-&gt;LTS分支 Linux 稳定内核版本合并 | Android 开源项目 | Android Open Source Project 其他公司的考量 企业与开源软件：「上游优先」，与善良无关 | 爱范儿 上游优先可以显著降低自己的维护成本, 技术债, 因此对于非关键特性, 合入上游对于降低自己将来的维护成本, 以及借助社区的能力, 非常关键. 生产力供应不足的社区创造的 Fork 则会在短暂的喧闹后自然地被遗忘，其收益远远不如采用 Upstream First 战略。[^6] 回归上游优先的例子:著名的商业案例有Google之于Android内核分支、AWS终究还是拥抱KVM，独立维护XEN太吃力 把开源项目新的 feature 更新到已经魔改过的自用版本上的最佳姿势是什么？ - V2EX 【综合】上游优先地开发-华为开发者论坛 | 华为开发者联盟 Git 分支管理与版本发布 | 夜天之书 开源不是商业模式 | 夜天之书 经验分享: 上游优先的故事 | 开源小镇 2022-25: 开源当以上游优先 我们如何消除两个开源项目之间长达 4 年的分叉-PingCAP | 平凯星辰","categories":[{"name":"专业","slug":"pro","permalink":"https://sean10.github.io/categories/pro/"}],"tags":[{"name":"开源","slug":"开源","permalink":"https://sean10.github.io/tags/%E5%BC%80%E6%BA%90/"}]},{"title":"fio之iolog回放能力初探","slug":"fio之iolog初探","date":"2023-06-23T15:38:24.000Z","updated":"2023-09-06T07:14:55.519Z","comments":true,"path":"2023/06/23/fio之iolog初探/","link":"","permalink":"https://sean10.github.io/2023/06/23/fio%E4%B9%8Biolog%E5%88%9D%E6%8E%A2/","excerpt":"","text":"背景 本文主要是针对压测工具fio的回放能力进行分析, 最终找到基于iolog来让fio产生用户指定的压力, 比如构造不同时刻不同的客户端iops压力, 亦或是产生存在显著数据命中热点的压力, 可用在诸如异常构造等问题上. 可以基于该iolog原理, 编写各自模型的iolog生成器 来满足 定制化需求. replay的iolog解读 有2种可供回放的格式 blkparse的bin文件, 支持的比较多 纯文本的iolog格式, 常用v2和v3 正常使用bin文件的方式 采集 12blktrace /dev/sdb1 blkparse sdb1 -d dd.bin &gt;/dev/null replay io 1234fio --direct=1 --read_iolog=&quot;dd.bin&quot; --replay_redirect=/dev/sdc1 --name=replay --replay_no_stall=1 --numjobs=1 --ioengine=libaio --iodepth=32fio --read_iolog=../bb.bin --filename=fio-rand-read --name=a iolog使用方式 fio Trace file format rbd引擎生成的iolog是v2协议 文件头指定fio version 2 iolog 然后声明job对应的action 1filename action add open close 1filename action offset length action wait read write sync datasync trim 样例如下 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849fio version 2 iologrbd_13.0.0 addrbd_13.0.0 openrbd_13.0.0 write 893865984 4096rbd_13.0.0 write 9905799168 4096rbd_13.0.0 write 6045495296 4096rbd_13.0.0 write 5778386944 4096rbd_13.0.0 write 9706029056 4096rbd_13.0.0 write 1973067776 4096rbd_13.0.0 write 3528716288 4096rbd_13.0.0 write 6849687552 4096rbd_13.0.0 write 2277048320 4096rbd_13.0.0 write 7225700352 4096rbd_13.0.0 write 5898452992 4096rbd_13.0.0 write 5612314624 4096rbd_13.0.0 write 10423967744 4096rbd_13.0.0 write 8727756800 4096rbd_13.0.0 write 5164285952 4096rbd_13.0.0 write 4583624704 4096rbd_13.0.0 write 4850122752 4096rbd_13.0.0 write 86384640 4096rbd_13.0.0 write 6490755072 4096rbd_13.0.0 write 7782293504 4096rbd_13.0.0 write 122646528 4096rbd_13.0.0 write 8404697088 4096rbd_13.0.0 write 1540767744 4096rbd_13.0.0 write 206385152 4096rbd_13.0.0 write 9246814208 4096rbd_13.0.0 write 2709151744 4096rbd_13.0.0 write 7710785536 4096rbd_13.0.0 write 2957721600 4096rbd_13.0.0 write 7532285952 4096rbd_13.0.0 write 52547584 4096rbd_13.0.0 write 4910313472 4096rbd_13.0.0 write 4400508928 4096rbd_13.0.0 write 1650491392 4096rbd_13.0.0 write 2253017088 4096rbd_13.0.0 write 8878170112 4096rbd_13.0.0 write 7537848320 4096rbd_13.0.0 write 9147822080 4096rbd_13.0.0 write 4819779584 4096rbd_13.0.0 write 907501568 4096rbd_13.0.0 write 3035762688 4096rbd_13.0.0 write 7090388992 4096rbd_13.0.0 write 5126242304 4096rbd_13.0.0 write 6447304704 4096rbd_13.0.0 write 6967037952 4096rbd_13.0.0 write 4684316672 4096rbd_13.0.0 write 4559695872 4096 v3格式在2的基础上增加第一列时间戳, 可达到指定每秒的IOPS的效果, 精准回放. 1100 rbd_13.0.0 write 6447304704 4096 以上代表在fio进程启动100纳秒时, 产生一个4K写 iolog的2类格式, fio如何识别? iolog基于文件头magic解析2类格式, 识别blktrace还是iolog格式 较直观 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768# iolog.cbool init_iolog(struct thread_data *td)&#123; bool ret; if (td-&gt;o.read_iolog_file) &#123; int need_swap; char * fname = get_name_by_idx(td-&gt;o.read_iolog_file, td-&gt;subjob_number); /* * Check if it&#x27;s a blktrace file and load that if possible. * Otherwise assume it&#x27;s a normal log file and load that. */ if (is_blktrace(fname, &amp;need_swap)) &#123; td-&gt;io_log_blktrace = 1; ret = init_blktrace_read(td, fname, need_swap); &#125; else &#123; td-&gt;io_log_blktrace = 0; ret = init_iolog_read(td, fname); &#125; free(fname);...&#125;...# blktrace.c/* * Check if this is a blktrace binary data file. We read a single trace * into memory and check for the magic signature. */bool is_blktrace(const char *filename, int *need_swap)&#123; struct blk_io_trace t; int fd, ret; fd = open(filename, O_RDONLY); if (fd &lt; 0) return false; ret = read(fd, &amp;t, sizeof(t)); close(fd); if (ret &lt; 0) &#123; perror(&quot;read blktrace&quot;); return false; &#125; else if (ret != sizeof(t)) &#123; log_err(&quot;fio: short read on blktrace file\\n&quot;); return false; &#125; if ((t.magic &amp; 0xffffff00) == BLK_IO_TRACE_MAGIC) &#123; *need_swap = 0; return true; &#125; /* * Maybe it needs to be endian swapped... */ t.magic = fio_swap32(t.magic); if ((t.magic &amp; 0xffffff00) == BLK_IO_TRACE_MAGIC) &#123; *need_swap = 1; return true; &#125; return false;&#125; 开源的iolog: 存储相关 各大评测规范(如SNIA)的测试集模型 SNIA - Storage Networking Industry Association: IOTTA Repository Home 从这里可以下载到对应的iolog.bin的replay文件. iolog中与ceph rbd关联 iolog中action对应的rbd接口 分别对应哪些rbd接口呢? add 无 open rbd_open close 没用, 只是设置个标签 当关闭引擎的时候触发fio_rbd_cleanup, 再调用底层shutdown action wait fio iolog内自己实现 read rbd_aio_read write rbd_aio_write sync rbd_aio_flush datasync 无 trim rbd_aio_discard 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748static int ipo_special(struct thread_data *td, struct io_piece *ipo)&#123; struct fio_file *f; int ret; /* * Not a special ipo */ if (ipo-&gt;ddir != DDIR_INVAL) return 0; f = td-&gt;files[ipo-&gt;fileno]; if (ipo-&gt;delay) iolog_delay(td, ipo-&gt;delay); if (fio_fill_issue_time(td)) fio_gettime(&amp;td-&gt;last_issue, NULL); switch (ipo-&gt;file_action) &#123; case FIO_LOG_OPEN_FILE: if (td-&gt;o.replay_redirect &amp;&amp; fio_file_open(f)) &#123; dprint(FD_FILE, &quot;iolog: ignoring re-open of file %s\\n&quot;, f-&gt;file_name); break; &#125; ret = td_io_open_file(td, f); if (!ret) break; td_verror(td, ret, &quot;iolog open file&quot;); return -1; case FIO_LOG_CLOSE_FILE: td_io_close_file(td, f); break; case FIO_LOG_UNLINK_FILE: td_io_unlink_file(td, f); break; case FIO_LOG_ADD_FILE: /* * Nothing to do */ break; default: log_err(&quot;fio: bad file action %d\\n&quot;, ipo-&gt;file_action); break; &#125; return 1;&#125; 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263static enum fio_q_status fio_rbd_queue(struct thread_data *td, struct io_u *io_u)&#123; struct rbd_data *rbd = td-&gt;io_ops_data; struct fio_rbd_iou *fri = io_u-&gt;engine_data; int r = -1; fio_ro_check(td, io_u); fri-&gt;io_seen = 0; fri-&gt;io_complete = 0; r = rbd_aio_create_completion(fri, _fio_rbd_finish_aiocb, &amp;fri-&gt;completion); if (r &lt; 0) &#123; log_err(&quot;rbd_aio_create_completion failed.\\n&quot;); goto failed; &#125; if (io_u-&gt;ddir == DDIR_WRITE) &#123; r = rbd_aio_write(rbd-&gt;image, io_u-&gt;offset, io_u-&gt;xfer_buflen, io_u-&gt;xfer_buf, fri-&gt;completion); if (r &lt; 0) &#123; log_err(&quot;rbd_aio_write failed.\\n&quot;); goto failed_comp; &#125; &#125; else if (io_u-&gt;ddir == DDIR_READ) &#123; r = rbd_aio_read(rbd-&gt;image, io_u-&gt;offset, io_u-&gt;xfer_buflen, io_u-&gt;xfer_buf, fri-&gt;completion); if (r &lt; 0) &#123; log_err(&quot;rbd_aio_read failed.\\n&quot;); goto failed_comp; &#125; &#125; else if (io_u-&gt;ddir == DDIR_TRIM) &#123; r = rbd_aio_discard(rbd-&gt;image, io_u-&gt;offset, io_u-&gt;xfer_buflen, fri-&gt;completion); if (r &lt; 0) &#123; log_err(&quot;rbd_aio_discard failed.\\n&quot;); goto failed_comp; &#125; &#125; else if (io_u-&gt;ddir == DDIR_SYNC) &#123; r = rbd_aio_flush(rbd-&gt;image, fri-&gt;completion); if (r &lt; 0) &#123; log_err(&quot;rbd_flush failed.\\n&quot;); goto failed_comp; &#125; &#125; else &#123; dprint(FD_IO, &quot;%s: Warning: unhandled ddir: %d\\n&quot;, __func__, io_u-&gt;ddir); r = -EINVAL; goto failed_comp; &#125; return FIO_Q_QUEUED;failed_comp: rbd_aio_release(fri-&gt;completion);failed: io_u-&gt;error = -r; td_verror(td, io_u-&gt;error, &quot;xfer&quot;); return FIO_Q_COMPLETED;&#125; 采用librbd用户态接口访问时, 如何采集回放? rbd map映射出来, 读取接口 lttng用户态采集 这里方案2社区有样例 ### lttng采集 RBD Replay — Ceph Documentation Capture the trace. Make sure to capture pthread_id context: 打开下述debug开关 123rbd_tracingosd_tracingrados_tracing 123456789101112131415lttng-sessiond --daemonizemkdir -p traceslttng create -o traces librbdlttng enable-event -u &#x27;librbd:*&#x27;lttng add-context -u -t pthread_idlttng start# run RBD workload herelttng stop# Process the trace with rbd-replay-prep:rbd-replay-prep traces/ust/uid/*/* replay.bin# Replay the trace with rbd-replay. Use read-only until you know it’s doing what you want:rbd-replay --read-only replay.bin 这里的rbd-replay代码基本上就是单独解析的lttng采集到的埋点格式了 FAQ TODO:为什么我blkparse得到的bin文件是前八位是7407 6561, 而不是那个代码中的0xffffff00呢 linux - How to make FIO replay a trace with multiple thread - Stack Overflow fio不支持对多线程io回放. 只能是用merge-blktrace-file合并后再进行处理. 目前初步实验来看, 采集或者生成多个job的时候, 最好让不同job的write_log 文件独立, 否则可能存在因同时追加写入冲突, 行内的格式出现错误, 导致执行时报解析格式错误. 然后得到独立的iolog文件后, 再使用fio --read_iolog=\"&lt;file1&gt;:&lt;file2&gt;\" --merge_blktrace_file=\"&lt;output_file&gt;\"来进行多个job文件的合并 然后就可以正常使用1个iolog文件使用read_log选项对多个job进行测试了.","categories":[{"name":"专业","slug":"pro","permalink":"https://sean10.github.io/categories/pro/"}],"tags":[{"name":"ceph","slug":"ceph","permalink":"https://sean10.github.io/tags/ceph/"},{"name":"fio","slug":"fio","permalink":"https://sean10.github.io/tags/fio/"}]},{"title":"分布式存储业务上的IOPS高低初理解","slug":"分布式存储业务上的IOPS高低初理解","date":"2023-06-19T14:07:10.000Z","updated":"2023-06-19T15:17:34.668Z","comments":true,"path":"2023/06/19/分布式存储业务上的IOPS高低初理解/","link":"","permalink":"https://sean10.github.io/2023/06/19/%E5%88%86%E5%B8%83%E5%BC%8F%E5%AD%98%E5%82%A8%E4%B8%9A%E5%8A%A1%E4%B8%8A%E7%9A%84IOPS%E9%AB%98%E4%BD%8E%E5%88%9D%E7%90%86%E8%A7%A3/","excerpt":"","text":"背景 目前也算是在分布式存储领域折腾了有一些时间了, 虽然还是比较入门的程度. 偶然又看到在讨论分布式存储与 集中式存储 应用场景的文档, 回想起来, 做个草草的初步思考. 性能评估要注意延时 最早的时候, 我给领导汇报测试数据时, 总是拿着跑bench时只管把depth往上加的最终数据汇报, 只要能看到IOPS上涨, 就继续加. 当时理解为理解为集群的性能是以depth跑满, 比如把集群的cpu或者硬盘的util用尽, 出现了硬件或者源码锁的逻辑瓶颈为止, 以该结论来作为集群水平汇报. 看上去数据确实挺美好, 看着至少也有业界的水准了的样子. 但是这里其实当时忽略了延时的因素, 延时应该如何理解呢? 这里的理解方式, 就是p99,p90等划分一个比例的延时, 要低于指定值, 比如5ms内, 这个情况下的IOPS才是一定程度上用户有机会发挥出来的. 为什么我说是有机会呢? 因为这里还存在一个问题, depth是否真的用户能跑出来? 诸如数据库或者自己开发的代码, 队列深度以及压力, 一般情况下能达到8/16已经算是比较可以的了. 所以实际上, 比如以ceph为例, 假设我现在3节点各3 ssd, rbd跑出了2W IOPS性能, 还需要细分, 延时是多少, 如果是3ms, 则代表我单队列深度时, IOPS只有333, 8队列深度时, 此时底层物理盘利用率尚未达到瓶颈, 则可以达到2664 IOPS. 而2664 IOPS 一般是无法满足数据库类业务的, 比如说某个现场的一组客户需求, 需要平均5000 IOPS, boost 15000 IOPS , 该数据是在psync 16队列深度下跑出的, 即基本可以换算为需要937.5 IOPS, 即1.06ms. 这个量级基本上是SATA固态的裸盘性能了. 从需求反推, 可以得知这个延时数量级, 只有当我们使用集中式存储的技术(诸如RAID, 且不能是EC类), 或是采用了nvme这类物理延时十位数微秒级别的硬件, 分布式存储才有希望可以满足这类用户的需求. 所以, 换句话说. 我们评估一个集群的实际可用性能时, 往往需要考虑用户的实际使用场景, 如果技术上可以做到, 肯定是最好像裸盘的硬件规格一样, 报出的延时和IOPS, 基本上是队列深度2-8就能跑出的水平, 从而完全可以保障任意用户都能够取得满足需求的性能. 以腾讯云的数据为例, 我的一块100G的云硬盘, 1.3ms, 6000 IOPS 队列深度 IOPS 延时(ms) 延时(p999) 延时(p99) 延时(p90) 1 713 1.3 146 81 26 2 1495 1.3 146 75 23 4 2828 1.4 146 77 25 8 6042 1.3 130 73 24 云硬盘 云硬盘类型-产品简介-文档中心-腾讯云 上面这组数据可以得到的一个推论是, 底层存储能够给予QoS稳定提供1.3ms延时, 并且可以支持极大的队列深度. 分布式存储的可扩展性体现在哪呢 主要就体现在, 提供了稳定的1.3ms延时后, 横向继续加设备,能够不停给这个集群扩充, 让往这个集群申请资源的业务, 能够几近无上限的扩展. 要注意多卷并发测试时单卷的性能和延时才是集群稳定的性能和延时 在实际使用luminous, 尚未引入QoS的版本的ceph中会发现, 一个集群只跑单卷时, 16队列比如能提供4000 IOPS, 当2-&gt;4-&gt;8-&gt;16个卷并发时, 平均单卷的性能降到3000, 直到最终可能就1000不到. TODO: 按照我目前的理解, 这个问题的关键点可能主要是集中在锁抢占或者说op之间排队出队的顺序之类的问题? QoS可能可以缓解这个问题. 亦或是rocksdb的一些解决长尾延时问题的技术也有所帮助? 这部分暂未投入了解了.","categories":[{"name":"专业","slug":"pro","permalink":"https://sean10.github.io/categories/pro/"}],"tags":[{"name":"ceph","slug":"ceph","permalink":"https://sean10.github.io/tags/ceph/"}]},{"title":"ceph之快照的应用一致性初探","slug":"ceph之快照的应用一致性初探","date":"2023-06-11T15:52:15.000Z","updated":"2023-06-11T16:30:38.933Z","comments":true,"path":"2023/06/11/ceph之快照的应用一致性初探/","link":"","permalink":"https://sean10.github.io/2023/06/11/ceph%E4%B9%8B%E5%BF%AB%E7%85%A7%E7%9A%84%E5%BA%94%E7%94%A8%E4%B8%80%E8%87%B4%E6%80%A7%E5%88%9D%E6%8E%A2/","excerpt":"","text":"以下讨论都是基于存储系统上的, 主要描述的为对块存储进行快照. 根据目前理解, 应用一致性可以粗分为 基于时间点的快照 没有明确的一致性等级支持 支持崩溃一致性的快照(Crash-consistent backup) 应用一致性快照. (Application-consistent backup) (包含内存中pending IO) 包含内存(pending IO)的快照 (存在大量停机时间) mirror的同步技术的, 包含pending IO 较通用的实现方案 (存在少量停机时间, 主要取决于内存缓了多少?) 基于时间点的快照(不一定一致/不一致) 很简单粗暴, 不管是否有 pending IO, 直接保存当前的硬盘状态, 做COW/ROW链接, 完成快照. 支持崩溃一致性的快照 采用崩溃一致性的备份来恢复云服务器，在数据恢复后，由于没有保证数据库事务的一致性，通常需要依赖数据自身的保护机制做自动的日志回滚，数据才能正常启动，数据是恢复到离备份时间点最近的一个一致性状态，相比应用一致性备份的恢复，RPO（Recovery Point Objective，指的是最多可能丢失的数据的时长）会更大，RTO（Recovery Time Objective 指的是从灾难发生到整个系统恢复正常所需要的最大时长）也更长。 基本上表达的一种实现方式可能就是会建多个快照, 然后会识别多个快照内业务的可用性, 无法通过数据库/文件系统修复工具回滚继续提供服务, 则去触发下一个快照. 直到找到一个能用的快照? ## 应用一致性快照. (Application-consistent backup) 包含内存(pending IO)的快照 以qemu和qcow2为例, qcow2支持内存快照, 但是是依赖于虚拟机先由qemu控制进入paused状态的. 这部分一般由于内存一般划的比较大, 内存完整写入, 一般比较慢. 停机时间特别长, 一般都是不太能接受的. 虽然应用一致性确实保障了. mirror的同步技术的快照 TODO: 这个暂时还支持猜想, 还没去细找是否有基于这类实现的. 诸如drbd/rbd mirror等, 本身除了这个业务本身, 还提供了其他设备进行备份, 其实应该算得上是备份技术了. 它确实能保障应用一致性, 但是其实是双活了. 针对快照时间点, 是在对端做flush, 然后创建快照了. 这个快照点, 基本上可以是在mirror对端按事件进行冻结, 然后flush, 然后创建快照了. 对本端无影响. 应用一致性快照 按照目前的认知, 这个可能是目前用的比较多的方案. 主要就是在创建快照前和后分别提供了一个hook接口. 针对文件系统类具有一定的通用约束的, 可以直接默认使用fsfreeze 类的偏通用的接口完成静默, 然后再进行对应的pending IO的持久化. 非文件系统类业务, 则需要上层业务自己去触发了, 就是根据对应的数据库开发对应的持久化方式, 完成快照的一致性保障. 如果是明确指定类型的数据库, 可能还能直接配合对应的方案做自动化检测和识别去完成对应数据库内的持久化快照, 无需用户自己实现. 不过当客户机上是windows 时, 则直接可以通过VSS来实现应用一致性快照. 无需开发介入了. 看到阿里云的文档里也写的很清楚, 如下表格. 类型 说明 实现方式 应用一致性快照 应用一致性快照在快照创建时刻备份内存数据及正在进行中的数据库事务，保证应用系统数据和数据库事务的一致性。通过应用一致性快照，没有数据的损坏及丢失，避免数据库启动时日志回滚，确保应用处于一致性的启动状态。应用一致性快照以标签APPConsistent:True标识。 根据操作系统类型，实现方式如下：Windows：通过卷影复制服务VSS（Volume Shadow Copy Service）实现。Linux：通过执行自定义Shell脚本（需要您根据应用自行编写脚本）实现。应用一致性的效果，由您自己编写的脚本负责保证。 文件系统一致性快照 如果开启应用一致性功能，但不满足相关条件，系统将会为您创建文件系统一致性快照。文件系统一致性确保在快照创建时刻同步文件系统内存和磁盘信息，冻结文件系统写操作，使得文件系统处于一致性的状态。通过文件系统一致性快照，可以避免操作系统在重启后进行chkdsk或fsck等磁盘检查修复操作。文件系统一致性快照以标签FsConsistent:True标识。 根据操作系统类型，实现方式如下：Windows：如果无Windows操作系统上特定应用的VSS Writer参与时，默认创建的为文件系统一致性。Linux：如果无对应的应用脚本，默认创建的为文件系统一致性。 看到阿里云的描述, 基本就知道了, 也是通过由用户自身的shell脚本内的行为来完成在创建快照前内存缓存持久化到硬盘, 确保硬盘此刻是完整的. 文件系统侧则通过默认的fsfreeze等通用方案来进行持久化. rbd的用例 If the volume contains a file system, the file system should be in an internally consistent state before a snapshot is taken. Snapshots taken without write quiescing could need an fsck pass before they are mounted again. To quiesce I/O you can use fsfreeze command. See the fsfreeze(8) man page for more details. Snapshots — Ceph Documentation rbd的文档里已经提供了fsfreeze的方案. ceph rbd内的实现 ceph在16版本librbd提供了quiesce能力, 主要描述的就是在创建快照前和后分别提供了一个hook接口. 然后暴露给上层用户, 可能就比较完善了. rbd device --device-type nbd map --quiesce --quiesce-hook ${QUIESCE_HOOK} 看了下16版本有提供rbd quiesce 逻辑, 针对snap create时可以主动block rbd块的io, 并提供静默io前后的hook. 没找着有写测试/使用样例, 不过rbd-nbd那边有写用例, 可以提供脚本做前置/后置检查. PR: librbd: API for quiesce callbacks · idryomov/ceph@269f4d2 commit: librbd: API for quiesce callbacks · idryomov/ceph@269f4d2 方案比较 参考What is Application Consistent Backup and How to Achieve It 可知几个方案的比较结果 Operation timebased (inconsistent) Crash-consistent Application-consistent Consistent point in time backup of files No Yes Yes Application consistency No yes Yes Aware of in memory and pending I/O No no Yes Requires no special steps for application data restore No yes Yes Reference 通过Go SDK创建应用一致性快照 云备份技术解析 （三）应用一致性备份-云社区-华为云 What is Application Consistent Backup and How to Achieve It","categories":[{"name":"专业","slug":"pro","permalink":"https://sean10.github.io/categories/pro/"}],"tags":[{"name":"ceph","slug":"ceph","permalink":"https://sean10.github.io/tags/ceph/"},{"name":"consistency","slug":"consistency","permalink":"https://sean10.github.io/tags/consistency/"},{"name":"snapshot","slug":"snapshot","permalink":"https://sean10.github.io/tags/snapshot/"}]},{"title":"ceph之版本升级特性点Luminous_Pacific整理草稿","slug":"ceph之版本升级特性点Luminous-Pacific整理草稿","date":"2023-06-09T15:19:04.000Z","updated":"2023-06-09T15:19:24.630Z","comments":true,"path":"2023/06/09/ceph之版本升级特性点Luminous-Pacific整理草稿/","link":"","permalink":"https://sean10.github.io/2023/06/09/ceph%E4%B9%8B%E7%89%88%E6%9C%AC%E5%8D%87%E7%BA%A7%E7%89%B9%E6%80%A7%E7%82%B9Luminous-Pacific%E6%95%B4%E7%90%86%E8%8D%89%E7%A8%BF/","excerpt":"","text":"背景 主要是针对rbd-&gt;openstack相关, 所以cephfs/rgw/dashboard等其他的特性相关的几乎都跳过了. 仅整理了rbd及以下模块, 从luminous以后到pacific为止的. 性能相关 Pacific 16.2.0 RADOS Pacific introduces :ref:bluestore-rocksdb-sharding, which reduces disk space requirements. Ceph now provides QoS between client I/O and background operations via the mclock scheduler. RBD A new persistent write-back cache is available. The cache operates in a log-structured manner, providing full point-in-time consistency for the backing image. It should be particularly suitable for PMEM devices. pacific: librbd/cache/pwl: persistant cache backports by ideepika · Pull Request #43772 · ceph/ceph Octopus 15.2.15 The default value of osd_client_message_cap has been set to 256, to provide better flow control by limiting maximum number of in-flight client requests. https://hub.nuaa.cf/ceph/ceph/pull/42616 https://docs.google.com/spreadsheets/d/1dwKcxFKpAOWzDPekgojrJhfiCtPgiIf8CGGMG1rboRU/edit#gid=0 这里的实测结论居然是256比较好? 还没细看. 15.2.0 RADOS Objects can now be brought in sync during recovery by copying only the modified portion of the object, reducing tail latencies during recovery. osd: partial recovery strategy based on PGLog by mslovy · Pull Request #21722 · ceph/ceph BlueStore has received several improvements and performance updates, including improved accounting for \"omap\" (key/value) object data by pool, improved cache memory management, and a reduced allocation unit size for SSD devices. (Note that by default, the first time each OSD starts after upgrading to octopus it will trigger a conversion that may take from a few minutes to a few hours, depending on the amount of stored \"omap\" data.) Snapshot trimming metadata is now managed in a more efficient and scalable fashion. RBD Clone operations now preserve the sparseness of the underlying RBD image. librbd: clone copy-on-write operations should preserve sparseness by trociny · Pull Request #27999 · ceph/ceph Nautilus 14.2.22 This release sets bluefs_buffered_io to true by default to improve performance for metadata heavy workloads. Enabling this option has been reported to occasionally cause excessive kernel swapping under certain workloads. Currently, the most consistent performing combination is to enable bluefs_buffered_io and disable system level swap. The default value of bluestore_cache_trim_max_skip_pinned has been increased to 1000 to control memory growth due to onodes. 14.2.8 The default value of bluestore_min_alloc_size_ssd has been changed to 4K to improve performance across all workloads. &gt; https://github.com/ceph/ceph/pull/32998 &gt; common/options: Set bluestore min_alloc size to 4K by markhpc · Pull Request #30698 · ceph/ceph &gt; &gt; &gt; I'm not sure that having 4K min_alloc_size for both ssd and spinner is a good choice. From my benchmarks 4K MAS is undoubtedly beneficial in all-flash setupы only. It shows performance boost for certain small R/W scenarios and no regression for other ones &gt; When main device is rotational performance boost is observed for a minor selection of 4K R/W scenarios. But other scenarios suffer from pretty large performance degradation. &gt; &gt; See columns B &amp; C, rows 20-36 at &gt; https://docs.google.com/spreadsheets/d/1xXbheoGwgyaLBc389TFo1vUyz9LjshI83_bW8zBYWl8/edit?usp=sharing &gt; So my suggestion is to tune bluestore_min_alloc_size_ssd only &gt; 14.2.0 The NUMA node for OSD daemons can easily be monitored via the ceph osd numa-status command, and configured via the osd_numa_node config option. Bug #42411: nautilus:osd: network numa affinity not supporting subnet port - RADOS - Ceph Mimic 13.2.0 RADOS: An async recovery feature reduces the tail latency of requests when the OSDs are recovering from a recent failure. https://github.com/ceph/ceph/pull/19811 OSD preemption of scrub by conflicting requests reduces tail latency. (12版本已有, 2017年的修改) osd/PG: allow scrub preemption by liewegas · Pull Request #18971 · ceph/ceph 其他功能性 16.2.11 Trimming of PGLog dups is now controlled by the size instead of the version. This fixes the PGLog inflation issue that was happening when the on-line (in OSD) trimming got jammed after a PG split operation. Also, a new off-line mechanism has been added: ceph-objectstore-tool got trim-pg-log-dups op that targets situations where OSD is unable to boot due to those inflated dups. If that is the case, in OSD logs the “You can be hit by THE DUPS BUG” warning will be visible. Relevant tracker: https://tracker.ceph.com/issues/53729 RBD: rbd device unmap command gained --namespace option. Support for namespaces was added to RBD in Nautilus 14.2.0 and it has been possible to map and unmap images in namespaces using the image-spec syntax since then but the corresponding option available in most other commands was missing. rados namespaces can be used to provide isolation between rados clients within a pool. For example, a client could only have full permissions on a namespace specific to them. This makes using a different rados client for each tenant feasible, which is particularly useful for rbd where many different tenants are accessing their own rbd images. 即主要用途其实算是更精细的权限控制? 确保底层即便拿到其他用户的权限, 也因为namespace无法使用? 16.2.2 Cephadm now supports an ingress service type that provides load balancing and HA (via haproxy and keepalived on a virtual IP) for RGW service (see High availability service for RGW). (The experimental rgw-ha service has been removed.) 16.2.0 Official Ceph RESTful API: OpenAPI v3 compliant. Stability commitment starting from Pacific release. Versioned via HTTP Accept header (starting with v1.0). Thoroughly tested (&gt;90% coverage and per Pull Request validation). Fully documented. Security (multiple enhancements and fixes resulting from a pen testing conducted by IBM): Account lock-out after a configurable number of failed log-in attempts. Improved cookie policies to mitigate XSS/CSRF attacks. Reviewed and improved security in HTTP headers. Sensitive information reviewed and removed from logs and error messages. TLS 1.0 and 1.1 support disabled. Debug mode when enabled triggers HEALTH_WARN. CLAY CODE PLUGIN ec池, 故障修复时, 可以减少对带宽的占用. CLAY code plugin — Ceph Documentation SPECIFYING EXPECTED POOL SIZE 支持多池共用osd, 做健康检查, 感知是否使用超过该池原定使用空间上限, 会有warning信息. ceph osd pool set {pool-name} recovery_priority {value} rbd 性能监控 - Image live-migration feature has been extended to support external data sources. Images can now be instantly imported from local files, remote files served over HTTP(S) or remote S3 buckets in raw (rbd export v1) or basic qcow and qcow2 formats. Support for rbd export v2 format, advanced QCOW features and rbd export-diff snapshot differentials is expected in future releases. Initial support for client-side encryption has been added. This is based on LUKS and in future releases will allow using per-image encryption keys while maintaining snapshot and clone functionality -- so that parent image and potentially multiple clone images can be encrypted with different keys. A Windows client is now available in the form of librbd.dll and rbd-wnbd (Windows Network Block Device) daemon. It allows mapping, unmapping and manipulating images similar to rbd-nbd. librbd API now offers quiesce/unquiesce hooks, allowing for coordinated snapshot creation. A new library is available, libcephsqlite. It provides a SQLite Virtual File System (VFS) on top of RADOS. The database and journals are striped over RADOS across multiple objects for virtually unlimited scaling and throughput only limited by the SQLite client. Applications using SQLite may change to the Ceph VFS with minimal changes, usually just by specifying the alternate VFS. We expect the library to be most impactful and useful for applications that were storing state in RADOS omap, especially without striping which limits scalability. 提供了基本的数据库 重构有了预计时间? 提供了静默rbd的hook接口 rbd device --device-type nbd map --quiesce --quiesce-hook ${QUIESCE_HOOK} 看了下16版本有提供rbd quiesce 逻辑, 针对snap create时可以主动block rbd块的io, 并提供静默io前后的hook. 没找着有写测试/使用样例, 不过rbd-nbd那边有写用例, 可以提供脚本做前置/后置检查. 15.2.15 A new ceph-erasure-code-tool has been added to help manually recover an object from a damaged PG. 14.2.22 A --max &lt;n&gt; option is available with the osd ok-to-stop command to provide up to N OSDs that can be stopped together without making PGs unavailable. msgr2下的arm/x86不兼容修复 * A long-standing bug that prevented 32-bit and 64-bit client/server interoperability under msgr v2 has been fixed. In particular, mixing armv7l (armhf) and x86_64 or aarch64 servers in the same cluster now works. 14.2.5 OSD: A new OSD daemon command, 'dump_recovery_reservations', reveals the recovery locks held (in_progress) and waiting in priority queues. A health warning is now generated if the average osd heartbeat ping time exceeds a configurable threshold for any of the intervals computed. The OSD computes 1 minute, 5 minute and 15 minute intervals with average, minimum and maximum values. New configuration option mon_warn_on_slow_ping_ratio specifies a percentage of osd_heartbeat_grace to determine the threshold. A value of zero disables the warning. New configuration option mon_warn_on_slow_ping_time specified in milliseconds over-rides the computed value, causes a warning when OSD heartbeat pings take longer than the specified amount. A new admin command, ceph daemon mgr.# dump_osd_network [threshold], will list all connections with a ping time longer than the specified threshold or value determined by the config options, for the average for any of the 3 intervals. Another new admin command, ceph daemon osd.# dump_osd_network [threshold], will do the same but only including heartbeats initiated by the specified OSD Ceph will now issue health warnings if daemons have recently crashed. Ceph has been collecting crash reports since the initial Nautilus release, but the health alerts are new. To view new crashes (or all crashes, if you've just upgraded):: ceph crash ls-new To acknowledge a particular crash (or all crashes) and silence the health warning:: ceph crash archive &lt;crash-id&gt; ceph crash archive-all 14.2.3 The RGW num_rados_handles has been removed. If you were using a value of num_rados_handles greater than 1, multiply your current objecter_inflight_ops and objecter_inflight_op_bytes parameters by the old num_rados_handles to get the same throttle behavior. 13.2.7 MDS: Cache trimming is now throttled. Dropping the MDS cache via the \"ceph tell mds.&lt;foo&gt; cache drop\" command or large reductions in the cache size will no longer cause service unavailability. 13.2.0 The monitor daemon uses significantly less disk space when undergoing recovery or rebalancing operations. CephFS: Snapshots are now stable when combined with multiple MDS daemons. Openstack 的差异 对nfs的使用支持如何? Wallaby对应Mimic-Pacific rocky到2023.1后面那个版本 当前业务已升级到train版本, 局部还在N版本 nova 27.0 Zed Yoga Wallaby The Hyper-V driver can now attach Cinder RBD volumes. The minimum requirements are Ceph 16 (Pacific) and Windows Server 2016. The Hyper-V virt driver can now attach Cinder RBD volumes. Victoria New [glance]/enable_rbd_download config option was introduced. The option allows for the configuration of direct downloads of Ceph hosted glance images into the libvirt image cache via rbd when [glance]/enable_rbd_download= True and [glance]/rbd_user, [glance]/rbd_pool, [glance]/rbd_connect_timeout, [glance]/rbd_ceph_conf are correctly configured. Added params [libvirt]/rbd_destroy_volume_retries, defaulting to 12, and [libvirt]/rbd_destroy_volume_retry_interval, defaulting to 5, that Nova will use when trying to remove a volume from Ceph in a retry loop that combines these parameters together. Thus, maximum elapsing time is by default 60 seconds. Nova tries to remove a volume from Ceph in a retry loop of 10 attempts at 1 second intervals, totaling 10 seconds overall - which, due to 30 second ceph watcher timeout, might result in intermittent object removal failures on Ceph side (bug 1856845). Setting default values for [libvirt]/rbd_destroy_volume_retries to 12 and [libvirt]/rbd_destroy_volume_retry_interval to 5, now gives Ceph reasonable amount of time to complete the operation successfully. The libvirt RBD image backend module can now handle a Glance multistore environment where multiple RBD clusters are in use across a single Nova/Glance deployment, configured as independent Glance stores. In the case where an instance is booted with an image that does not exist in the RBD cluster that Nova is configured to use, Nova can ask Glance to copy the image from whatever store it is currently in to the one that represents its RBD cluster. To enable this feature, set [libvirt]/images_rbd_glance_store_name to tell Nova the Glance store name of the RBD cluster it uses. Glance multistore configuration with multiple RBD backends is now supported within Nova for libvirt RBD-backed images using [libvirt]/images_rbd_glance_store_name configuration option. ussuri Nova now has a config option called [workarounds]/never_download_image_if_on_rbd which helps to avoid pathological storage behavior with multiple ceph clusters. Currently, Nova does not support multiple ceph clusters properly, but Glance can be configured with them. If an instance is booted from an image residing in a ceph cluster other than the one Nova knows about, it will silently download it from Glance and re-upload the image to the local ceph privately for that instance. Unlike the behavior you expect when configuring Nova and Glance for ceph, Nova will continue to do this over and over for the same image when subsequent instances are booted, consuming a large amount of storage unexpectedly. The new workaround option will cause Nova to refuse to do this download/upload behavior and instead fail the instance boot. It is simply a stop-gap effort to allow unsupported deployments with multiple ceph clusters from silently consuming large amounts of disk space. train The reporting for bytes available for RBD has been enhanced to accomodate unrecommended Ceph deployments where multiple OSDs are running on a single disk. The new reporting method takes the number of configured replicas into consideration when reporting bytes available. The libvirt driver’s RBD imagebackend no longer supports setting force_raw_images to False. Setting force_raw_images = False and images_type = rbd in nova.conf will cause the nova compute service to refuse to start. To fix this, set force_raw_images = True. This change was required to fix the bug 1816686. Note that non-raw cache image files will be removed if you set force_raw_images = True and images_type = rbd now. A new [libvirt]/rbd_connect_timeout configuration option has been introduced to limit the time spent waiting when connecting to a RBD cluster via the RADOS API. This timeout currently defaults to 5 seconds. This aims to address issues reported in bug 1834048 where failures to initially connect to a RBD cluster left the nova-compute service inoperable due to constant RPC timeouts being hit. ### stein Adds support for extending RBD attached volumes using the libvirt network volume driver. ### rocky The [workarounds]/ensure_libvirt_rbd_instance_dir_cleanup configuration option has been introduced. This can be used by operators to ensure that instance directories are always removed during cleanup within the Libvirt driver while using [libvirt]/images_type = rbd. This works around known issues such as bug 1414895 when cleaning up after an evacuation and bug 1761062 when reverting from an instance resize. Operators should be aware that this workaround only applies when using the libvirt compute driver and rbd images_type as enabled by the following configuration options: [DEFAULT]/compute_driver = libvirt [libvirt]/images_type = rbd ### queens Nova now requires Ceph/librados &gt;= 11.1.0 if running under Python 3 with the RBD image backend for the libvirt driver. Requirements for Python 2 users or users using a different backend remain unchanged. QEMU 2.6.0 and Libvirt 2.2.0 allow LUKS encrypted RAW files, block devices and network devices (such as rbd) to be decrypted natively by QEMU. If qemu &gt;= 2.6.0 and libvirt &gt;= 2.2.0 are installed and the volume encryption provider is ‘luks’, the libvirt driver will use native QEMU decryption for encrypted volumes. The libvirt driver will generate a secret to hold the LUKS passphrase for unlocking the volume and the volume driver will use the secret to generate the required encryption XML for the disk. QEMU will then be able to read from and write to the encrypted disk natively, without the need of os-brick encryptors. Mitaka When RBD is used for ephemeral disks and image storage, make snapshot use Ceph directly, and update Glance with the new location. In case of failure, it will gracefully fallback to the “generic” snapshot method. This requires changing the typical permissions for the Nova Ceph user (if using authx) to allow writing to the pool where vm images are stored, and it also requires configuring Glance to provide a v2 endpoint with direct_url support enabled (there are security implications to doing this). See http://docs.ceph.com/docs/master/rbd/rbd-openstack/ for more information on configuring OpenStack with RBD. cinder unreleased Bug #1997980: RBD: Fixed failure to update rbd image features for multi-attach when features = 0. ### 2023.1 RBD driver: Sets the Ceph cluster FSID as the default value for the rbd_secret_uuid configuration option. RBD driver bug #1960206: Fixed total_capacity reported by the driver to the scheduler on Ceph clusters that have renamed the bytes_used field to stored. (e.g., Nautilus). RBD Driver bug #1957073: Fixed snapshot deletion failure when its volume doesn’t exist. ### Zed RBD driver bug #1942210: When creating a volume from a snapshot, the operation could fail due to an uncaught exception being raised during a check to see if the backend Ceph installation supported the clone v2 API. The driver now handles this situation gracefully. librbd , 12就支持了. 但是kernel要3.11才支持, 所以我们的是应该没支持的. Yoga When the Ceph backup driver is used for the backup service, restoring a backup to a volume created on a non-RBD backend fails. The cinder team has developed a fix but decided to do more thorough testing before including it in a release. When ready, the solution is expected to be backported to a future release in the Yoga series. The issue is being tracked as Bug #1895035. RBD driver: Enable Ceph V2 Clone API and Ceph Trash auto purge In light of the fix for RBD driver bug #1941815, we want to bring the following information to your attention. Using the v2 clone format for cloned volumes allows volumes with dependent images to be moved to the trash - where they remain until purged - and allow the RBD driver to postpone the deletion until the volume has no dependent images. Configuring the trash purge is recommended to avoid wasting space with these trashed volumes. Since the Ceph Octopus release, the trash can be configured to automatically purge on a defined schedule. See the rbd trash purge schedule commands in the rbd manpage. RBD driver bug #1941815: Fixed deleting volumes with snapshots/volumes in the ceph trash space. RBD driver bug #1916843: Fixed rpc timeout when backing up RBD snapshot. We no longer flatten temporary volumes and snapshots. RBD driver bug #1947518: Corrected a regression caused by the fix for Bug #1931004 that was attempting to access the glance images RBD pool with write privileges when creating a volume from an image. ### Xena Bug #1931004: Fixed use of incorrect stripe unit in RBD image clone causing volume-from-image to fail when using raw images backed by Ceph. Wallaby Added new Ceph iSCSI driver rbd_iscsi. This new driver is derived from the rbd driver and allows all the same features as the rbd driver. The only difference is that volume attachments are done via iSCSI. 已知问题 - Anomalies with encrypted volumes For the most part, users are happy with the cinder feature [Volume encryption supported by the key manager](https://docs.openstack.org/cinder/wallaby/configuration/block-storage/volume-encryption.html). There are, however, some edge cases that have revealed bugs that you and your users should be aware of. First, some background. The Block Storage API supports the creation of volumes in gibibyte (GiB) units. When a volume of a non-encrypted volume type of size _n_ is created, the volume contains _n_ GiB of usable space. When a volume of an encrypted type is requested, however, the volume contains less than _n_ GiB of usable space because the encryption metadata that must be stored within that volume in order for the volume to be usable consumes an amount of the otherwise usable space. Although the encryption metadata consumes less than 1% of the volume, suppose that a user wants to retype a volume of a non-encrypted type to an encrypted type of the same size. If the non-encrypted volume is “full”, we are in the position of trying to fit 101% of its capacity into the encrypted volume, which is not possible under the current laws of physics, and the retype should fail (see [Known Issues](https://docs.openstack.org/cinder/wallaby/configuration/block-storage/volume-encryption.html) for volume encryption in the cinder documentation). (Note that whether a volume should be considered “full”, even if it doesn’t contain exactly _n_ GiB of data for an _n_ GiB volume, can depend upon the storage backend technology used.) A similar situation can arise when a user creates a volume of an encrypted volume type from an image in Glance. If the image happens to be sized very close to the gibibyte boundary given by the requested volume size, the operation may fail if the image data plus the encryption metadata exceeds the requested volume size. So far, the behavior isn’t anomalous; it’s basically what you’d expect once you are aware that the encryption metadata must be stored in the volume and that it consumes some space. We recently became aware of the following anomalies, however, when using the current RBD driver with a Ceph storage backend. - When creating an encrypted volume from an image in Glance that was created from a non-encrypted volume uploaded as an image, or an image that just happens to be sized very close to the gibibyte boundary given by the requested volume size, the space consumed by the encryption header may not leave sufficient space for the data contained in the image. In this case, the data is silently truncated to fit within the requested volume size. - Similarly, when creating an encrypted volume from a snapshot of an encrypted volume, if the amount of data in the original volume at the time the snapshot was created is very close to the gibibyte boundary given by the volume’s size, it is possible for the data in the new volume to be silently truncated. Not to put too fine a point on it, silent truncation is worse than failure, and the Cinder team will be addressing these issues in the next release. Additionally (as if that isn’t bad enough!), we suspect that the above anomalies will also occur when using volume encryption with NFS-based storage backends, though this has not yet been reported or confirmed. RBD driver: Prior to this release, the Cinder project did not have a statement concerning what versions of Ceph are supported by Cinder. We hereby announce that: For a given OpenStack release, Cinder supports the current Ceph active stable releases plus the two prior releases. For any OpenStack release, it is expected that the versions of the Ceph client and server are in alignment. The Ceph RADOS Block Device (RBD) driver documentation has been updated to reflect this policy and explains it in more detail. Ceph/RBD volume backends will now assume exclusive cinder pools, as if they had rbd_exclusive_cinder_pool = true in their configuration. This helps deployments with a large number of volumes and prevent issues on deployments with a growing number of volumes at the small cost of a slightly less accurate stats being reported to the scheduler. RBD driver bug #1907964: Add support for fast-diff on backup images stored in Ceph. Provided fast-diff is supported by the backend it will automatically be enabled and used. With fast-diff enabled, the generation of diffs between images and snapshots as well as determining the actual data usage of a snapshot is speed up significantly. Bug 1913449: Fix RBD driver _update_volume_stats() failing when using Ceph Pacific python rados libraries. This failed because we were passing a str instead of bytes to cluster.mon_command() Ceph/RBD: Fix cinder taking a long time to start for Ceph/RBD backends. (Related-Bug #1704106) Ceph/RBD: Fix Cinder becoming non-responsive and stats gathering taking longer that its period. (Related-Bug #1704106) Supported Ceph versions The Cinder project wishes to clarify its policy concerning what versions of Ceph are supported by Cinder. For a given OpenStack release, Cinder supports the current Ceph active stable releases plus the two prior releases. For any OpenStack release, it is expected that the versions of the Ceph client and server are in alignment. The Ceph RADOS Block Device (RBD) driver documentation has been updated to reflect this policy and explains it in more detail. RBD driver Bug #1898918: Fix thread block caused by the flatten operation during cloning a volume. Now the flatten operation is executed in a different thread. RBD driver bug #1901241: Fixed an issue where decreasing the rbd_max_clone_depth configuration option would prevent volumes that had already exceeded that depth from being cloned. Victoria RBD driver: the rbd_keyring_conf configuration option, which was deprecated in the Ussuri release, has been removed. If it is present in a configuration file, its value will silently be ignored. For more information, see OSSN-0085: Cinder configuration option can leak secret key from Ceph backend. Bug #1828386: Fix the bug that a volume retyped from another volume type to a replicated or multiattach type cannot have replication or multiattach enabled in rbd driver. Bug #1873738: RBD Driver: Added cleanup for residue destination file if the copy image to encrypted volume operation fails. ### Ussuri RBD driver: support added for reverting a volume to the most recent snapshot taken. Please be aware of the following known issues with this operation and the Ceph storage backend: Rolling back a volume to a snapshot overwrites the current volume with the data from the snapshot, and the time it takes to complete this operation increases with the size of the volume. It is faster to create a new volume from a snapshot. You may wish to recommend this option to your users whose use cases do not strictly require revert-to-snapshot. The efficiency of revert-to-snapshot is also dependent upon the Ceph storage backend in use, namely, whether or not BlueStore is being used in your Ceph installation. Please consult the Ceph documentation for details. Fix volume migration fails in the same ceph RBD pool. Bug 1871524. ### Train Catch argument exceptions when configuring multiattach for rbd volumes. This allows multiattach images with flags already set to continue instead of raising an exception and failing. Rbd replication secondary device could set different user and keyring with primary cluster. Secondary secret_uuid value is configed in libvirt secret, and libvirtd using secondary secret reconnect to secondary cluster after Cinder failover host. Fixed issue where all Ceph RBD backups would be incremental after the first one. The driver now honors whether --incremental is specified or not. ### stein RBD driver has added multiattach support. It should be noted that replication and multiattach are mutually exclusive, so a single RBD volume can only be configured to support one of these features at a time. Additionally, RBD image features are not preserved which prevents a volume being retyped from multiattach to another type. This limitation is temporary and will be addressed soon. Add support for deferred deletion in the RBD volume driver. ## glance 除Newton版本全部没有cephfs/rbd/cephfs关键词日志 RedHat Enterprise Storage Red Hat Ceph Storage Life Cycle - Red Hat Customer Portal 6 应该是17版本 Chapter 3. New features Red Hat Ceph Storage 6.0 | Red Hat Customer Portal Compression on-wire with msgr2 protocol is now available librbd plugin named persistent write log cache to reduce latency With this release, the new librbd plugin named Persistent Write Log Cache (PWL) provides a persistent, fault-tolerant write-back cache targeted with SSD devices. It greatly reduces latency and also improves performance at low io_depths. This cache uses a log-ordered write-back design which maintains checkpoints internally, so that writes that get flushed back to the cluster are always crash consistent. Even if the client cache is lost entirely, the disk image is still consistent; but the data will appear to be stale. 意思是 这个是在quincy版本才支持的. 所以这个版本还是太新了. * - The allocation metadata is removed from RocksDB and now performs a full destage of the allocator object with the OSD allocation. - With cache age binning, older onodes might be assigned a lower priority than the hot workload data. See the Ceph BlueStore for more details. 不看6了... 5 应该是15或者16 只支持容器化集群 bluestore支持了4K粒度, With this release, the default value of BlueStore’s min_alloc_size for SSDs and HDDs is 4 KB. This enables better use of space with no impact on performance. Sharding of RocksDB database using column families is supported rbd Improved librbd small I/O performance Previously, in an NVMe based Ceph cluster, there were limitations in the internal threading architecture resulting in a single librbd client struggling to achieve more than 20K 4KiB IOPS. With this release, librbd is switched to an asynchronous reactor model on top of the new ASIO-based neorados API thereby increasing the small I/O throughput potentially by several folds and reducing latency. Built in schedule for purging expired RBD images Previously, the storage administrator could set up a cron-like job for the rbd trash purge command. With this release, the built-in schedule is now available for purging expired RBD images. The rbd trash purge schedule add and the related commands can be used to configure the RBD trash to automatically purge expired images based on a defined schedule. See the Defining an automatic trash purge schedule section in the Red Hat Ceph Storage Block Device Guide for more information. 支持内建的trash周期清理等逻辑. Overriding read-from-replica policy in librbd clients is supported Online re-sparsification of RBD images Previously, reclaiming space for image extents that are zeroed and yet fully allocated in the underlying OSD object store was highly cumbersome and error prone. With this release, the new rbd sparsify command can now be used to scan the image for chunks of zero data and deallocate the corresponding ranges in the underlying OSD object store. ocf:ceph:rbd cluster resource agent supports namespaces Previously, it was not possible to use ocf:ceph:rbd cluster resource agent for images that exist within a namespace. With this release, the new pool_namespace resource agent parameter can be used to handle images within the namespace. RBD images can be imported instantaneously With the rbd import command, the new image becomes available for use only after it is fully populated. With this release, the image live-migration feature is extended to support external data sources and can be used as an alternative to rbd import. The new image can be linked to local files, remote files served over HTTP(S) or remote Amazon S3-compatible buckets in raw, qcow or qcow2 formats and becomes available for use immediately. The image is populated as a background operation which can be run while it is in active use. Snapshot-based mirroring of RBD images The journal-based mirroring provides fine-grained crash-consistent replication at the cost of double-write penalty where every update to the image is first recorded to the associated journal before modifying the actual image. With this release, in addition to journal-based mirroring, snapshot-based mirroring is supported. It provides coarse-grained crash-consistent replication where the image is mirrored using the mirror snapshots which can be created manually or periodically with a defined schedule. This is supported by all clients and requires a less stringent recovery point objective (RPO). 4 看起来是13 bluestore稳定 Asynchronous recovery for non-acting OSD sets Previously, recovery with Ceph was a synchronous process by blocking write operations to objects until those objects were recovered. In this release, the recovery process is now asynchronous by not blocking write operations to objects only in the non-acting set of OSDs. This new feature requires having more than the minimum number of replicas, as to have enough OSDs in the non-acting set. The new configuration option, osd_async_recovery_min_cost, controls how much asynchronous recovery to do. The default value for this option is 100. A higher value means asynchronous recovery will be less, whereas a lower value means asynchronous recovery will be more. Introduction of diskprediction module Erasure coding for Ceph Block Device RBD performance monitoring and metrics gathering tools Cloned images can be created from non-primary images Creating cloned child RBD images from mirrored non-primary parent image is now supported. Previously, cloning of mirrored images was only supported for primary images. When cloning golden images for virtual machines, this restriction prevented the creation of new cloned images from the golden non-primary image. This update removes this restriction, and cloned images can be created from non-primary mirrored images. Segregating RBD images within isolated namespaces within the same pool RBD images can now be segregated within isolated namespaces within the same pool. When using Ceph Block Devices directly without a higher-level system, such as OpenStack or OpenShift Container Storage, it was not possible to restrict user access to specific RBD images. When combined with CephX capabilities, users can be restricted to specific pool namespaces to restrict access to RBD images. Moving RBD images between different pools within the same cluster This version of Red Hat Ceph Storage adds the ability to move RBD images between different pools within the same cluster. For details, see the Moving images between pools section in the Block Device Guide for Red Hat Ceph Storage 4. Long-running RBD operations can run in the background Long-running RBD operations, such as image removal or cloned image flattening, can now be scheduled to run in the background. RBD operations that involve iterating over every backing RADOS object for the image can take a long time depending on the size of the image. When using the CLI to perform one of these operations, the rbd CLI is blocked until the operation is complete. These operations can now be scheduled to run by the Ceph Manager as a background task by using the ceph rbd task add commands. The progress of these tasks is visible on the Ceph dashboard as well as by using the CLI. 3 Red Hat Ceph Storage 3 这个比较像是12 Chapter 3. New features Red Hat Ceph Storage 3.3 | Red Hat Customer Portal ceph-ansible The new device_class Ansible configuration option With the device_class`feature, you can alleviate post deployment configuration by updating the `groups_vars/osd.yml file in the desired layout. This feature offers you multi-backend support by avoiding to comment out sections after deploying Red Hat Ceph Storage. The default BlueStore and BlueFS allocator is now bitmap New omap usage statistics per PG and OSD Listing RADOS objects in a specific PG \u0000","categories":[{"name":"专业","slug":"pro","permalink":"https://sean10.github.io/categories/pro/"}],"tags":[{"name":"ceph","slug":"ceph","permalink":"https://sean10.github.io/tags/ceph/"},{"name":"upgrade","slug":"upgrade","permalink":"https://sean10.github.io/tags/upgrade/"}]},{"title":"(施工中)cephalocon2023之bluestore_v2","slug":"cephalocon2023之bluestore-v2","date":"2023-06-04T16:16:06.000Z","updated":"2023-06-07T02:17:10.582Z","comments":true,"path":"2023/06/05/cephalocon2023之bluestore-v2/","link":"","permalink":"https://sean10.github.io/2023/06/05/cephalocon2023%E4%B9%8Bbluestore-v2/","excerpt":"","text":"TODO: 找到对应的PR, 从而将口语化难以理解的内容转换为正确的描述. BlueStore V2 - an Evolutionary Step Forward - Adam Kupczyk, IBM &amp; Mark Nelson, Clyso GmbH - YouTube 规划 filestore 在 Pacific 和 Quincy 中被弃用，在 Reef 中被完全移除 bluestore目前暂不知道什么时候会移出, 但是期望是将来seastore能够替代他. 也许会发生一些不可预料的新内容让他变得更好. 成熟 vs 变革 目前, 根据tracker和telemetry的统计, bluestore已经成熟了. 目前进入维护阶段 其中telemetry提供的错误会进入tracker队列的顶端. 而一些只提了单子, 但没有信息的单子就暂时没有办法处理. 更进一步的, 则是在bluestore的performance meeting例会和头脑风暴例会上进行讨论. 3个还会长期阻塞我们的bug单 关于Onode的引用计数, 关于Onode的缓存的assert SIGSEGV 关于Onode的引用计数, 关于Onode的缓存. 很恼人, 不过不够critical, osd自动重启后数据没问题. 问题点 * 引用技术为0时自动清理, 很多版本中都很普遍而且我们甚至无法向后移植它. * 在Octopus版本中, 在引入技术为2时, 我们需要额外的操作. * 除了引用计数外, 还存活在了缓存中. 如果被pinned, 无法修改他. 只有unpined才能修改, 但是unpin依赖lock. 这个问题花了9条PR, 其中4条真的进入的后续版本, 直到Igor真的解决了, 但不是从技术上解决的. 做了个从缓存中lazy unpining的功能. 所以可以使他正常工作. 我们之所以不能回滚掉他, 是因为基于他有太多内容已经变更. 如果有个解决方案, 我们会考虑, 但是Pacific和Quincy版本的解决方案将有所不同. rocksdb checksum mismatch rocksdb损坏后, 没有办法还原时, OSD只能重新部署, 没有办法绕过他. 有两个原因 1. direct vs buffed 问题来源非常早, 来源于linux manual中说的不应该同时使用direct和buffered mode. 我们没有这么做, 但是我们保证打开同一个设备, 但永远不会使用read buffered和read direct读取同一个block device. 除了bluefs log. 这个让我们付出了代价, 当你重启设备/osd, 他启动的非常快时, 你可能无法取得你刚才写到bluefs log上的数据. 其中一些对rocksdb表的更新, 结果是我们在Nuatilus中引入了另一个问题, 我们修改了bluestore和bluefs只建传输的内存的部分. 目前为止这部分是不可见的. TODO: 暂未找到这条PR的单子. 2. blueFS ENOSPC os/bluestore: enable 4K allocation unit for BlueFS by ifed01 · Pull Request #48854 · ceph/ceph 这个问题今年刚在master分支修复, 会backport到pacific分支, 但尚未完毕, 值得关注. 具体指代的是block 上仍有空间, 但是碎片化, 没有能提供给bluefs的满足对齐要求的空间. 这个问题最早在luminous版本, 我们做了个flip-flop触发器, 在block和bluefs之间gifting和reclaiming数据, 1M对齐显然是可怕的, 因此我们选择了64K 的chunk. 这部分持续了很久, 最终我们现在有个支持4K对齐的bluefs. 可能有人会问为什么设置一个4K的bluefs chunk 需要这个久. 这是个好问题. 最早创造bluefs的时候, 有一个bluefs启动的4K的超级块. 当启动时, 从一个4K扇区读取重放日志. 如果chunks大小很大, 你的log就不可能会非常大. 但是如果是4K大小的chunks, logs就很有可能被用尽. 很快就可以得到非常零碎的bluefs log. 因此,4k大小时, 只是不适合那个大小. 所以现在, 通过special trampoline multi-stage booting of bluefs log可以实现了(待理解, 暂未在PR中找到解释的关键词), 性能在大量碎片时当然不太好, 但是不会再失败了. 不再会有半夜因多个osd bluefs空间不足被叫起来, 不得不去迁移数据的情况. 目录 为什么这些很重要, 因为这样我们就有更多时间去给bluestore添加新功能. 这里有一张完整功能规划的图. 这些如果实现了将提供巨大的质量改进. 其中有一些次要优先级, 但是简单一些的. free disc space fragmentation stupid 分配器 早期我们引入了stupid 分配器, 实际上这个名字我觉得不太好, 功能很简单表现也很不错. 在我们测试过程中发现他创建了很多碎片, 可用空间碎片化之后, 只能期望你的新对象也是碎片化的, 自然性能就会下降, 甚至会导致bluefs内部空间也无法回收. 一般在性能下降之前, bluefs就会告诉你空间不足了. 这是个现实中的例子, 可能是你们中的一个集群. 在固定地点长期运行之后的图 这个图不是截断的, 就是19个allocation unit. 会看到长期运行之后, 大部分对象都在少数分配单元中. 这张图表达的不是对数也不是线性刻度, 单纯表达的有数量级差异. 之所以这样说, 是因为当时用户需要我们从no space的情况下将数据救回来. bitmap 分配器 然后, 如果你想要你的对象分段像这样连续, 选择bitmap分配器. 但是你的对象会像下面这样, 所以最终并没有性能提升 how much fragments there is? 我们真的不知道, 因为有个基于分片数量的wired碎片打分. 这个确实告诉了你bluefs的内部空间条件, 不过现在他不再有用. 所以我们需要一张直方图.不过即便我们有碎片, 也并不是很明显有多少成本. 如果你正在运行RBD, 你是以4MB的块以某种方式碎片化. 他们在不同的时间被覆盖. 如果RBD的对面正在运行任何文件系统, 仍旧是没问题. 如果chunks代表不同的文件, 只要不发生同时读取他们的事情, 你仍旧不会受到碎片的影响. TODO: why? 当然Romin会抱怨, 在scrub的时候, 所有的对象都是red, 会拖慢scrub的速度. 我认为从这个过程中, 我们会得到一个感觉, 也许应该只修复真正热点的对象的碎片化. 待会会有张关于碎片的幻灯片. 现在让我讲下其他的主题 #### rocksdb block cache 当我们合并rocksdb给bluestore时, 我们实现了我们自己的block cache , 因为我们需要内存管理. 现在我们的block cache和其他的cache之间循环,这部分要感谢Mark Nelson, 目前这部分是个非常好的动态过程, 对于最热点地区的goals和gifts是最令人难忘的. 但是似乎有些东西在和block cache运作时令人感到strinky(恶臭的). 在一些情况下我们似乎并没有真正使用block cache , 但是莫名其妙的提供大量相等于Block cache数量的linux page cache可以解决性能问题. 所以要么是我们错误的实现了它, 我们只是缓存了它, 然后我们并没有在rocksdb想要时, 给回它. 亦或是其他的一些错误导致我们无法归还它. 这个问题已经很长时间了. iterations 为什么block cache非常重要呢? 因为如果不缓存数据, 迭代是慢的. 并且在rocksdb中迭代可能会花很多时间, 并且很多人抱怨甚至到了试图删除空的collection的度. 这个是删除PG的最后一步, 它最后一次尝试遍历只是为了检查是否真的是空的. 当所有内容被删除时, 有很多墓碑, 这些只是thmb stones, 但它仍然需要花很多时间来做这个. em, 我听到一个好消息, 我认为是时候承认Corey Snyder在改进迭代器方面迈出了非常好的一步. 因为他的一条PR, 使用range iterators, 在大部分场景下, 可以把事情分开进行. collection_list specifially 但如果我们遇到迭代器问题, 我们可能会使用collection_list 的方案来解决它. 不过暂时还不知道怎么去做他, 不颠覆当前的架构. 因为我们当前确实从把所有内容放在一个地方并使用rocksdb迭代中收益良多. 也许其中一个解决方案可能是用speedb替换rocksbd. speedb有一个模式, 他们告知了我, 我也测试了一下, 姑且让我们假设它正常工作, 当你区分了key 流和 value 流, 它能够做什么? 如果我们把他用在onode collection, 即便我们只有某个范围内的墓碑, 它会是个非常短的表. 它只包含名称, 而名称在rocksdb中可以被很好的压缩. 所以它应该会快得多. 当然这还只是个想法 spillover revert 另一个spliiover revert. 溢出是我们很不喜欢的一种情况, 但你有一个非常慢的HDD, 你用nvme/ssd的一部分来给他备份. 这不是一个很好的组合, 然后没有空间放你的rocksdb的meta, 它必须使用hdd上的临时空间, 这个不会出问题. 只是非常慢, 问题发生在当他只是个过渡性质的溢出. 因为如果你空间真的多于容量, 那没有什么可以解决的. 但是如果你压缩一个db刚好比你的数据库空间一半大一点. 它可能会溢出到慢速设备, 并且它会在那停留很长一段时间. 因为如果它碰巧是一个非常深的压缩, 影响了很多层级. 你的新SSd文件将驻留很长时间, 而溢出恢复只是简单的从慢速设备移动回来到db的概念. 正如你们所知, bluefs files可以驻留在这些设备中的任何一个上, 只是物理上执行复制并切换extents到新的形状上, 这部分没问题. 棘手的部分是如何做出复制什么的决定, 这很困难. 因为我们没有跟踪, 并不区分hot SST tables ,也许叫做SSD tables. 亦或是我期望的情况, 甚至可能是某些部分的一部分SSD tables很热, 与此同时其他表很慢. 但我们可能会忽略它, 只是为了简化一些其他的东西. Mounting bluestore RO 可能有人会问, 为什么这里会有这个深奥的功能 因为任何原因, bluestore失败时, 你想要救回一些PG数据, 真的很难使用ceph-objectstore-tool来做到这件事. 举例来说, 你进入了一个真的没有空间继续写的情况下, rocksdb需求更多空间, 而你的设备确实没有了. 你不能用ceph-objectstore-tool去挂载rocksdb, 并解压导出数据. 因为bluestore期望待定名字完成所有pending压缩, 不同的权限等等. 所以你被困在了这个点上, 只是想做一点点修改. 所以你想得到一个只读的bluestore, 只需要保持冻结状态, 可以加载到内存里, 在内存里的rocksdb, 从而可以将数据提取到另一个osd的superblock中. 我期望这件事不会发生在你们身上, 但是确实发生在了很多人身上. OSD无法启动, 因为OSD写入的第一个对象是OSD超级块,因为对于他来说, 选中它知道他自己的状态并继续是需要的. 有一些技术可以恢复, 不过这部分还是相对困难的, 成功率不是100%. 现在OSD 超级块, 再次感谢Igor, 将位于多个地方, 包括rocksdb本身, 并且代码也变了, 对象通常处在磁盘开头的对象, 现在也可能存在不同的地方. 在大多数环境中, 超级块都处于磁盘头, 因为它需要占用第一个分配单元, 并且它总是被更新, 且他很小. 它总是进入不同的权限路线, 所以它只是被覆盖了, 难怪osd开头的任何损坏都会引起osd的超级块崩溃. 一个我最喜欢的例子是, 你如何下放一个功能, 很长时间以来真的不可能挂载bluestore 2次, 我们使用flock, 管理资源独占锁来实现挂载bluestore 2次. 但当容器化的时候, 它就变得无用了. 因为容器化环境也区分了那些锁, 所以如果你有一个讨厌的情况, 你尝试运行你的容器2次, 你得到它, 并且你的超级块损坏了, 因为其中一个覆盖了第二个, 这也是一个问题我们已经解决了的. 我现在除了locking之外, 我们还使用了额外的方式. 为什么不使用内核级特殊处理, 是因为打开块设备独占, 对于其他所有块设备的工作方式梧桐, 我无法打破它. 如果有人能够打破那个保护, 麻烦告知我. TODO: osd启动时有peek_meta, 不知道是不是这个 To improve (CD) 在CD中, 我们需要清理的, mount/umount顺序是一点, 我们存放可配置的地方bluefs, rocksdb ,RO, 关闭/打开, 读分配. 现在可以简称 free list的清理. 以及Greg实现的一个非常好的功能, 删除rocksdb关于分配的升级. 所以我们现在节省了很多时间在kv sync thread上, 不更新位置. 我真正想做的事一对对检查, 我不知道admin socket 最有可能或者不同的类型, 对我来说, 就是这样, 好奇我需要看看我的元数据是什么样的, 我希望能在运行时关联它, 我不想运行一些调试登记的bluestore只是为了看看对象在磁盘上是如何结构化的, 此时所有osd不得不回复我. 我自己的笔记, 我感兴趣的事我的SharedBlobs是如何拆分, 等等. 和运行时检查相同, 但是也区分在线或者撩闲. 当然runtime cache/buffers 现在基本上更好, 也很有价值对于碎片化的报告. 我想要直方图, 以及分裂的热点区域是什么, 碎片化的可能成本是多少. Defragmentation 所以这部分是接下来碎片化最有可能完成的事情, 它将包括自由空间的碎片和应该可以再一次运行中完成的对象, 我们正在考虑使用一种算法来迭代的提供一些迭代改进, 我们不希望一个全局的操作来操作OSD每周半小时, 期望它内联的运行, 或者如果我们提供更好的分配器和更好的策略, 我们跳过他, 新的OSD对于现有的部署不会那么碎片化, 也许我们在想, 对于本地化分配会有所帮助. 意味着, 吸纳关系那改一下, 你把可用磁盘空间分配给某些区域, 如果你需要空间, 你想要获得接近分配大小的卡攻坚, 但是你真的想要接近这个对象的空间爱你, 你已经知道对象的所有其他数据, 是否相信他不是这种情况, 我们只是在分配时, 我们不知道请求它的对象在哪里. 我们的想法是即便对于spinner, 如果有个相同的cyliner, 我们仍然大体上还可以紧挨着他. 当然, 对于固态的策略并没有真正发挥作用, 更重要的是落盘可能不是以正确的顺序, 而是由于无论硬盘内部的架构如何, 你都可以一口气读到他. 以及如何做一些额外特别的scrub优化的一部分来完成, 事实上我们不知道. 目前我们正在和GSoC合作, 我们会创建一个模拟器, 尽可能模拟一些工作集. 想看到运行成年累月之后的垃圾数据之后的表现. 因为很不想bluestore代码对于实验不够好. 你只有实现模拟器才能让我们有可能以最小的成本来测试不同的分配器或则和不同的策略. 最后一个是碰巧针对HDD, 我有一个问题如何通过微调来预测实际延时. 这是一种模式允许你, 构造删除很多数据, 只更新元数据的集群, 当我想要看看我的硬盘在一年的数据碎片化之后的表现, 我只需要切换模式, 插入真实设备, 他就会执行真实操作, 这样就可以作为真实的长时间运行后的测试工具. Lazy Compression 我们可能会抛弃当前的数据结构, 摆脱我们目前的所有缺陷, 并让他离线. 这样我们可以平衡你想要让他使用多少cpu, 选择只有冷数据进行压缩, 这样我们就不再会遇到那种奇怪的情况, 我们应该使用3个分配单元, 但是实际却使用了6个. 这是我们内部组织blob的方式. 这对我们来说更好. 而且在适应之后, 来自前面那一部分的模拟器应该能够给我们预测使用惰性压缩有多好. custom WAL 然后以一个额外的概念, 来自Igor. 这是一个自定义WAL, 意味着我们删除了当前场景, rocksdb正在实现一个headlock , 我们在这里有延时. 在这条竖线后面, 我们可以通知用户事务已经结束. 我们可以修改它, 并提供我们自己的WAL日志, 我们在kvsync线程总并行处理主表, 同时我们也可以压缩他. 我们队数据做了一个fdat, 所以他更早的匹配, 是为了发出事务最终完成的信号, 取决于这里写操作可以像读其他任何我可能错的内容一样执行. 这个概念是为了进一步减少经过rocksdb的数据量. 我们将为PG log创建一个特殊通道,而不是像当前那样讲PG log更新作为新的简直更新到rocksdb中, 每个他们都会写入一些特殊的环形对象, 也许带有一个写headlock. 目前这部分还没有决定, 但我们会卸载掉那个关键的东西, improve Deferred 因为我想大家都知道kvsync线程是个关键的部分. 在bluestore中产生延时. 这是个简单的解释, 我们当前的默认机制太粗糙了, 想象一下, 你追加到你已经写了一些数据的对象, 你追加数据, 现在有一个扇区需要被替换, 但是那个进入了不同的机制, 但是所有其他的只是分配, 这是讲不通的. 因为如果你有spinner, 意味着你必须访问2个地方. 但是实际上你可以只访问其中一个地方 New Deferred 毫无疑问, 这是一个完全不同的东西, 我们正在考虑制作一个新的延迟机制. 不进保留在rocksdb中derred的对象, 那部分应该只保留一部分时间, 不然会不得不被rocksdb写入SST, 产生巨大的写惩罚, 我们想保留一个特殊的延时缓存, 并添加一个长期使用的快速分区, 这样你就可以有10/20/50G的数据, 将你的数据缓存在一个慢速设备中, 我们将允许保留它, 只在有一些迭代过程时, 才触发清理. 这样有序的进行, 好的部分是缓存的任何对象都指向已经分配到某处扇区, 所以没有注入什么奇怪的逻辑.","categories":[{"name":"专业","slug":"pro","permalink":"https://sean10.github.io/categories/pro/"}],"tags":[{"name":"ceph","slug":"ceph","permalink":"https://sean10.github.io/tags/ceph/"},{"name":"cephalocon","slug":"cephalocon","permalink":"https://sean10.github.io/tags/cephalocon/"}]},{"title":"cephalocon2023之ceph performance tuning:from bluestore to rbd -Mark Nelson, Clyso GmbH","slug":"cephalocon2023之ceph_performance_tuning","date":"2023-05-08T13:09:38.000Z","updated":"2023-06-05T15:48:44.969Z","comments":true,"path":"2023/05/08/cephalocon2023之ceph_performance_tuning/","link":"","permalink":"https://sean10.github.io/2023/05/08/cephalocon2023%E4%B9%8Bceph_performance_tuning/","excerpt":"","text":"Ceph Performance Tuning: From Bluestore to RBD - Mark Nelson, Clyso GmbH - YouTube Mark Nelson: Performance / CBT模块成员 推荐性能优化时使用工具 当前性能测试, 60个osd, 450W 随机4K读, 平均75K每个osd. 硬件性能如何很关键, 测试过程中升级驱动解决了nvme Q8持续运行性能波动显著下降问题 pg数量对性能影响 随机读, 每个osd 8192*3/60=409.6个pg, 相比正常理解里的100, 差挺多的 随机写, 每个osd2048*3/60=102.4 , 倒是正常 为什么pg数量有效? pg数少时的效果似乎与蒙特卡洛算法有关? Random distributions look clumpy at low samples counts. Higher PG counts results in a more even workload and data distribution across OSDs. The new primary workload balancer being developed by Josh Salomon and Laura Flores will attempt to improve the distribution even at low PG counts. Is distribution quality the only explanation for the performance differences though? 主pg的均衡, 有助于在pg数少时提高性能. 如pg争用是pg数外影响性能的一点 其他有趣的样例 cephfs在多mds, 通过动态子树分区得到了不错的效果 RBD Snap Trimming 似乎是在shared-blob上做了一些努力, 碎片整理等? 以及不用遍历所有的元数据了. OSD Threading Why does performance level off, then drop, as the number of threads per shard increases? A key point is that there is only 1 messenger thread in this test. With more messenger threads, the effect diminishes. shard_lock contention? Possibly. We might spend too much time in notify_one / notify_all with relation to the wait_lock. More testing needed. 主要是msgr线程数也需要考虑匹配. 具体原因还需要更多实验. PGLog/RocksDB Interaction 主要集中在下述2个场景, 针对2个的冲突, 修改了一些rocksdb逻辑, 会在reef版本上车. 针对kv sync, 我们期望尽可能小的memtable(内部实现的跳表), 减少此时rocksdb为了保序消耗的大量cpu, 针对pg log写入到rocksdb head log, pg log本身是期望尽可能短存在的一个东西, 我们不期望触发rocksdb的compact被压缩, 因此期望内存使用越大越好, 使用了big buffer, 期望在flush memtable时, 这些pg log已经被标注tombstone, 已经可以删除, 无需写入数据库. 无需落盘 bluestore WAL prototype 期望能达成无需使用rocksdb的 head log, 初步看到效果单OSD 12W RocksDB Tombstones 可能会出现一个情况, 由于迭代大量的删除墓碑, 可能导致osd 心跳超时 range deletion 仅需要一次删除大量场景下有效, 4-5年前实验时效果不好, 听说最近有改进, 还没关注 限制搜索和扫描范围, 目前使用有效 强制周期压缩sst, 对磁盘压力大, 且存在引起心跳超时风险. mark开发的一个小PR [WIP] kv/RocksDBStore: Improved RocksDB Settings and Tombstone behavior by markhpc · Pull Request #47221 · ceph/ceph 逻辑比较简单, 只是迭代过程中, 看到一定数量的墓碑, 然后设置了强制压缩条件, 则触发压缩. 在Digital Ocean使用过程中, 对延时有了极大的优化效果. 这个图片是DO提供的, 看延时应该是个非常大压力的hdd集群, 60s 延时 David Orman团队在云上运行了一个非常大的集群, 使用了rocksdb的TTL来使用刚才那个patch, 磁盘利用率从90-95%下降到20-25% 总结 提问 自动化调优控制memtables size 是否有助于PGLog/RocksDB Interaction问题? 只修改memtable size 会导致性能下降 但是如果配合同时修改level 0/1等的size大小到恰当好处, 即从memtable-&gt;level0-&gt;level1控制的很好, 效果应该会很好, 但是这个场景很复杂. 我们后续可以考虑. 检测什么时候你的块设备会开始拖累你的集群性能是否有帮助? 确实有帮助, 值得做.","categories":[{"name":"专业","slug":"pro","permalink":"https://sean10.github.io/categories/pro/"}],"tags":[{"name":"ceph","slug":"ceph","permalink":"https://sean10.github.io/tags/ceph/"},{"name":"cephalocon","slug":"cephalocon","permalink":"https://sean10.github.io/tags/cephalocon/"}]},{"title":"ceph之L版本purged_snaps过多问题","slug":"ceph之purged-snaps多场景下问题","date":"2023-03-22T14:06:44.000Z","updated":"2025-04-20T10:29:27.993Z","comments":true,"path":"2023/03/22/ceph之purged-snaps多场景下问题/","link":"","permalink":"https://sean10.github.io/2023/03/22/ceph%E4%B9%8Bpurged-snaps%E5%A4%9A%E5%9C%BA%E6%99%AF%E4%B8%8B%E9%97%AE%E9%A2%98/","excerpt":"","text":"背景及初步定位 背景是通过perf捕获ceph-osd的cpu消耗, 发现在下述环节极高. 123--10.64%--PG::_prepare_write_info --10.02%--interval_set&lt;snapid_t, std::map&lt;snapid_t, snapid_t, std::less&lt;snapid_t&gt;, std::allocator&lt;std::pair&lt;snapid_t const, snapid_t&gt; &gt; &gt; &gt;::operator== --9.70%--std::_Rb_tree_increment 由于找不到现场版本的debuginfo了, 因此姑且先推导一下. interset的==, 对应是map的==, _Rb_tree_increment初步定位应该是 map的迭代器调用的? 123bool operator==(const interval_set&amp; other) const &#123; return _size == other._size &amp;&amp; m == other.m;&#125; 123456_Self&amp;operator++() _GLIBCXX_NOEXCEPT&#123; _M_node = _Rb_tree_increment(_M_node); return *this;&#125; 根据上述Map的内部实现来看, 基本就是他了, 比较map, 根据下述stl实现来看, 确实是operator==产生的大量迭代 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788//迭代器基类struct __rb_tree_base_iterator&#123; typedef __rb_tree_node_base::base_ptr base_ptr; typedef bidirectional_iterator_tag iterator_category; typedef ptrdiff_t difference_type; base_ptr node; //节点基类类型的指针，将迭代器连接到RB-tree的节点 void increment() &#123; if (node-&gt;right != 0) &#123;//如果node右子树不为空，则找到右子树的最左子节点 node = node-&gt;right; while (node-&gt;left != 0) node = node-&gt;left; &#125; else &#123;//如果node右子树为空，则找到第一个“该节点位于其左子树”的节点 base_ptr y = node-&gt;parent; while (node == y-&gt;right) &#123; node = y; y = y-&gt;parent; &#125; if (node-&gt;right != y) node = y; &#125; &#125;class Map... typedef _Rb_tree&lt;key_type, value_type, _Select1st&lt;value_type&gt;, key_compare, _Pair_alloc_type&gt; _Rep_type; /// The actual tree structure. _Rep_type _M_t; /** * @brief Map equality comparison. * @param __x A %map. * @param __y A %map of the same type as @a x. * @return True iff the size and elements of the maps are equal. * * This is an equivalence relation. It is linear in the size of the * maps. Maps are considered equivalent if their sizes are equal, * and if corresponding elements compare equal. */ template&lt;typename _Key, typename _Tp, typename _Compare, typename _Alloc&gt; inline bool operator==(const map&lt;_Key, _Tp, _Compare, _Alloc&gt;&amp; __x, const map&lt;_Key, _Tp, _Compare, _Alloc&gt;&amp; __y) &#123; return __x._M_t == __y._M_t; &#125;...# stl_tree.hclass _Rb_tree... friend bool operator==(const _Rb_tree&amp; __x, const _Rb_tree&amp; __y) &#123; return __x.size() == __y.size() &amp;&amp; std::equal(__x.begin(), __x.end(), __y.begin()); &#125;# 根据[std::equal \\- cppreference\\.com](https://en.cppreference.com/w/cpp/algorithm/equal)可知, equal内的实现必然用到了`operator++` ... _Self&amp; operator++() _GLIBCXX_NOEXCEPT &#123; _M_node = _Rb_tree_increment(_M_node); return *this; &#125; _Self operator++(int) _GLIBCXX_NOEXCEPT &#123; _Self __tmp = *this; _M_node = _Rb_tree_increment(_M_node); return __tmp; &#125; 包含debuginfo后 定位到purged_snaps后 ceph的快照删除官方文档如下, 因此purged_snaps高在业务场景很正常. SNAP REMOVAL To remove a snapshot, a request is made to the Monitor cluster to add the snapshot id to the list of purged snaps (or to remove it from the set of pool snaps in the case of pool snaps). In either case, the PG adds the snap to its snap_trimq for trimming. A clone can be removed when all of its snaps have been removed. In order to determine which clones might need to be removed upon snap removal, we maintain a mapping from snap to hobject_t using the SnapMapper. See PrimaryLogPG::SnapTrimmer, SnapMapper This trimming is performed asynchronously by the snap_trim_wq while the pg is clean and not scrubbing. The next snap in PG::snap_trimq is selected for trimming We determine the next object for trimming out of PG::snap_mapper. For each object, we create a log entry and repop updating the object info and the snap set (including adjusting the overlaps). If the object is a clone which no longer belongs to any live snapshots, it is removed here. (See PrimaryLogPG::trim_object() when new_snaps is empty.) We also locally update our SnapMapper instance with the object’s new snaps. The log entry containing the modification of the object also contains the new set of snaps, which the replica uses to update its own SnapMapper instance. The primary shares the info with the replica, which persists the new set of purged_snaps along with the rest of the info. RECOVERY Because the trim operations are implemented using repops and log entries, normal pg peering and recovery maintain the snap trimmer operations with the caveat that push and removal operations need to update the local SnapMapper instance. If the purged_snaps update is lost, we merely retrim a now empty snap. 快照删除流程： 当需要删除快照时，会向Monitor集群发起请求，将该快照ID加入已清除快照列表（对于存储池快照则是从池快照集合中移除）。无论哪种情况，PG都会将该快照加入其snap_trimq队列等待修剪。 克隆删除条件： 只有当某个克隆的所有快照都被删除后，该克隆才能被移除。为了确定哪些克隆可能在快照删除时需要被移除，我们通过SnapMapper维护了从快照到hobject_t的映射关系。 异步修剪机制： 修剪操作由snap_trim_wq在PG处于干净状态且未进行清洗时异步执行。系统会从PG::snap_trimq中选择下一个待修剪的快照。 对象修剪流程： 对于每个对象，我们会创建日志条目和repop操作来更新对象信息和快照集（包括调整重叠部分）。如果对象是已不属于任何存活快照的克隆体，则在此处被移除。 映射表更新： 我们同时会使用对象的新快照信息更新本地的SnapMapper实例。包含对象修改的日志条目也会记录新的快照集合，副本节点利用这些信息更新自己的SnapMapper实例。 数据同步机制： 主节点会与副本节点共享这些信息，副本节点会将新的purged_snaps集合与其他信息一起持久化。 恢复机制： 由于修剪操作是通过repop和日志条目实现的，常规的PG peering和恢复过程会维持快照修剪操作，但需要注意推送和删除操作需要更新本地SnapMapper实例。如果purged_snaps更新丢失，系统仅会重新修剪一个现已为空的快照。 目前可以通过ceph pg 2.892 query 查到对应pg的purged_snaps, 足足有2412条, 确实数量很大, 对应的迭代高也看来合理. ~~那剩下就是为啥有的osd 有这个的情况下cpu消耗不高了? ~~该问题可忽略, 后定位节点间cpu型号性能有差异, osd cpu消耗低的节点cpu性能确实更好. _prepare_write_info的 call trace的触发逻辑? 主要是pglog的正常IO处理流程 ceph中PGLog处理流程 | Ivanzz 高版本修复了该设计问题 12removed_snaps_queue [8f1~1,8f4~1] 查看16版本环境, 发现好像是改成了removed_snaps_queue, 且purged_snaps在pg query里也看不到了. 初步看, 虽然pg_info还比较purged_snaps, 但是这项大部分时间为空了. 即不存在该版本的问题了 根据这条PRmon,osd,osdc: refactor snap trimming (phase 1) by liewegas · Pull Request #18276 · ceph/ceph, 提到曾经设计在这里提到过 Ceph Etherpad 时间轴 (注意, 只有4697版本可以看, 之后2020年被人用了机翻.) 在19年, 15版本分支中做了73条commit修改, osd,mon: remove pg_pool_t::removed_snaps by liewegas · Pull Request #28330 · ceph/ceph (github.com) 看Phase 2和3: remove SnapSet::snaps, 好像在17版本已经准备去除了? 目标 snaps are per-pool, so we should annouce deletion via OSDMap successful purge is the intersection of all pool PGs purged_snaps once a pool has purged, we can remove it from removed_snaps AND purged_snaps. this should also be announced via the OSDMap mon and osd need the full removed set, but it can be global (and mostly read-only) once each pool has purged? 基于资源池的snap id信息, 通过osdmap公告 成功的清理, 是所有池的pool pg上的purged_snaps的交集 一旦池清理完毕, 可以从removed_snaps和purged_snaps去除该snap id. 也应该通过osdmap公告 mon和osd需要完整的removed快照集合, 一旦池清理完毕,就可以是全局完整和只读的 主要差异总结: -- planD planC planB planA osdmap相关 仅维护当前正在删除和删除完正在purged的snap pg_pool_t增加recent_removed_snaps_lb_epoch, 维护该epoch后删除的snap列表 pg_pool_t增加代表最早的deletion操作的removed_snaps_lb_epoch维护, new_purged_snaps维护在该epoch之后的 只维护deleted_snaps 请求 - 请求参数中增加removed_snaps和purged_snaps的snapc 请求参数中增加removed_snaps和purged_snaps的snapc 维护一个序号, 仅当存在比这个序号低的snap信息, 才去访问old_purged_snaps, 否则忽略 pginfo pginfo中维护removed_snaps和purged_snaps - - mon 维护删除操作的epoch 维护删除操作的epoch, 并负责根据定义的窗口大小更新osdmap的recent_removed_snaps 维护删除操作的epoch, 定义一个时间周期参数, 满足该周期, 聚拢最早的删除的快照, 从而更新removed_snaps_lb_epoch 每个周期(如100个osdmap)更新purged_snaps的快照interval_set 解读phase-1 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115本次pr之前已增加了13版本的逻辑, 保留了12版本功能6e1b7c4 osd/PG: use new mimic osdmap structures for removed, pruned snapsgh pr view 18276 --json commits| jq &#x27;.commits[]|.oid , .messageHeadline&#x27;使用vscode正则替换`^([0-9a-f]+)\\s*\\n`为`$1 `c536d4c294ec1f1c8cac6ca44675d25cb361e4f2 osd/osd_types: note about removed_snaps hack# add in the new seq, just to try to keep the interval_set contiguousc8bfe3fa53323c05f061ae01dba93574f4cf0747 osd/PG: share_pg_info shares past_itnervals, not PastIntervals()# 去除过度防御设计的PastInervals, 仅当peered之后才需要新建81d63f2994db1d6cf9b48dc8e4f6b473e83ca520 osd/OSDMap: improve osdmap flag dumping in json# [重要]在osdmap里增加了flag_set的打印, 没看出`OSDMap::get_flag_set`这个函数起了什么作用, 还是对`flags`变量的操作.df7523b882c798f17ecda6d2c605feaccc8b2040 qa/suites/rados/singleton/all/thrash-eio: more whitelist# qa日志白名单增加OBJECT_ea308ad54eb46782ec6197143bd5a5058026f4f0 include/interval_set: add get_end() to iterator# [重要]增加通过begin+length获取结束的snapid的函数get_end3119cf5ceea6253d1623a09e8716c29901b04d70 include/mempool: add flat_set alias # [重要]未理解, 不过后面就被重构掉了, 不重要了1b1eec29ae17677a3388404afa274515d9aa812d include/types: flat_set operator&lt;&lt; # [重要]TODO: 同上, 怀疑是某个下面要用的数据结构要用的?b9c5a243958997ab793636a80480ef04eb58d0ab osd/osd_types: SnapSet: remove get_first_snap_after() # [重要]删除指定快照后的一个快照的函数e89649dca590266de4e31ac50627052fabe9e658 mds/SnapServer: fix reset()# [重要]将mds的osdmap SnapServer::reset_state这里pi-&gt;removed_snaps.range_end()更正为snap_seq1f133a2350afedff9e10e725ff23684aaefb43b9 mon/OSDMonitor: reset OSDMap state before decode # [重要]OSDMonitor::update_from_paxos里在decode前增加重置, 应该是某个缺陷问题? 37c4affa25bc5462d83cdf21097ef1576150c429 mon/OSDMonitor: clear pending_metadata* in create_pending# [重要]和commit一样 , PaxosService::_active触发create_pending()553048fbf97af999783deb7e992c8ecfa5e55500 osd/OSDMap: track newly removed and purged snaps in each epoch # [关键] 增加了new_removed_snaps和new_purged_snaps, OSDMap::apply_incremental主要是new_removed_snaps会加入到removed_snaps_queue, new_purged_snaps里的会从removed_snaps_queue里去除还存在一个缺失点, 那就是这俩new_purged_snaps和new_removed_snaps的更新.9d606c587e1f9d8dd2b9e5554bf56d97710c4be7 mon/OSDMonitor: record removed_snaps by epoch outside of the osdmap# [关键] typedef interval_set&lt; snapid_t, mempool::osdmap::flat_map&lt;snapid_t,snapid_t&gt;&gt; snap_interval_set_t;这个结构是什么?OSDMonitor::encode_pending增加写入到osd的db里的make_snap_epoch_keyprepare_remove_snaps里添加了待删除的snap到new_removed_snaps if (!pi.removed_snaps.contains(*q) &amp;&amp; (!pending_inc.new_pools.count(p-&gt;first) || !pending_inc.new_pools[p-&gt;first].removed_snaps.contains(*q))) &#123;TODO:但是为什么是通过上面这个判定才添加是个问题, 没理解, 和new_pools有什么关系? new_pools在这里有什么指代含义?49833c3bb264949b8126796997a95a95b50af411 mon/OSDMonitor: share snaps removed during a map gap# [关键] get_removed_snaps_range 根据传入的epoch版本, 从mon的db中读取写入的make_snap_epoch_key等# MOSDMap中增加gap_removed_snaps好像是用在当客户端需要获取比mon中存的removed_snaps更老的版本的时候用的? 但是好像还没看到哪里使用# 增加了MOSDMap兼容性的解析的compat_version标记38e96ec2794d193f4a6cf6d5372d3b1c849ac4d2 mon/MgrStatMonitor: dump PGMapDigest at debug level 20# [重要]增加了日志打印pgmap digest32d7538a506be03b077da77095702b47f8150f34 osdc/Objecter: prune new_removed_snaps from active op snapc&#x27;s# [重要]objecter定义了_prune_snapc, 在Objecter::_scan_requests和Objecter::handle_osd_map中触发# _prune_snapc主要是去除已经存在于new_removed_snaps中的snap id. 没看明白有啥特殊价值?b1b8fc67388e1b28d8adabcf241bfbca51db2dfd osdc/Objecter: rename _scan_requests force_resend -&gt; skipped_map# [重要]TODO: 变量重命名, 暂不理解192a8dc7862fcbd532c6a11a5afcf1b9cb0a8c51 osdc/Objecter: apply removed_snaps from gap to in-flight requests# [重要]_scan_requests入参中增加gap_removed_snaps# Objecter::handle_osd_map和_scan_requests如果skipped_map=true, 修剪gap_removed_snapsa53ba7314c53e75d1e0b8a0edd29181db3c93863 osd,mon: add &#x27;nosnaptrim&#x27; osd flag# [重要]添加nosnaptrim实现# SnapTrimmer状态机的can_trim增加flag判定# PrimaryLogPG::kick_snap_trim()先检查flag# boost::statechart::result PG::RecoveryState::Active::react(const ActMap&amp;)重构的状态机或者mark_clean会触发kick_snap_trim()345d3b655a62f221e06187b67d53aeb5f7239062 osd/osd_types: add purged_snaps to pg_stat_t # [重要]见题知义6df912b18b4c493c9a8f2e65ecd158f119c8c210 osd/PG: share purged_snaps with mgr at mimic # [重要]设置osd_max_snap_prune_intervals_per_epoch默认100, 并在PG::publish_stats_to_osd()的pg_stat_t中按该参数为上限填充purged_snaps项86f0b811882de334f0d7e577b6c47bef6aba2422 mon/PGMap: add purged_snaps map to PGMapDigest # [关键] PGMapDigest增加purged_snaps, 实现PGMap::calc_purged_snaps(), 使用所有pg的pg_stat_t里的purged_snaps合并出池的purged_snaps# PGMap::encode_digest中调用calc_purged_snaps# 增加mutex_lock, 实现with_mutable_pgmap# mgr DaemonServer::send_report()使用with_mutable_pgmape5f62fb8ac8a1ef79aa97361e83c796b0d94fc28 osd/PG: move debug_verify_cached_snaps check into PGPool::update # [重要]PGPool::update(CephContext *cct, OSDMapRef map) 增加context # osd_debug_verify_cached_snaps调整到update函数中 , 待理解33c9907662ad5b504581b373c4f4e3b4b5a1cc63 osd/PG: some whitespace # 字符格式化f04729cedee9c2c53dd56b952b6b2167ae392da1 osd/PG: break out of Active AdvMap handler if interval change# [重要]PG::RecoveryState::Active::react(const AdvMap&amp; advmap) 通过PastIntervals增加快速检查重新peer 231ec67b7a6d0ca228266cccd0ef53a77b5428e6 osd/PG: simplify replica purged_snaps update # [重要]改为仅由主处理purged_snaps更新, 从只负责同步6e1b7c4c14be575a554ffe1d6e71c0d6189486af osd/PG: use new mimic osdmap structures for removed, pruned snaps# [关键] PGPool中, cached_removed_snaps和newly_removed_snaps只在12版本使用# PG::activate中, 12版本snap_trimq = pool.cached_removed_snaps;# 13版本则使用get_removed_snaps_queue中的, 并去除pginfo的purged_snaps已包含的. 并将purged_snaps中且在removed_snaps中的替换掉原来的pginfo的purged_snaps. 这里的purged_snaps只放有可能还在removed_snaps队列中的.# PG::RecoveryState::Active::react(const AdvMap&amp; advmap)状态机增加13版本处理逻辑# 遍历new_removed_snaps, pg-&gt;snap_trimq增加不相交的部分的snap_interval_set_t, 如果存在重复的部分, 设置bad为true. 如果出现重复就assert崩溃, 说明不可能重复. 设置pg-&gt;dirty_info = true; 和pg-&gt;dirty_big_info = true;# 遍历new_purged_snaps, 如果pg_info的purged_snaps中包含了该部分, 则去除# 如果存在交集, 和上文同样一起崩溃# if (pg-&gt;dirty_big_info) &#123; // share updated purged_snaps to mgr/mon so that we (a) stop reporting // purged snaps and (b) perhaps share more snaps that we have purged // but didn&#x27;t fit in pg_stat_t. pg-&gt;publish_stats_to_osd(); pg-&gt;share_pg_info(); &#125;16c5bcc0218069edcd5e16b8d17912d47b8e70b3 osd/osd_types: pg_pool_t: add FLAG_&#123;SELFMANAGED,POOL&#125;_SNAPS flags# [重要]add selfmanaged_snaps ,而不是通过removed_snaps的空与否区分fd6a59ebf45a397e9530b9350ee46db99e70e5f8 mon/OSDMonitor: convert removed_snaps on first mimic map# [关键] PG增加last_require_osd_release, 针对12升13的第一次PG进入active状态机的响应, 跳过上面的检查崩溃逻辑. 进入下一次处理# OSDMonitor::encode_pending( 增加 根据removed_snaps空设置pi.flags# 并设置new_removed_snaps以及mon中的key9607a2db466835406d6fb73ad6776eccdf3a7d6c mon/OSDMonitor: prune purged snaps# [重要]osd实现`try_prune_purged_snaps`, 并在bluestore的key中存储`purged_snap_&#123;pool_id&#125;_&#123;snap_id的十六进制&#125;`的信息.f2d602acb8d8142119a89f17ccc28e7ee6a34be9 mon/OSDMonitor: propagate new_removed_snaps to other tiers# [重要] OSDMap::Incremental::propagate_snaps_to_tiers中将base的new_removed_snaps信息同步给tier池, 怎么看着是553048fbf97af999783deb7e992c8ecfa5e55500 osd/OSDMap: track newly removed and purged snaps in each epoch 这条后边的提交?8c44dabe4b26bb2df77145f1b2227c87087f315e osd/PG: ignore purged_snaps inconsistencies for now# [重要]注释了bad = true; 说明去除了上面的崩溃逻辑 TODO: 这里的15版本之前的兼容性是为了什么服务的呢? osd/PG: use new mimic osdmap structures for removed, pruned snaps · ceph/ceph@6e1b7c4 在开始pr前, 通过该修改调整了osdmap等的格式? 1234567891011---title: luminous快照删除实现---sequenceDiagramclient -&gt;&gt; mon: send remove snapmon -&gt;&gt; osd: send `OSDMap::newly_removed_snaps`osd -&gt;&gt; tp_peering: `snaptrimmer_state_machine snap_trimq`tp_peering -&gt;&gt; tp_peering: `pg_info_t::purged_snaps`tp_peering -&gt;&gt; osd: `OSDMap::cached_removed_snaps`osd -&gt;&gt; mon: `OSDMap::removed_snaps` 1234567891011121314---title: mimic设计---sequenceDiagramclient -&gt;&gt; mon: remove snapmon -&gt;&gt; osd: `OSDMap::new_removed_snaps`osd -&gt;&gt; pg: `OSDMap::new_removed_snaps-&gt;snap_trimq`%% 这里是每有一个成功删除就产生吗? 还是以什么为边界发送新的? 比如pg完成一次pg的?pg -&gt;&gt; osd: `pg_info_t::purged_snaps`osd -&gt;&gt; mon: `Mondb::gap_removed_snaps` 梳理FAQ 大方向梳理 升级更新 OSDMontior.cc: 处理OSDMap::Increment new_removed_snaps 处理mon数据库中的snap信息 OSD_SNAP_PREFIX osdmap更新 removed_snaps 归档 removed_snap_queue中 新增的newly_removed_snaps和newly_purged_snaps的维护 PGPool::update(CephContext *cct, OSDMapRef map) new_removed_snaps PG::activate( 13版本 snap_trimq 用removed_snaps_queue, 12版本继续用cached_removed_snaps 13版本的话, 并将pg_info_t中的purged_snaps更新成当前仅需要放的部分, 不再维持那么多, 12版本维持不变. PG::publish_stats_to_osd() 13版本后从pg_info_t中将purged_snaps更新到pg_stat_t中, 12版本的话, 该osd依旧不提供该信息 PG::RecoveryState::Active::react(const AdvMap&amp; advmap) 13版本则用新逻辑, 且如果该pg的上个版本last_require_osd_release是12, 则snap_trimq减去pg_info_t中的purged_snaps. TODO:这块持疑问, 是因为snap_trimq来源的地方复用? 12版本继续用newly_removed_snaps PGPool 初始化 12版本, 需要构造cached_removed_snaps pg_info_t中的removed_snaps清理 pg_stat_t中的removed_snaps维护 涉及pg激活流程? 以及快照删除状态机的流程 通信流程串起来 pg_pool_t::removed_snaps 用在用户定义场景 unmanaged_snap OSDMonitor::prepare_remove_snaps OSDMonitor::preprocess_remove_snaps pg_pool_t::add_unmanaged_snap pg_pool_t::remove_unmanaged_snap pg_pool_t::encode pg_pool_t::decode const mempool::osdmap::map&lt;int64_t,pg_pool_t&gt;&amp; pools\u0000 响应osdmap, 创建/删除快照, 确实会带来osdmap变更 OSDMap::Incremental::propagate_snaps_to_tiers pool属性的全局snaps pg_pool_t::build_removed_snaps snap existence/non-existence defined by snaps[] and snap_seq 当未生成removed_snaps时, 查询pg_pool_t-&gt;snaps, 遍历当前存在哪些快照, 生成该项 pg_pool_t::maybe_updated_removed_snaps PGPool::update pg_pool_t::add_snap pg_pool_t::remove_snap PGPool::cached_removed_snaps // current removed_snaps set 应该是正在干活的 PGPool::update PG::handle_advance_map( 检测到当前osd内存里的cached_removed_snaps没有osdmap里的removed_snaps新了, 则更新cached_removed_snaps为新的removed_snaps, newly_removed_snaps为subtract后的差. 如果不是子集, 则直接更换cached_removed_snaps. PG::activate 作为主pg时, 设置snap_trimq为cached_removed_snaps, 并去除pg_info_t中的purged_snaps 需要更新pglog时, 发送MOSDPGLog, 包括本pg的purged_snaps PG::handle_advance_map 开启调试选项osd_debug_verify_cached_snaps时, 从build_removed_snaps生成一次removed_snaps进行比较, 校验通过才能继续 PGPool::newly_removed_snaps // newly removed in the last epoch 最新删除的 PG::RecoveryState::Active::react(const AdvMap&amp; advmap) pg-&gt;snap_trimq.union_of(pg-&gt;pool.newly_removed_snaps); 收到重构事件时, 检测到newly_removed_snap非空, 则合并到snap_trimq中. 从而用于干活 pg_info_t::purged_snaps pg_info_t::encode pg_info_t::decode bool operator==(const pg_info_t&amp; l, const pg_info_t&amp; r) PG::activate PG::split_into(pg_t child_pgid, PG *child, unsigned split_bits) PG::_prepare_write_info 根据环境里看到dirty_big_info 应该为false 在提供pg_info时, 临时将purged_snaps置空, encode完再还原 map&lt;string,bufferlist&gt; km; PG::read_info PG::filter_snapc PG::proc_primary_info PG::RecoveryState::ReplicaActive::react(const MInfoRec&amp; infoevt) 重构恢复时, 更新pg_info_t的purged_snaps PGLog::merge_log( PrimaryLogPG::AwaitAsyncWork::react(const DoSnapWork&amp;) pg_info_t中的purged_snaps 添加get_next_objects_to_trim的 snap_to_trim pg的snap_trimq清理掉snap_to_trim PGTransaction::ObjectOperation::updated_snaps\u0000 PG::snap_mapper PG::clear_object_snap_mapping PG::update_object_snap_mapping PG::update_object_snap_mapping PG::update_snap_map PG::_scan_snaps(ScrubMap &amp;smap) scrub的时候触发, 似乎只是校验快照元数据, 本身不起啥作用. TODO:scrub校验侧逻辑 PrimaryLogPG::on_local_recover( PrimaryLogPG::AwaitAsyncWork::react(const DoSnapWork&amp;) snapset legacy看着是12版本以下, 更早的时候的 首先所有进程重启, 此时, 进程空间知道自身feature为13了 检测osdmap的继续走12版本逻辑 检测HAVE_FEATURE的, 则都会进入新逻辑? 这里有问题? 此时将require_osd_release更新为13 此时osdmap的也都触发新逻辑, 但是osd通信总有先后, 意味着存在13版本和12版本通信的情况. 此时怎么保障部崩溃? osd和mgr通信也是一点. pg_stat_t pg状态机 mon与osd通信的, 新的gap_removed_snaps的兼容性. 测试场景 着重观察 升级后 * mgr与osd通信的pg_stat_t新增对象的解析 * mon与osd的历史gap_removed_snaps的处理 * 查询与新增写入 * pg_info_t转到pg_stat_t * osdmap/pg_stat_t/pg_info_t/MOSDMap的编解码 稳定性 1. mgr升级后 1. 与低版本通信. 2. 全服务重启 3. 正常业务测试 2. mgr/mon升级后, 1. 与低版本通信 2. 全服务重启 3. 正常业务性能/功能接口测试 3. mgr/mon/osd局部升级后 1. 与低版本通信 2. 全服务重启 3. 正常业务性能/功能接口测试 4. mgr/mon/osd全部升级后 1. 与低版本通信 2. 全服务重启 3. 正常业务性能/功能接口测试 5. qa/unittest中, 是否存在相关测试集? 1. test_snap_mapper.cc 1. snaps 2. testPGLog.cc 1. pg_info_t中的purged_snaps mon更新数据库持久化的效果? 以及性能影响 12版本的设计实现中, 是如何持久化的? 且都在哪些地方使用到? pg_pool_t::removed_snaps 用在用户定义场景 unmanaged_snap OSDMonitor::prepare_remove_snaps OSDMonitor::preprocess_remove_snaps pg_pool_t::add_unmanaged_snap pg_pool_t::remove_unmanaged_snap pg_pool_t::encode pg_pool_t::decode OSDMap::Incremental::propagate_snaps_to_tiers pool属性的全局snaps pg_pool_t::build_removed_snaps snap existence/non-existence defined by snaps[] and snap_seq 当未生成removed_snaps时, 查询pg_pool_t-&gt;snaps, 遍历当前存在哪些快照, 生成该项 pg_pool_t::maybe_updated_removed_snaps PGPool::update pg_pool_t::add_snap pg_pool_t::remove_snap PGPool::cached_removed_snaps // current removed_snaps set 应该是正在干活的 PGPool::update PG::handle_advance_map( 检测到当前osd内存里的cached_removed_snaps没有osdmap里的removed_snaps新了, 则更新cached_removed_snaps为新的removed_snaps, newly_removed_snaps为subtract后的差. 如果不是子集, 则直接更换cached_removed_snaps. PG::activate 作为主pg时, 设置snap_trimq为cached_removed_snaps, 并去除pg_info_t中的purged_snaps 需要更新pglog时, 发送MOSDPGLog, 包括本pg的purged_snaps PG::handle_advance_map 开启调试选项osd_debug_verify_cached_snaps时, 从build_removed_snaps生成一次removed_snaps进行比较, 校验通过才能继续 PGPool::newly_removed_snaps // newly removed in the last epoch 最新删除的 PG::RecoveryState::Active::react(const AdvMap&amp; advmap) pg-&gt;snap_trimq.union_of(pg-&gt;pool.newly_removed_snaps); 收到重构事件时, 检测到newly_removed_snap非空, 则合并到snap_trimq中. 从而用于干活 pg_info_t::purged_snaps pg_info_t::encode pg_info_t::decode bool operator==(const pg_info_t&amp; l, const pg_info_t&amp; r) PG::activate PG::split_into(pg_t child_pgid, PG *child, unsigned split_bits) PG::_prepare_write_info 根据环境里看到dirty_big_info 应该为false 在提供pg_info时, 临时将purged_snaps置空, encode完再还原 map&lt;string,bufferlist&gt; km; PG::read_info PG::filter_snapc PG::proc_primary_info PG::RecoveryState::ReplicaActive::react(const MInfoRec&amp; infoevt) 重构恢复时, 更新pg_info_t的purged_snaps PGLog::merge_log( PrimaryLogPG::AwaitAsyncWork::react(const DoSnapWork&amp;) pg_info_t中的purged_snaps 添加get_next_objects_to_trim的 snap_to_trim pg的snap_trimq清理掉snap_to_trim PGTransaction::ObjectOperation::updated_snaps\u0000 PG::snap_mapper PG::clear_object_snap_mapping PG::update_object_snap_mapping PG::update_object_snap_mapping PG::update_snap_map PG::_scan_snaps(ScrubMap &amp;smap) scrub的时候触发, 似乎只是校验快照元数据, 本身不起啥作用. TODO:scrub校验侧逻辑 PrimaryLogPG::on_local_recover( PrimaryLogPG::AwaitAsyncWork::react(const DoSnapWork&amp;) snapset legacy看着是12版本以下, 更早的时候的 SnapTrimmer状态机 1234567891011121314151617181920212223242526272829303132333435363738394041---title: SnapTrimmer---stateDiagram-v2state if_state &lt;&lt;choice&gt;&gt;state if_state2 &lt;&lt;choice&gt;&gt;state if_state3 &lt;&lt;choice&gt;&gt;state if_state4 &lt;&lt;choice&gt;&gt; NotTrimming --&gt; if_state2: KickTrim if_state2 --&gt; Trimming: pg active+clean+primary+no scrub if_state2 --&gt; WaitScrub: pg scrub Trimming --&gt; NotTrimming: Reset Trimming --&gt; Trimming: KickTrim WaitScrub --&gt; NotTrimming: Reset WaitScrub --&gt; WaitScrub: KickTrim WaitScrub --&gt; NotTrimming: ScrubCompletestate Trimming &#123;[*] --&gt; WaitReservation WaitTrimTimer --&gt; if_state : SnapTrimTimerReady if_state --&gt; AwaitAsyncWork: can_trim if_state --&gt; NotTrimming: not can_trim WaitRWLock --&gt; if_state3: TrimWriteUnblocked if_state3 --&gt; AwaitAsyncWork: can_trim if_state3 --&gt; NotTrimming: not can_trim WaitRepops --&gt; if_state4: RepopsComplete if_state4 --&gt; WaitTrimTimer: can_trim if_state4 --&gt; NotTrimming: not can_trim AwaitAsyncWork --&gt; NotTrimming: DoSnapWork and 干活 AwaitAsyncWork --&gt; WaitRepops AwaitAsyncWork --&gt; WaitRWLock WaitReservation --&gt; AwaitAsyncWork: SnapTrimReserved WaitReservation --&gt; NotTrimming: not can_trim &#125; snap_mapper 12345678910111213141516171819202122/** * SnapMapper * * Manages two mappings: * 1) hobject_t -&gt; &#123;snapid&#125; * 2) snapid -&gt; &#123;hobject_t&#125; * * We accomplish this using two sets of keys: * 1) OBJECT_PREFIX + obj.str() -&gt; encoding of object_snaps * 2) MAPPING_PREFIX + snapid_t + obj.str() -&gt; encoding of pair&lt;snapid_t, obj&gt; * * The on disk strings and encodings are implemented in to_raw, to_raw_key, * from_raw, to_object_key. * * The object -&gt; &#123;snapid&#125; mapping is primarily included so that the * SnapMapper state can be verified against the external PG state during * scrub etc. * * The 2) mapping is arranged such that all objects in a particular * snap will sort together, and so that all objects in a pg for a * particular snap will group under up to 8 prefixes. */ clones clone_snaps snapSet If the head is deleted while there are still clones, a snapdir object is created instead to house the SnapSet. rbd 创建和删除快照 时间长 原因? 好像是mon响应慢了? 12345678910111213142023-04-24 11:34:36.966012 7faa90ff9700 10 librbd::ImageWatcher: 0x7faa7801b160 current lock owner: [9975878,140370134551008]2023-04-24 11:34:36.966015 7faa90ff9700 10 librbd::Watcher::C_NotifyAck 0x7faa78022960 finish: r=02023-04-24 11:34:36.966237 7faacffff700 10 librados: finish completed notify (linger op 0x7faa800038a0), r = 02023-04-24 11:34:36.966273 7faa90ff9700 20 librbd::watcher::Notifier: 0x7faa7801b1e0 handle_notify: r=02023-04-24 11:34:36.966281 7faa90ff9700 20 librbd::watcher::Notifier: 0x7faa7801b1e0 handle_notify: pending=02023-04-24 11:34:38.125463 7faa93fff700 10 monclient: _renew_subs2023-04-24 11:34:38.125478 7faa93fff700 10 monclient: _send_mon_message to mon.worker3 at 192.168.70.4:6789/02023-04-24 11:34:38.171149 7faa90ff9700 5 librbd::SnapshotCreateRequest: 0x7faa80002ad0 handle_allocate_snap_id: r=0, snap_id=413212023-04-24 11:48:28.274546 7f5f7325d700 10 mon.master1@0(leader).osd e35237 preprocess_query pool_op(create unmanaged snap pool 3 auid 0 tid 21 name v0) v4 from client.10348311 192.168.70.1:0/3015903241 2023-04-24 11:48:28.274557 7f5f7325d700 20 is_capable service=osd command=osd pool op unmanaged-snap write on cap allow * 2023-04-24 11:48:28.274561 7f5f7325d700 20 allow so far , doing grant allow * 2023-04-24 11:48:28.274562 7f5f7325d700 20 allow all 2023-04-24 11:48:28.274565 7f5f7325d700 7 mon.master1@0(leader).osd e35237 prepare_update pool_op(create unmanaged snap pool 3 auid 0 tid 21 name v0) v4 from client.10348311 192.168.70.1:0/3015903241 2023-04-24 11:48:28.274570 7f5f7325d700 10 mon.master1@0(leader).osd e35237 prepare_pool_op pool_op(create unmanaged snap pool 3 auid 0 tid 21 name v0) v4 snapdir? CEPH_SNAPDIR 说是通过clone保留了原始快照造出来的. pg状态机和PGPool::update的关联 snaptrim逻辑 1234567891011121314151617181920212223242526rbd::Shell::execute() --&gt; rbd::action::snap::execute_remove() --&gt; rbd::action::snap::do_remove_snap() --&gt; librbd::Image::snap_remove2() --&gt; librbd::snap_remove() --&gt; librbd::Operations&lt;librbd::ImageCtx&gt;::snap_remove() --&gt; Operations&lt;I&gt;::snap_remove() --&gt; librbd::Operations&lt;librbd::ImageCtx&gt;::execute_snap_remove() --&gt; librbd::operation::SnapshotRemoveRequest::send() --&gt; cls_client::snapshot_remove() --&gt; ... --&gt; 发送op给rbd_header对象所在的Primary OSD// OSD删除快照信息cls_rbd::snapshot_remove() --&gt; cls_cxx_map_remove_key() --&gt; ReplicatedPG::do_osd_ops(CEPH_OSD_OP_OMAPRMKEYS)// RBD客户端向Monitor发送删除快照的消息librbd::operation::SnapshotRemoveRequest::send() --&gt; SnapshotRemoveRequest&lt;I&gt;::send_release_snap_id() --&gt; Objecter::delete_selfmanaged_snap() --&gt; Objecter::pool_op_submit() --&gt; Objecter::_pool_op_submit() --&gt; MonClient::send_mon_message()// Monitor删除快照信息OSDMonitor::prepare_pool_op() --&gt; pg_pool_t::remove_unmanaged_snap() --&gt; pg_pool_t::removed_snapsrbd::Shell::execute() --&gt; rbd::action::snap::execute_remove() --&gt; rbd::action::snap::do_remove_snap() --&gt; librbd::Image::snap_remove2() --&gt; librbd::snap_remove() --&gt; librbd::Operations&lt;librbd::ImageCtx&gt;::snap_remove() --&gt; Operations&lt;I&gt;::snap_remove() --&gt; librbd::Operations&lt;librbd::ImageCtx&gt;::execute_snap_remove() --&gt; librbd::operation::SnapshotRemoveRequest::send() --&gt; cls_client::snapshot_remove() --&gt; ... --&gt; 发送op给rbd_header对象所在的Primary OSD// OSD删除快照信息cls_rbd::snapshot_remove() --&gt; cls_cxx_map_remove_key() --&gt; ReplicatedPG::do_osd_ops(CEPH_OSD_OP_OMAPRMKEYS)// RBD客户端向Monitor发送删除快照的消息librbd::operation::SnapshotRemoveRequest::send() --&gt; SnapshotRemoveRequest&lt;I&gt;::send_release_snap_id() --&gt; Objecter::delete_selfmanaged_snap() --&gt; Objecter::pool_op_submit() --&gt; Objecter::_pool_op_submit() --&gt; MonClient::send_mon_message()// Monitor删除快照信息OSDMonitor::prepare_pool_op() --&gt; pg_pool_t::remove_unmanaged_snap() --&gt; pg_pool_t::removed_snaps snaptrim中的qos | 李厅 关键的trim_object和get_next_object_to_trim 这里应该是通过事务生成pglog里用的update_snaps设置snaps,然后正常pg逻辑里从pglog merge的? merge是直接merge的purged_snaps, 所以这里update的snaps是怎么更新成purged_snaps呢? 应该不是 123456789&#125; else if (r == -ENOENT) &#123; // Done! ldout(pg-&gt;cct, 10) &lt;&lt; &quot;got ENOENT&quot; &lt;&lt; dendl; ldout(pg-&gt;cct, 10) &lt;&lt; &quot;adding snap &quot; &lt;&lt; snap_to_trim &lt;&lt; &quot; to purged_snaps&quot; &lt;&lt; dendl; pg-&gt;info.purged_snaps.insert(snap_to_trim); pg-&gt;snap_trimq.erase(snap_to_trim); SnapTrimmer进入初始状态的条件? 1234567891011121314151617181920snap_trimmer_machinePGQueueablePGSnapTrim在AwaitAsyncWork 实例化的时候, 会queue_for_snap_trimboost::statechart::result PG::RecoveryState::Active::react(const ActMap&amp;)在RecoveryState应该是重构状态机理触发的重构状态机进入条件就是收到新的osdmap之类的是在tp_peering线程, peering_wq但是那个好像是常规状态机, 一旦进入干活, 还是tp_osd_tp干活PGQueueable, 是否跟这个有关? 13版本的设计中, 初步理解是在mon的数据库中持久化, 那osd需要用到时, 是会产生一条新的和mon通信的协议吗? pg_pool_t::removed_snaps OSDMonitor::encode_pending(MonitorDBStore::TransactionRef t) 第一次升级的时候, 将removed_snaps转换为new_removed_snaps, 并写入到mon数据库中 OSDMonitor::preprocess_remove_snaps(MonOpRequestRef op) OSDMonitor::prepare_remove_snaps(MonOpRequestRef op) \"tier add --force-nonempty\" pg_pool_t::is_removed_snap(snapid_t s) const pg_pool_t::build_removed_snaps(interval_set&amp; rs) const pg_pool_t::maybe_updated_removed_snaps(const interval_set&amp; cached) const pg_pool_t::add_unmanaged_snap(uint64_t&amp; snapid) pg_pool_t::remove_unmanaged_snap(snapid_t s) pg_pool_t::encode(bufferlist&amp; bl, uint64_t features) const pg_pool_t::decode(bufferlist::iterator&amp; bl) OSDMap::Incremental::propagate_snaps_to_tiers(CephContext *cct, PGPool::update(CephContext *cct, OSDMapRef map) 检测osdmap版本, 12版本旧逻辑, 13版本则清理掉12版本的newly_removed_snaps和cached_removed_snaps PG::activate osdmap 12版本, snap_trimq继续使用cached_removed_snaps 13版本, snap_trimq使用removed_snaps_queue pg_pool_t::new_removed_snaps OSDMonitor::encode_pending(MonitorDBStore::TransactionRef t) OSDMonitor::prepare_remove_snaps(MonOpRequestRef op) OSDMonitor::prepare_pool_op(MonOpRequestRef op) OSDMap::Incremental::propagate_snaps_to_tiers(CephContext *cct OSDMap::Incremental::encode(bufferlist&amp; bl, uint64_t features) const OSDMap::Incremental::decode(bufferlist::iterator&amp; bl) OSDMap::apply_incremental(const Incremental &amp;inc) OSDMap::encode(bufferlist&amp; bl, uint64_t features) const OSDMap::decode(bufferlist::iterator&amp; bl) const mempool::osdmap::map&lt;int64_t,snap_interval_set_t&gt;&amp; PG::RecoveryState::Active::react(const AdvMap&amp; advmap) Objecter::_prune_snapc( get_new_removed_snaps() pg_pool_t::new_purged_snaps OSDMonitor::encode_pending(MonitorDBStore::TransactionRef t) OSDMonitor::try_prune_purged_snaps() OSDMap::Incremental::encode(bufferlist&amp; bl, uint64_t features) const OSDMap::Incremental::decode(bufferlist::iterator&amp; bl) OSDMap::apply_incremental(const Incremental &amp;inc) OSDMap::encode(bufferlist&amp; bl, uint64_t features) const OSDMap::decode(bufferlist::iterator&amp; bl) get_new_purged_snaps() PG::RecoveryState::Active::react(const AdvMap&amp; advmap) removed_snaps_queue OSDMonitor::encode_pending(MonitorDBStore::TransactionRef t) OSDMap::apply_incremental(const Incremental &amp;inc) OSDMap::encode(bufferlist&amp; bl, uint64_t features) const OSDMap::decode(bufferlist::iterator&amp; bl) get_removed_snaps_queue() PG::activate osdmap版本大于13, 兼容 PGMapDigest::purged_snaps OSDMonitor::try_prune_purged_snaps() PGMapDigest::encode(bufferlist&amp; bl, uint64_t features) const PGMapDigest::decode(bufferlist::iterator&amp; p) PGMap::calc_purged_snaps() pg_stat_t::purged_snaps pg_stat_t::encode(bufferlist &amp;bl) const pg_stat_t::decode(bufferlist::iterator &amp;bl) operator==(const pg_stat_t&amp; l, const pg_stat_t&amp; r) pg_info_t::purged_snaps pg_info_t::encode(bufferlist &amp;bl) const pg_info_t::decode(bufferlist::iterator &amp;bl) operator==(const pg_info_t&amp; l, const pg_info_t&amp; r) PG::activate PG::split_into PG::publish_stats_to_osd() PG::_prepare_write_info PG::filter_snapc(vector &amp;snaps) PG::proc_primary_info(ObjectStore::Transaction &amp;t, const pg_info_t &amp;oinfo) PG::RecoveryState::Active::react(const AdvMap&amp; advmap) PGLog::merge_log PrimaryLogPG::AwaitAsyncWork::react(const DoSnapWork&amp;) MOSDMap::mempool::osdmap::map&lt;int64_t,OSDMap::snap_interval_set_t&gt; gap_removed_snaps; encode_payload decode_payload OSDMonitor::send_incremental( 在osd启动阶段, 会需要从mon拿到指定版本之间的MOSDMap? OSDMonitor::get_removed_snaps_range 取决于first_committed和当前osdmap版本, 是不是比如trim或者compact的时候, 这个first_commited才会更改? 否则mon内存里其实一直存着所有的removed_snaps? 确实 Objecter::_scan_requests( Objecter::handle_osd_map 只有client和mgr的objecter客户端层, 这边一开始查下这个. osd干活的时候就不再查了. 客户端查到之后用作什么? 好像主要是剪枝, 确保客户端的请求的snapset不再包含该快照版本? 减少误判? 比如客户端拿到的id是旧的场景吗? 什么时候通知mon更新这个? 由osdmap的版本更新, 收到osdmap中的new_removed_snaps和removed_snaps的时候 mds中也有SnapServer, 也涉及该项, 需要了解该部分中的使用逻辑 removed_snaps的入口添加在哪里? 是怎么加入到increment的事务里的? OSDMonitor::prepare_remove_snaps MRemoveSnaps void pg_pool_t::remove_snap(snapid_t s) { assert(snaps.count(s)); snaps.erase(s); snap_seq = snap_seq + 1; } case POOL_OP_DELETE_SNAP: { snapid_t s = pp.snap_exists(m-&gt;name.c_str()); if (s) { pp.remove_snap(s); pending_inc.new_removed_snaps[m-&gt;pool].insert(s); changed = true; } } break; Objecter::delete_pool_snap removed_snaps 残留代表啥? new_purged_snaps 实际执行? PrimaryLogPG::kick_snap_trim() snap_trimq应该是干活的, 这块状态机基本上没咋改应该. moncap里提到了快照的注释? mds如何使用的快照? 合入过程 忽略, 看错了. * osdmap的decode, 需要feature识别...但是有差别, 在快照前应该还有个v功能. 初步理解, 还是需要引入mimic这个版本的feature标记. 才能区分是老osd? 能不能不引入mimic, 直接引入feature识别? SERVER_M 这个flag已经在了 12这个patch需要转换下. 把SERVER_MIMIC换成 SERVER_M 20这个patch需要查下pg_stat_t, 12版本是22, patch是23-&gt;24 涉及PR, 2条commit https://hub.nuaa.cf/ceph/ceph/pull/18058/commits a25221e 结果这个修改, 立马就被重构掉了 osd_types.cc: don't store 32 least siognificant bits of state twice · ceph/ceph@0230fe6 · GitHub 也是2条commit的PR osd_types.cc: reorder fields in serialized pg_stat_t by branch-predictor · Pull Request #19965 · ceph/ceph · GitHub ae7472f 0230fe6 目前初步看到的障碍是 , 12版本 snaptrimq_len还在invalid后面, 13-14也做了一此reorder, 其实也兼容 13版本是033d246 12版本是ca4413d 所以为了满足12版本的兼容性? 这里那12升13怎么保证兼容性? 根据ceph/osd_types.cc at nautilus · ceph/ceph · GitHub 可以知道14和12是保证了兼容性的. pg_stat_t::decode(bufferlist::iterator &amp;bl) 需要先合入osdmap增加的 27d6f43 中间0020左右, 手动把新的recovery_unfound给合入了, 暂时不知道为啥会合入这段, 手动合入了.osd_types.h的#define那段 然后0028, 在pg_pool_t::encode增加了v改到27 0030, PGMapDigest&amp; get_digest 这个的修改依赖高版本将mon里的部分函数重构到mgr中的修改, 所以尝试性修改是维持不变. 根据12版本现状做处理 编译通过, 实际运行 2023-04-12 14:43:11.981804 7f44f6d7d700 0 log_channel(cluster) log [DBG] : pgmap v10: 192 pgs: 165 active+clean, 18 peering, 9 unknown; 180GiB data, 415GiB used, 1.20TiB / 1.61TiB avail 2023-04-12 14:43:12.871023 7f44fdd8b700 -1 failed to decode message of type 87 v1: buffer::malformed_input: void object_stat_collection_t::decode(ceph::buffer::list::iterator&amp;) no longer understand old encoding version 2 &lt; 122 2023-04-12 14:43:13.866212 7f4500d91700 -1 failed to decode message of type 87 v1: buffer::malformed_input: void object_stat_collection_t::decode(ceph::buffer::list::iterator&amp;) no longer understand old encoding version 2 &lt; 122 2023-04-12 14:43:13.982740 7f44f6d7d700 4 OSD 0 is up, but has no stats 2023-04-12 14:43:13.982742 7f44f6d7d700 2 wc osd 3avail: 71955388378 2023-04-12 14:43:13.982744 7f44f6d7d700 2 wc osd 4avail: 86134315413 2023-04-12 14:43:13.982744 7f44f6d7d700 2 wc osd 5avail: 61272017967 2023-04-12 14:43:13.982748 7f44f6d7d700 4 OSD 0 is up, but has no stats 2023-04-12 14:43:13.982749 7f44f6d7d700 2 wc osd 1avail: 827202140267 mgr无法处理osd发来的消息, 同理, osd上也有 搜到个scrub的测试脚本? 推荐的升级流程 The upgrade order starts with managers, monitors, then other daemons. Each daemon is restarted only after Ceph indicates that the cluster will remain available. compatv确实是2, 但是小于25, 那个25哪来的? 还有header.version的6 哪来的? 终于想起来了, mgr应该是没重新编译, mon也是 编译mgr没问题 ,mon需要 把PGMonitor.cc这里的int32_t改成 uint64_t, 因为pg数据结构改了 mempool::pgmap::unordered_map&lt;uint64_t,int32_t&gt; num_pg_by_state; 替换之后 , 崩在了 12345678910111213141516171819ceph version 12.2.12 (1436006594665279fe734b4c15d7e08c13ebd777) luminous (stable)1: (()+0xa73541) [0x55c718be4541]2: (()+0xf5d0) [0x7f88944635d0]3: (gsignal()+0x37) [0x7f8893484207]4: (abort()+0x148) [0x7f88934858f8]5: (__gnu_cxx::__verbose_terminate_handler()+0x165) [0x7f8893d937d5]6: (()+0x5e746) [0x7f8893d91746]7: (()+0x5e773) [0x7f8893d91773]8: (()+0x5e993) [0x7f8893d91993]9: (object_stat_collection_t::decode(ceph::buffer::list::iterator&amp;)+0x530) [0x55c7188ca990]10: (pg_stat_t::decode(ceph::buffer::list::iterator&amp;)+0x1e5) [0x55c7188d0da5]11: (pg_info_t::decode(ceph::buffer::list::iterator&amp;)+0x13a) [0x55c7188d149a]12: (PG::read_info(ObjectStore*, spg_t, coll_t const&amp;, ceph::buffer::list&amp;, pg_info_t&amp;, PastIntervals&amp;, unsigned char&amp;)+0x231) [0x55c71871d731]13: (PG::read_state(ObjectStore*, ceph::buffer::list&amp;)+0x7b) [0x55c718725efb]14: (OSD::load_pgs()+0x9b4) [0x55c718677334]15: (OSD::init()+0x2169) [0x55c718695ca9]16: (main()+0x2d07) [0x55c7185974a7]17: (__libc_start_main()+0xf5) [0x7f88934703d5]18: (()+0x4c65b3) [0x55c7186375b3] 找到问题了,pg_stat_t里 之前合并purged_snaps合并错了, 应该是环境里的osd被我之前误启动已经污染了, 暂时跳过升级的验证项 先单纯验证功能 osdmap里 removed_snaps_queue 和pg query看不到pg_info里有purged_snaps. 好像是我新增的代码都没生效? 是要让他满足HAVE_FEATURES选项, 在OSDMap.cc里获取过程uint64_t OSDMap::get_encoding_features() const if (require_osd_release &lt; CEPH_RELEASE_MIMIC) { f &amp;= ~CEPH_FEATURE_SERVER_MIMIC; } monCommands.h里 require-osd-release需要增加 | mimic | | ----- | | 增加这段, 让她可以通过mimic if (rel == osdmap.require_osd_release) &#123; // idempotent err = 0; goto reply; &#125; assert(osdmap.require_osd_release &gt;= CEPH_RELEASE_LUMINOUS); if (rel == CEPH_RELEASE_MIMIC) &#123; if (!osdmap.get_num_up_osds() &amp;&amp; sure != &quot;--yes-i-really-mean-it&quot;) &#123; ss &lt;&lt; &quot;Not advisable to continue since no OSDs are up. Pass &quot; &lt;&lt; &quot;--yes-i-really-mean-it if you really wish to continue.&quot;; err = -EPERM; goto reply; &#125; if ((!HAVE_FEATURE(osdmap.get_up_osd_features(), SERVER_MIMIC)) &amp;&amp; sure != &quot;--yes-i-really-mean-it&quot;) &#123; ss &lt;&lt; &quot;not all up OSDs have CEPH_FEATURE_SERVER_MIMIC feature&quot;; err = -EPERM; goto reply; &#125; &#125; else &#123; ss &lt;&lt; &quot;not supported for this release yet&quot;; err = -EPERM; goto reply; &#125; CEPH_FEATURES_ALL 增加MIMIC, 否则osd被判定为低版本的 合入了d9cd2d7 mon feature mimic的这个commit ceph mon feature set mimic --yes-i-really-mean-it 目前没看到起到什么作用. ceph features可以忽略, 即便是16/17, 打出来都是叫luminous SIGNIFICANT_FEATURES 好像默认osdmap用的这个feature, 这里没加上MIMIC 启动后, pg_info里确实没了, pg_stat_t里确实也没看到, ] osd_snap / removed_epoch_1_00000f08 osd_snap / removed_epoch_39_00000f08 osd_snap / removed_epoch_39_00000f0b osd_snap / removed_epoch_39_00000f0e osd_snap / removed_epoch_39_00000f11 osd_snap / removed_epoch_39_00000f14 osd_snap / removed_epoch_39_00000f17 osd_snap / removed_epoch_39_00000f1a osd_snap / removed_epoch_39_00000f1d osd_snap / removed_epoch_39_00000f20 osd_snap / removed_epoch_39_00000f23 osd_snap / removed_epoch_39_00000f26 osd_snap / removed_epoch_39_00000f29 osd_snap / removed_epoch_39_00000f2c osd_snap / removed_epoch_39_00000f2f osd_snap / removed_epoch_39_00000f32 osd_snap / removed_epoch_39_00000f35 osd_snap / removed_epoch_39_00000f38 osd_snap / removed_epoch_39_00000f3b osd_snap / removed_epoch_39_00000f3e osd_snap / removed_epoch_39_00000f41 osd_snap / removed_epoch_39_00000f44 osd_snap / removed_epoch_39_00000f47 osd_snap / removed_epoch_39_00000f4a osd_snap / removed_epoch_39_00000f4d osd_snap / removed_epoch_39_00000f50 osd_snap / removed_epoch_39_00000f53 osd_snap / removed_epoch_39_00000f56 osd_snap / removed_epoch_39_00000f59 osd_snap / removed_epoch_39_00000f5c osd_snap / removed_epoch_39_00000f5f osd_snap / removed_epoch_39_00000f62 osd_snap / removed_epoch_39_00000f65 osd_snap / removed_epoch_39_00000f68 osd_snap / removed_epoch_39_00000f6b osd_snap / removed_epoch_39_00000f6e osd_snap / removed_epoch_39_00000f71 osd_snap / removed_epoch_39_00000f74 osd_snap / removed_epoch_39_00000f77 osd_snap / removed_epoch_39_00000f7a osd_snap / removed_epoch_39_00000f7d osd_snap / removed_epoch_39_00000f80 osd_snap / removed_epoch_39_00000f83 osd_snap / removed_epoch_39_00000f86 osd_snap / removed_epoch_39_00000f89 osd_snap / removed_epoch_39_00000f8c osd_snap / removed_epoch_39_00000f8f osd_snap / removed_epoch_39_00000f92 osd_snap / removed_epoch_39_00000f95 osd_snap / removed_epoch_39_00000f98 osd_snap / removed_epoch_39_00000f9b 看上去removed_snaps是生效了, 但是pg_stat_t里的purged_snaps好像没工作 osdmap的removed_snaps_queue确实工作了, 但是旧的removed_snaps里的好像没清理掉. TODO:解读phase 1.5 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747541c24a13261222cc76f45a51ba213d83f566fc81 osd: remove luminous compat code for removed_snaps713d48eff06a84aee8c98c9fed39696546e411b3 osd/osd_types: remove build_removed_snaps(), maybe_update_removed_sna…248fe11dd25a98f82eda6af5ef91956f9131209c mon/OSDMonitor: remove support for pre-mimic conversion04b946d9131973ada2913bef057c447c41e675d1 mon/OSDMonitor: remove pre-mimic snap behavior support99970bb795d61fc1691e7846bd583e602f23b4d6 mon: drop mon_debug_no_require_mimic58c4c8fc8ef9f85c3efdd31740f2a91054258b08 osd: move snap_interval_set_t to osd_typese963ee6039a29def026d90100e2ca5454b658649 osd/PeeringState: removed pre-mimic removed snap trackingb59a25d9c985e414e3015c76f3fd84a1525afe3c osd/PG: drop pre-mimic snap_trimq code9b6acc2caddc235436aa1f0d6ae6d955a12dc769 osd/PeeringState: drop some mimic conditionals3f9c28823aafc6b970eefba1455a26df98563536 mon/OSDMonitor: avoid is_removed_snap()cabc48c40332875e8827f4f0e6dbde9ab7e9fd7a osd/PrimaryLogPG: use osdmap removed_snaps_queue for snap trimminga6f85089c0d0213481c8038f57820d3d31cf9ebd osd/PrimaryLogPG: find_object_context: trust SnapSet&#x27;s clone_snaps25b690fe06c261648564e3e0428f2003a85b07ca messages/MRemoveSnaps: int -&gt; int32_t on encoded type8c0c63c7e1b4e8eeb23622ac5cf58dcec3e575c6 mds/SnapServer: int -&gt; int32_t for encoded typeb1a5bff4a888d69bc783d8ffae855c639fb98969 osd/PrimaryLogPG: make best effort to sanitize clones on copy-fromc88d860dcef695124ae0d7af72b8e3046ee4bc41 osd/PrimaryLogPG: trim_objects: only filter SnapSet::snaps for pre-oc…096449813272af262be27baf4205eaf3c542b78d osd/PrimaryLogPG: only filter SnapSet::snaps for flush for pre-octopu…a362fedc81ab5ae76149397b2b1544206568ea9f osd/PrimaryLogPG: change fabrication of promoted clone snapsf43d2147896c22a25ebe3c05296a1debbbeaea4f osd/osd_types: SnapSet::get_ssc_as_of: use clone_snaps8f714e2ba6944f15764739f9ea9f3863d31defd1 osd/osd_types: mark SnapSet::snaps as legacyde5d3f6a0ad2d63744fa3accb022da7896f87cc4 mon/OSDMonitor: only maintain pg_pool_t::removed_snaps for pre-octopusd7c343eebff1b40bb7f0ecb7ca91ca2d10ed3c2f osd/PrimaryLogPG: only maintain SnapSet::snaps for pre-octopus compatf58f5cfc5197e283bb1b1b0f234a6133b9a7feaa osd/PrimaryLogPG: use get_ssc_as_of for snapc for flushing clones419251a401f58c78fabe006cd978a968bb6c8087 ceph_test_rados_api_tier_pp: fix osd version checks7fe43cc4e4652a5cda6e2b789220c16677cf2582 ceph_test_rados: stop doing long object namesb945de141f3a97efd339ee82f1ccd2caeae3a40f mon/OSDMonitor: only update removed_snaps when pre-octopusfa7655351c61d36b189131d7e3e8107605fdf54b mon/OSDMonitor: make snap removal handle dups safelyd056372e7bd50c9755e5fc866fcc6e02e9dcc63c vstart.sh: wait for mgr volume module to start updcc8b6b28a0b18bb4d7043bf7bdec751dfa3f05f vstart.sh: remove useless auth add for osds75edd21c4572c833450baf7e9d68a8feec7d33e4 vnewosd.sh: add script to add a new osd to an existing vstartbc4c31a439a2cd201d89538fd519feefeb2aeb34 mon/PaxosService: add C_ReplyOp7eeee5b49bf67ccd197820a692472a6707e97074 CMakeLists: include &#x27;cephfs&#x27; (which includes libcephfs) in &#x27;vstart&#x27; t…ab405ab56036ad44f79e36f65031585a86b1e967 mds/SnapServer: handle MRemoveSnaps acks from mone457b73075b63433a63f6ddbf945555f2573a5ee mon/OSDMonitor: send MRemoveSnaps back to octopus MDSec4cd082617b88ccb61ca74205cf38fa27b43b5e mon/OSDMonitor: use structured binding for prepare_remove_snapse8a359814cf533bbb4064b1bd27d40c6d7bff629 osd/SnapMapper: document stored keys and values14fdb52c50c018c6580fc0a1115495875ebb1a9e mon/OSDMonitor: document osd snap metadata format84bea65d3e3b4c5bf04591700f8da8e99e7a1bc2 osd/SnapMapper: include poolid in snap index94ebe0eab968068c29fdffa1bfe68c72122db633 osd: adjust snapmapper keys on first start as octopusa12d80a8137a47743996d89379e63cf80d005ae3 mon/OSDMonitor: lookup_pruned_snap -&gt; lookup_purged_snap441f42b8add06304df331b655b75da9b3a491cd8 mon/OSDMonitor: fix lookup_purged_snap implementation19a590e11494d33477442a4f749852c38b111a74 mon/OSDMonitor: make_snap_key -&gt; make_removed_snap_key, make_purged_s…c0f362434560ea773350b5677365d7eed83c2c42 mon/OSDMonitor: refactor snap key and value helpersc0233801a8bd78ce44e6bbf8baab1eae73e9fa5c mon/OSDMonitor: generalize/refactor lookup_*_snap1e7718c37c5ebbc98d4c3caec91d71a99f5c0982 mon/OSDMonitor: move (removed, purged) snap update into a helperacd7e903d3eb7745e92dbcbf2b851a77d0dc1929 mon/OSDMonitor: make &#123;removed,purged&#125;_snap storage more efficient61d8407514da8ce68d0bed18ff5c4cbe512cdf01 osd/osd_types: clean up initial values for OSDSuperblock3217ca77cbd683a0f5d918c4cadb0cf5a149eacc osd/osd_types: add purged_snaps_last to OSDSuperblock847dc5fb78a6abe1ae0e010645e905fa833c16bb mon/OSDMonitor: make_snap_epoch_key -&gt; make_removed_snap_epoch_key47fb89c072b63202ba61e9c8bcd411816af2701b mon/OSDMonitor: record purged_snaps for each epoch4e5093cee357c79672991d1899d30dcbe22810ac mon/OSDMonitor: record pre-octopus purged snaps with first octopus map7315d3fdba0ab917fc2b01d1d7ae99220fcbcf43 mon/OSDMonitor: add messages to get past purged_snaps87b539c2b65c80a105e1c374ff88cb69b571686f osd: record purged_snaps when we store new maps81f7edc6bda47fce626abfc861b268c61c6a26bd osd: sync old purged_snaps on startup after upgrade or osd creation8d9a27f5ea9d860f2c407346b8b7ef7b99afcbce ceph_test_rados_api_snapshots_pp: (partial) test to reproduce stray c…7628474723489d9bb5ef97e35a2e102a8ae04d63 osd/PrimaryLogPG: always remove the snap we are trimming6192fb60313d42761a2ff59d2dee5581a68d6139 osd: implement scrub_purged_snaps commanda1f649c2e763eb21c47f013e1bf8b6ae24700359 mds/SnapServer: make not about pre-octopus compat coded3d06bcd7c1230e8f4d49a0dafa7b32d3860f39a osdc/Objecter: don&#x27;t worry about gap_removed_snaps from map gapsbc0553147b229855def6da92e4dd2b58a32ba9ad mon/OSDMonitor: do not bother reporting gaps in removed_snapsd831abeae1688a18eb446dd1a63eb6ed94f45d81 mon/OSDMonitor: record snap removal seq as purged6b26fcd1bdd8910cb2dbd84fe342cd65be2a70ec mon/OSDMonitor: fix bug in try_prune_purged_snapse4aed74cd4799d922b8cba2d65996b7cbe90cab5 osd/OSDMap: add last_purged_snaps_stamp to osd_xinfo_ta03e8ab662559b395380864980bfec7958585a53 osd: record last_purged_snaps_scrub in superblockab475cda08ff7cf872d342caa5680a97973dc535 osd: log purged_snaps scrub to cluster log4f4dedb8d62bcafb3c698f35ab374b7a4d72ed88 osd: report last_purged_snaps_scrub as part of beacon85ddc1a0345c24487f85103dd6a4b9a4dad87e2b mon/OSDMonitor: record last_purged_snaps_scrub from beacon to osdmap0d10e63d8d158ec503aab42a8b8f16997e8a8a87 ceph_test_rados_api_snapshots_pp: drop unnecessary assertfc2a96638ddec2a9e1f5e16045adb71e816bc8c5 osd/OSDMap: SERVER_OCTOPUS feature bit is now significant647cfb460371b2f3255160d73d7432d41fcc0b9f osd: move scrub_purged_snaps to helper5b0ed6ff9e10fbbe70c789796099223a38996401 osd: automatically scrub purged_snaps every deep scrub intervaladacc20046c5f3a96b59df3fe01f9764e8437156 ceph_test_rados_api_tier_pp: tolerate ENOENT or success from deleted …b17850a6653f2f5870907ee54c72955735ffc84a","categories":[{"name":"专业","slug":"pro","permalink":"https://sean10.github.io/categories/pro/"}],"tags":[{"name":"ceph","slug":"ceph","permalink":"https://sean10.github.io/tags/ceph/"},{"name":"snap","slug":"snap","permalink":"https://sean10.github.io/tags/snap/"}]},{"title":"hexo更新并配置gh_action","slug":"hexo更新并配置gh-action","date":"2023-03-17T16:18:47.000Z","updated":"2023-05-15T16:19:14.862Z","comments":true,"path":"2023/03/18/hexo更新并配置gh-action/","link":"","permalink":"https://sean10.github.io/2023/03/18/hexo%E6%9B%B4%E6%96%B0%E5%B9%B6%E9%85%8D%E7%BD%AEgh-action/","excerpt":"","text":"本地适配最新版hexo 配合action操作 修改action 12git push origin --tags 或者直接找相对路径 Workflow syntax for GitHub Actions - GitHub Docs 处理成功之后, 相对还是比较简单的? 当前版本包 123456789101112131415161718192021&quot;hexo&quot;: &quot;^4.2.1&quot;,&quot;hexo-asset-image&quot;: &quot;^1.0.0&quot;,&quot;hexo-deployer-git&quot;: &quot;^0.3.1&quot;,&quot;hexo-douban&quot;: &quot;^0.2.9&quot;,&quot;hexo-generator-archive&quot;: &quot;^0.1.5&quot;,&quot;hexo-generator-category&quot;: &quot;^0.1.3&quot;,&quot;hexo-generator-feed&quot;: &quot;^2.2.0&quot;,&quot;hexo-generator-index&quot;: &quot;^0.2.1&quot;,&quot;hexo-generator-json-content&quot;: &quot;^3.0.1&quot;hexo-generator-tag&quot;: &quot;^0.2.0&quot;,&quot;hexo-inject&quot;: &quot;^1.0.0&quot;,&quot;hexo-migrator-rss&quot;: &quot;^0.1.2&quot;,&quot;hexo-renderer-ejs&quot;: &quot;^0.3.1&quot;,&quot;hexo-renderer-less&quot;: &quot;^1.0.0&quot;,&quot;hexo-renderer-pandoc&quot;: &quot;^0.2.2&quot;,&quot;hexo-renderer-stylus&quot;: &quot;^0.3.3&quot;,&quot;hexo-server&quot;: &quot;^0.3.1&quot;,&quot;hexo-symbols-count-time&quot;: &quot;^0.3.2&quot;,&quot;hexo-util&quot;: &quot;^1.9.1&quot; 以前引入了这些组件, 待会升级时需要处理 更新插件 123npm install -g npm-upgradenpm-upgradenpm udpate --save _config.yml更新 external_link deprecated 更改格式为以下 123456external_link: enable: true field: site exclude: [] 更新theme版本 比如indigo更换scarqin/hexo-theme-indigo: 维护 hexo-theme-indigo 自用 style.css 渲染失败 12ERROR Asset render failed: css/style.cssUnrecognised input 发现style.css是空的 说明less生成失败了 折腾了半天, Valine.less文件有问题, 更新了上面repo里的文件就恢复正常了 图片链接都变成.io前缀的 根据该issue可知Package hexo-asset-image doesn't return correct image path · Issue #4930 · hexojs/hexo, 是用了过时的hexo-asset-image引起.卸载即可. 通过Hexo: wrong address for meta and img tags - Stack Overflow 更换了另一个插件cocowool/hexo-image-link: 当MD中引用本地文件时，处理生成的html中的图片链接。解决的.","categories":[{"name":"专业","slug":"pro","permalink":"https://sean10.github.io/categories/pro/"}],"tags":[{"name":"hexo","slug":"hexo","permalink":"https://sean10.github.io/tags/hexo/"}]},{"title":"联调集成质量小思","slug":"联调集成质量小思","date":"2022-10-29T17:01:47.000Z","updated":"2023-03-18T15:11:14.864Z","comments":true,"path":"2022/10/30/联调集成质量小思/","link":"","permalink":"https://sean10.github.io/2022/10/30/%E8%81%94%E8%B0%83%E9%9B%86%E6%88%90%E8%B4%A8%E9%87%8F%E5%B0%8F%E6%80%9D/","excerpt":"","text":"问题背景 写本文的背景, 主要来源于项目开发过程中的一些问题, 属于是十分影响进度的那类. 联调期间发现一些与约定接口文档不同问题, 导致存在的重新联调. 变更比例相对较大. 业务的开发/调试需要等待平台上游功能开发完. 如OS组和集群组的平台功能完毕后, 依赖这俩部分提供的基础系统与数据库的业务组件方能开工. 这部分过程中, 其他组其实无法投入这部分的开发. 但是联调又基本就是同一时间各个组之间开展的. ceph与业务层SAN/NAS之间的联动测试. SAN/NAS依赖ceph的实施能力 新架构下, 尝试通过更高的功能需求, 对老代码进行重构. 所需耗时就不单纯是开发的时间了. 问题理解 1. 需求/设计变更 这点, 个人理解只能是期望个人设计能力以及评委的用心程度了. 确认功能与需求全覆盖 接口交互, 异常考虑周全 清楚代码的历史包袱, 准备/沟通好变更. 这里倒是有个需要注意的, 模块与设计应当是匹配的. 后续其实迭代模块, 这些设计也是应该保留下来的. 仅在项目流程中出现一次, 后续这个设计就不再维护迭代, 可能不太好. 2. 基于平台的业务功能的开发过程 一个新增业务功能, 需要平台提供新功能支持, 而后业务部门方可开始开发. 目前采用的方式是, 业务小组的该功能相关的负责人会参与平台部门提供的业务功能配置的填写. 需求方面, 参与度较少. 主要还是架构师与平台功能组澄清功能. 从这个角度, 业务小组在这个开发过程的参与, 一般出现在平台功能组输出了 规格文档, 平台功能组需要各业务组开始使用, 调试. 然后联调阶段. 然后在联调阶段, 业务团队会发现平台团队的功能/环境存在的问题, 此时平台方面开始处理修复. 然后继续联调. 按照缺陷单和最终的输出上肯定是一样的. 但是是否可能通过分批上车, 让平台功能的稳定性也能通过完整的闭环流程予以通过呢? 这种情况下, 业务部门此时是否更适合作为需求方? 而不是单纯的平台部门的联调方? 从上面的描述来看, 其实一开始就参与也可以. 但是, 实际执行过程中, 业务小组实际上在一开始阶段没有怎么投入人力, 但是基于项目管理的统计时, 由于需求并不区分平台功能, 还是业务功能, 此类需求最终统计人力资源消耗时其实也是将业务团队在一开始纳入了考量的. 而实际, 这个功能是初期平台功能组投入, 后期各业务组投入. 所以这部分, 可能按照[^## 5. 多任务同时派发 与 分批次派发]拆解成分批次的需求, 可能更为恰当? TODO: 是否平台功能与业务功能, 是需要拆分的? 需求方面也应该区分对待? 简单搜了下, 没搜到此类的区分. 在多团队组织中, 是否确实是有必要区分处理? 3. 组装开源组件时的集成测试 部署类代码 ceph产品的cluster-&gt;osd-&gt;pool-&gt;rbd|cephfs|rgw-&gt;iSCSi|nfs|samba的部署就是一个链式关系, 这部分角度上来说, 关键是开源组件之间的接口依赖关系的联调测试的问题. 根据ceph-ansible的情况来看Test Scenarios — ceph-ansible documentation, 是通过vagrant搭建虚拟机, 然后拉起不同规格虚拟机来测试集群部署. vagrant根据测试功能所需配置拉起对应盘的虚拟机, 然后运行. 1234567891011121314151617181920212223242526272829303132333435NOSDS = settings[&#x27;osd_vms&#x27;]...(0..NOSDS - 1).each do |i| config.vm.define &quot;#&#123;LABEL_PREFIX&#125;osd#&#123;i&#125;&quot; do |osd| osd.vm.hostname = &quot;#&#123;LABEL_PREFIX&#125;osd#&#123;i&#125;&quot; if ASSIGN_STATIC_IP osd.vm.network :private_network, ip: &quot;#&#123;PUBLIC_SUBNET&#125;.#&#123;$last_ip_pub_digit+=1&#125;&quot; osd.vm.network :private_network, ip: &quot;#&#123;CLUSTER_SUBNET&#125;.#&#123;$last_ip_cluster_digit+=1&#125;&quot; end # Virtualbox osd.vm.provider :virtualbox do |vb| # Create our own controller for consistency and to remove VM dependency unless File.exist?(&quot;disk-#&#123;i&#125;-0.vdi&quot;) # Adding OSD Controller; # once the first disk is there assuming we don&#x27;t need to do this vb.customize [&#x27;storagectl&#x27;, :id, &#x27;--name&#x27;, &#x27;OSD Controller&#x27;, &#x27;--add&#x27;, &#x27;scsi&#x27;] end (0..2).each do |d| vb.customize [&#x27;createhd&#x27;, &#x27;--filename&#x27;, &quot;disk-#&#123;i&#125;-#&#123;d&#125;&quot;, &#x27;--size&#x27;, &#x27;11000&#x27;] unless File.exist?(&quot;disk-#&#123;i&#125;-#&#123;d&#125;.vdi&quot;) vb.customize [&#x27;storageattach&#x27;, :id, &#x27;--storagectl&#x27;, &#x27;OSD Controller&#x27;, &#x27;--port&#x27;, 3 + d, &#x27;--device&#x27;, 0, &#x27;--type&#x27;, &#x27;hdd&#x27;, &#x27;--medium&#x27;, &quot;disk-#&#123;i&#125;-#&#123;d&#125;.vdi&quot;] end vb.customize [&#x27;modifyvm&#x27;, :id, &#x27;--memory&#x27;, &quot;#&#123;MEMORY&#125;&quot;] end 根据ceph-ansible和openEuler的做法来看, 部署类代码均藉由对虚拟机的控制的CICD来完成质量保障. 这些操作, 关键是属于资源的调度, 如果撇去虚拟机提供的资源, 实际上就无法测试到其对虚拟机内的硬盘等资源的实际分配了. 如果是分配逻辑贴近业务, 则可以比如mock不同的配置进行单元测试, 输出的也是一种配置形态. 但是如果分配逻辑关键就是对虚拟机操作系统提供的基础API的兼容性确认, 则就只能是藉由CICD完成质量闭环了. IO路径的核心逻辑代码 SAN/NAS对ceph存在依赖关系, 而ceph如果做大规模升级, 经常会出现不兼容的问题, 此时SAN/NAS基本上就很难在ceph适配开发的同时, 同时使用新版本进行开发. 开发阶段, 手动搭建ceph环境即可. 联调/集成阶段, 理论上下层接口如ceph自身的单元测试完成了一定程度的保障, 剩下产品层面的完整功能集成这种确实只能依赖CICD. 管理的web前后端代码 后端 当前我们的web后端, 是直接依赖底层的具体响应, 属于协议转换层. 而不是存在自身数据库设计的一个完整的管理平台后端, 因此个人来看确实无法脱离底层接口与操作系统, 自身进行这个web后端的业务逻辑的单元测试. 此时的话, 确实只能在底层开发完毕后, 通过CICD来闭环自身的质量. 如果是一个独立的后端, 底层只是作为一层数据来源, 以及具体实现层. 底层异常时, 其实不影响页面的数据展示与交互. 只是下发的请求会超时/失败. 但是不影响查询和展示. 这种层面的模块可能才能完成自身的单元测试吧. 前端 前端模块主要就是依赖后端提供的协议设计了, 本身就具有mock能力. 协议设计变了, mock也要跟着变. 可能存在一方面因素就是, 由于目前CICD不完善, 后端在开发过程中极度依赖底层的接口, 底层接口的设计变更导致链路的变更. 从而工作量加大. 本身如果做好了解耦, 可能前端,后端,底层三层之间不至于耦合这么紧密. 4. 藉由新版本需求, 同时进行功能开发 按照我现在的理解, 一般情况下感觉因为有版本的功能需求, 比如支持集群规模, 性能等存在了更高的要求, 所以此时可以抛弃一大波历史包袱, 从而进行代码重构. 但是客观上, 实际进行的过程中也确实遇到了很严重的问题. 代码的重构开发, 实际上需要的时间要比预估的多不少. 重构是在项目整个过程当中的一种习惯，并非是其中的一个阶段。 不要定下一两周时间，说这个工作是重构。应该在整个项目过程当中，随时开始，随时停止。每一次重构都是很细微。 [^在感觉项目代码的构架不行的时候,你们会怎么办? - 知乎](https://www.zhihu.com/question/47283785) 按照上文的表达, 其实一些工作, 可能不能在新项目上进行. 而应该提前或者在日常过程中, 就开展了. 新项目只做一个局部适配或者切换版本的工作, 这样可以相当程度上降低需要的时间代价. 5. 多任务同时派发 与 分批次派发 其实还是任务并行的问题, 如果是单纯的开发需求, 那实际上开发时已有初稿设计, 如果大家都提前定义后, 那确实后面开发的时间就无所谓, 互相之间没有依赖. 但是对于一些新定义的平台需求, 他基础平台开发完-&gt;自测通过-&gt;联调通过, 这个过程中其实是存在需要拉其他业务团队来设计, 沟通, 联调的. 而此时, 这就对其他团队的时间做出了限制, 这个阶段的时间由于要配合平台需求的落地, 就只得拆解部分时间. 这方面是否对于业务团队, 是否有必要那么快开始? 这个其实我现在来看, 还是个疑问. 考虑的可能的解决方式 分批次需求, 拆分轮次. 如平台功能, 提前进入. 如B1/B2轮次等, 其他相关依赖第一波平台功能开启. 需求的数量级太大, 局部拆解. 如需要长时间预研的, 则纳入预研项目跟进进展. 在新项目的第一轮需求中不纳入考量. 不能直接让多个资源组同时处理大批量需求, 这样就完全取决于资源组的人力协调. 这个协调成本每个阶段核对都会存在忽视风险. 比如OS组的包管理机制, 提供基础环境这种, 更适合提前开始. 至少先提供出基础框架/可供开发的基于老版本的兼容性方案. 如3-4月份优先复用老成果物提供基础方案也行. 并行任务最好一个人同一时间不要超过3个? 工作流, 要拆解的更加细. 否则上下文切换带来的切换时间/环境准备时间等可能也会占用一部分? 项目中明确分批次验收, 甚至分子项目验收. 每个轮次出的成果物, 后续的人需要审核审批, 审批的人的时间管理由项目经理控制. 因为每个组阻塞一阵子, 上下游链路太长. 就仿佛ceph的链路一样, 对于不知晓常见问题的人, 就只能一层层推进. 而不是一步到位. TODO TODO: 这款其实是可以参考下开源社区如何处理这部分的? ceph的话, 这部分其实是通过qa集成测试完成的? TODO: 持续集成/基线开发, 这部分应该跟测试所需的代码之间的解耦无关吧? TODO:ceph-ansible的测试是怎么跑? 是否要做隔离? 企业集成[^【网站架构】中大型网站如何防止项目延期？敏捷开发在实际项目如何应用？\\_停止重构的博客\\-CSDN博客] 这里说的集成, 跟集成测试应该关联并不大. 跟ERP系统也有些关联. 指的是企业内的组件功能之间的集成好像. 类似大中台的那种理解? 由中心代理服务来管理各组件之间的通信. 更进一步就是 基于消息的企业服务总线, 将组件之间关联通过一条总线完成管理 当然这种管理机制, 如果总线不出问题的情况下, 延时可接受的情况下问题不大. 猪油最新的那种RDMA等技术, 对延时有要求时, 则物理总线会进行处理. ESB 的定位，是一项采用开放标准的服务。这样就不需要为每个应用编写唯一的接口了。 只需对应用进行最小幅度的更改，就能部署集成服务。 ESB 依靠符合行业标准的开放协议和接口，简化新的部署。 [^【网站架构】中大型网站如何防止项目延期？敏捷开发在实际项目如何应用？\\_停止重构的博客\\-CSDN博客](https://blog.csdn.net/Daniel_Leung/article/details/122347803) OpenEuler 日常构建测试范围 QA: QA repo provides rules about how QA team runs and how contributors to this project, also includes test cases and framework alpha版本 安装部署 我们比较关心的项 软件包安装/卸载 组件测试(内核/虚拟化/容器/编译器等) 系统集成类 系统服务类(登录/防火墙/分区/服务状态检查/日志/kdump) beta版本 冒烟测试内容 新需求/特性功能验证 性能测试 升级 社区众测 TODO:beta由qa团队组织, 是否会保存类似系统测试用例设计呢? 这种是否有资料可以借鉴? release β版本测试内容 压力稳定性测试 安全测试 兼容性测试 文档测试 软件包 测试标准 基本总结可以理解为, 是基于mugen: Test framework and test suites框架, 对软件包提供的CLI接口进行测试验证, 并完成安装卸载的. 有无痕要求. TODO:潜在的问题, 如何解决那种依赖较多的包? 如ceph? 暂未找到 开源实习经验分享：openEuler软件包加固测试 测试代码 openEuler/integration-test - 码云 - 开源中国 系统基础包/命令的集成测试","categories":[{"name":"专业","slug":"pro","permalink":"https://sean10.github.io/categories/pro/"}],"tags":[{"name":"项目","slug":"项目","permalink":"https://sean10.github.io/tags/%E9%A1%B9%E7%9B%AE/"},{"name":"流程","slug":"流程","permalink":"https://sean10.github.io/tags/%E6%B5%81%E7%A8%8B/"}]},{"title":"vscode之markless二次开发","slug":"vscode之markless二次开发","date":"2022-08-16T13:58:15.000Z","updated":"2024-12-01T07:22:31.107Z","comments":true,"path":"2022/08/16/vscode之markless二次开发/","link":"","permalink":"https://sean10.github.io/2022/08/16/vscode%E4%B9%8Bmarkless%E4%BA%8C%E6%AC%A1%E5%BC%80%E5%8F%91/","excerpt":"","text":"理解 markdown是有对应的标准的. 似乎这篇可以参考? 下面todo中提到的一些list的识别场景, 其实这篇spec有做一定的边界澄清? CommonMark Spec 中文版CommonMark Spec 单元测试 TODO:针对vscode渲染后的页面, 如何进行单元测试感知? html的识别? TODO:针对vscode提供的API, 如何验证其渲染效果? Issue 搜索, 点到行后, 渲染的位置偏移跳转太严重了. 如何支持直接复制渲染后的内容? comments 现在 长期运行后, 似乎会出现资源占用问题, 卡顿 疑似是1.0.25这次这个增加自定义引起的这个问题 似乎是1.0.25去掉了memoize引起的. comments 现在老是自动弹出来. 右键了这个弹出来的comments的hide comments了, 不知道会怎么样. 无效 似乎 跟之前设置的Panel: Opens Maximized 设置有关 是否有持久化渲染的实现方式 vscode-markdown 看看? 新开的那种to-side的preview 窗口是否是? 如何区分切换文件和文件内编辑? * onDidChangeActiveTextEditor * 其实切换文件也不重要, 关键是感知到文件是第一次被打开就行? 似乎变量是持久化渲染的, 所以理论上是可以做计数器的? 插件的变量是全局的, 所以需要维护一张表, 打开的map, 占用这个内存? 而不是每次切换就打开一次? TODO: 这个可以作为功能处理吧? 如果需要频繁切换, 减少图片渲染的代价则处理. 纳入计划中. 每次切换文件, 为什么comment重新渲染时, 焦点位置就变了呢? 使用comment, 是否可以仅修改的图片变更渲染, 而其他的不变? 应该可以做到. 即使用内存来减少这部分切换 判定是文件刚切换带来的行切换事件,从而绕过这种渲染? TODO:指针判定里增加哪些位置未渲染的逻辑吧, 这样仅当指针出现在存在未渲染的页面时,才会对那些位置进行渲染. 其他情况下指针的迁移, 不触发渲染. 报错 Error setting up request: SyntaxError: Invalid regular expression: /*.md/: Nothing to repeat, 忽然就无法渲染了 会出现图片重复渲染的情况 好像就是在那几行写新的对象, 那个comment并没有自动被换行符往后推. 好像就是在图片渲染那行上面, 敲回车, 会逐渐走到图片下面去. 而不是让图片切换行? 这个所以应该是我这个插件处理的问题吧? 是否可以从comment切换成其他的来进行渲染? 既然html都支持的话. 偶尔会出现某个单元没渲染的情况似乎... TODO: 打开文件, 好像如果不点一下其他位置, 好像还不会触发渲染? TODO:support data src image preview page jump when switch to other file and back. maybe image preview's problem 可能只要不点到那里, 就不触发图片重新渲染更加合适? 但是如果是批量位置修改呢? 被选中的时候再重新渲染? 主要涉及需要重新渲染的时候, 应该是用户点击那行的时候. 但是每次切换的时候, 实际上会触发一次 搞个索引存储吧, 每行尽量只渲染一次吧. 渲染完, 如果没有选中, 就不再触发? state.activeEditor.document.lineAt来存储, 好像不太行? 怎么把一行里所有的内容都存储进去呢? 以range为范围? 然后通过一张map记录? 为了减少时间复杂度? 如果open触发的不是onDidChangeActiveTextEditor这个的话, 其实把这个关闭就可以了? 切换文件的时候, onDidChangeTextEditorVisibleRanges这个也被触发了. 关键问题是, 图片的渲染应该是我在切换页面之后发生的, 所以导致页面上滑了... 应该是其中初始化置空那次的问题. 但是onDidChangeActiveTextEditor感知不到每个文件是第一次打开, 所以导致其实切换 ImageComment的高度固化有可能不 到底是因为切换走了, 导致渲染全部没了, 还是说只是代码里的因素呢?Comment 记错了, 不是以文本为单位的. 还是以进程为单位的, 也就代表确实需要一个线程处理所有的markdown文件渲染了...这种情况下, 也就是最好uri也保存一下map... TODO: 图片是在线程里, 开了一张map. createCommentThread 确实是离开的时候, 触发了dispose图片引起的? 好像不清理线程, 就会出现图片重复被塞进渲染线程里的情况? 好像每次都会被push进去的原因是Range对象是不同的? 在string化的时候, 也是可变的. 是不是因为这个导致不同? 不对啊, 我维持了一张rangeMap, 那不应该出现那个不匹配的问题才对啊. 临时变量的地址应该是不同的, 所以最好转换一下成string? 奇怪, 怎么每次每个对象都触发了2次呢? 另外, 这个列表应该会触发几次, 理论上这张map里应该有3个或者以下的对象才对. 试了下, 官方的comment-sample也会触发这个跳变的情况. 所以这里其实要解决的历史已经渲染的, 实时渲染的问题? 图片渲染不支持webp格式, 也可能是本地file协议不支持? (官方已合入支持) MarkdownString cannot render webp image · Issue #144188 · microsoft/vscode 但是markdown all in one的preview是支持的, 所以可能我的用法不太对? 看了下这个库里只是调用了官方的markdown.showPreviewcommand, 所以可能得看官方的里是怎么渲染webp的 &lt;img src=\"../imgs/leveldb3.webp\" alt=\"\" class=\"loading\" id=\"image-hash--205375520\" data-src=\"../imgs/leveldb3.webp\"&gt; addImageRenderer, 官方使用的MarkdownIt触发的image渲染应该. 那问题就是这个,MarkdownString并不是用的MarkdownIt, 走的两套代码方案实现的? 看官方怎么回复吧. yes~就是一开始发现的那个private readonly validExtensions = new Set(['.svg', '.png', '.jpg', '.jpeg', '.gif', '.bmp']);这里加上就支持了. 疑似某种文件格式下的bug 1234`TypeError: Cannot read property &#x27;start&#x27; of undefined`at vscode-file://vscode-app/Users/sean10/.vscode/extensions/sean10.markless-sean10-1.0.24/out/main.js:53 at Generator.next (&lt;anonymous&gt;) at o (vscode-file://vscode-app/Users/sean10/.vscode/extensions/sean10.markless-sean10-1.0.24/out/main.js:1) 那个租房的文章里的. performance问题, 总觉得输入的时候稍微有一点卡顿的现象 TODO:有没有能够精确的profile我的插件的实际cpu占用时间呢? 有点怀疑是我引入的那个log库占用的资源. image渲染后默认显示大小不是配置的Panel: Opens Maximized createCommentThread这个接口操作的. panel应该属于comment的父类的感觉. collapsibleState目前已经设置了Expand了. 所以问题是, expand的panel的默认加载模式? 所以, 其实需要知道的是, 什么时候他才读取Panel: Opens Maximized里的变量. private panelOpensMaximized() &#123;似乎是在这里控制? toggleMaximizedPanel 这个函数为什么默认触发的始终是temrinal的呢? TODO:这个变量哪次提交引入的呢PANEL_OPENS_MAXIMIZED, 是不是我用错了? 是不是可以像人为手动折叠一次一样, 自动完成, 这样就能放大成最大化的了. 不行, 试了下, 通过属性设置的Expanded依旧是部分图片状态. 所以关键还是在这个手动折叠展开, 用的哪个函数了. A collection of comments representing a conversation at a particular range in a document. Comment这个类型似乎还有edit和preview模式. 不过初步看与这个问题的解决方案无关, 可能如果官方不提供api, 那就得更换comment以外的方案? table不识别插入的&lt;br/&gt;问题 代码里用的remark-gfm的渲染, 理论上不应该存在这个问题才对?. 试了下demo, 似乎是remark-gfm的问题? 难道是&lt;br/&gt;不符合gfm标准? 123456789101112async function main() &#123; const file = await unified() .use(remarkParse) .use(remarkGfm) .use(remarkRehype, &#123;allowDangerousHtml: true&#125;) // .use(rehypeSanitize) .use(rehypeStringify) .process(data) fs.writeFileSync(&quot;output.html&quot;, String(file)) // console.log(String(file))&#125; 根据HTML blocks inside table cells not treated as blocks · Issue #10 · remarkjs/remark-gfm找到设置允许危险的方式, 可以渲染html 看来还是那个XSS的风险, 所以导致默认关闭了. 并不是remarkGfm的问题. 所以我也可以增加这个属性, 默认关闭即可. 这里作者用的不是remark系列的了, mdast-util-to-hast和hast-util-to-html应该是remark-rehype的前身. 在toHast和toHtml处, 都打开这个&#123;allowDangerousHtml: true&#125;就可以了. 但是的确危险系数还是比较高的. 之后考虑直接更换为remark-rehype. 启用了2个危险属性之后, 变成空白了... 应该是svg没有渲染出来把? 开了debug之后, 可以看到确实html的AST是有的, 应该就是svg渲染的问题了. 确实, 是&lt;br/&gt;在被转换后变成了&lt;br&gt;, 导致不符合svg语法了. 符合语法之后就正常了. 我把这个作为一个选项开启吧. TODO: 原生HTML的渲染能力 在打开了这个allowDangerousHtml之后, 也变得可以实现了 现在遇到的问题是, 理论上&lt;h1&gt;的样例, 应该能显示出来才对, 但是没进入到html的node解析逻辑里... 看起来是remark这个解析库拦截掉了? 并没有, 单独打印出AST还是有的, 但是的确进不到那个内部逻辑了现在. 带结局 quote之后的内容导致卡顿 疑似是我行的长度过长之后的渲染就会比较卡顿? 至少滚动就不流畅了. 应该是blockquote这段的. 但是卡顿这个我怎么排查是哪的呢? 好像是css切换那块的. 我把filter换掉能不能解决呢? 去掉filter的渲染之后就正常了. 拆分无序列表和有序列表的渲染 理解 state.offset用途? ListItems是哪里得到的type? 好像某个第三方库的, 不是这套代码里的. 搜一下. 疑似是来自这段的. 12345const parser = require(&#x27;unified&#x27;)() .use(require(&#x27;remark-math&#x27;)) .use(require(&#x27;remark-parse&#x27;)) .use(require(&#x27;remark-gfm&#x27;)) .parse; 嗯, 没错, 应该是remark这个markdown解析库里的listitem. 怎么区分有序列表和无序列表呢? 根据下面这段, 一开始type为list, 具有ordered属性, children中才是具体的列表内容. 所以如果要改, 预计需要在判断listitem前就进行区分处理. 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110&#123; &quot;type&quot;: &quot;list&quot;, &quot;ordered&quot;: true, &quot;start&quot;: 1, &quot;spread&quot;: true, &quot;children&quot;: [ &#123; &quot;type&quot;: &quot;listItem&quot;, &quot;spread&quot;: false, &quot;checked&quot;: null, &quot;children&quot;: [ &#123; &quot;type&quot;: &quot;paragraph&quot;, &quot;children&quot;: [ &#123; &quot;type&quot;: &quot;text&quot;, &quot;value&quot;: &quot;First&quot;, &quot;position&quot;: &#123; &quot;start&quot;: &#123; &quot;line&quot;: 71, &quot;column&quot;: 4, &quot;offset&quot;: 437 &#125;, &quot;end&quot;: &#123; &quot;line&quot;: 71, &quot;column&quot;: 9, &quot;offset&quot;: 442 &#125; &#125; &#125; ], &quot;position&quot;: &#123; &quot;start&quot;: &#123; &quot;line&quot;: 71, &quot;column&quot;: 4, &quot;offset&quot;: 437 &#125;, &quot;end&quot;: &#123; &quot;line&quot;: 71, &quot;column&quot;: 9, &quot;offset&quot;: 442 &#125; &#125; &#125; ], &quot;position&quot;: &#123; &quot;start&quot;: &#123; &quot;line&quot;: 71, &quot;column&quot;: 1, &quot;offset&quot;: 434 &#125;, &quot;end&quot;: &#123; &quot;line&quot;: 71, &quot;column&quot;: 9, &quot;offset&quot;: 442 &#125; &#125; &#125;, &#123; &quot;type&quot;: &quot;listItem&quot;, &quot;spread&quot;: false, &quot;checked&quot;: null, &quot;children&quot;: [ &#123; &quot;type&quot;: &quot;paragraph&quot;, &quot;children&quot;: [ &#123; &quot;type&quot;: &quot;text&quot;, &quot;value&quot;: &quot;Second&quot;, &quot;position&quot;: &#123; &quot;start&quot;: &#123; &quot;line&quot;: 73, &quot;column&quot;: 4, &quot;offset&quot;: 447 &#125;, &quot;end&quot;: &#123; &quot;line&quot;: 73, &quot;column&quot;: 10, &quot;offset&quot;: 453 &#125; &#125; &#125; ], &quot;position&quot;: &#123; &quot;start&quot;: &#123; &quot;line&quot;: 73, &quot;column&quot;: 4, &quot;offset&quot;: 447 &#125;, &quot;end&quot;: &#123; &quot;line&quot;: 73, &quot;column&quot;: 10, &quot;offset&quot;: 453 &#125; &#125; &#125; ], &quot;position&quot;: &#123; &quot;start&quot;: &#123; &quot;line&quot;: 73, &quot;column&quot;: 1, &quot;offset&quot;: 444 &#125;, &quot;end&quot;: &#123; &quot;line&quot;: 73, &quot;column&quot;: 10, &quot;offset&quot;: 453 &#125; &#125; &#125;, todo: extension.js里start和end和node这几个参数哪里传进来的呢? 现阶段传入的每个node, ordered属性并不在单个上面. 预计需要改成三层 list chilren listItem children paragraph 无序的则是 * listItem * chilren * paragraph 或者 * listItem * children * paragraph * list * children * listItem * children * paragraph 存在多层关联的这种.不能直接以node的type来区分了. 这个节点的遍历关系? 是DFS还是BFS? 目前并没有找到 增加http链接图片支持 只是单纯的增加http的schema的透传就可以, 剩下的交给vscode自身支持 似乎支持了?1.62里? MarkdownString.supportHtml The new supportHtml property on MarkdownString enables rendering of a safe subset of raw HTML that appears inside the Markdown text. The supportHtml property defaults to false. When disabled, VS Code will strip out any raw HTML tags that appear in the Markdown text. 修复latex显示的渲染结果太小的问题 用Elements定位了下, 实际上是svg渲染的图片的渲染尺寸不对. 大致是通过 html/svg+xml base64 渲染 svg. 通过在ebfore元素里增加url的content. 把SVG代码直接内联在CSS的url()方法中 这个逻辑里可能之所以会根据行的数量来决定要渲染的长度, 应该是为了确保不会点到后面的空行, 结果触发的是这行的内容? 这个的做法是不是弄成自动收缩这几行更好? mermaid的图也有同样的问题. 分析lineHeight 首先, 我的配置中默认lineHeight是设置为0的, 所以走的下面这个逻辑 Use 0 to automatically compute the line height from the font size. Values between 0 and 8 will be used as a multiplier with the font size. Values greater than or equal to 8 will be used as effective values. 根据这个, 所以跟font size应该是成成比例的. 1234567const lineHeight = vscode.workspace.getConfiguration(&quot;editor&quot;).get(&quot;lineHeight&quot;, 0);// https://github.com/microsoft/vscode/blob/45aafeb326d0d3d56cbc9e2932f87e368dbf652d/src/vs/editor/common/config/fontInfo.ts#L54if (lineHeight === 0) &#123; state.lineHeight = Math.round(process.platform == &quot;darwin&quot; ? 1.5 * state.fontSize : 1.35 * state.fontSize);&#125; else if (lineHeight &lt; 8) &#123; state.lineHeight = 8;&#125; 的确, 发现这段代码这里lineHeight只得到了2, 大概是这里写错了. 可能作者不是darwin平台的, 所以感知不到. 多行的latex除了按行数整比放大代码之外, 是否有正常的方式折叠到那几行? collapse folding FoldingRange registerFoldingRangeProvider Todo:怎么找不到javascript如何使用FoldingRangeProvider的呢... 使用方式类似下面这样: 123456789context.subscriptions.push(vscode.languages.registerFoldingRangeProvider(&#x27;markdown&#x27;, &#123; provideFoldingRanges: (document, context, _) =&gt; &#123; console.log(document.languageId); console.log(&quot;try to folding range&quot;); let ranges = [] const temp = new vscode.FoldingRange(1, 50, vscode.FoldingRangeKind.Comment); ranges.push(temp); return ranges &#125;&#125;)); context.subscriptions.push如何理解? 是不是这个只是用在当我即将触发folding的时候, 才会进入这个函数逻辑? 确实, 比如我设置kind为Comment的时候, 触发Fold all comments就能够把我标记的范围给圈起来. 所以自动圈, 应该不是这个函数 fold/unfolder API? 目前根据这个[folding] API for programmatically folding lines · Issue #37682 · microsoft/vscode来看似乎是不存在的. 根据Built-in Commands | Visual Studio Code Extension API这篇里的editor.fold 发现还是文档里没写清楚参数的数据结构, 搜代码样例从这里找到的autofold/extension.ts at c721aa8b616060624b107cbdd44c44ec4827adec · TigerGold59/autofold 实际使用方式是类似这种 1vscode.commands.executeCommand(&#x27;editor.fold&#x27;, &#123;&quot;selectionLines&quot;: [1]&#125;); wrod wrap折叠后的后面几行开头无渲染效果 比如quote的特殊符号仅第一行有. 修复When the cursor is in the line of heading, should it show '#' at the begining of the line? · Issue #10 · Sean10/markless 2组rangeBehavior目前没有办法合并. 当处在中间时, 没有办法让左侧的识别到右侧的参与. 左侧的隐藏, 右侧的需要放大 鼠标在这行上时, 希望所有效果全部取消. 直到cursor离开该行 目前效果: 右侧的渲染: 鼠标在行末, 取消了放大效果. 鼠标在heading的左侧离开时, 重新恢复放大效果 左侧的渲染: 鼠标在行末甚至heading期间, 依旧不显示 指针直到接近#的范围, 才取消隐藏. 考虑增加一个覆盖的操作, 当鼠标出现在这个范围内, 取消所有的装饰器. 但是条件必须是这个触发效果在最后. 从而覆盖掉另外俩装饰效果. 考虑咨询下这个的效果兄弟萌，让我们在 Vscode 里放烟花吧 - 51CTO.COM 似乎他对这个range使用比较熟练. 如果我这个后加, 应该就有效了把? A TextEditorDecorationType is a disposable which can be removed/releaded by calling its dispose-method 好像有清理的逻辑? 我先试试现在这套代码的pop逻辑?pop 不行, 我需要的是清理掉对应的decoration. 而不是现在的这种. 可以考虑增加一个清理掉所有的css的装饰, 在鼠标在上面时触发, 离开时, 这个效果被清理掉. 如果用dispose, 那所有的装饰器的变量也释放了, 如果要用这个, 那就必须要把每个heading 维护一个单独的装饰器, 否则就一起被释放了. 所以最好是有一个disable的方法, 比如从队列里去掉这个. 可能维护一张map, 或者这个列表里就自带了行号的属性, 这样就能够比较当前行是不是其中一个了. 官方的2个方法:Remove decoration type · Issue #22 · microsoft/vscode-extension-samples &gt; option1 to nuke all uses of a certain decoration type across all editors is decType.dispose() &gt; option2 to nuke all uses of a certain decoration type in a single editor instance is editor.setDecorations(decType, []) 好像memoize这个函数还做了缓存加速. 好像代码里用的是offset, 而不是Range. 这样的话的确没有line属性了. 这是原生的decorationRanges的限制吗? 之前好像没看到这种要求. Range噢, 2种构造函数而已. todo:成功了. 不过好像enlarge那个, 因为指针一移动, 又加回去了的样子? 这个明天再修一下. heading的字体放大, 似乎其实也可以接着放大. 好像行的高度, 会跟着我的指定的字体大小变大而变大 所以并不是我一开始理解的字体大小默认设置14, 这个行就只能容纳14的情况. heading的隐藏存在一个问题, 凡是在标题上触发的其他模式的渲染, 依旧会存在渲染错的问题, 清理可能需要考虑取消所有该位置的渲染. 是通过反查? 还是通过map出来之后, 检查? block quote存在2个渲染问题 位置, 依旧是按照未隐藏#来的 可能需要梳理一下, 这种怎么让多种模式能够复用一套清理逻辑? 怎么获取到对应的字的宽度呢? 毕竟不是以类型来显示node, 而是反过来拆解的. 是否可以引入关联性呢? 毕竟本身是存在children的概念的, 只是在子节点的时候, 不知道怎么访问到父亲节点的内容. 如果增加父亲节点的访问链接, 那就可以迭代父节点, 是否存在其他属性需要渲染了 ? 这样的话, 就可以按顺序一个个处理了? 这个好像其实就是迭代顺序? 只是后接收到的处理的数据依旧是原始数据, 而不是上级已经处理过后的数据? 目前是按照visit的顺序. 如果让每次visit之后, 使用的数据也进行更新呢? 这样的话, 其实会在原始的数据里增加好几个链接? 思路 修改visit之后, 使用的node数据来源? 或者增加基础属性? 比如font等? 修改数据结构? 从map改为链表关系? map之间其实是可以营造链表效果的. 暂时沿用之前那个修改listItem的思路, 直接在visite的时候, 把上层的depth赋给子节点. #### 暂时沿用之前那个修改listItem的思路, 直接在visite的时候, 把上层的depth赋给子节点. 目前存在的问题: 位置是移动了, 但是好像还有一层外圈没跟着移动? 怀疑不是inlineCode的装饰. 的确, 注释掉这个处理之后, 还存在. 怀疑是其他插件的. 确实, markdown_all_in_one里的... 那如果我解决了这个问题, 可能还需要考虑那边如何关闭? 毕竟挺多快捷键依赖那个的... \b先试试吧. 另外, 这里如果成功了, 还需要考虑inlineCode在进入该行时, 自动被消除的操作. 另外, 似乎大小也并没有跟着变... 优先尝试解决border的size的问题吧? Border do not match correctly if the font size if too big or small · Issue #33 · leodevbro/vscode-blockman 根据这个来看, 好像是根据lineHeight来的? 虽然fontSize大的时候好像把lineHeight也撑大了, 但是看起来border没有变. 根据这个的意思, 好像可以把fontSize调大, 然后影响border. 不过这块有点不理解, 为啥目前fontSize已经大了, 并没有正常呢? 试了下, 直接在元素上加border属性是能够按照字体大小扩大border的. 所以问题就在于现在背景上显示的border到底绑定在哪个元素上. 奇怪, 为什么全局搜索, 在html的这个总元素上搜到的呢? 而且调整一点用都没有... todo:现在的核心痛点就是怎么找到这个border的css设置. 不在默认点击找到的div属性里, 因为删掉该行依旧存在. 好像确实很难找到. 不知道chrome为啥有的css就找不到呢? 之后再看看 view-overlays? 终于一个个找找到的&lt;div class=\"cdr ced-1-TextEditorDecorationType10-0\" style=\"left:0px;width:36px;height:18px;\"&gt;&lt;/div&gt; .monaco-editor .ced-1-TextEditorDecorationType10-0 ced-1-TextEditorDecorationType10-0 奇怪, 这个class的css在哪? 手动逐个删除二分定位是找到了 但是在哪呢? vscode createTextEditorDecorationType view-overlays 什么情况下, 装饰器会被添加到一个独立的div里呢? 为啥不复用文本的那部分呢? export class ViewOverlays extends ViewPart implements IVisibleLinesHost&lt;ViewOverlayLine&gt; &#123; -&gt; ContentViewOverlays const contentViewOverlays = new ContentViewOverlays(this._context); export class View extends ViewEventHandler { 这里构造的时候就能看到了. contentViewOverlays.addDynamicOverlay(new CurrentLineHighlightOverlay(this._context)); contentViewOverlays.addDynamicOverlay(new SelectionsOverlay(this._context)); contentViewOverlays.addDynamicOverlay(new IndentGuidesOverlay(this._context)); contentViewOverlays.addDynamicOverlay(new DecorationsOverlay(this._context)); 怀疑进到不同的渲染里了? 好像view-overlays是属于标准的?不对 一个是view-lines 是我之前那几个元素的. view-overlays是那几个Css渲染的...基本上目前只看到border会进这里. Todo: 忽然想到一个猜测点. 由于html的正文始终只有一份, 会不会是如果对一个range存在多个css的装饰器, 则会把新增的装饰器添加到view-overlays里. todo: 但是理论上其实是可以做到识别用户插入的多个装饰器, 然后对Range进行拆分的吧? 拆分到比如以1个字符为单位, 然后重叠装饰器. 可以验证下, 是哪种. 这块不知道官方文档里有没有提到. emm, *和**并没有进入到view-overlays, 依旧在view-lines TODO: 还是说仅限于border这种参数才会被放到overlays? 尝试了, outline也被加到overlays里了, 而top虽然是同一个装饰器塞入的, 这个操作被放到了view-lines里. 所以初步怀疑是根据属性划分? 明明可以把border属性直接绑在对应的位置, 为啥非得拆到overlays里呢? 应该是了, 这行单纯只有border属性,同样也是被加在overlays范畴. 目前, 位置对上了. 但是因为和字体大小不匹配, 还是会存在丢失的情况. TODO:把判定当前行进入修改的逻辑封装为函数比较好. 在View构造的时候, 会构造ViewLines和ViewOverlays 好像是在registerThemingParticipant这里触发的? .monaco-editor .ced-1-TextEditorDecorationType10-0, 注册时应该是.ced-这个关键词 走的这个CSSNameHelper...这样的话, 就没 cdr呢? 具体的div上有这个class 在DecorationsOverlay的_renderNormalDecoration 是这条contentViewOverlays.addDynamicOverlay(new DecorationsOverlay(this._context)); ViewOverlays-&gt;prepareRender viewPart.prepareRender(renderingContext); 好像接下来就是ViewImpl里的触发渲染条件调用的了. 那现在问题就是那个border参数是什么时候被传递进来的了? 我应该使用的是createTextEditorDecorationType的state.activeEditor.setDecorations 一时这个好像没找到到底做了什么 从这里添加DecorationsOverlay啥都没找到, 直接用的const className = d.options.className!; let decorations: ViewModelDecoration[] = [], decorationsLen = 0; const _decorations = ctx.getDecorationsInViewport(); TODO:好像走到了这段_getDecorationsViewportData, 这里是不是就是我需要知道的区分border和textDecoration的地方? const renderingContext = new RenderingContext(this._context.viewLayout, viewportData, this._viewLines); 大小, 也是按照字体的初始大小, 而不是渲染后的大小来的. 是否能够感知当前行已经渲染的字体大小等参数, 然后基于这个做二次渲染呢? 毕竟完全是存在特效重叠的情况的. 翻了下文档, border好像没有size的调整属性. 那是否这个就是限制呢? 感觉不至于. 那猜测, 可能是因为decoration没有命中同一个区域. 所以没能采用到那个较大的size? 根据这篇Border do not match correctly if the font size if too big or small · Issue #33 · leodevbro/vscode-blockman跟我的现象一样 根据Get editor line height (px) and character space-width (px) by VSCode API · Issue #125341 · microsoft/vscode这个可以知道目前为止, 这个feature官方暂时不做. 批量处理当前行, 去除装饰器的效果 本来像统一用 12345678910111213const delDecorationIfCurrentLine = (node, decoration, start=0, end=0, ...others) =&gt; &#123; // console.log(&quot;decoration: &quot;, decoration, &quot;others:&quot;, others); if (node.position.start.line - 1 == editor.selection.active.line) &#123; delDecoration(state, decoration, editor.selection.active.line); &#125; else &#123; if (others.length &gt; 0)&#123; addDecoration(decoration(...others), start, end); &#125; else &#123; addDecoration(decoration, start, end); &#125; &#125;&#125; 但是遇到一个问题, 居然有的node没有position属性... table latex img link f5调试显示的效果, 和本地打包安装后不同. 不对, 1.0.17版本正常, 之后的版本和现在开发的版本都有问题. 1.0.18版本是否正常, 代表了是否我这个修改的思路是正确的... 奇怪, 好像是文件的问题 我这个文件的, node, 行号始终在400行以内显示. 而实际上我行已经到2000行了. 用remark跑了下, 是能到2000行的呀...为啥呢? 12345678910111213node: 221 &#123;type: &quot;heading&quot;, depth: 2, children: Array(1), position: &#123;…&#125;&#125;children: Array(1)0: &#123;type: &quot;text&quot;, value: &quot;有序列表下无序列表下有序列表&quot;, position: &#123;…&#125;&#125;length: 1__proto__: Array(0)depth: 2position:end: &#123;line: 222, column: 18, offset: 7909&#125;start: &#123;line: 222, column: 1, offset: 7892&#125;__proto__: Objecttype: &quot;heading&quot; 实际上是1569行, 为啥显示222行? 另外, 似乎此时的渲染速度慢了很多, 是不是因为那个遍历的操作? 是不是得内容优化 目前来看, 这个遍历的资源开销特别大, 达到用户会感知的层级了... 这块先优化成map再看吧. emm, map里最后存的不是地址, 而是这个range对象, 这样的话可能不太行. 除非我把所有的Range对象都做了单例模式? 奇怪, 我做了单例, 为啥还找不到呢? 好像一定情况下照不出来是正常的. 因为如果同一行有多个渲染, 那就找不到. 是不是因为decoration这个不是单例, 有好几次会创建新的? 这样的话, 就会导致我以为是同一个装饰器, 但是实际上这个装饰器是新的, 里面没有之前的 其实这样也没太大问题. 至少解释不了为什么第二次进这个函数, 底下就变成undefined了. 还真是一个全新的. 基于这个遍历的方案成功是成功了, 但是cpu占用太高. 而且试验了下, onDidChangeTextEditorSelection是可以捕获到当前的行的. 至于更进一步的思路再想想. 考虑只处理指定行? 选中范围内会自动触发, 在临界范围内, range取消的能力. 这就不存在资源消耗了. 所以可能得放弃根据行来判断的逻辑. 好像大佬在setDecorations这里做了实现? 123if (state.config.cursorDisables) &#123; ranges = ranges.filter((r) =&gt; !state.selection.intersection(r));&#125; 好像是利用这里更新range, 直接去除存在范围内的. 这样的话, 我只需要把行添加到这里, 也能起到一样的效果. 确实, 实现了. 关键是因为setDecoration这里做了一次循环遍历了, 所以导致我在那侧做的实现, 完全重复了. 出现了2重循环引起的. 但是那个##连带着这个一起放大的问题还是存在, 那就跟性能没关系了. (放弃)让索引位置与字符所在位置对应上? 不让其出现删除空格, 实际是删除了最后的文字的问题. 如何实现呢? 一种就是让由于存在被隐藏了空格的部分出现. 但是由于heading的特性是在于表头, 因此无法复现. 多现实2个'#'的问题, 意思hide异常 398行为什么在node中显示265? 为什么content打印出了list的项? 奇怪, 为什么日志里记录的行号, 并不是我当前看的这几行呢? 所以是渲染的范围有问题? 12const ms = new vscode.MarkdownString(latexElement); ms.isTrusted = true; 初步怀疑是这块构造部分的markdown这里出的问题. 1range = new vscode.Range(Math.max(range.start.line - 200, 0), 0, range.end.line + 200, 0); 好像是这里引起的, 所以按照这段的意思, 如果把我超过400行的json去掉.是不是就正确了? 好像还是不对. 还是怀疑这里的range存在问题. 12345678910&#123;type: &quot;heading&quot;, depth: 3, children: Array(1), position: &#123;…&#125;&#125;children: Array(1)0: &#123;type: &quot;text&quot;, value: &quot;作废的折叠代码.&quot;, position: &#123;…&#125;&#125;length: 1__proto__: Array(0)depth: 3position:end: &#123;line: 421, column: 13, offset: 11791&#125;start: &#123;line: 421, column: 1, offset: 11779&#125; 噢噢. 忽然意识到问题点了. 这里construct传入的是个相对路径, 但是我却去当做真实路径计算引起的问题. 奇怪, 为什么我必须用node, 而不是直接用 日志里记录heading的逻辑里会出现普通节点的行... 可能存在内存泄露, 由于装饰器的不断new. 清空也只是[], 并不是dispose. 有必要增加单例 TODO:存在单行由于字体过大, 没有自动换行的问题. 目前看到的实现, 是在vscode进入view-line的渲染之前就修改了字体大小等才行. 如果等到view-line建完之后, wrap已经结束了 TODO: 所以需要考虑是不是有什么API可以重新指定wrap. 或者重新根据我的渲染结果重新触发render的view-line. 可能也得看下wrap的实现代码有没有对应的接口. sometimes, 还是会出现#没被隐藏的问题. 1.0.22版本. 依旧存在'#'的复现条件, 似乎是切换Editor和切换其他文件的时候发生的. Illegal value for line 奇怪, 不是只要是整型就行了吗? 1234567mainThreadExtensionService.ts:64 Error: Illegal value for `line` at l._lineAt (vscode-file://vscode-app/Applications/Visual Studio Code.app/Contents/Resources/app/out/vs/workbench/services/extensions/node/extensionHostProcess.js:88) at Object.lineAt (vscode-file://vscode-app/Applications/Visual Studio Code.app/Contents/Resources/app/out/vs/workbench/services/extensions/node/extensionHostProcess.js:88) at updateSelectionToLine (vscode-file://vscode-app/Users/sean10/Code/markless/out/main.js:55935) at setDecorations (vscode-file://vscode-app/Users/sean10/Code/markless/out/main.js:55944) at runNextTicks (internal/process/task_queues.js:58) at processTimers (internal/timers.js:494) 最后定位到, 实际上还是editor切换的时候, 全局变量没有重新更新的问题,用了错误的editor了. 这样行号肯定是对不上的. 在heading处的 最后发现之前加的const editor = vscode.window.activeTextEditor;在切换editor时没能切换, 所以访问错文件的line了. TODO:疑似图片默认不会全放大状态, 通过Paste Image现加的渲染的时候, 需要收缩一次再点开才会按照我的配置进行? 包括切换editor的时候, 切换完好像也有问题, 除了关闭重新打开好像是正常的 TODO: 性能优化, 触控板滚动的时候, 有触发selection的变化, 或者什么的变化引起重新渲染吗? 增加日志动态调整记录. config修改的同步时间是什么时候呢? 我改完, 再切换回窗口, 我看到触发的还是原来的配置. config好像还有active那几个mermaid的逻辑要用到. 这里的俩registerWebviewViewProvider这个就不注册了把 小模块就不考虑按模块/功能拆分日志了, 直接手动过滤筛选吧. TODO: support env? Expose log level and log path to extensions · Issue #40053 · microsoft/vscode clearDecotaions里的对象找不到setDecoration, 初步怀疑是切换到非markdown的文件上, 出现的问题. 没能把函数取消掉. 部分listItem的无序列表的那个符号怎么好像没被添加上去? 隐藏了? 初步实验, 好像关键点是这行含不含有中文? 奇怪, 看起来decoration还是生成了的. 在addDecoration内部失败的, 目前初步怀疑是vscode版本升级引入的问题? todo TODO:可以通过MarkdownString来完成彻底的渲染html. 自带了这个能力 todo: 第一级有序列表无法被verified库解析出ordered的list属性. 所以这种得翻一下unified的API, 他的判断逻辑里, 如果只有一层, 那还具有列表属性吗? listItem应该也有区分前缀才对? todo: 遍历一层下述节点时, 第一级的node中包含了其内的子节点的属性. 然后会再次遍历其中的子节点. 所以这里会存在一个覆盖的效果. 目前来看只有text层级的position属性可以作为一个表来判定节点之间的关联. todo: 下属节点的遍历能力是否要进行区分? 可能没办法区分, 因为只有遍历进paragraph层之后才能知道其children是否是list还是listItem. todo: 如果我模拟的有序列表的数字并不连续, 是否还能判定为有序列表? 得看下unified代码. 如果这里可以让直接根据在每个node的属性那里就能区分出是ordered与否, 那就不用考虑状态机转移了. emm, 似乎根据现有代码, 可以直接利用正则手动处理. 虽然性能低一点. todo: 这里出现一个新问题, node的value里只有去掉了列表之后的内容, 现在导致我无法正则判断了. 怎么才能从解析后的node反得到对应的完整行呢? 虽然有range可以手动找到. Todo: 我似乎可以找到对应的level层级, 手动得到前面的地址, 然后通过range提取到值 根据上面的spec可知有序列表的开始数字由第一个列表项的数字决定，而不考虑 后面的列表项。 所以理论上remark应该直接解析出list的ordered属性才对? remark-parse主要用的syntax-tree/mdast: Markdown Abstract Syntax Tree format这个库来进行的解析. mdast这个库里只是文档? 那Remark这么多repo之间的关系到底是什么? unified代码里没搜到listItem, 重新推一下 123456const parser = require(&#x27;unified&#x27;)() .use(require(&#x27;remark-math&#x27;)) .use(require(&#x27;remark-parse&#x27;)) .use(require(&#x27;remark-gfm&#x27;)) .parse; 所以应该在remark-parse或者remark-gfm里. emm, remark-gfm下载下来和mdast一样是空的... unified.js和remark.js是什么关联? 如果单纯只是API聚合的话, 应该不值得赞助吧? 噢, 根据这篇An Introduction to Unified and Remark - Braincoke | Security Blog, remark看起来更像是unifed的下属子集能力. 1import &#123;fromMarkdown&#125; from &#x27;mdast-util-from-markdown&#x27; 根据这个, 而这个代码里又写来自于micromark, 所以说明这个数据来源是这个库. 的确在这个库的代码里搜到了listItem. 根据micromark里的描述 remark is the most popular markdown parser. It’s built on top of micromark and boasts syntax trees. For an analogy, it’s like if Babel, ESLint, and more, were one project. 不过似乎语法树的部分解析可能还是在其他的代码里的. 乍看, 核心逻辑都在对应的compile里的handler那里. micromark输出的是html, 那之前那些节点信息, 是哪个插件的呢? 奇怪, 用remark-parse输出的节点结构基本对应上了 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194&#123; &quot;type&quot;: &quot;root&quot;, &quot;children&quot;: [ &#123; &quot;type&quot;: &quot;list&quot;, &quot;ordered&quot;: true, &quot;start&quot;: 1, &quot;spread&quot;: false, &quot;children&quot;: [ &#123; &quot;type&quot;: &quot;listItem&quot;, &quot;spread&quot;: false, &quot;checked&quot;: null, &quot;children&quot;: [ &#123; &quot;type&quot;: &quot;paragraph&quot;, &quot;children&quot;: [ &#123; &quot;type&quot;: &quot;text&quot;, &quot;value&quot;: &quot;1&quot;, &quot;position&quot;: &#123; &quot;start&quot;: &#123; &quot;line&quot;: 1, &quot;column&quot;: 4, &quot;offset&quot;: 3 &#125;, &quot;end&quot;: &#123; &quot;line&quot;: 1, &quot;column&quot;: 5, &quot;offset&quot;: 4 &#125; &#125; &#125; ], &quot;position&quot;: &#123; &quot;start&quot;: &#123; &quot;line&quot;: 1, &quot;column&quot;: 4, &quot;offset&quot;: 3 &#125;, &quot;end&quot;: &#123; &quot;line&quot;: 1, &quot;column&quot;: 5, &quot;offset&quot;: 4 &#125; &#125; &#125; ], &quot;position&quot;: &#123; &quot;start&quot;: &#123; &quot;line&quot;: 1, &quot;column&quot;: 1, &quot;offset&quot;: 0 &#125;, &quot;end&quot;: &#123; &quot;line&quot;: 1, &quot;column&quot;: 5, &quot;offset&quot;: 4 &#125; &#125; &#125;, &#123; &quot;type&quot;: &quot;listItem&quot;, &quot;spread&quot;: false, &quot;checked&quot;: null, &quot;children&quot;: [ &#123; &quot;type&quot;: &quot;paragraph&quot;, &quot;children&quot;: [ &#123; &quot;type&quot;: &quot;text&quot;, &quot;value&quot;: &quot;2&quot;, &quot;position&quot;: &#123; &quot;start&quot;: &#123; &quot;line&quot;: 2, &quot;column&quot;: 4, &quot;offset&quot;: 8 &#125;, &quot;end&quot;: &#123; &quot;line&quot;: 2, &quot;column&quot;: 5, &quot;offset&quot;: 9 &#125; &#125; &#125; ], &quot;position&quot;: &#123; &quot;start&quot;: &#123; &quot;line&quot;: 2, &quot;column&quot;: 4, &quot;offset&quot;: 8 &#125;, &quot;end&quot;: &#123; &quot;line&quot;: 2, &quot;column&quot;: 5, &quot;offset&quot;: 9 &#125; &#125; &#125; ], &quot;position&quot;: &#123; &quot;start&quot;: &#123; &quot;line&quot;: 2, &quot;column&quot;: 1, &quot;offset&quot;: 5 &#125;, &quot;end&quot;: &#123; &quot;line&quot;: 2, &quot;column&quot;: 5, &quot;offset&quot;: 9 &#125; &#125; &#125;, &#123; &quot;type&quot;: &quot;listItem&quot;, &quot;spread&quot;: false, &quot;checked&quot;: null, &quot;children&quot;: [ &#123; &quot;type&quot;: &quot;paragraph&quot;, &quot;children&quot;: [ &#123; &quot;type&quot;: &quot;text&quot;, &quot;value&quot;: &quot;3&quot;, &quot;position&quot;: &#123; &quot;start&quot;: &#123; &quot;line&quot;: 3, &quot;column&quot;: 4, &quot;offset&quot;: 13 &#125;, &quot;end&quot;: &#123; &quot;line&quot;: 3, &quot;column&quot;: 5, &quot;offset&quot;: 14 &#125; &#125; &#125; ], &quot;position&quot;: &#123; &quot;start&quot;: &#123; &quot;line&quot;: 3, &quot;column&quot;: 4, &quot;offset&quot;: 13 &#125;, &quot;end&quot;: &#123; &quot;line&quot;: 3, &quot;column&quot;: 5, &quot;offset&quot;: 14 &#125; &#125; &#125; ], &quot;position&quot;: &#123; &quot;start&quot;: &#123; &quot;line&quot;: 3, &quot;column&quot;: 1, &quot;offset&quot;: 10 &#125;, &quot;end&quot;: &#123; &quot;line&quot;: 3, &quot;column&quot;: 5, &quot;offset&quot;: 14 &#125; &#125; &#125; ], &quot;position&quot;: &#123; &quot;start&quot;: &#123; &quot;line&quot;: 1, &quot;column&quot;: 1, &quot;offset&quot;: 0 &#125;, &quot;end&quot;: &#123; &quot;line&quot;: 3, &quot;column&quot;: 5, &quot;offset&quot;: 14 &#125; &#125; &#125; ], &quot;position&quot;: &#123; &quot;start&quot;: &#123; &quot;line&quot;: 1, &quot;column&quot;: 1, &quot;offset&quot;: 0 &#125;, &quot;end&quot;: &#123; &quot;line&quot;: 5, &quot;column&quot;: 1, &quot;offset&quot;: 16 &#125; &#125;&#125; 好像跟html的结构一样, 先是外部结构, ul还是ol, 然后才是内部的item渲染. 这样的话, 也得按照html的逻辑去渲染, 才能区分有序列表和无序列表了把. 现阶段的实现上, 是按照node迭代去渲染的, 所以这块当进入子节点的时候就没办法感知了. 这样的话, 最好是找到内部节点, 然后往上去遍历节点是什么结构, 然后再渲染? 那这样的话, 最好渲染一次就不是渲染一个节点, 而是一组节点的. 这样就可以在ordered变量存在的那层处理了. 当节点是listItem类型的时候, 这里存一下父节点的信息, 是不是list,然后type为list的ordered参数作为渲染用参数. 最好是在得到这个node信息的时候, 就遍历一下, 然后把这个属性给加到listItem那项里. 接下来就是在什么遍历的时候增加这个属性了. 应该哪种都行. 反正只要type匹配即可. 增加在Visit那里了 作废的折叠代码. 12345678910// context.subscriptions.push(vscode.languages.registerFoldingRangeProvider(&#x27;markdown&#x27;, &#123;// provideFoldingRanges: (document, context, _) =&gt; &#123;// console.log(document.languageId);// console.log(&quot;try to folding range&quot;);// let ranges = []s// const temp = new vscode.FoldingRange(1, 50, vscode.FoldingRangeKind.Comment);// ranges.push(temp);// return ranges// &#125;&#125;));// vscode.commands.executeCommand(&#x27;editor.fold&#x27;, &#123;&quot;selectionLines&quot;: [1]&#125;); todo: 回车和backspace按键卡顿, 怀疑跟这个markless的实时渲染有关. 好像禁用了markless还是卡, 开了进程监控, 也没看到是哪个进程的cpu显著的高, 除了main窗口. todo: markless是如何隐藏一部分文字的? 但是实际好像又能被搜索到? 透明色? 数据记录 在每个大节点的访问之后, 会再进到children内进行子节点的访问. 无序列表下无序列表 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229&#123; &quot;type&quot;: &quot;listItem&quot;, &quot;spread&quot;: false, &quot;checked&quot;: null, &quot;children&quot;: [ &#123; &quot;type&quot;: &quot;paragraph&quot;, &quot;children&quot;: [ &#123; &quot;type&quot;: &quot;text&quot;, &quot;value&quot;: &quot;b&quot;, &quot;position&quot;: &#123; &quot;start&quot;: &#123; &quot;line&quot;: 4, &quot;column&quot;: 3, &quot;offset&quot;: 13 &#125;, &quot;end&quot;: &#123; &quot;line&quot;: 4, &quot;column&quot;: 4, &quot;offset&quot;: 14 &#125; &#125; &#125; ], &quot;position&quot;: &#123; &quot;start&quot;: &#123; &quot;line&quot;: 4, &quot;column&quot;: 3, &quot;offset&quot;: 13 &#125;, &quot;end&quot;: &#123; &quot;line&quot;: 4, &quot;column&quot;: 4, &quot;offset&quot;: 14 &#125; &#125; &#125;, &#123; &quot;type&quot;: &quot;list&quot;, &quot;ordered&quot;: false, &quot;start&quot;: null, &quot;spread&quot;: false, &quot;children&quot;: [ &#123; &quot;type&quot;: &quot;listItem&quot;, &quot;spread&quot;: false, &quot;checked&quot;: null, &quot;children&quot;: [ &#123; &quot;type&quot;: &quot;paragraph&quot;, &quot;children&quot;: [ &#123; &quot;type&quot;: &quot;text&quot;, &quot;value&quot;: &quot;b.a&quot;, &quot;position&quot;: &#123; &quot;start&quot;: &#123; &quot;line&quot;: 5, &quot;column&quot;: 5, &quot;offset&quot;: 19 &#125;, &quot;end&quot;: &#123; &quot;line&quot;: 5, &quot;column&quot;: 8, &quot;offset&quot;: 22 &#125; &#125; &#125; ], &quot;position&quot;: &#123; &quot;start&quot;: &#123; &quot;line&quot;: 5, &quot;column&quot;: 5, &quot;offset&quot;: 19 &#125;, &quot;end&quot;: &#123; &quot;line&quot;: 5, &quot;column&quot;: 8, &quot;offset&quot;: 22 &#125; &#125; &#125; ], &quot;position&quot;: &#123; &quot;start&quot;: &#123; &quot;line&quot;: 5, &quot;column&quot;: 3, &quot;offset&quot;: 17 &#125;, &quot;end&quot;: &#123; &quot;line&quot;: 5, &quot;column&quot;: 8, &quot;offset&quot;: 22 &#125; &#125; &#125;, &#123; &quot;type&quot;: &quot;listItem&quot;, &quot;spread&quot;: false, &quot;checked&quot;: null, &quot;children&quot;: [ &#123; &quot;type&quot;: &quot;paragraph&quot;, &quot;children&quot;: [ &#123; &quot;type&quot;: &quot;text&quot;, &quot;value&quot;: &quot;b.b&quot;, &quot;position&quot;: &#123; &quot;start&quot;: &#123; &quot;line&quot;: 6, &quot;column&quot;: 5, &quot;offset&quot;: 27 &#125;, &quot;end&quot;: &#123; &quot;line&quot;: 6, &quot;column&quot;: 8, &quot;offset&quot;: 30 &#125; &#125; &#125; ], &quot;position&quot;: &#123; &quot;start&quot;: &#123; &quot;line&quot;: 6, &quot;column&quot;: 5, &quot;offset&quot;: 27 &#125;, &quot;end&quot;: &#123; &quot;line&quot;: 6, &quot;column&quot;: 8, &quot;offset&quot;: 30 &#125; &#125; &#125; ], &quot;position&quot;: &#123; &quot;start&quot;: &#123; &quot;line&quot;: 6, &quot;column&quot;: 3, &quot;offset&quot;: 25 &#125;, &quot;end&quot;: &#123; &quot;line&quot;: 6, &quot;column&quot;: 8, &quot;offset&quot;: 30 &#125; &#125; &#125;, &#123; &quot;type&quot;: &quot;listItem&quot;, &quot;spread&quot;: false, &quot;checked&quot;: null, &quot;children&quot;: [ &#123; &quot;type&quot;: &quot;paragraph&quot;, &quot;children&quot;: [ &#123; &quot;type&quot;: &quot;text&quot;, &quot;value&quot;: &quot;b.c&quot;, &quot;position&quot;: &#123; &quot;start&quot;: &#123; &quot;line&quot;: 7, &quot;column&quot;: 5, &quot;offset&quot;: 35 &#125;, &quot;end&quot;: &#123; &quot;line&quot;: 7, &quot;column&quot;: 8, &quot;offset&quot;: 38 &#125; &#125; &#125; ], &quot;position&quot;: &#123; &quot;start&quot;: &#123; &quot;line&quot;: 7, &quot;column&quot;: 5, &quot;offset&quot;: 35 &#125;, &quot;end&quot;: &#123; &quot;line&quot;: 7, &quot;column&quot;: 8, &quot;offset&quot;: 38 &#125; &#125; &#125; ], &quot;position&quot;: &#123; &quot;start&quot;: &#123; &quot;line&quot;: 7, &quot;column&quot;: 3, &quot;offset&quot;: 33 &#125;, &quot;end&quot;: &#123; &quot;line&quot;: 7, &quot;column&quot;: 8, &quot;offset&quot;: 38 &#125; &#125; &#125; ], &quot;position&quot;: &#123; &quot;start&quot;: &#123; &quot;line&quot;: 5, &quot;column&quot;: 3, &quot;offset&quot;: 17 &#125;, &quot;end&quot;: &#123; &quot;line&quot;: 7, &quot;column&quot;: 8, &quot;offset&quot;: 38 &#125; &#125; &#125; ], &quot;position&quot;: &#123; &quot;start&quot;: &#123; &quot;line&quot;: 4, &quot;column&quot;: 1, &quot;offset&quot;: 11 &#125;, &quot;end&quot;: &#123; &quot;line&quot;: 7, &quot;column&quot;: 8, &quot;offset&quot;: 38 &#125; &#125;&#125; 无序列表下有序列表 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228&#123; &quot;type&quot;: &quot;listItem&quot;, &quot;spread&quot;: false, &quot;checked&quot;: null, &quot;children&quot;: [ &#123; &quot;type&quot;: &quot;paragraph&quot;, &quot;children&quot;: [ &#123; &quot;type&quot;: &quot;text&quot;, &quot;value&quot;: &quot;o.1&quot;, &quot;position&quot;: &#123; &quot;start&quot;: &#123; &quot;line&quot;: 17, &quot;column&quot;: 3, &quot;offset&quot;: 93 &#125;, &quot;end&quot;: &#123; &quot;line&quot;: 17, &quot;column&quot;: 6, &quot;offset&quot;: 96 &#125; &#125; &#125; ], &quot;position&quot;: &#123; &quot;start&quot;: &#123; &quot;line&quot;: 17, &quot;column&quot;: 3, &quot;offset&quot;: 93 &#125;, &quot;end&quot;: &#123; &quot;line&quot;: 17, &quot;column&quot;: 6, &quot;offset&quot;: 96 &#125; &#125; &#125;, &#123; &quot;type&quot;: &quot;list&quot;, &quot;ordered&quot;: true, &quot;start&quot;: 1, &quot;spread&quot;: false, &quot;children&quot;: [ &#123; &quot;type&quot;: &quot;listItem&quot;, &quot;spread&quot;: false, &quot;checked&quot;: null, &quot;children&quot;: [ &#123; &quot;type&quot;: &quot;paragraph&quot;, &quot;children&quot;: [ &#123; &quot;type&quot;: &quot;text&quot;, &quot;value&quot;: &quot;o.1.1&quot;, &quot;position&quot;: &#123; &quot;start&quot;: &#123; &quot;line&quot;: 18, &quot;column&quot;: 6, &quot;offset&quot;: 102 &#125;, &quot;end&quot;: &#123; &quot;line&quot;: 18, &quot;column&quot;: 11, &quot;offset&quot;: 107 &#125; &#125; &#125; ], &quot;position&quot;: &#123; &quot;start&quot;: &#123; &quot;line&quot;: 18, &quot;column&quot;: 6, &quot;offset&quot;: 102 &#125;, &quot;end&quot;: &#123; &quot;line&quot;: 18, &quot;column&quot;: 11, &quot;offset&quot;: 107 &#125; &#125; &#125; ], &quot;position&quot;: &#123; &quot;start&quot;: &#123; &quot;line&quot;: 18, &quot;column&quot;: 3, &quot;offset&quot;: 99 &#125;, &quot;end&quot;: &#123; &quot;line&quot;: 18, &quot;column&quot;: 11, &quot;offset&quot;: 107 &#125; &#125; &#125;, &#123; &quot;type&quot;: &quot;listItem&quot;, &quot;spread&quot;: false, &quot;checked&quot;: null, &quot;children&quot;: [ &#123; &quot;type&quot;: &quot;paragraph&quot;, &quot;children&quot;: [ &#123; &quot;type&quot;: &quot;text&quot;, &quot;value&quot;: &quot;o.1.2&quot;, &quot;position&quot;: &#123; &quot;start&quot;: &#123; &quot;line&quot;: 19, &quot;column&quot;: 6, &quot;offset&quot;: 113 &#125;, &quot;end&quot;: &#123; &quot;line&quot;: 19, &quot;column&quot;: 11, &quot;offset&quot;: 118 &#125; &#125; &#125; ], &quot;position&quot;: &#123; &quot;start&quot;: &#123; &quot;line&quot;: 19, &quot;column&quot;: 6, &quot;offset&quot;: 113 &#125;, &quot;end&quot;: &#123; &quot;line&quot;: 19, &quot;column&quot;: 11, &quot;offset&quot;: 118 &#125; &#125; &#125; ], &quot;position&quot;: &#123; &quot;start&quot;: &#123; &quot;line&quot;: 19, &quot;column&quot;: 3, &quot;offset&quot;: 110 &#125;, &quot;end&quot;: &#123; &quot;line&quot;: 19, &quot;column&quot;: 11, &quot;offset&quot;: 118 &#125; &#125; &#125;, &#123; &quot;type&quot;: &quot;listItem&quot;, &quot;spread&quot;: false, &quot;checked&quot;: null, &quot;children&quot;: [ &#123; &quot;type&quot;: &quot;paragraph&quot;, &quot;children&quot;: [ &#123; &quot;type&quot;: &quot;text&quot;, &quot;value&quot;: &quot;o.1.3&quot;, &quot;position&quot;: &#123; &quot;start&quot;: &#123; &quot;line&quot;: 20, &quot;column&quot;: 6, &quot;offset&quot;: 124 &#125;, &quot;end&quot;: &#123; &quot;line&quot;: 20, &quot;column&quot;: 11, &quot;offset&quot;: 129 &#125; &#125; &#125; ], &quot;position&quot;: &#123; &quot;start&quot;: &#123; &quot;line&quot;: 20, &quot;column&quot;: 6, &quot;offset&quot;: 124 &#125;, &quot;end&quot;: &#123; &quot;line&quot;: 20, &quot;column&quot;: 11, &quot;offset&quot;: 129 &#125; &#125; &#125; ], &quot;position&quot;: &#123; &quot;start&quot;: &#123; &quot;line&quot;: 20, &quot;column&quot;: 3, &quot;offset&quot;: 121 &#125;, &quot;end&quot;: &#123; &quot;line&quot;: 20, &quot;column&quot;: 11, &quot;offset&quot;: 129 &#125; &#125; &#125; ], &quot;position&quot;: &#123; &quot;start&quot;: &#123; &quot;line&quot;: 18, &quot;column&quot;: 3, &quot;offset&quot;: 99 &#125;, &quot;end&quot;: &#123; &quot;line&quot;: 20, &quot;column&quot;: 11, &quot;offset&quot;: 129 &#125; &#125; &#125; ], &quot;position&quot;: &#123; &quot;start&quot;: &#123; &quot;line&quot;: 17, &quot;column&quot;: 1, &quot;offset&quot;: 91 &#125;, &quot;end&quot;: &#123; &quot;line&quot;: 20, &quot;column&quot;: 11, &quot;offset&quot;: 129 &#125; &#125;&#125; 有序列表下有序列表 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228&#123; &quot;type&quot;: &quot;listItem&quot;, &quot;spread&quot;: false, &quot;checked&quot;: null, &quot;children&quot;: [ &#123; &quot;type&quot;: &quot;paragraph&quot;, &quot;children&quot;: [ &#123; &quot;type&quot;: &quot;text&quot;, &quot;value&quot;: &quot;4&quot;, &quot;position&quot;: &#123; &quot;start&quot;: &#123; &quot;line&quot;: 12, &quot;column&quot;: 4, &quot;offset&quot;: 58 &#125;, &quot;end&quot;: &#123; &quot;line&quot;: 12, &quot;column&quot;: 5, &quot;offset&quot;: 59 &#125; &#125; &#125; ], &quot;position&quot;: &#123; &quot;start&quot;: &#123; &quot;line&quot;: 12, &quot;column&quot;: 4, &quot;offset&quot;: 58 &#125;, &quot;end&quot;: &#123; &quot;line&quot;: 12, &quot;column&quot;: 5, &quot;offset&quot;: 59 &#125; &#125; &#125;, &#123; &quot;type&quot;: &quot;list&quot;, &quot;ordered&quot;: true, &quot;start&quot;: 1, &quot;spread&quot;: false, &quot;children&quot;: [ &#123; &quot;type&quot;: &quot;listItem&quot;, &quot;spread&quot;: false, &quot;checked&quot;: null, &quot;children&quot;: [ &#123; &quot;type&quot;: &quot;paragraph&quot;, &quot;children&quot;: [ &#123; &quot;type&quot;: &quot;text&quot;, &quot;value&quot;: &quot;4.1&quot;, &quot;position&quot;: &#123; &quot;start&quot;: &#123; &quot;line&quot;: 13, &quot;column&quot;: 7, &quot;offset&quot;: 66 &#125;, &quot;end&quot;: &#123; &quot;line&quot;: 13, &quot;column&quot;: 10, &quot;offset&quot;: 69 &#125; &#125; &#125; ], &quot;position&quot;: &#123; &quot;start&quot;: &#123; &quot;line&quot;: 13, &quot;column&quot;: 7, &quot;offset&quot;: 66 &#125;, &quot;end&quot;: &#123; &quot;line&quot;: 13, &quot;column&quot;: 10, &quot;offset&quot;: 69 &#125; &#125; &#125; ], &quot;position&quot;: &#123; &quot;start&quot;: &#123; &quot;line&quot;: 13, &quot;column&quot;: 4, &quot;offset&quot;: 63 &#125;, &quot;end&quot;: &#123; &quot;line&quot;: 13, &quot;column&quot;: 10, &quot;offset&quot;: 69 &#125; &#125; &#125;, &#123; &quot;type&quot;: &quot;listItem&quot;, &quot;spread&quot;: false, &quot;checked&quot;: null, &quot;children&quot;: [ &#123; &quot;type&quot;: &quot;paragraph&quot;, &quot;children&quot;: [ &#123; &quot;type&quot;: &quot;text&quot;, &quot;value&quot;: &quot;4.2&quot;, &quot;position&quot;: &#123; &quot;start&quot;: &#123; &quot;line&quot;: 14, &quot;column&quot;: 7, &quot;offset&quot;: 76 &#125;, &quot;end&quot;: &#123; &quot;line&quot;: 14, &quot;column&quot;: 10, &quot;offset&quot;: 79 &#125; &#125; &#125; ], &quot;position&quot;: &#123; &quot;start&quot;: &#123; &quot;line&quot;: 14, &quot;column&quot;: 7, &quot;offset&quot;: 76 &#125;, &quot;end&quot;: &#123; &quot;line&quot;: 14, &quot;column&quot;: 10, &quot;offset&quot;: 79 &#125; &#125; &#125; ], &quot;position&quot;: &#123; &quot;start&quot;: &#123; &quot;line&quot;: 14, &quot;column&quot;: 4, &quot;offset&quot;: 73 &#125;, &quot;end&quot;: &#123; &quot;line&quot;: 14, &quot;column&quot;: 10, &quot;offset&quot;: 79 &#125; &#125; &#125;, &#123; &quot;type&quot;: &quot;listItem&quot;, &quot;spread&quot;: false, &quot;checked&quot;: null, &quot;children&quot;: [ &#123; &quot;type&quot;: &quot;paragraph&quot;, &quot;children&quot;: [ &#123; &quot;type&quot;: &quot;text&quot;, &quot;value&quot;: &quot;4.3&quot;, &quot;position&quot;: &#123; &quot;start&quot;: &#123; &quot;line&quot;: 15, &quot;column&quot;: 7, &quot;offset&quot;: 86 &#125;, &quot;end&quot;: &#123; &quot;line&quot;: 15, &quot;column&quot;: 10, &quot;offset&quot;: 89 &#125; &#125; &#125; ], &quot;position&quot;: &#123; &quot;start&quot;: &#123; &quot;line&quot;: 15, &quot;column&quot;: 7, &quot;offset&quot;: 86 &#125;, &quot;end&quot;: &#123; &quot;line&quot;: 15, &quot;column&quot;: 10, &quot;offset&quot;: 89 &#125; &#125; &#125; ], &quot;position&quot;: &#123; &quot;start&quot;: &#123; &quot;line&quot;: 15, &quot;column&quot;: 4, &quot;offset&quot;: 83 &#125;, &quot;end&quot;: &#123; &quot;line&quot;: 15, &quot;column&quot;: 10, &quot;offset&quot;: 89 &#125; &#125; &#125; ], &quot;position&quot;: &#123; &quot;start&quot;: &#123; &quot;line&quot;: 13, &quot;column&quot;: 4, &quot;offset&quot;: 63 &#125;, &quot;end&quot;: &#123; &quot;line&quot;: 15, &quot;column&quot;: 10, &quot;offset&quot;: 89 &#125; &#125; &#125; ], &quot;position&quot;: &#123; &quot;start&quot;: &#123; &quot;line&quot;: 12, &quot;column&quot;: 1, &quot;offset&quot;: 55 &#125;, &quot;end&quot;: &#123; &quot;line&quot;: 15, &quot;column&quot;: 10, &quot;offset&quot;: 89 &#125; &#125;&#125; 有序列表下无序列表下有序列表 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332&#123; &quot;type&quot;: &quot;listItem&quot;, &quot;spread&quot;: false, &quot;checked&quot;: null, &quot;children&quot;: [ &#123; &quot;type&quot;: &quot;paragraph&quot;, &quot;children&quot;: [ &#123; &quot;type&quot;: &quot;text&quot;, &quot;value&quot;: &quot;p.1&quot;, &quot;position&quot;: &#123; &quot;start&quot;: &#123; &quot;line&quot;: 22, &quot;column&quot;: 3, &quot;offset&quot;: 133 &#125;, &quot;end&quot;: &#123; &quot;line&quot;: 22, &quot;column&quot;: 6, &quot;offset&quot;: 136 &#125; &#125; &#125; ], &quot;position&quot;: &#123; &quot;start&quot;: &#123; &quot;line&quot;: 22, &quot;column&quot;: 3, &quot;offset&quot;: 133 &#125;, &quot;end&quot;: &#123; &quot;line&quot;: 22, &quot;column&quot;: 6, &quot;offset&quot;: 136 &#125; &#125; &#125;, &#123; &quot;type&quot;: &quot;list&quot;, &quot;ordered&quot;: true, &quot;start&quot;: 1, &quot;spread&quot;: false, &quot;children&quot;: [ &#123; &quot;type&quot;: &quot;listItem&quot;, &quot;spread&quot;: false, &quot;checked&quot;: null, &quot;children&quot;: [ &#123; &quot;type&quot;: &quot;paragraph&quot;, &quot;children&quot;: [ &#123; &quot;type&quot;: &quot;text&quot;, &quot;value&quot;: &quot;p.1.1&quot;, &quot;position&quot;: &#123; &quot;start&quot;: &#123; &quot;line&quot;: 23, &quot;column&quot;: 6, &quot;offset&quot;: 142 &#125;, &quot;end&quot;: &#123; &quot;line&quot;: 23, &quot;column&quot;: 11, &quot;offset&quot;: 147 &#125; &#125; &#125; ], &quot;position&quot;: &#123; &quot;start&quot;: &#123; &quot;line&quot;: 23, &quot;column&quot;: 6, &quot;offset&quot;: 142 &#125;, &quot;end&quot;: &#123; &quot;line&quot;: 23, &quot;column&quot;: 11, &quot;offset&quot;: 147 &#125; &#125; &#125; ], &quot;position&quot;: &#123; &quot;start&quot;: &#123; &quot;line&quot;: 23, &quot;column&quot;: 3, &quot;offset&quot;: 139 &#125;, &quot;end&quot;: &#123; &quot;line&quot;: 23, &quot;column&quot;: 11, &quot;offset&quot;: 147 &#125; &#125; &#125;, &#123; &quot;type&quot;: &quot;listItem&quot;, &quot;spread&quot;: false, &quot;checked&quot;: null, &quot;children&quot;: [ &#123; &quot;type&quot;: &quot;paragraph&quot;, &quot;children&quot;: [ &#123; &quot;type&quot;: &quot;text&quot;, &quot;value&quot;: &quot;p.1.1.1&quot;, &quot;position&quot;: &#123; &quot;start&quot;: &#123; &quot;line&quot;: 24, &quot;column&quot;: 8, &quot;offset&quot;: 155 &#125;, &quot;end&quot;: &#123; &quot;line&quot;: 24, &quot;column&quot;: 15, &quot;offset&quot;: 162 &#125; &#125; &#125; ], &quot;position&quot;: &#123; &quot;start&quot;: &#123; &quot;line&quot;: 24, &quot;column&quot;: 8, &quot;offset&quot;: 155 &#125;, &quot;end&quot;: &#123; &quot;line&quot;: 24, &quot;column&quot;: 15, &quot;offset&quot;: 162 &#125; &#125; &#125; ], &quot;position&quot;: &#123; &quot;start&quot;: &#123; &quot;line&quot;: 24, &quot;column&quot;: 5, &quot;offset&quot;: 152 &#125;, &quot;end&quot;: &#123; &quot;line&quot;: 24, &quot;column&quot;: 15, &quot;offset&quot;: 162 &#125; &#125; &#125;, &#123; &quot;type&quot;: &quot;listItem&quot;, &quot;spread&quot;: false, &quot;checked&quot;: null, &quot;children&quot;: [ &#123; &quot;type&quot;: &quot;paragraph&quot;, &quot;children&quot;: [ &#123; &quot;type&quot;: &quot;text&quot;, &quot;value&quot;: &quot;p.1.1.2&quot;, &quot;position&quot;: &#123; &quot;start&quot;: &#123; &quot;line&quot;: 25, &quot;column&quot;: 8, &quot;offset&quot;: 170 &#125;, &quot;end&quot;: &#123; &quot;line&quot;: 25, &quot;column&quot;: 15, &quot;offset&quot;: 177 &#125; &#125; &#125; ], &quot;position&quot;: &#123; &quot;start&quot;: &#123; &quot;line&quot;: 25, &quot;column&quot;: 8, &quot;offset&quot;: 170 &#125;, &quot;end&quot;: &#123; &quot;line&quot;: 25, &quot;column&quot;: 15, &quot;offset&quot;: 177 &#125; &#125; &#125; ], &quot;position&quot;: &#123; &quot;start&quot;: &#123; &quot;line&quot;: 25, &quot;column&quot;: 5, &quot;offset&quot;: 167 &#125;, &quot;end&quot;: &#123; &quot;line&quot;: 25, &quot;column&quot;: 15, &quot;offset&quot;: 177 &#125; &#125; &#125;, &#123; &quot;type&quot;: &quot;listItem&quot;, &quot;spread&quot;: false, &quot;checked&quot;: null, &quot;children&quot;: [ &#123; &quot;type&quot;: &quot;paragraph&quot;, &quot;children&quot;: [ &#123; &quot;type&quot;: &quot;text&quot;, &quot;value&quot;: &quot;p.1.1.3&quot;, &quot;position&quot;: &#123; &quot;start&quot;: &#123; &quot;line&quot;: 26, &quot;column&quot;: 8, &quot;offset&quot;: 185 &#125;, &quot;end&quot;: &#123; &quot;line&quot;: 26, &quot;column&quot;: 15, &quot;offset&quot;: 192 &#125; &#125; &#125; ], &quot;position&quot;: &#123; &quot;start&quot;: &#123; &quot;line&quot;: 26, &quot;column&quot;: 8, &quot;offset&quot;: 185 &#125;, &quot;end&quot;: &#123; &quot;line&quot;: 26, &quot;column&quot;: 15, &quot;offset&quot;: 192 &#125; &#125; &#125; ], &quot;position&quot;: &#123; &quot;start&quot;: &#123; &quot;line&quot;: 26, &quot;column&quot;: 5, &quot;offset&quot;: 182 &#125;, &quot;end&quot;: &#123; &quot;line&quot;: 26, &quot;column&quot;: 15, &quot;offset&quot;: 192 &#125; &#125; &#125;, &#123; &quot;type&quot;: &quot;listItem&quot;, &quot;spread&quot;: false, &quot;checked&quot;: null, &quot;children&quot;: [ &#123; &quot;type&quot;: &quot;paragraph&quot;, &quot;children&quot;: [ &#123; &quot;type&quot;: &quot;text&quot;, &quot;value&quot;: &quot;p.1.2&quot;, &quot;position&quot;: &#123; &quot;start&quot;: &#123; &quot;line&quot;: 27, &quot;column&quot;: 6, &quot;offset&quot;: 198 &#125;, &quot;end&quot;: &#123; &quot;line&quot;: 27, &quot;column&quot;: 11, &quot;offset&quot;: 203 &#125; &#125; &#125; ], &quot;position&quot;: &#123; &quot;start&quot;: &#123; &quot;line&quot;: 27, &quot;column&quot;: 6, &quot;offset&quot;: 198 &#125;, &quot;end&quot;: &#123; &quot;line&quot;: 27, &quot;column&quot;: 11, &quot;offset&quot;: 203 &#125; &#125; &#125; ], &quot;position&quot;: &#123; &quot;start&quot;: &#123; &quot;line&quot;: 27, &quot;column&quot;: 3, &quot;offset&quot;: 195 &#125;, &quot;end&quot;: &#123; &quot;line&quot;: 27, &quot;column&quot;: 11, &quot;offset&quot;: 203 &#125; &#125; &#125; ], &quot;position&quot;: &#123; &quot;start&quot;: &#123; &quot;line&quot;: 23, &quot;column&quot;: 3, &quot;offset&quot;: 139 &#125;, &quot;end&quot;: &#123; &quot;line&quot;: 27, &quot;column&quot;: 11, &quot;offset&quot;: 203 &#125; &#125; &#125; ], &quot;position&quot;: &#123; &quot;start&quot;: &#123; &quot;line&quot;: 22, &quot;column&quot;: 1, &quot;offset&quot;: 131 &#125;, &quot;end&quot;: &#123; &quot;line&quot;: 27, &quot;column&quot;: 11, &quot;offset&quot;: 203 &#125; &#125;&#125; Reference CommonMark Spec","categories":[{"name":"专业","slug":"pro","permalink":"https://sean10.github.io/categories/pro/"}],"tags":[{"name":"vscode","slug":"vscode","permalink":"https://sean10.github.io/tags/vscode/"},{"name":"markdown","slug":"markdown","permalink":"https://sean10.github.io/tags/markdown/"}]},{"title":"ceph社区进展跟进2022Q1+Q2","slug":"ceph社区进展跟进2022Q1+Q2","date":"2022-04-18T03:02:36.000Z","updated":"2023-03-18T15:11:14.896Z","comments":true,"path":"2022/04/18/ceph社区进展跟进2022Q1+Q2/","link":"","permalink":"https://sean10.github.io/2022/04/18/ceph%E7%A4%BE%E5%8C%BA%E8%BF%9B%E5%B1%95%E8%B7%9F%E8%BF%9B2022Q1+Q2/","excerpt":"","text":"17.2.0 正式发布 Ceph.io — v17.2.0 Quincy released * telementry report优化, 是否可以满足性能问题定位? the \"kvs\" Ceph object class is not packaged anymore. 这个是什么能力? crimson相关 根据History for src/crimson -quincy ceph/ceph来看, 好像是官方不准备在这个版本上这个功能了. 相比History for src/crimson -master ceph/ceph已经差了大概2个月的更新了. Ceph Leadership Team meeting 2022-05-25 These are the topics discussed in today's meeting: Change in the release process Patrick suggesting version bump PRs vs current commit push approach Commits are not signed Avoids freezing the branch during hotfixes Both for hotfixes and regular dot releases Needs further discussion https://www.atlassian.com/git/tutorials/comparing-workflows/gitflow-workflow &lt;-- more closely matches current model + proposed changes re: PRs, with the addition of a development branch https://www.atlassian.com/continuous-delivery/continuous-integration/trunk-based-development ceph-Jenkins account needs admin privs to ceph.git in order to push directly to branches doesn't apply to PR version bump publishing (Windows) binaries signed by cloudbase? Issues with Linux/Ceph Foundation RH might provide the signed binaries Probably don't publish binaries signed by Cloudbase b/c we wouldn't get telemetry data back from crashes etc. master-main rename rename completed there are still issues with some Jenkins jobs quincy blogs 17.2.1 readiness 3 PRs left release candidate by Jun 1st week 16.2.8 issue retrospective: https://docs.google.com/presentation/d/1hbwo_GW48O4nnM78US2ghVXglxZw5TRwmWUOy_oxam8/ scale testing stricter backport policy lack of reviews in the backport mgr component is orphaned (RADOS, lack of experience in other teams) conflict solving was not properly documented mgr has become too critical (due to cephadm it is now key) don't merge with 1 approval reviewers on sensitive PRs/files should acknowledge they understand the code changes different standards across teams try out requiring reviews from CODEOWNERS on the pacific branch 2022-04-06 CDS Reef Crimson会议 稳定性和部署 目前crimson支持rook和cephadm 投入在teuthology上的测试套件 在初始的teuthology test上修复了许多稳定性的bug refinements to op ordering logic 改进watch/notify apis 优化/修复 crimson的bluestore support. seastore metrics seastore去年变化很多, 现在有了一批监控seastore的metrics能力, 有助于未来的优化 新的有助于理解seastore的性能模式的指标 cache: 事务冲突率, 缓存利用率信息 lba tree: lba 分配 事务管理器 segment_manager/block: 读写计数器 Seastore Internals joyhound添加了支持placing extents in an non-journal segments 内部重构支持多设备 冲突检测改良 增加了已经在实际zns设备上测试过的zns segment manager rados_api_test coverage fix 性能方面 lba hinting on onode tree, omap tree journal coalescing quincy的crimson, 应该支持在没有快照的情况下在crimson测试rbd负载, 用单个reactor配置下基于cyanstore或者seastore后端, 用rook或者cephadm部署. crimson reef计划 后续规划里, crimson比较巨大的事情是 多核(op processing) 多核(messengers) 快照 scrub 快照是Baton负责开发的一个相当核心的功能, 已经填好了rbd测试用例, 后续多核会比较严峻. seastore reef计划 后续在多设备和分层的gc机制上上会有进一步改进 在nvme设备的基于随机块管理器和多核的gc机制上. 多核支持 后续一开始会对nvme划多个分区运行seastore来得到性能基线, 后续用于评估元数据结构. 可用性/测试 日志 保持debug_*配置选项 pg log messages格式保持和传统一致 vstart, teuthology 集群日志到和传统一样的文件里 尽量使用debug common选项, 快速收集到一些问题原因. 尽量确保所有人在调试的同一个页面上. 包括vstart和teuthology的日志, 这块与传统osd不太一样. 后续计划增加一个teuthology套件测试所有的pr. 如果有人愿意做审计, 会非常好 基础日志框架上, 有一个差异是, 20等级在传统上已经是debug, 而crimson不止. 目前只有debug_ms这块比较好, 1就会打印所有的消息. 最好不仅仅是debug_ms 这里有一个约定, 10-20是调试, 30是trace. 但是我们创建了5这类边界的日志日志 用teuthology tests控制crimson PRs 选择一批测试集 crimson讨论 qlc, zns讨论 qlc比tlc更密集 我的策略是, 要么足够快, 可以被视为随机(block)块管理器, 或者足够慢, 被视为(segment)段管理器, 被落入到与zns相同的存储桶汇总. RedHat 分享性能基准, 如果期望早点测试rbd 今年不会太稳定, 但是几年会有所改善, 行业正在转向accuracy,而不是tlc. TODO: 这里有疑问, 这里的accuracy指的是什么新介质还是什么? 看到了该领域的兴趣, 看看crimson如何帮助从tlc过度 seastore目前进度落后于crimson, 所以成熟会有点困难 不过应该可以工作了. 经典osd的测试 最新版本通过用于人们的测试 但是Crimson, 不期望人们在quincy测试 也许每月一次或者每周一次, 某种自动构建的快照. 我们不做任何测试, 也不提供后端端口. 只是提供下载和运行的时间点快照, 给人们提供一些更频繁地测试crimson的方法比每年的发布. 如果有一些图像和说明, 会更好. 从bluestore转到crimson, 这是新贡献者可以做的另一个地方. 这个也可以作为一个强制功能来改进发布pipeline. crimson可以在quincy一起使用, 但是没有快照, 所以还需要继续改进rbd, 以及得到rgw, cephfs的支持. rbd一直是我们的主要目标, 因为从a cpu per io的角度, rbd大多数情况下最苛刻, 所以一直是我们的重点. gc策略 yangson SeaStore Generational Segment Cleaning - Google Docs 接下来讨论的链接是这个 这块gc没细看, 跳过...详见CDS Reef: Crimson - YouTube &gt; seastar把Extent存储到磁盘. 每个extent具有标记热的character, 意味着root extent或者logical lba extent, 或者未知的, 元数据. &gt; &gt; 可以是想对象数据块或者omap leave的代码 &gt; &gt; 每个extent有一个Age, 具有lfs的设计. 将相同字符和相似age的分组. &gt; &gt; 根据论文, 有一个成本效益的垃圾收集策略. 如果实现将相似的extent合并到同一个segment中进行回收会更有效. device tier 这个方法, 划分多层. 每一层设备比另一层设备更强, 感觉这个思路不错. Reef 性能会议 这个应该是下一个ceph版本的规划讨论? rocksdb 列族 pg log 优化? rocksdb增加merge pg log. recycling pidgey lobe a mapping from the real pg info to the pg log key 导致性能下降. more or less working implementation now poc at the moment and the idea is yeah to replace roxdb write ahead log with 用外部日志替换 roxdb 预写日志， external one residing to store 以便 implementation for write the hedge log 实现附近写入对冲日志 bluestore 性能提升. you prototyped moving the pg log out of rocks db completely and you stop because it increased our iops by 20 yeah the first one is about you write a headlock and the second one is about making well removing uh pg lock implementation at all along with all this replication stuff iops增长20% igor 早期 just write out um pg log updates to 64k allocations in bluefest and um 她没有看到任何好处，所以她很快就放弃 it sounds like igor you're you're having much better success with it with your i with roxdb iterator boundaries corey ? rgw实现对接daos rgw: add DAOS SAL implementation by zalsader · Pull Request #45888 · ceph/ceph Ceph User + Dev Monthly Meeting 2022-06-01 ceph developer monthly block deduction feature 2022-02-02 trace Ceph Crimson/SeaStore 2022-06-07 multi-core计划继续推进 修复容量问题 发现fio zipf模式更适合作为测试gc的工作负载 使用统一分布的zipf是Gc的最差场景 zipf分布? 考虑在Seastore上增加一些采样, 用于观察调整zipf用的参数 ## 2022-05-11 seastore concurrent 讨论 performance weekly 2022-05-05 closed: https://github.com/ceph/ceph/pull/46095 (kv/RocksDBStore: Remove ability to bound WholeSpaceIterator, aclamk) &lt;-- merged to master by yuriw https://github.com/ceph/ceph/pull/45993 (crimson/osd: fix argument parsing after seastar changes, markhpc) &lt;-- merged to master by markhpc updated: https://github.com/ceph/ceph/pull/46062 (crimson: Enable tcmalloc when using seastar, markhpc) &lt;-- Discussion, updates https://github.com/ceph/ceph/pull/45771 (os/bluestore: Switch to time-based adaptive near-fit alogrithm, markhpc) &lt;-- disccusion https://github.com/ceph/ceph/pull/45888 (rgw: add DAOS SAL implementation, zalsader) &lt;-- discussion, review, needs rebase igor的bluestore实现, 下周分享. 2022-04-13 视频未上传, 12345678910111213141516- CURRENT STATUS OF PULL REQUESTS (since 2021-04-07): new: https://github.com/ceph/ceph/pull/45904 (os/bluestore: set upper and lower bounds on rocksdb omap iterators, cfsnyder) &lt;-- cbodley reviews https://github.com/ceph/ceph/pull/45888 (rgw: add DAOS SAL implementation, zalsader) &lt;-- new PR closed: https://github.com/ceph/ceph/pull/45884 (os/bluestore: Always update the cursor position in AVL near-fit search, markhpc) &lt;-- Merged to master by Yuri https://github.com/ceph/ceph/pull/45755 (common/options: Disable AVL allocator first-fit optimizations, markhpc) &lt;-- superceded by #45884 and #45771 updated: https://github.com/ceph/ceph/pull/45771 (os/bluestore: Switch to time-based adaptive near-fit alogrithm, markhpc) &lt;-- disccusion https://github.com/ceph/ceph/pull/44684 (tracer: set tracing compiled in by default, zenomri) &lt;-- reviews, updates, discussion, more testing, ideepika reviews, updates https://github.com/ceph/ceph/pull/31694 (♪ I&#x27;ve got the world on a string, sittin&#x27; on a rainbow ♪, adamemerson) &lt;-- cbodley reviews, mbenjamin reviews, needs-rebase, anything left to merge? 2022-04-07 Ceph Performance Meeting 2022-04-07 - YouTube 1234567891011- CURRENT STATUS OF PULL REQUESTS (since 2021-03-31): new: https://github.com/ceph/ceph/pull/45771 (os/bluestore: Switch to time-based adaptive near-fit alogrithm, markhpc) &lt;-- disccusion https://github.com/ceph/ceph/pull/45755 (common/options: Disable AVL allocator first-fit optimizations, markhpc) &lt;-- discussion closed: updated: https://github.com/ceph/ceph/pull/44684 (tracer: set tracing compiled in by default, zenomri) &lt;-- reviews, updates, discussion, more testing, review req for ideepika and markhpc master分支一般会搞砸性能 gabby's talking 关于fast nvme test nodes, 在基线上得到了较好的结果? 70K-80K的小对象随机iops 但是现在master分支只有20-30K. mako notes and still saw high performance avl分配器 本周2个新pr与avl分配器有关 we determine when to go into best fit mode in the avl allocator替换去年夏天的fit mode? 在三星硬盘上, 大块顺序写性能大量的slow down. 看起来是动态调整分配模式 ,而不是线性分配. 写64K这种io模型似乎不太适配三星硬盘. 后续尝试增加4x或者8x的参数来让他适配? 这个有帮助, 不过并不能解决问题. 可能主要体现在搜索空间的耗时上. 所以写了这个基于cycles和字节来选择最优拟合. 超过1ms, 就切换到快速模式? 在pacific 16.2.7版本似乎更好. 将64K划分64个块. 可能是这些硬盘的模式针对我们的修改, 并不喜欢?导致很容易进入性能下降. 不管是其他nvme, 包括基于intel p3700的硬盘的性能?差异都不大, 但在三星上, 差异就大. os/bluestore: Switch to time-based adaptive near-fit alogrithm by markhpc · Pull Request #45771 · ceph/ceph common/options: Disable AVL allocator first-fit optimizations by markhpc · Pull Request #45755 · ceph/ceph 这张图里好像有性能测试的图? 从而决定要关闭或采取上面的优化方案的? david galloway ? workload test相关 dp compaction . avl分配器在4K情况下, 看到了70-700ms的情况. stupid和hybrid分配器? 主要还是64K的申请上? 当分配器花2ms找2个连续的块的时候, 会锁住其他在相同块上的操作的处理. 导致没买哦只有500的分配能力?当我申请500K的chunk时, 实际分配单元是64K, 但是空间本身可能会用16K的块碎片. 目前修改后的stupid分配器没有原版的(没合入这个patch)的性能更好 ... 后面都是针对这个分配逻辑的讨论了, 未了解, 后续了解后再翻译. 来源 https://pad.ceph.com/p/performance_weekly https://www.youtube.com/c/Cephstorage/videos TODO:https://www.openeuler.org/zh/interaction/blog-list/ 这里openEuler整理的比较好?","categories":[{"name":"专业","slug":"pro","permalink":"https://sean10.github.io/categories/pro/"}],"tags":[{"name":"ceph","slug":"ceph","permalink":"https://sean10.github.io/tags/ceph/"},{"name":"community","slug":"community","permalink":"https://sean10.github.io/tags/community/"}]},{"title":"hammerspoon神器扩展","slug":"hammerspoon神器扩展","date":"2022-02-19T16:01:59.000Z","updated":"2023-03-18T15:11:14.867Z","comments":true,"path":"2022/02/20/hammerspoon神器扩展/","link":"","permalink":"https://sean10.github.io/2022/02/20/hammerspoon%E7%A5%9E%E5%99%A8%E6%89%A9%E5%B1%95/","excerpt":"","text":"概览 ashfinal/awesome-hammerspoon: awesome configuration for Hammerspoon. 开源,有点厉害,初步看着像是提供了整套操纵mac桌面的Lua API. 基本上是等同于alfred的效果了吧? 参照ashfinal/awesome-hammerspoon: awesome configuration for Hammerspoon.部署, 然后修改~/.hammerspoon/init.lua即可 功能扩展 剪切板历史 Hammerspoon docs: TextClipboardHistory 注册快捷键\"alt+\"v\" 123456789hs.loadSpoon(&#x27;TextClipboardHistory&#x27;)spoon.TextClipboardHistory.show_in_menubar = falsespoon.TextClipboardHistory.paste_on_select = truespoon.TextClipboardHistory.honor_ignoredidentifiers = truespoon.TextClipboardHistory:start()hs.hotkey.bind(&quot;alt&quot;, &quot;V&quot;, function() spoon.TextClipboardHistory:toggleClipboard() mode:exit()end) Hammerspoon docs: TextClipboardHistory hsearch: 类似alfred 实现类似alfred的自定义能力. 疑似卡顿 Hammerspoon “Freezes” After a While · Issue #2219 · Hammerspoon/hammerspoon 但是hammerspoon的Choooser好像实在是太卡了, hidden和显示都会转圈圈. 提了个issue,看看官方大佬有没有人能够解决, 我试了下我编译老是报错,感觉像是objective-c里还有什么依赖不在那个cocoa里的. TODO:后来没怎么用这个功能, 后续遇到再定位看看 resizeM: 平铺窗口管理器 实现将当前转换快速修改窗口大小以及在桌面的平铺位置. 默认用的awesome-hammerspoon里的 Option+R进入hammerspoon模式, 通过方向键右切换到左右屏幕, 然后通过F来进行全屏化. 另一种实现方式 找的大佬的脚本1 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152-- Window management-- Defines for window maximize togglerlocal frameCache = &#123;&#125;local logger = hs.logger.new(&quot;windows&quot;)-- Resize current windowfunction winresize(how) local win = hs.window.focusedWindow() local app = win:application():name() local windowLayout local newrect if how == &quot;left&quot; then newrect = hs.layout.left50 elseif how == &quot;right&quot; then newrect = hs.layout.right50 elseif how == &quot;up&quot; then newrect = &#123;0,0,1,0.5&#125; elseif how == &quot;down&quot; then newrect = &#123;0,0.5,1,0.5&#125; elseif how == &quot;max&quot; then newrect = hs.layout.maximized elseif how == &quot;left_third&quot; or how == &quot;hthird-0&quot; then newrect = &#123;0,0,1/3,1&#125; elseif how == &quot;middle_third_h&quot; or how == &quot;hthird-1&quot; then newrect = &#123;1/3,0,1/3,1&#125; elseif how == &quot;right_third&quot; or how == &quot;hthird-2&quot; then newrect = &#123;2/3,0,1/3,1&#125; elseif how == &quot;top_third&quot; or how == &quot;vthird-0&quot; then newrect = &#123;0,0,1,1/3&#125; elseif how == &quot;middle_third_v&quot; or how == &quot;vthird-1&quot; then newrect = &#123;0,1/3,1,1/3&#125; elseif how == &quot;bottom_third&quot; or how == &quot;vthird-2&quot; then newrect = &#123;0,2/3,1,1/3&#125; end win:move(newrect)endfunction winmovescreen(how) local win = hs.window.focusedWindow() if how == &quot;left&quot; then win:moveOneScreenWest() elseif how == &quot;right&quot; then win:moveOneScreenEast() endend-- Toggle a window between its normal size, and being maximizedfunction toggle_window_maximized() local win = hs.window.focusedWindow() if frameCache[win:id()] then win:setFrame(frameCache[win:id()]) frameCache[win:id()] = nil else frameCache[win:id()] = win:frame() win:maximize() endend-- Move between thirds of the screenfunction get_horizontal_third(win) local frame=win:frame() local screenframe=win:screen():frame() local relframe=hs.geometry(frame.x-screenframe.x, frame.y-screenframe.y, frame.w, frame.h) local third = math.floor(3.01*relframe.x/screenframe.w) logger.df(&quot;Screen frame: %s&quot;, screenframe) logger.df(&quot;Window frame: %s, relframe %s is in horizontal third #%d&quot;, frame, relframe, third) return thirdendfunction get_vertical_third(win) local frame=win:frame() local screenframe=win:screen():frame() local relframe=hs.geometry(frame.x-screenframe.x, frame.y-screenframe.y, frame.w, frame.h) local third = math.floor(3.01*relframe.y/screenframe.h) logger.df(&quot;Screen frame: %s&quot;, screenframe) logger.df(&quot;Window frame: %s, relframe %s is in vertical third #%d&quot;, frame, relframe, third) return thirdendfunction left_third() local win = hs.window.focusedWindow() local third = get_horizontal_third(win) if third == 0 then winresize(&quot;hthird-0&quot;) else winresize(&quot;hthird-&quot; .. (third-1)) endendfunction right_third() local win = hs.window.focusedWindow() local third = get_horizontal_third(win) if third == 2 then winresize(&quot;hthird-2&quot;) else winresize(&quot;hthird-&quot; .. (third+1)) endendfunction up_third() local win = hs.window.focusedWindow() local third = get_vertical_third(win) if third == 0 then winresize(&quot;vthird-0&quot;) else winresize(&quot;vthird-&quot; .. (third-1)) endendfunction down_third() local win = hs.window.focusedWindow() local third = get_vertical_third(win) if third == 2 then winresize(&quot;vthird-2&quot;) else winresize(&quot;vthird-&quot; .. (third+1)) endendfunction center() local win = hs.window.focusedWindow() win:centerOnScreen()end-------- Key bindings-- Halves of the screenhs.hotkey.bind(&#123;&quot;ctrl&quot;,&quot;cmd&quot;&#125;, &quot;Left&quot;, hs.fnutils.partial(winresize, &quot;left&quot;))hs.hotkey.bind(&#123;&quot;ctrl&quot;,&quot;cmd&quot;&#125;, &quot;Right&quot;, hs.fnutils.partial(winresize, &quot;right&quot;))hs.hotkey.bind(&#123;&quot;ctrl&quot;,&quot;cmd&quot;&#125;, &quot;Up&quot;, hs.fnutils.partial(winresize, &quot;up&quot;))hs.hotkey.bind(&#123;&quot;ctrl&quot;,&quot;cmd&quot;&#125;, &quot;Down&quot;, hs.fnutils.partial(winresize, &quot;down&quot;))-- Center of the screenhs.hotkey.bind(&#123;&quot;ctrl&quot;, &quot;cmd&quot;&#125;, &quot;C&quot;, center)-- Thirds of the screenhs.hotkey.bind(&#123;&quot;ctrl&quot;, &quot;alt&quot;&#125;, &quot;Left&quot;, left_third)hs.hotkey.bind(&#123;&quot;ctrl&quot;, &quot;alt&quot;&#125;, &quot;Right&quot;, right_third)hs.hotkey.bind(&#123;&quot;ctrl&quot;, &quot;alt&quot;&#125;, &quot;Up&quot;, up_third)hs.hotkey.bind(&#123;&quot;ctrl&quot;, &quot;alt&quot;&#125;, &quot;Down&quot;, down_third)-- Maximizedhs.hotkey.bind(&#123;&quot;ctrl&quot;, &quot;alt&quot;, &quot;cmd&quot;&#125;, &quot;F&quot;, hs.fnutils.partial(winresize, &quot;max&quot;))hs.hotkey.bind(&#123;&quot;ctrl&quot;, &quot;alt&quot;, &quot;cmd&quot;&#125;, &quot;Up&quot;, hs.fnutils.partial(winresize, &quot;max&quot;))-- Move between screenshs.hotkey.bind(&#123;&quot;ctrl&quot;, &quot;alt&quot;, &quot;cmd&quot;&#125;, &quot;Left&quot;, hs.fnutils.partial(winmovescreen, &quot;left&quot;))hs.hotkey.bind(&#123;&quot;ctrl&quot;, &quot;alt&quot;, &quot;cmd&quot;&#125;, &quot;Right&quot;, hs.fnutils.partial(winmovescreen, &quot;right&quot;)) hints: 窗口切换器 实现根据前缀快速切换到指定的窗口. 这里显示的图标位置按照窗口的左上角索引位置排列, 所以只要能记住窗口的位置, 就选择对应的前缀输入就可以完成切换了2 windowhints 经常卡顿几秒才弹出切换的窗口和对应的按键 根据WindowHints Performance · Issue #233 · Hammerspoon/hammerspoon这篇来看, 这个问题早早已经存在, 且主要受限于各自电脑装上的某些会阻塞的程序. 根据下面的代码, 可以发现关键点是windows = windows or window.allWindows()这段的用时长. 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253--- hs.hints.windowHints([windows, callback, allowNonStandard])--- Function--- Displays a keyboard hint for switching focus to each window------ Parameters:--- * windows - An optional table containing some `hs.window` objects. If this value is nil, all windows will be hinted--- * callback - An optional function that will be called when a window has been selected by the user. The function will be called with a single argument containing the `hs.window` object of the window chosen by the user--- * allowNonStandard - An optional boolean. If true, all windows will be included, not just standard windows------ Returns:--- * None------ Notes:--- * If there are more windows open than there are characters available in hs.hints.hintChars, multiple characters will be used--- * If hints.style is set to &quot;vimperator&quot;, every window hint is prefixed with the first character of the parent application&#x27;s name--- * To display hints only for the currently focused application, try something like:--- * `hs.hints.windowHints(hs.window.focusedWindow():application():allWindows())`function hints.windowHints(windows, callback, allowNonStandard) if hints.style == &quot;vimperator&quot; then hintChars = hints.hintCharsVimperator else hintChars = hints.hintChars end windows = windows or window.allWindows() selectionCallback = callback if (modalKey == nil) then modalKey = hints.setupModal() end hints.closeHints() hintDict = &#123;&#125; for _, win in ipairs(windows) do local app = win:application() if app and app:bundleID() and isValidWindow(win, allowNonStandard) then if hints.style == &quot;vimperator&quot; then local appchar = string.upper(string.sub(app:title(), 1, 1)) if hintDict[appchar] == nil then hintDict[appchar] = &#123;&#125; end hints.addWindow(hintDict[appchar], win) else hints.addWindow(hintDict, win) end end end takenPositions = &#123;&#125; if next(hintDict) ~= nil then hints.displayHintsForDict(hintDict, &quot;&quot;, nil, allowNonStandard) modalKey:enter() endend 在opt+z呼出的窗口中输入, 获取到自己环境中导致耗时长的程序 123456789101112131415&gt; hs.window._timed_allWindows()2022-02-19 23:15:05: took 0.12s for com.sogou.inputmethod.sogou2022-02-19 23:15:05: took 0.07s for com.apple.inputmethod.EmojiFunctionRowItem2022-02-19 23:15:05: took 1.68s for com.apple.quicklook.QuickLookUIService2022-02-19 23:15:05: took 0.06s for N/A2022-02-19 23:15:05: took 4.81s for com.apple.WebKit.WebContent2022-02-19 23:15:05: took 0.12s for com.apple.ViewBridgeAuxiliary2022-02-19 23:15:05: took 0.08s for com.apple.studentd2022-02-19 23:15:05: took 5.66s for com.apple.appkit.xpc.openAndSavePanelService2022-02-19 23:15:05: took 1.10s for com.apple.LookupViewService2022-02-19 23:15:05: took 0.11s for com.apple.controlstrip2022-02-19 23:15:05: took 1.25s for com.apple.ActivityMonitor2022-02-19 23:15:05: took 0.35s for com.apple.PressAndHold2022-02-19 23:15:05: took 0.90s for com.apple.amp.devicesui2022-02-19 23:15:05: table: 0x600000245f40 根据下文这段里的, 可以发现allWindows默认已经通过SKIP_APPS跳过了一些程序. 123456789101112131415161718192021222324local SKIP_APPS=&#123; [&#x27;com.apple.WebKit.WebContent&#x27;]=true,[&#x27;com.apple.qtserver&#x27;]=true,[&#x27;com.google.Chrome.helper&#x27;]=true, [&#x27;org.pqrs.Karabiner-AXNotifier&#x27;]=true,[&#x27;com.adobe.PDApp.AAMUpdatesNotifier&#x27;]=true, [&#x27;com.adobe.csi.CS5.5ServiceManager&#x27;]=true,[&#x27;com.mcafee.McAfeeReporter&#x27;]=true&#125;-- so apparently OSX enforces a 6s limit on apps to respond to AX queries;-- Karabiner&#x27;s AXNotifier and Adobe Update Notifier fail in that fashionfunction window.allWindows() local r=&#123;&#125; for _,app in ipairs(application.runningApplications()) do if app:kind()&gt;=0 then local bid=app:bundleID() or &#x27;N/A&#x27; --just for safety; universalaccessd has no bundleid (but it&#x27;s kind()==-1 anyway) if bid==&#x27;com.apple.finder&#x27; then --exclude the desktop &quot;window&quot; -- check the role explicitly, instead of relying on absent :id() - sometimes minimized windows have no :id() (El Cap Notes.app) for _,w in ipairs(app:allWindows()) do if w:role()==&#x27;AXWindow&#x27; then r[#r+1]=w end end elseif not SKIP_APPS[bid] then for _,w in ipairs(app:allWindows()) do r[#r+1]=w end end end end return rend 理论上使用hs.window.filter可能有帮助? 最后短时间没搞明白filter的注入到window.allWindows里的防范, 先手动在/Applications/Hammerspoon.app/Contents/Resources/extensions/hs/window.lua底下的SKIP_APPS直接增加了自己环境里耗时多的程序, 跳过后基本呼出alt+tab的延时正常了.34 根据这句来判断, hammerspoon在关闭SIP之后还是会存在这个问题的. 123456789local SKIP_APPS=&#123; [&#x27;com.apple.WebKit.WebContent&#x27;]=true,[&#x27;com.apple.qtserver&#x27;]=true,[&#x27;com.google.Chrome.helper&#x27;]=true, [&#x27;org.pqrs.Karabiner-AXNotifier&#x27;]=true,[&#x27;com.adobe.PDApp.AAMUpdatesNotifier&#x27;]=true, [&#x27;com.adobe.csi.CS5.5ServiceManager&#x27;]=true,[&#x27;com.mcafee.McAfeeReporter&#x27;]=true,[&#x27;com.apple.appkit.xpc.openAndSavePanelService&#x27;]=true, [&#x27;com.apple.quicklook.QuickLookUIService&#x27;]=true,[&#x27;com.apple.PressAndHold&#x27;]=true,[&#x27;com.apple.ActivityMonitor&#x27;]=true,[&#x27;com.apple.amp.devicesui&#x27;]=true&#125; 快捷方式打开指定目录下最新的文件(如截图) 1234567891011121314151617181920212223hs.hotkey.bind(&quot;alt&quot;, &quot;o&quot;, function() logger = hs.logger.new(&#x27;preview newest screenshot&#x27;) max = 0 newest_file = nil for file in hs.fs.dir(&quot;~/Desktop&quot;) do filepath = hs.fs.pathToAbsolute(table.concat(&#123;&quot;~/Desktop&quot;, file&#125;, &quot;/&quot;)) time = hs.fs.attributes(filepath)[&#x27;creation&#x27;] if max &lt; time then max = time newest_file = filepath end end if (max ~= 0) then logger.i(&quot;open \\&quot;&quot;..newest_file..&quot;\\&quot;&quot;) res = os.execute(&quot;open \\&quot;&quot;..newest_file..&quot;\\&quot;&quot;) logger.i(res) endend) TODO:os.execute会自动补全路径? 123&gt; os.execute(&quot;open \\&quot;~/Desktop/temp.sh\\&quot;&quot;)The file /Users/sean10/Desktop/~/Desktop/temp.sh does not exist.nil exit 1 快速切换显示器信号源, 基于DDC工具 增加了shift+F11的快速切换信号源的方案. 123hs.hotkey.bind(&quot;shift&quot;, &quot;f11&quot;, function() hidden_status = os.execute(&quot;/usr/local/bin/ddcctl -d 1 -i 15&quot;)end) 日志调试方式 How to debug Hammerspoon scripts? · Issue #989 · Hammerspoon/hammerspoon [pkulchenko/MobDebug: Remote debugger for Lua.](https://github.com/pkulchenko/MobDebug 根据上述链接, 应该可以用lua的调试方式来操作, mobdebug.lua 日志 12345logger = hs.logger.new(&#x27;preview snap&#x27;)logger.i(&quot;hello info&quot;)-- 默认hammerspoon是error等级日志logger.e(&quot;error) Reference (つェ⊂)咦!又好了!↩︎ Switching between windows with Alt + Tab · Issue #856 · Hammerspoon/hammerspoon↩︎ Hammerspoon get sluggish with vscode running · Issue #2289 · Hammerspoon/hammerspoon↩︎ windowHints are slow · Issue #2970 · Hammerspoon/hammerspoon &gt; Yabai is capable of doing what you want using only the window id, but that solution requires disabling SIP and injecting code into Dock.app.↩︎","categories":[{"name":"专业","slug":"pro","permalink":"https://sean10.github.io/categories/pro/"}],"tags":[{"name":"mac","slug":"mac","permalink":"https://sean10.github.io/tags/mac/"},{"name":"hammerspoon","slug":"hammerspoon","permalink":"https://sean10.github.io/tags/hammerspoon/"},{"name":"Alfred","slug":"Alfred","permalink":"https://sean10.github.io/tags/Alfred/"},{"name":"extension","slug":"extension","permalink":"https://sean10.github.io/tags/extension/"}]},{"title":"ceph之dashboard社区状态小探","slug":"ceph之dashboard","date":"2021-12-02T11:26:04.000Z","updated":"2023-03-18T15:11:14.811Z","comments":true,"path":"2021/12/02/ceph之dashboard/","link":"","permalink":"https://sean10.github.io/2021/12/02/ceph%E4%B9%8Bdashboard/","excerpt":"","text":"本篇主要是把旧文重新整理一下. 定位 目前已经为唯一的非自研的开源对接ceph的, 已将grafana嵌入. 监控/告警 支持大部分想看到的数据 实施方面, 对接cephadm? 那是否对接ceph-ansible? 不对接, 但是ceph-ansible似乎也对接了cephadm, 作为cephadm的上层统一管理? ceph-orch的能力? Orchestrator CLI — Ceph Documentation 根据这里看到的, 对接了cephadm后支持了基本上所有的服务能力 提供监控/告警 dashboard 更新背景 The original Ceph Dashboard that was shipped with Ceph Luminous started out as a simple read-only view into run-time information and performance data of Ceph clusters. It used a very simple architecture to achieve the original goal. However, there was growing demand for richer web-based management capabilities, to make it easier to administer Ceph for users that prefer a WebUI over the CLI. 12版本的定位还是单纯的只读. 后面版本引入了OpenATTIC的组件. On 9 November 2016, SUSE announced the acquisition of assets relating to the OpenAttic storage management assets from the German IT firm it-novum.[16] OpenAttic was integrated into SUSE Enterprise Storage as a graphical tool to manage and monitor Ceph-based storage clusters. --SUSE - Wikipedia Suse以前提供Calamari的管理页面, 在Luminos发布前一年收购了OpenATTIC(当时就是提供ceph支持的web UI)替换Calamari, 在Luminous在2017-08-01发布时, 社区自己也开发了一个只读的dashboard_v1. 在Nautilus发布时2019-03-19, The openATTIC project enters maintenance mode | openATTIC在2019-08-22正式宣布,openATTIC只做维护, 所有开发直接在上游ceph进行. 实际上, 在Mimic版本就开始合入提供这个新的dashboard支持了, 只是在Nautilus提供了第一个稳定的支持多功能的dashboard_v2. mgr/dashboard_v2: Initial submission of a web-based management UI (replacement for the existing dashboard) by LenzGr · Pull Request #20103 · ceph/ceph 2020年末suse在渠道中SUSE POC - Dead in the water - ceph-users - lists.ceph.io宣布最后一个基于ceph的企业存储版本, 同期收购了Rancher Labs, 后续将投入Longhorn TODO: 所以是否suse还在提供dashboard的维护支持? dashboard模块负责人 Ernesto Puerta, RedHat等人依旧在维护. Tatjana Dehler和Kiefer Chang等SUSE成员自20年12月已停止继续提交到ceph中. 另外dashboard/的许可证是否确实是LGPL? 或者AGPL, 导致无法使用? Free software (LGPL 2.1).所以修改是必须遵守的, 要拆分Python和js框架, 不太确认. grafana在21年修改为AGPL3.0, Grafana 8版本以前还是Apache 2.0可以使用 初步来看, 是支持cephadm提供的所有能力. API来源 The dashboard module’s backend code uses the CherryPy framework and implements a custom REST API. TODO: 所以是配合\bmgr提供的API能力, 还是自己重新写的调用呢? 内部走的mgr的rados接口, 只是封装成OpenAPI3.0的协议. src/pybind/mgr/dashboard/controllers/crush_rule.py比如这里就可以看到 一个计划做的: crush map的自定义能力. 目前依旧不支持自定义能力. osd的实施界面, 计划仿2004 Storage Devices and OSDs Management Workflows — Ceph Documentation 这里的设计也是类2004那种, 需要手动指定db,wal的. 2020年9月时的设计, 目前未更新. 目前的, 看到的主要是将cephadm集成入dashboard 根据service来看, 是将所有进程同等管理? SUSE的文档基本足够了About the Ceph Dashboard | Administration and Operations Guide | SUSE Enterprise Storage 7 RH也是这个界面的文档Storage Devices and OSDs Management Workflows — Ceph Documentation ceph-ansible似乎也对接了cephadm. 具体还没看 运行一个带cephadm的dashboard 1234567891011121314151617MON=1 MGR=1 OSD=3 MDS=1 ../src/vstart.sh -d -n -x --cephadm -i 0.0.0.00.0.0.0不行, 因为这里还设置mon的绑定ip.# cephadm需要asyncsshpip3 install asyncssh# 配置ssh免密cd ~/.ssh/ &amp;&amp; ssh-keygen chmod 600 ~/.ssh/id_rsacat ~/.ssh/id_rsa.pub &gt;&gt; ~/.ssh/authorized_host# cephadm需要部署docker或者podmandnf install docker-ceceph config set mgr mgr/dashboard/server_addr 0.0.0.0ceph mgr module disable dashboardceph mgr module enable dashboard 以下为旧文, 当时针对Luminous版本分析 Luminous版本局限功能 health object/data used/capacity mon数量监控 meta services 数量监控 OSD up, in数量监控 manager 状态监控 pool下pg状态, usage, IOPS监控 cluster log 集群角色列表, 每个节点上部署的mon, osd OSDS IOPS, 吞吐量, 约25s左右的5次左右的时间窗口的折线图 ceph原生配置 rbd mirror iSCSI 每个pool的rbd size/objects/object size, snap概念 filesystem. 数据时效性 疑似还是没有数据库的实时数据 但是似乎又支持嵌入grafana的图[^2] Nautilus新增的应该. Additionally, the Ceph Dashboard’s “Block” tab now includes a new “Overall Performance” sub-tab which will display an embedded Grafana dashboard of high-level RBD metrics. This provides a quick at-a-glance view of the overall block workloads’ IOPS, throughput, and average latency. It also displays the top 10 images that are using the highest IOPS and throughput, and as well as the images with the highest request latency.[^1] 是否支持页面修改集群? mon 不支持扩容节点 Nautilus版本的dashboard_v2已支持 osd 支持mark osd状态 不支持创建osd Nautilus版本dashboard_v2已支持 只提供这些展示的设计缘由?[^3] 不知道有没有这个设计的理由, 因为看起来,像是grafana+prometheus的历史数据折线图展示并没有出现在这里. 只提供实时信息展示有什么特别的理由吗? 状态窗口 cluster status hosts monitors running num quorum manager active num standby num pools block iSCSI running Object Gateways num NFS Filesystems metadata servers Object Gateway running Object Gateways num 性能窗口 client IOPS client Throughout client Read/write ratio recovery throughout scrub status 容量窗口 pools raw capacity objects PGs per OSD PG status dashboard 账户权限系统 设置各权限账户的增删改查权限. 集群具体信息 这里好像monitors,osd级别都只能看, 从pool开始才能做创建修改 cluster nodes set cluster configuration monitors in quorum and not in quorum list. rank public address open sessions OSDs name status number of pgs size usage reads/write ops/throughout bluestore performance counter set recovery priority watch crush map set manager modules watch logs POOLS add del edit RBD add del edit snapshots iSCSI Gateway add edit del QoS config RBD Mirror config NFS Ganesha add view edit Filesystems view Object Gateways view user add edit del bucket view update del manual configuration TLS/SSL self-signed Ceriticates SSO SAML 2.0 protocol. cli control user and roles. prometheus + grafana 这个在Nautilus的版本来看, 基本比较一般. Reference Ceph New in Nautilus: RBD Performance Monitoring - Ceph Ceph Dashboard | Administration Guide | SUSE Enterprise Storage 6 Ceph Dashboard — Ceph Documentation","categories":[{"name":"专业","slug":"pro","permalink":"https://sean10.github.io/categories/pro/"}],"tags":[{"name":"ceph","slug":"ceph","permalink":"https://sean10.github.io/tags/ceph/"},{"name":"dashboard","slug":"dashboard","permalink":"https://sean10.github.io/tags/dashboard/"}]},{"title":"高可用初理解","slug":"高可用初理解","date":"2021-11-27T15:17:08.000Z","updated":"2022-07-15T00:46:00.000Z","comments":true,"path":"2021/11/27/高可用初理解/","link":"","permalink":"https://sean10.github.io/2021/11/27/%E9%AB%98%E5%8F%AF%E7%94%A8%E5%88%9D%E7%90%86%E8%A7%A3/","excerpt":"","text":"高可用的目标 提升平均无故障间隔（MTTF） 缩短平均修复时间（MTTR） 定义上, 高可用其实分为以下几种. 冗余 以及可以基于这个剩下的节点提供除冗余外的完整的服务. 降级 关闭某些功能的情况下继续提供服务. 熔断 熔断更多指检测到连续故障, 让后续的也先拦截掉, 避免无法提供服务但依旧冲击服务压力. 检测到恢复之后再自愈那种. ceph-osd假设重构降级了, 这个情况下业务io继续打下来, 这个时候应该是阻塞, 而并没有通过熔断中断io. 但是如果是业务io, 发现io异常了, 倒是上层可以自行熔断. 只是这种其实更要求下层的可靠性. 不然上游服务器应该会拥塞住. 假设上游服务器还承担其他功能, 此时就会被僵死. 扛不住这点, 根本上应该通过限流控制, 当组件存在异常后, 此时带来的处理能力不足, 就需要熔断来尽量避免堆积. 熔断后短时间无法恢复则应该考虑整体降级功能了. 限流 针对自身能提供的能力通过限流拦住. 高并发整体可用性：一文详解降级、限流和熔断_Hollis的技术博客_51CTO博客 面试官：说说降级、熔断、限流 - 掘金 服务降级与服务熔断区别 - 知乎 完整高可用方案的分类 完整的高可用方案目前理随着当前发展主要分为以下几类. 冷备 手动恢复 双机热备 active/standy 即应用级灾备 同城双活 异地双活 异地多活 本文不讨论完整的灾备/多活方案, 主要只涉及本地的高可用, 即双机热备那种, 应用级灾备. 应用级高可用方案细分 客户端 客户端直接填写多个服务端ip, 故障后自行切换. 比如ceph的客户端节点访问mon, 主要依赖客户端节点的配置中mon的地址. 根据mon地址去连接. 当一个mon故障时, 会根据其他mon地址进行连接. 服务之间 指的就是基于选举自身实现高可用了. 比如ceph-mon之间选举leader, 中间件 如早期不支持集群的redis上层增加的Codis等等 或者就是存储端上层, 增加keepalived/nginx等进行处理, 比如云计算当节点存在异常时, 会疏散切换到另一个节点, 比如keepalive提供的vip切换节点的能力. 或是提供dns层级的 脑裂问题 脑裂问题按目前理解, 算是高可用问题中存在风险较大的一个了 常见解决方案[^HA高可用集群中\"脑裂\"问题解决 - 运维总结 - 散尽浮华 - 博客园] 添加冗余的心跳线路 如网口绑定, 避免单根线故障, 引起节点直接异常. 做的更极端一些, 两根线连不同的交换机? 避免交换机的单点故障? 但一般小规模集群不需要. 大规模集群有节点/机柜层级的冗余了. 设置第三方仲裁机制 显式的仲裁, 即明确的第三方节点参数选举/判定等 借助环境中节点以外的资源进行仲裁 如主备的keepalived配置中增加周期ping网关的check操作, ping不通则代表本节点有问题, 需要自行停止服务 如双控设备, 借助同时连接的硬盘, 在硬盘上设置标记, 实现磁盘锁. 似乎相比上面ping网关, 提供了额外的数据同步能力? 存在奇数节点的选举算法 fense(屏蔽)机制 --硬件设备 利用ipmi的fence设备, 将故障节点踢出集群? 为啥不是局部组件踢出? RHCS的Fence设备分为内部和外部两种Fence。内部fence有IBMRSAII卡，HP的ILO卡，以及IPMI设备等；外部FENCE设备有UPS，SANswitch ，Networkswitch等。 对于小规模集群有必要吗? 如果是多个组件, 比如内网异常可能只影响到某些用内网的组件呀. 为啥要把整个节点的服务都踢出呢? 大规模集群的话合理, 但是小规模呢? 屏蔽可以定义为一种使 HA 群集具有已知状态的方法。 根据上面这句话来理解, 至少能够做到对节点的处理能力状态进行一定程序的定义. 资源级别和节点级别的屏蔽 在 Pacemaker 群集中，节点级别屏蔽的实施方式是 STONITH（关闭其他节点） 屏障和 STONITH | 管理指南 | SUSE Linux Enterprise High Availability Extension 15 SP1 ^HA高可用集群中\"脑裂\"问题解决 - 运维总结 - 散尽浮华 - 博客园 场景 目前主要是以下场景 2节点场景下, 需要提供数据存储/计算资源/等的高可用能力(有些情况还是有这种需求) 3节点以上场景, 则基本都是正常的疏散逻辑能够处理的. 这里我们讨论的, 目前主要是存储的冗余能力. 回到关心的存储的冗余的场景里, 指的是2个节点下, 其中一个节点彻底离线, 或者是出现了2个节点之间的网络中断, 而期望对外的业务服务并不中断的场景. P.S. 其实严格意义上来说, 存储冗余之外,上层业务也需要做上面的另外三种方案. 只是如虚拟机等方案比如存储外再通过本地存储备份拉起可用虚拟机做降级等, 可能在一般的冗余要求下 投入成本过高. 以ceph 2节点举例. 以具体的存储比如ceph举例, ceph如果是基于rbd/cephfs/rgw协议直接对接使用时, 是需要先基于rados协议与mon节点建立连接, 获取到当前最新的osdmap后, 根据osdmap计算出当前请求的目标osd, 然后客户端与osd直接建立连接的. 当2节点场景下, 按官方默认推荐方案仅实施1个mon/mgr时, 当这个mon所在节点离线的情况下, 就会存在无法查询到最新的osdmap, 也就无法与osd建立连接的情况. 发散一下思路 1. 是否有可能让ceph在无法与mon通信的情况下, 依旧支持根据现有的osdmap去建立通信的方案? 可能有. 但是去中心化, 参考区块链的定义, 其实也意味着数据要么在任意协议中都有保存, 要么本地曾经有过, 保存下来了. 那可能的实现思路就是基于本地历史的osdmap去计算目标源. 然后连上osd之后, osd再承接一部分osdmap分发的能力, 转派真实的osd地址. 这样技术上有一定的实现难度, 但看起来似乎也不是不行. 2. 是否可以在2节点情况下, 让存活足够数量的mon 比如2节点运行3个mon? 这里的方案, 其实就首先每个节点运行一个节点服务, 另外1个节点会运行一个额外的服务. 当出现节点异常时, 通过感知到对端离线, 本地去启动那个额外的服务, 确保本节点数量是满足要求的. 这里引出一个需求点: 这个额外的服务的数据库哪里来? 无论是ceph-mon还是zookeeper其实都具有一个特点, 就是数据强一致性, 即数据库是完全可重用的. 即当判断时, 临时复制出一个也不是不可以. 或是通过一个共享存储空间. P.S. 这里其实共享存储空间是否可能并不是决定性的? 因为本身节点之间通过强一致算法去写数据, 这里数据库之间不一致的检查是为了处理跨节点因网络或各式因素引起的强一致性不可靠. 而对于单节点拉起2个程序, 这点上, 起到的冗余效果可能只是进程级别的? 基本可能没有太大作用? 只是为了实现2节点下高可用才进行的. 按理想的场景 确实对端彻底离线了, 那切换确实问题不大. 但是这里的核心问题点, 当出现网络隔离或脑裂时, 如果两端真的同时拉起新服务, 同时起集群. 那就会导致数据不一致了. 换言之, 这个方案也还是需要一个第三方在网络隔离时, 能够识别出哪个节点才是真实可服务的. 比如就拉起2个mon? 通过设置mon之间的权重优先级,是否有可能? 其实是有可能的, 关键问题其实是在于脑裂, 网络隔离时, 两边都无法感知到对端时, 如何不两边同时拉起 或停止服务. 即需要有一个第三方仲裁者来完成这件事. 思路 如果除了ceph和keepalived的ip之外, 这两个节点还使用了如keepalived这类vip层级. 即2节点其实是共用一个vip的. 这时vip的共用引入了一个第三方, 网关(三层交换机/路由器). 此时利用路由器网关的能力, 通过vip ping一下网关, 确保一个子网里, 只有一个vip存活. 这种思路, 其实就是依赖了ip冲突的检测能力, 从而完成了一个仲裁. TODO: 这里存在一个疑问项, 网关按RFC协议如何响应呢? 双控服务器 则是特例 如果是双控服务器, 则双控服务器接入了同一套expander, 可以从expander层面作为一个第三方, 物理磁盘是同一套, 不同控制器可以在磁盘上存储标记位, 检测磁盘锁. 这样确保一个控制器离线的情况下, 另一个节点能够从磁盘锁上判断对端是否存活, 是否在本节点拉起额外的服务. 现实化场景 依旧如果是普通节点的情况下, 划分管理网络,前端网络, 后端网络, 2节点场景 业务程序分为运行在本节点上, 用户基于BS/CS使用本节点上的业务, 和外部节点通过前端网络通信 两种 脑裂为主要场景, 所以这里主要讨论网络异常引起的那种. 不讨论节点正常离线那种. 业务运行在本节点上(如计算/存储一体, 此时存储的前后端网络其实都是节点的后端网络) 前端网络断开 此时计算需要进行冗余处理. 只需要计算资源能够确认哪个节点是继续提供服务节点即可. 即通过上面的高可用常见解决方案来完成 此时存储无异常. 后端网络断开 一台设备内网线全异常了. 这个情况下, 这俩与外网依旧能通, 但是这俩节点之间的后端网络不通了. 此时计算无异常. 此时, 因为前端网络依旧是通的, 所以vip本身还是可以保障的, 对外的vip一般应该是不变的. 即用户访问计算资源, 还是可以正常连接上的. 此时存储需要冗余处理. 但是ceph-mon的程序无法工作, 导致计算资源无法再操作存储了. 如果需要解决, 即需要存储在这个情况下不脑裂继续提供服务. 其实是可以通过上面说的拉起3个/以及后端网络也存在vip来处理. 因为当断一个外部网络, 存储自身通过网关检测到哪个节点的后端网络先能使用这个ip, 则由该节点拉起足够数量的mon继续提供服务. 全断开 此时计算/存储均出问题. 此时计算, 可能会出现两端都拉起了计算程序. 因为彻底无第三方, 则可能计算节点自身同时启动. 存储如果也做了上面的拉起足够数量的mon继续提供服务, 则也会出现脑裂问题. 两端同时启动, 同时对本机上的计算资源提供服务. 此时如果业务会有周期操作, 如快照等. 则会出现节点内产生的数据不一致的写操作. 业务是外部节点 通过存储的前端网络通信 前端网络断开 业务请求无法访问某一台了, 存储如果没做上面拉起足够数量mon的方案, 则在mon节点离线时无法响应. 如果做了, 则正常冗余切换到另一节点继续提供服务即可. 后端网络断开 此时即存储内网, 会正常通过心跳降级掉无法连上的节点的osd, 继续提供服务. 全断开 如果采用了拉起足够数量mon方案, 此时两端会同时尝试提供降级服务. 但是由于业务节点不在存储端, 倒是不会产生数据不一致问题. 总结 根据上面可以看到, 在有些场景下, 提高了可用性, 会引起数据不一致风险. C和A在此时互相冲突. 这里就不再是技术问题了, 而是主要看市场如何了. 是支持高可用带来的利润足以抵消几起数据不一致风险, 还是为了数据一致性, 牺牲部分场景的高可用支持能力了. Reference 超大规模数据库集群保稳系列之一：高可用系统 - 美团技术团队","categories":[{"name":"专业","slug":"pro","permalink":"https://sean10.github.io/categories/pro/"}],"tags":[{"name":"高可用","slug":"高可用","permalink":"https://sean10.github.io/tags/%E9%AB%98%E5%8F%AF%E7%94%A8/"},{"name":"keepalived","slug":"keepalived","permalink":"https://sean10.github.io/tags/keepalived/"}]},{"title":"团队管理初探","slug":"团队管理初探","date":"2021-10-24T15:53:05.000Z","updated":"2024-06-30T06:57:04.181Z","comments":true,"path":"2021/10/24/团队管理初探/","link":"","permalink":"https://sean10.github.io/2021/10/24/%E5%9B%A2%E9%98%9F%E7%AE%A1%E7%90%86%E5%88%9D%E6%8E%A2/","excerpt":"","text":"背景 近年来, 在组织团队的任务跟进方面, 存在一部分欠缺, 存在进度滞后的现象. 进展存在阻塞, 但是又没有及时感知到, 申请SE等协助, 导致问题长期阻塞的情况. 因此在这里整理了一下目前主要的几个诉求. 诉求 记录和评估方面 工作量记录 预研类不可预计的工作量, 当存在ddl时, 如何确保人力是否需要追加 繁琐的必须做的任务的工作量, 当存在坑时, 需要能够识别. rdms有工作量任务统计要求, 所以总体的时间是需要同步到这里的. 利用团队的力量 共同解决难点(PS. 从产出角度, 如果是已经踩过的坑, 让新人快速绕过, 最省时间, 同样产出最大化) 存在阻塞或者坑时, 能够让其他人也发现问题, 看看是否能够共同解决 能够识别出踩坑后耗时的工作量, 用以区分是否有新发现, 还是进入到了错误的分支 避免无效任务 工作量和产 出价值 符合 对应的水准 是否显著的可评分? 由于大部分水平是相近的, 其实大概输出的概率是相似的 根据表格识别出绩效优劣, 直接输出结果. 这种严格需要一个综述概况的表, 难度较高 团队整体评估 预计任务的工作量? 然后咱们算加权平均? 来代表这个任务的难度? 然后产出的时候就拿完成的任务的工作量来比较? 感觉可以, 这样至少每个任务都是大家全部参与过评估的了? 有异议的则增加具体的评估理解, 然后多轮次达成一致. 紧急需求和重要慢慢做的需求, 其实评分可以靠近的. 一些任务的完成情况的评价? 还是相关人员的复盘? 调研类, 无法评估时长的这种? 则另说, 看调研后的产出和用时吧? 估计大部分情况下, 产出的评价是很贴近的. 怎么才能拉开区分度呢? 任务描述, 如何体现价值? 同样写一句话的任务, 复杂度肯定是不同的. 怎么评价呢? 进度同步 站立会 进度同步 关键任务 和 阻塞的内容, 口头简述 任务详情记录 继续在任务上继续详细信息 一眼直观可见每个人/每个大OR任务进展, 不必具体点进去 irdms记录任务长期计划 hikke拆解\b详细子任务, 建议子任务不超过16小时. 任务安排 杂活如何安排, 一些比较耗时的工作, 产出角度可能没那么大. 十分需要领导的理解, 领导在判定这部分时, 需要理解其确实有工作量. 接收该任务的人的评估要求需要适当放低. 比如合格起步. 难度较高的模块, 当出现没人能解决的问题时, 此部分时间可以接受. 难度可能适中的模块, 如果阻塞的问题实际上其他人可能解决过, 这部分的时间是可提升的. 所以需要通过一个手段比如站立会, 快速感知. 而不是长期被阻塞在其中. 评估标准中, 是否有人协助并不那么重要, 不过复盘时, 如果没有站立会, 确实需要一个这个来体现任务的难度. 另外有人协助的模块和没人协助的模块 没人协助的是否需要增加评价? 如果有人协助, 协助的人应该加分在团队协作层面吧? 然后主任务的进度如果落后了, 这个属于个人水平过敏啊 不过像是一个全新的组件, 没人协助是正常的, 这种情况下耗时久咋算呢? 学习曲线, 评估是 关键任务安排 关键任务. 是否要搞成基本很赶的那种? 是否要给一些自定义的任务时间? 关键任务要平均分吗? 还是 初步计划 初期将OKR拆解成大任务, 周会等中间采取JIRA看板方式同步具体进展. 周会 同步OKR进展(根据每周站立会进展, 可以确认是否需要变更, 然后绩效的任务也跟着变化即可) 通过在周会中确认进展是否恰当, 是否存在滞后 OKR, 提供整体目标, 然后具体任务都是为了这个目标服务的. 基于这个整体目标, 大家可以自行对任务进行调整. 整体目标是固定的, 然后任务的细节是会随着调研或者开发过程中逐渐发现问题而调整的. 月度总结, review整体进度, 然后确认. 似乎跟周会存在重合, 先实践再确认月度是否需要? 拆分详细的周目标和 月目标用? 站立会 通过站立会把存在的障碍, 和需要的帮助协调了. (口头沟通即可, 无需记录. 具体记录的还是个人通过任务和进度来记录) 每天下午5点做站立会吧? 这样刚好? 大任务进展同步 超过16小时的任务, 拆分下一步计划, 将任务明确. 以细节来理. 大任务到底单独跟进 输出具体目标的大任务的每日进展的表? 通过hikke平台进行吧 这个就不通过那个irdms了, 不方便记录和复盘. 这个hikke 是用于闭环所有任务? 还是仅关键任务呢? 需求列表里肯定是把所有大任务都给描述上. 那一些小任务, 是在irdms那里自己添加? 嗯 评估的时间不准确, 或者预计耗时长, 无法让项目经历认同很正常, 此时就应该拆解出具体的任务细节, 以及实际过程执行的效率来有理有据的说明, 达成一致后, 再上升领导看增加人力或者调整任务计划. 耗时优化则通过规范化,流程化方案, 进行配置管理, 减少重复的投入 敏捷在这方面的考虑可能更倾向于拥抱变化, 及时更新计划. 可参考指标 统计开发工时, 可以通过irdms查看统计的工作量和一些日常任务的分类占用时间. 这部分可以用于参考, 和考虑将一些占用时间多的赋能给其他部门进行. 调研 白盒的前提的基础模板最好是有一个经过迭代验证过的计算模型, 否则白盒可能带来更大的不公正. 现阶段还是沿用其他组一样的黑盒模式吧. 然后重点就是让任务的进展都在把控中, 重点就是OKR的理念, 每月同步进展, 更新绩效计划具体的任务和小目标. 然后这种情况下, 是否存在因个人原因脱钩, 才是需要考虑的点. 一切按计划进行, 则绩效就没那么重要了.1 评估点 业务贡献：包括需求把控，业务项目和业务创新。 技术贡献：包括设计重构、技术影响力、Code Review、创新提效和代码质量。 团队贡献：包括招聘、新人培养和团队氛围。 scrum Scrum实践总结-团队绩效评估_hellion2的专栏-CSDN博客 自发认领任务? 目前一些耗时长, 产生质量等方面价值的事情, 个人成长性较少, 预计不太可行. 工作量评估, 可让所有人参与? 投票过程采用求大同、存小异、取平均的方式。计划会议过程采用：讲解需求-&gt;提问与解释-&gt;匿名出牌-&gt;讨论-&gt;重新出牌-&gt;达到近似一致-&gt;采取平均的流程，确保大家都理解功能点的业务需求、处理方式 评估 绩效评估的统计及公布。每个sprint迭代结束时候的反思会公布统计排名结果。邮件发送给全体成员，并记录到项目的总的绩效统计中。在项目奖的分配上严格按照工作量的统计结果计算。 360评价? 绩效排名的指导原则： 团队内提前对齐标准，形成正确预期，不能有惊喜 信息收集要全面，要体现多元价值观，避免单一标准 定性与定量结合，任何数据都只是参考，警惕虚假的精确性 字节跳动，到底是怎么管理11万员工绩效的？ - 《财富管理》杂志社 OKR 目标对齐 评估主观 质量这块，量化难度太大，但也不是完全没法量化，它有一部分是可以量化的，在我看来，质量可以分成三部分：代码质量：代码本身的质量决定了对后续开发的友好程度研发质量：研发阶段产生的bug运维质量：产品上线以后的故障情况和资源消耗情况其中，第一类，我认为没法量化，我的做法是不考核，只作为努力提高的方向和主观考核依据，因为它产生的成本可以通过自己后续的努力重构来弥补，原则上应该谁挖的坑谁填（这样还是会有问题，可能导致\"透支\"，即坑越挖越大最后人跑了留下个烂摊子，但我没找到更好的办法了，摊手）。第二类，很难用bug数量来衡量研发质量，所以这块我比较倾向于用红线的形式来考核：冒烟bug、build break、低级bug和regression做记录，其它bug视为正常研发中的沟通。第三类我认为是可以量化的，通过线上服务器消耗、故障恢复时长等来做考核，这种考核的优点同样是投资人和老板看得见，不需要担心指定的KPI偏离了大方向。总之呢，技术管理这事其实挺复杂的，现在这个发展阶段，很多问题都没答案，我觉得我能给的最重要的建议是“不要瞎搞”，宁肯全用主观评价，也不要引入错误的量化指标。 作者：winter 链接：https://www.zhihu.com/question/19995922/answer/138897200 来源：知乎 著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。 市场机制 如何量化衡量一个程序员的工作量和工作效率？ - 知乎 &gt; 市场机制每个人的工作效率不同，如何量化工作效率也是一个问题。假定公司需要解决一个 bug，这个 bug 由普通程序员来解决，需要1个月，但天才只需要1天时间。那么给天才的报酬就应该比普通人高一些。代码除了数量和质量不同，难度很可能也不同。难度越高，相应的报酬也越高。继续假定公司需要解决一个 超级难搞的 bug，这个 bug 由普通程序员修复是不可能的，这个bug远远超过了任何普通程序员的能力，他们根本就无法定位问题。而天才可以修复这个 bug。这区区几行代码的难度是什么，需要评估。如何评估这些不同，是让所有人都头大的难题。但如果我们换一种方式思考，所有的问题就迎刃而解了。让所有程序员对同一个任务的难度打分，然后将任务分配给打分较低的程序员。 &gt; &gt; 作者：松柏 &gt; 链接：https://www.zhihu.com/question/20422695/answer/15095960 &gt; 来源：知乎 &gt; 著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。 &gt; 黑盒评估 \b由理解这些的TL来在心里建立一些代价的评估标准. 对内遵循TL的设计, 对上级汇报组内评估后的结构, 代价由TL来承接即可. TL来确保 重构额代价可接受 Q： 你这个设计重构怎么量化？ A： 这个很难用系统标准化，更多的还是要依赖TL的专业能力进行评分，但即使是这样，也比以前什么都没有完全黑盒要强。至少在传达一个信息，我们鼓励好的设计，鼓励不断地重构优化。 Q：我们现在的业务需求已经在堆积，一线同学根本没有时间去做重构优化。 A：这个问题开篇其实已经说过了，你是要不断地裹挟在业务需求和烂代码里面呢，还是花时间improve，然后更快地支持业务。这个权衡应该不难做，关键是要看决心和能力。对于很多业务，我没有看到推迟几天上线就会影响业务格局的业务场景，所以作为技术团队，我们就应该在User Story之外，加上我们的Technical Story，把完成业务需求和系统重构都当成我们的核心任务。 如何量化考核技术人的 KPI？_阿里技术-CSDN博客 任务执行前, 大致明确计划, 然后根据信息动态规划更新进展 这篇同样指的是OKR的动态跟进进展, 及时更新计划. 作者：知乎用户 链接：https://www.zhihu.com/question/19995922/answer/139929808 来源：知乎 著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。 我觉得量化管理是做不到的，更多的是「set expectation」和「manage expectation」，然后通过「calibration」是做到更大范围内的公平公正。什么是「set expectation」，就是在事情没有做之前就要先说好事情做成功应该是什么样子的，需要付出怎样的代价。例如说，「未来 3 个月优化用户注册流程，使得用户注册转化率提高 10%」。如果一个 E5 的工程师跟经理说，「我能在未来 3 个月提高用户注册转化率 10%，你觉得怎样？」那么经理有几种回应的方法：1.「这很好，你去做吧，做好了至少 E5 能够拿一个 meets all expectation。」2.「这太简单了，只能算 E4 的工作，你 E5 做出来了也只能拿 meets most expectation。」3.「这可能比你想象中的要复杂，能做出来的话你升 E6 没问题，但有一些可能存在的问题你先要想清楚。」这样「set expectation」做好了，好处就是双方不用猜测到底自己做成怎样然后对方会给什么结果。然而这样的事情不是做一次就结束的，因为工作过程中会获得新的信息，然后这些新的信息会带来新的抉择，就如同一个动态规划执行的过程一样，所以中间必须不停地「manage expectation」。可能需要沟通的状况例如：1.「我们一个月就把转化率提升了 8%，我们应该把三个月的目标重新设置为 20%。」2.「我们第一个月只提升了 2%，在研究同类产品的注册转化率后我们觉得提升 5% 就封顶了，目标应该调整为 5%。」 接下来的问题就是怎样保证公平公正。因为每个人会都会想把 expectation 往下调，那怎样说明你做了你这个级别应该做的工作呢？就只能通过「calibration」来横向对比了。如果其它在这个级别的人做出来的结果跟你相似，那你做的结果就是没问题的。这个横向对比不仅仅可以在不同人之间做，还可以在跨不同时间段做。 作者：知乎用户 链接：https://www.zhihu.com/question/19995922/answer/139929808 来源：知乎 著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。 最搞笑的是有些答案提及 OKR 的 Objective 要能量化。OKR 中的 Objective 和 Key Results 分离就是为了让 Objective 不能量化只能指导方向，然后 Key Results 是否指向正确方向允许争论。如果 Objective 是「让用户更加享受我们的应用」，Key Results 可以是「增加用户使用时间到 X」或者是「App Store 评分增加到 Y」。但如果你拼命忽悠用户去 App Store 给你打高分，他们因此而不爽这个应用，那你就是满足了 Key Results 而违背了 Objective。OKR 存在的意义就是允许允许大家了解 Objective 从而盯着 Key Results 的实现方式，阻止违背 Objective 的行为出现。 作者：知乎用户 链接：https://www.zhihu.com/question/19995922/answer/139929808 来源：知乎 著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。 OKR与绩效拆分 也就是说把 OKR 打分和绩效打分不放一起，中间隔 1 到 2 个月，这是一个反思并改进的过程。绩效评定出来之后，管理者需要和员工做绩效面谈，它分为两种，一种是内部激励，第二种是外部激励，内部和外部激励是分两次去进行的。第一次是去跟员工讲 OKR 的结果，主要是和他讲清楚哪些目标没做到？接下来应该怎么做？方法是否有欠缺？或者员工需要哪些帮助？从这个角度和员工聊，不涉及到工资和奖金，员工比较容易听进区去，不会友太大的抵触心理。 进度把控是绩效的重点, 快速发现问题并推进 创业公司是如何进行研发管理和绩效考核的？从豌豆荚说开去 | 人人都是产品经理 敏捷绩效管理三剑客：OKR 、KPI、CFR | CODING 洞见 周例会 会前充分准备：从成员们正在处理的事务入手，确定哪些是争议问题，哪些又是关键信息。 确定工作优先级：专注于促进 OKR 达成的事情。 状态确认：团队对于 OKR 达成的信心是上升还是下降了？大家是否愿意说出困难和风险？ 激发员工敬业度：要利用 OKR 激发员工的创造性思考，同时避免挑战性目标带来的消极情绪。 从大局出发：OKR 是对公司战略的执行，我们要从整体的角度来评判 OKR 的进展或问题，以及对未来的影响。 周例会的目标有三个： 评估目标； 在问题爆发前识别潜在风险； 在使用 OKR 之初，就严谨地把 OKR 管理方法融入到企业文化之中，确保团队持续聚焦； 腾讯 接下来说最重要的部分：过程度量和review 目前来说，我们是一个月review一次，review的过程接受跟进实际情况的部分调整，但这里得拉大家一起讨论处理。另外，对于大型项目，review的过程也可以发现kpi目标的制定是否有可度量的方式，如果不行，那需要再次细化kpi，避免出现最后核算的时候，确认不了是否能完成。 作者：匿名用户 链接：https://www.zhihu.com/question/20190597/answer/111073368 来源：知乎 著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。 可能就是OKR的理念, 每月同步进展, 更新绩效计划具体的任务和小目标. Peer Review 绩效考核中的PeerReview与结果分析 - 知乎 结论似乎就是没啥用目前 绩效结果 信任关系 花大量时间来确保公平 目标 公平、无偏差和清晰的反馈。反馈应该基于先前设定的预期，期望值应该经过校准，并清楚地说明该员工是否达到、低于或高于该预期。 激励。我希望我们在评估结束后都很受激励。这如何做到？首先承认所有好的工作，然后讨论下一步要关注什么。这里有一个棘手的部分：如果员工的实际表现不支持我试图传达的信息怎么办（低于预期）？ 建立信任。由于绩效评估是经理和员工之间信任的最大考验，我的目标是去扭转这种情况，并加强我们两人之间的信任。这至少要求评估是一次诚实的双向对话。 这篇里, 我觉得作者花了很多时间来处理这个, 花在具体的沟通上? 然后这里的说服的关键, 是要维持和下属的信任关系. 但是作为一个研发, 非完全的管理岗, 这样是否合适? 程序员：年底的绩效评估，你觉得公司的评估合适吗-InfoQ 没有时间也经常被认为是一个不肯花心思的糟糕的借口。 这种如果是偏管理岗, 我觉得这样做无可厚非, 毕竟体现深度. 但是研发岗且组人数不那么多, 目前不觉得这种做法是效益最大化的. 需要收集的 1：1 会议记录。 工程师参加的项目，他们贡献了什么？ 产生的输出：代码，文档，电子邮件。 他们收到的反馈：同行反馈，通过电子邮件或其他方式收到的感谢，以及我能找到的其他反馈。 他们给出的反馈：代码审查、计划文档审查、与他人的交互。 自我评估：他们从自己的工作中收集到了什么？我会把这一个放到最后，尽可能收集他们可能遗漏的东西。 咨询其他组大佬 根据OKR, 增加阶段性成果物, 然后增加例会, 汇报OKR进展. 针对会踩坑的那种任务, 个人内部心里绩效合格打底, 但是需要确认进展合理. 的确有产出. 管理方面要关注沟通, 避免被陷入细节 我是如何失去团队掌控的？ - zer0black - 博客园 沟通 TODO: 将沟通这条进行方法论/系统化. 有效沟通元素 沟通背景 需求明确 责任明确 判定明确 反向澄清以减少信息预设的风险 汇报 先陈述结果, what2 再描述why, 通过什么措施做到的 how, 后续计划 组员做的不足时 认知错误时, 展示你理解的 多次没达到预期时, 说明哪些点没达到预期需要返工. 惩罚机制(事不过三) 对外, 承担组员的责任. 对内, 组员哪里做错了该怎么说就怎么说3 定计划 smart原则 若不足, 复盘时5W原则至少2条原因 不将每个单个事物之间进行逻辑上的联系, 以免造成心理暗示 也不将错误范围扩大到形而上的层面, 否定事儿不否定人 不扩大责任范围 不扩大这项建议的传播范围 这条之前没遵循, 可能是一个问题的引起原因.4 沟通技巧的边界5 认知水平导致的无法沟通 利益和立场关系导致的无法沟通 执行尝试 执行方案 每个人将每个任务拆解成1-2天的子任务, 尽量按实事求是预留出处理其他事情的时间的情况下创建任务单 遇到的问题 任务单的变更频次极高. 临时插入的任务较多, 预估不足 任务变更时, 需要触发的流程较多 任务每个人都是按满的2天算的, 当他关闭时, 是需要审批人确认才算完成的. 但是创建任务的ddl是包含审批的. 当天晚上点完成, 但是审批人第二天早上才看到任务结束. Reference 别人家的技术leader是如何建设团队、管理人员、沟通工作的？ 这二十个问题，可能是你技术人生中已经或即将遭遇的痛点，怎么解？ 透过 OKR 进行项目过程管理↩︎ “后浪”职场生存指南_职场生涯_鸟哥笔记↩︎ 下属工作没有做好，该如何跟他们说？ - 知乎↩︎ 下属工作没有做好，该如何跟他们说？ - 知乎↩︎ 什么是「有效」的沟通？如何面对难以沟通的人？ - 知乎↩︎","categories":[{"name":"专业","slug":"pro","permalink":"https://sean10.github.io/categories/pro/"}],"tags":[{"name":"团队","slug":"团队","permalink":"https://sean10.github.io/tags/%E5%9B%A2%E9%98%9F/"},{"name":"绩效","slug":"绩效","permalink":"https://sean10.github.io/tags/%E7%BB%A9%E6%95%88/"},{"name":"技术","slug":"技术","permalink":"https://sean10.github.io/tags/%E6%8A%80%E6%9C%AF/"}]},{"title":"微信聊天记录及语音导出方案实践","slug":"微信语音导出","date":"2021-09-17T17:02:34.000Z","updated":"2023-03-18T15:11:14.874Z","comments":true,"path":"2021/09/18/微信语音导出/","link":"","permalink":"https://sean10.github.io/2021/09/18/%E5%BE%AE%E4%BF%A1%E8%AF%AD%E9%9F%B3%E5%AF%BC%E5%87%BA/","excerpt":"","text":"背景 需求是把微信多个对话里的语音全部保存下来, 保存到一个文件或者一份链接. 指向多个文件. 调查 目前主流的方案是手动点击收藏, 然后把语音转存为笔记, 然后实际就变成了一份silk文件, 在android或者在pc上就能够从目录里提取出来, 进行编码转换. wechatExporter导出ios设备 wxbackup导出ios设备 微痕迹 app 微信语音导出助手 for android 手动导出转换语音 0. 进入微信聊天记录所在位置 12mkdir ~/Downloads/voicecd ~/Library/Containers/com.tencent.xinWeChat/Data 1. 复制出音频, 按照时间顺序重命名. 123find . -name &#x27;*.silk&#x27; | xargs -L1 -I &#123;&#125; cp -af &#123;&#125; ~/Downloads/voice/ cd ~/Downloads/voice/i=1; for x in `ls -tr *.silk`; do cp -af $x &quot;$i&quot;.silk; let i=i+1; done; 2. silk解码转换为mp3 kn007/silk-v3-decoder: [Skype Silk Codec SDK]Decode silk v3 audio files (like wechat amr, aud files, qq slk files) and convert to other format (like mp3). Batch conversion support. 主要使用以上脚本 1sh converter.sh ~/Downloads/voice ~/Downloads/out mp3 3. 安装ffmpeg 1brew install ffmpeg 4. 筛选后, 拼接mp3 生成要拼接的文件的目录. 1ls ./ | xargs -I &#123;&#125; realpath &#123;&#125; | xargs -I &#123;&#125; echo &quot;file &#x27;&quot;&quot;&#123;&#125;&quot;&quot;&#x27;&quot; &gt;&gt; ~/Downloads/filelist.txt 使用ffmpeg进行拼接 1ffmpeg -f concat -safe 0 -i filelist.txt -y output.mp3 5. 校验拼接后的mp3长度和 12python3 xx.py $&#123;mp3_path&#125; 输出的结果和我上面拼接后的文件的长度一致, ok没问题 12345678910111213141516171819202122232425262728293031323334353637383940414243444546#!/bin/python3import osimport sysimport globimport jsonimport loggingimport subprocessdef get_file_duration(file): process = subprocess.Popen(&quot;ffprobe &#123;&#125; -print_format json -show_format -show_streams&quot;.format(file), shell=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE) stdout = process.communicate()[0] logging.debug(f&quot;stdout: &#123;stdout&#125;&quot;) format_data = json.loads(stdout) duration = parse_duration(file, format_data) return duration def parse_duration(file, data): format_data = data.get(&#x27;format&#x27;, &#123;&#125;) res = float(format_data.get(&#x27;duration&#x27;)) if not res: res = 0 logging.error(f&quot;&#123;file&#125; cannot get duration&quot;) return resdef get_mp3_files(path): files = list(glob.glob(os.path.join(path, &quot;*.mp3&quot;))) return filesdef calc_duration(data_list): res = sum(data_list) return resdef main(): logging.basicConfig(level=logging.INFO) result = [] files = get_mp3_files(sys.argv[1]) logging.debug(files) for file in files: result.append(get_file_duration(file)) print(calc_duration(result))main() 使用wxbackup完整导出聊天记录 1. 使用微信自带的迁移聊天记录功能迁移到ipad/iphone上 用ipad/iphone登录同一个微信账号, 需要安卓机和ios设备在同一个局域网(即同一Wifi里), 然后进入设置 -&gt; 聊天 -&gt; 聊天记录备份与迁移. 2. 将ipad连接到mac/pc上, 将ios设备进行整机备份 高版本macOS比如10.15是在finder里进行的备份, 低版本则在itunes中. 参照apple官方文档即可, 如何备份您的 iPhone、iPad 和 iPod touch - Apple 支持 (中国) 备份速度通过lightning转usb-c, 最快也只有40MB/s, how long should an initial backup take on… - Apple Community 3. 备份后, 使用wxbackup的软件, 指定ios设备在mac/pc里的备份数据库路径 可能因为finder高版本导致默认打开软件时没找到备份路径, 手动指定到~/Library/Application Support/MobileSync/Backup即可. 就立刻会显示出微信的聊天记录了. 不过似乎存在一个缺憾, 不能全选导出. 只能一个个选择导出. 4. 点进各个对话目录里index.html查看和微信一般的web页面来看记录吧 Reference Windows下批量转换Silk v3音频文件为MP3格式 | kn007的个人博客 mryqu.github.io/微信语音导出和转换.md at f48df2cb1fc0e604eca4c5452b5c7498fe5717bd · mryqu/mryqu.github.io 关于微信语音导出，这个方法强烈建议~ 批量导出微信语音消息为mp3并附python修改文件名脚本 | 韶华尐沐 批量导出微信语音的方法（技术向） – vector090's blog 微信聊天记录导出方案总结 (1 封私信 / 20 条消息) 如何导出微信【收藏】中的语音文件？ - 知乎 tsycnh/WeChatExporter: 一个可以快速导出、查看你的微信聊天记录的工具 微信聊天记录导出 Collections/GitHub 出品：一键导出解密微信聊天记录.md at c9901d41cb43ba8cbb04d8331b853fd3da13a3bf · RobertWang/Collections","categories":[{"name":"专业","slug":"pro","permalink":"https://sean10.github.io/categories/pro/"}],"tags":[{"name":"wechat","slug":"wechat","permalink":"https://sean10.github.io/tags/wechat/"},{"name":"ffmpeg","slug":"ffmpeg","permalink":"https://sean10.github.io/tags/ffmpeg/"}]},{"title":"IO路径流向初探","slug":"IO路径流向初探","date":"2021-09-08T03:59:38.000Z","updated":"2023-03-18T15:11:14.882Z","comments":true,"path":"2021/09/08/IO路径流向初探/","link":"","permalink":"https://sean10.github.io/2021/09/08/IO%E8%B7%AF%E5%BE%84%E6%B5%81%E5%90%91%E5%88%9D%E6%8E%A2/","excerpt":"","text":"todo ceph-fuse是如何将系统调用注册成自己的程序的呢? libcephfs 是ceph-fuse通信的内核模块 ceph-fuse来处理真实的逻辑 本文提到为了系统实现概念的统一性、设计的一致性以及层次抽象与共用，操作系统将iscsi协议对接到scsi中间层。这种实现对性能的损失有多大？如果我们在device-mapper之下实现又会怎么样 https://www.kernel.org/doc/html/latest/admin-guide/device-mapper/cache-policies.html kernel的文档 磁盘Cache 是否是在硬盘驱动哪层 avgrq-sz这个东西应该有个上限, 好像是512K Increasing the maximum I/O size in Linux | Martins Blog The default maximum IO size set by Max_Sectors_KB restricts the largest IO size that the OS will issue to a block device. Whether you will be issuing IO at this size will depend on the elevator (scheduler) being used, the driver, and the type of IO your applications are issuing. But large reads and writes are often at the maximum IO size. The answer is to use UDEV. All you need to do is create a file “71-block-max-sectors.rules” under /etc/udev/rules.d/ with the following line. ACTION==”add|change”, SUBSYSTEM==”block”, RUN+=”/bin/sh -c ‘/bin/echo 1024 &gt; /sys%p/queue/max_sectors_kb’”[^18] – max_sectors_kb – max_hw_sectors_kb 这个内核的队列到底有多大. 队列大小. \b\b\b\bautocork FAQ write返回成功数据落盘了吗？ &gt; Buffered IO：write返回数据仅仅是写入了PageCache，还没有落盘。 &gt; &gt; Direct IO：write返回数据仅仅是到了通用块层放入IO队列，依旧没有落盘。 &gt; &gt; 此时设备断电、宕机仍然会发生数据丢失。需要调用fsync或者fdatasync把数据刷到磁盘上，调用命令时，磁盘本身缓存(DiskCache)的内容也会持久化到磁盘上。 &gt; 2、write系统调用是原子的吗？ &gt; write系统调用不是原子的，如果有多线程同时调用，数据可能会发生错乱。可以使用O_APPEND标志打开文件，只能追加写，这样多线程写入就不会发生数据错乱。 &gt; 3、mmap相比read、write快在了哪里？ &gt; mmap直接把PageCache映射到用户态，少了一次系统调用，也少了一次数据在用户态和内核态的拷贝。 &gt; &gt; mmap通常和read搭配使用：写入使用write+sync，读取使用mmap。 &gt; 4、为什么Direct IO需要数据对齐？ &gt; DIO跳过了PageCache，直接到通用块层，而通用块层的IO都必须是块大小对齐的，所以需要用户程序自行对齐offset、length。 &gt; 5、Libaio的IO栈？ &gt; write()---&gt;sys_write()---&gt;vfs_write()---&gt;通用块层---&gt;IO调度层---&gt;块设备驱动层---&gt;块设备 6、为什么需要 by pass pagecache？ &gt; 当应用程序不满Linux内核的Cache策略，有更适合自己的Cache策略时可以使用Direct IO跳过PageCache。例如Mysql。 &gt; 为什么需要 by pass kernel？ &gt; 当应用程序对延迟极度敏感时，由于Linux内核IO栈有7层，IO路径比较长，为了缩短IO路径，降低IO延迟，可以by pass kernel，直接使用用户态的块设备驱动程序。例如spdk的nvme，阿里云的ESSD。 &gt; 为什么需要直接操作裸设备？ &gt; 当应用程序仅仅使用了基本的read、write，用不到文件系统的大而全的功能，此时文件系统的开销对于应用程序来说是一种累赘，此时需要跳过文件系统，接管裸设备，自己实现磁盘分配、缓存等功能，通常使用DIO+Libaio+裸设备。例如Ceph FileStore的Journal、Ceph BlueStore。 mmap和direct IO区别 &gt; &gt; 系统调用，write会触发用户态/内核态切换？是的。那有没有办法避免这些消耗。这时候该mmap出场了，mmap把page cache 地址空间映射到用户空间，应用程序像操作应用层内存一样，写文件。省去了系统调用开销。 &gt; &gt; 那如果继续刨根问底，如果想绕过page cache，直接把数据送到磁盘设备上怎么办。通过open文件带上O_DIRECT参数，这是write该文件。就是直接写到设备上。 &gt; &gt; &gt; &gt; 如果继续较劲，直接写扇区有没有办法。这就是所谓的RAW设备写，绕开了文件系统，直接写扇区，想fdsik，dd，cpio之类的工具就是这一类操作。 LIO Linux-IO Target在Linux内核中（linux 2.6.38后），用软件实现各种SCSI Target，其支持的SAN技术中所有流行的存储协议包括Fibre Channel（Qlogic，linux3.5）、FCoE（linux3.0）、iSCSI（linux 3.1）、iSER (Mellanox InfiniBand，linux3.10), SRP (Mellanox InfiniBand，linux3.3), USB等，同时还能为本机生成模拟的SCSI设备，以及为虚拟机提供基于virtio的SCSI设备。Linux-IO Target使用户能够使用相对廉价的Linux系统实现SCSI、SAN的各种功能，而不用购买昂贵的专业设备。 TCMU+librbd 用户态方案? TCM targets 运行在内核态，TCMU（TCM in Userspace）是LIO 的用户态实现。 网络协议栈 传统的网络层数据传输协议栈： 内核层：硬件中断---&gt;取包分发至内核线程---&gt;软件中断---&gt;内核线程在协议栈中处理包---&gt;处理完毕通知用户层 用户层：收包--&gt;网络层---&gt;逻辑层---&gt;业务层 分布式IO路径 存储协议 IO路径 存储的接入模块包括协议层接入、Client 模块。协议层就是上面所说的 iSCSI、NFS 等协议，而 Client 模块则负责将上层请求转换成存储系统所能支持的读写请求发送到存储的核心 IO 模块，这些要做的以及可以做东西很多：故障域管理、IO 转发、IO 超时重试、IO 条带化、集群节点视图等，每一个点都很有搞头。接入模块的改造潜力是比较大的，如利用 SPDK 改造 vhost / iSCSI . 这里其实指的就是iSCSI的Target端与下层存储服务的对接了把 主节点负责管理元数据和 IO 调度，从节点则负责读写数据，乖乖的干活即可。在没有主从之分的 peer 存储系统中，可管理元数据并不多，并且多集中在接入模块的 Client 中，因为它的元数据多是计算出来的，而集中式存储系统多是查出来的，所以存储系统按照这种方式可以分为计算型和查表型。集中式存储系统的元数据多存于类似 LevelDB 或 RocksDB 的单机存储引擎中。 iSCSi 对于K8S, openstack对接的存储路径 常见的 CSI 对接有块存储的 iSCSI、对象存储的 FUSE，还有一些其他比较小众的，比如 ceph 的 rbd、sheepdog 的 sbd 等，这些的原理就是通过注册内核相关的 block device 类型来做的。 https://runsisi.com/2018-12-26/ceph-iscsi-research 工具 blocktrace 第一个字段：8,0 这个字段是设备号 major device ID和minor device ID。 第二个字段：3 表示CPU 第三个字段：11 序列号 第四个字段：0.009507758 Time Stamp是时间偏移 第五个字段：PID 本次IO对应的进程ID 第六个字段：Event，这个字段非常重要，反映了IO进行到了那一步 第七个字段：R表示 Read， W是Write，D表示block，B表示Barrier Operation 第八个字段：223490+56，表示的是起始block number 和 number of blocks，即我们常说的Offset 和 Size 第九个字段： 进程名 其中第六个字段非常有用：每一个字母都代表了IO请求所经历的某个阶段。 Q – 即将生成IO请求 | G – IO请求生成 | I – IO请求进入IO Scheduler队列 | D – IO请求进入driver | C – IO请求执行完毕 iowatcher 文件系统IO路径 操作系统路径 当用户调用了write、read等系统调用陷入内核之后，系统会首先针对关联的file对象找到对应的file system，此处针对后端是否有持久化存储可将众多的file system划分为两类，在此我们关心的是后端对应真实存储的file system，经过了file system层处理之后将所有的数据块划分为了一个个的bio，交给device mapper层处理，device mapper层主要完成逻辑设备到物理设备的映射工作，例如可以将bio按LBA地址分别映射到管理的多个设备上(linear，raid0)，将bio映射到每个设备上（mirror, raid1），或者是提供快照和多路径的功能，再往下是具体的block层，此处会为每个设备提供一个queue，在queue之上使用各种io scheduler(noop/deadline/cfq)进行请求的合并，最后调用各种不同的设备驱动完成服务。SCSI子模块就是这众多驱动中的一种，其他的还有按照协议和总线划分还有USB，ATA等等。 VFS Layer 系统调用文件系统的函数, 参数为文件描述符和文件偏移量. VFS支持的文件系统主要有三种类型： 基于磁盘的文件系统：Ext系列、XFS等。 网络文件系统：NFS、CIFS等。 特殊文件系统：/proc、裸设备等。 VFS主要有四个对象类型(不同的文件系统都要实现)： superblock：整个文件系统的元信息。对应的操作结构体：struct super_operations。 inode：单个文件的元信息。对应的操作结构体：struct inode_operations。 dentry：目录项，一个文件目录对应一个dentry。对应的操作结构体：struct dentry_operations。 file：进程打开的一个文件。对应的操作结构体：struct file_operations 文件系统驱动层 具体的文件系统实现 物理页与扇区的对应关系由文件系统定义，文件系统定义了一个内存页(4KB)与多少个块对应，对应关系在格式化磁盘时设定，运行时由buffer_head保存对应关系：[^23] linux # cat /proc/slabinfo | grep buffer_head buffer_head 12253 12284 104 37 1 : tunables 120 60 8 : slabdata 332 332 0 NFS Ext2 Ext3 Ext4 cephfs (内核) NTFS Page Cache Layer Cache层在内存中缓存了磁盘上的部分数据。 Page Cache主要用来作为文件系统上的文件数据的缓存来用，尤其是针对当进程对文件有read/write操作的时候。 在Linux的实现中，文件Cache分为两个层面，一是Page Cache，另一个Buffer Cache，每一个Page Cache包含若干Buffer Cache。Page Cache主要用来作为文件系统上的文件数据的缓存来用，尤其是针对当进程对文件有read/write操作的时候。Buffer Cache则主要是设计用来在系统对块设备进行读写的时候，对块进行数据缓存的系统来使用。 磁盘Cache有两大功能：预读和回写。预读其实就是利用了局部性原理，具体过程是：对于每个文件的第一个读请求，系统读入所请求的页面并读入紧随其后的少数几个页面（通常是三个页面），这时的预读称为同步预读。对于第二次读请求，如果所读页面不在Cache中，即不在前次预读的页中，则表明文件访问不是顺序访问，系统继续采用同步预读；如果所读页面在Cache中，则表明前次预读命中，操作系统把预读页的大小扩大一倍，此时预读过程是异步的，应用程序可以不等预读完成即可返回，只要后台慢慢读页面即可，这时的预读称为异步预读。任何接下来的读请求都会处于两种情况之一：第一种情况是所请求的页面处于预读的页面中，这时继续进行异步预读；第二种情况是所请求的页面处于预读页面之外，这时系统就要进行同步预读。 回写是通过暂时将数据存在Cache里，然后统一异步写到磁盘中。通过这种异步的数据I/O模式解决了程序中的计算速度和数据存储速度不匹配的鸿沟，减少了访问底层存储介质的次数，使存储系统的性能大大提高。Linux 2.6.32内核之前，采用pdflush机制来将脏页真正写到磁盘中， Linux 2.6.32内核之后，放弃了原有的pdflush机制，改成了bdi_writeback机制。bdi_writeback机制主要解决了原有fdflush机制存在的一个问题：在多磁盘的系统中，pdflush管理了所有磁盘的Cache，从而导致一定程度的I/O瓶颈。bdi_writeback机制为每个磁盘都创建了一个线程，专门负责这个磁盘的Page Cache的刷新工作，从而实现了每个磁盘的数据刷新在线程级的分离，提高了I/O性能。 回写机制存在的问题是回写不及时引发数据丢失（可由sync|fsync解决），回写期间读I/O性能很差。 ### 参数 sysctl -a | grep dirty &gt; ls -l /proc/sys/vm/dirty_* 1234567891011121314# ls -l /proc/sys/vm/dirty_*# 内存可以填充数据的字节数-rw-r--r-- 1 root root 0 Oct 15 22:05 /proc/sys/vm/dirty_background_bytes# 内存可以填充脏数据的百分比-rw-r--r-- 1 root root 0 Sep 26 07:59 /proc/sys/vm/dirty_background_ratio-rw-r--r-- 1 root root 0 Oct 15 22:05 /proc/sys/vm/dirty_bytes# 指定仓数据能够存活的时间-rw-r--r-- 1 root root 0 Oct 15 22:05 /proc/sys/vm/dirty_expire_centisecs# 可以用脏数据填充的绝对最大系统内存量. 到这个时候, 所有IO会被阻塞-rw-r--r-- 1 root root 0 Sep 26 07:59 /proc/sys/vm/dirty_ratio# 指定多长时间pdflush/flush/kdmflush这些进程会唤醒一次, 然后检查是否有缓存需要清理.-rw-r--r-- 1 root root 0 Oct 15 22:05 /proc/sys/vm/dirty_writeback_centisecs 查看内存中脏数据 123456$ cat /proc/vmstat | egrep &quot;dirty|writeback&quot;nr_dirty 106nr_writeback 0nr_writeback_temp 0nr_dirty_threshold 3934012nr_dirty_background_threshold 1964604 Generic Block Layer 通用块层的主要工作是：接收上层发出的磁盘请求，并最终发出I/O请求。该层隐藏了底层硬件块设备的特性，为块设备提供了一个通用的抽象视图。 对于VFS和具体的文件系统来说，块（Block）是基本的数据传输单元，当内核访问文件的数据时，它首先从磁盘上读取一个块。但是对于磁盘来说，扇区是最小的可寻址单元，块设备无法对比它还小的单元进行寻址和操作。由于扇区是磁盘的最小可寻址单元，所以块不能比扇区还小，只能整数倍于扇区大小，即一个块对应磁盘上的一个或多个扇区。一般来说，块大小是2的整数倍，而且由于Page Cache层的最小单元是页（Page），所以块大小不能超过一页的 多情况下，数据的传输通过DMA方式 通用块层的核心数据结构是一个称为BIO的描述符，它描述了块设备的IO操作。每个bio结构都包含一个磁盘存储区标识符（存储区中的起始扇区和扇区数目）和一个或多个描述符 与IO操作相关的内存区的段。 Device Mapper Layer[^15] I/O Scheduler Layer I/O调度层的功能是管理块设备的请求队列。即接收通用块层发出的I/O请求，缓存请求并试图合并相邻的请求。并根据设置好的调度算法，回调驱动层提供的请求处理函数，以处理具体的I/O请求。 如果简单地以内核产生请求的次序直接将请求发给块设备的话，那么块设备性能肯定让人难以接受，因为磁盘寻址是整个计算机中最慢的操作之一。为了优化寻址操作，内核不会一旦接收到I/O请求后，就按照请求的次序发起块I/O请求。为此Linux实现了几种I/O调度算法，算法基本思想就是通过合并和排序I/O请求队列中的请求，以此大大降低所需的磁盘寻道时间，从而提高整体I/O性能。 常见的I/O调度算法包括Noop调度算法（No Operation）、CFQ（完全公正排队I/O调度算法）、DeadLine（截止时间调度算法）、AS预测调度算法等。 在许多的开源框架如Kafka、HBase中，都通过追加写的方式来尽可能的将随机I/O转换为顺序I/O，以此来降低寻址时间和旋转延时，从而最大限度的提高IOPS。 Block Device Driver Layer 驱动层中的驱动程序对应具体的物理块设备。它从上层中取出I/O请求，并根据该I/O请求中指定的信息，通过向具体块设备的设备控制器发送命令的方式，来操纵设备传输数据。 俗话说的SCSI协议栈，包括三层，一个是上层的协议驱动，指磁盘驱动，磁带驱动，如果有其他的设备，比如打印机之类的，SCSI打印机和扫描仪也有，很早的时候，这块就是驱动设备了。SCSI Middle 层就是管SCSI指令，下发下来都是在内存里的数据结构，每个OS都不一样，但是如果发到磁盘，发到外面的交换机，必须把它弄成标准化的，因为外面有很多厂商做硬件，你不标准，就没法做了这个硬件，你不能说为每个OS都做一个硬件。这层除了翻译成SCSI指令，这边有SCSI语义，还有管真正的SCSI的处理，比如超时了怎么办这些事情，这是中间层。 底下这层是HBA层，首先要有驱动，在HBA上有设备发现的这么一层库，因为传统的SCSI几十年前，那时候只有SCSI这么一种物理硬件，大家可能有人见过，很粗很笨的线缆，后来出现了FC，SAS这些，更快速的、高效的物理链路类型。SCSI协议，如果想跑在这些物理链路类型说，就需要有这么一块代码，这个网络里面，把你对端的SCSI设备发现上来，如果后端改成SAS，这块代码就会往SAS网络上发出一些广播的消息，将设备探测到，然后才生成设备符号。 Block Device Layer 硬盘缓存功能等就在硬件内了. 比如最近我们接触的希捷高速缓存. 块对象的IO路径. 读路径 应用态业务程序 应用态程序缓存, 命中则提高 文件系统层 \b\b\b\b\b内核态缓存, 命中则提高 page cache? 通用块层 内核态到块设备之间的驱动, 包含缓存? 分层缓存设备 元数据分离, 通过高速硬件提高元数据读取性能 根据元数据指定的地址, 在低速设备上查询真实速度 硬盘预读能力, 如果命中了提高性能 写路径 应用态业务程序 应用态程序缓存, IO聚合, 随机IO转顺序, 或缓存命中直接返回, 存在一致性风险 内核态缓 存, IO聚合, 或缓存命中直接返回, 存在一致性风险 内核态到块设备, 驱动层面聚合 分层缓存设备, 写命中的对象, 则可以直接返回, 免去访问更底层的 元数据分离, 如果是小io, 直接落元数据分区所在的高速设备, 如果是低速, 则继续下传 硬盘随机写能力, 看硬盘的算法, 是否有缓存进行IO聚合之类的. 基于IO路径的优化 采用追加写 从文件中读一些数据时将会需要更多的时间：需要倒序扫描，直到找到所需要的内容。当然在一些简单的场景下也能够保证读操作的性能： 数据是被整体访问，比如HDFS HDFS建立在一次写多次读的模型之上。在HDFS中就是采用了追加写并且设计为高数据吞吐量；高吞吐量必然以高延迟为代价，所以HDFS并不适用于对数据访问要求低延迟的场景；由于采用是的追加写，也并不适用于任意修改文件的场景。HDFS设计为流式访问大文件，使用大数据块并且采用流式数据访问来保证数据被整体访问，同时最小化硬盘的寻址开销，只需要一次寻址即可，这时寻址时间相比于传输时延可忽略，从而也拥有良好的读性能。HDFS不适合存储小文件，原因之一是由于NameNode内存不足问题，还有就是因为访问大量小文件需要执行大量的寻址操作，并且需要不断的从一个datanode跳到另一个datanode，这样会大大降低数据访问性能。 知道文件明确的偏移量，比如Kafka LSM p 小文件合并 小文件合并为大文件后，首先减少了大量元数据，提高了元数据的检索和查询效率，降低了文件读写的I/O操作延时。其次将可能连续访问的小文件一同合并存储，增加了文件之间的局部性，将原本小文件间的随机访问变为了顺序访问，大大提高了性能。同时，合并存储能够有效的减少小文件存储时所产生的磁盘碎片问题，提高了磁盘的利用率。最后，合并之后小文件的访问流程也有了很大的变化，由原来许多的open操作转变为了seek操作，定位到大文件具体的位置即可 文件合并和元数据优化 # 直接IO[^23] &gt; 当我们以O_DIRECT标志调用open函数打开文件时，后续针对该文件的read、write操作都将以直接I/O(direct I/O)的方式完成；对于裸设备，I/O方式也为直接I/O。 &gt; &gt; 直接I/O跳过了文件系统这一层，但块层仍发挥作用，其将内存页与磁盘扇区对应上，这时不再是建立cache到DMA映射，而是进程的buffer映射到DMA。进行直接I/O时要求读写一个扇区(512bytes)的整数倍，否则对于非整数倍的部分，将以带cache的方式进行读写。 &gt; &gt; 使用直接I/O，写磁盘少了用户态到内核态的拷贝过程，这提升了写磁盘的效率，也是直接I/O的作用所在。而对于读操作，第一次直接I/O将比带cache的方式快，但因带cache方式后续再读时将从cache中读，因而后续的读将比直接I/O快。有些数据库使用直接I/O，同时实现了自己的cache方式。 异步aio 队列深度决定了给块设备写I/O的最大并发数，对于Linux系统，默认值为128，一般情况下不建议用户修改此参数。用户可以使用cat命令查询当前块设备队列深度。 linux-ob3a:~ # cat /sys/block/sdc/queue/nr_requests 预读 预读量的默认值为512扇区，即256KB。用户可以使用cat命令查询当前块设备预读量。 linux-ob3a:~ # cat /sys/block/sdc/queue/read_ahead_kb 512 内存参数 $ cat /proc/sys/vm/swappiness vm.swappiness的值的大小对如何使用swap分区是有着很大的联系的。swappiness=0的时候表示最大限度使用物理内存，然后才是 swap空间，swappiness＝100的时候表示积极的使用swap分区，并且把内存上的数据及时的搬运到swap空间里面。linux的基本默认设置为60，也就是说，你的内存在使用到100-60=40%的时候，就开始出现有交换分区的使用。大家知道，内存的速度会比磁盘快很多，这样子会加大系统io，同时造的成大量页的换进换出，严重影响系统的性能，所以我们在操作系统层面，要尽可能使用内存，对该参数进行调整，一般sysctl vm.swappiness=10。 $ cat /proc/sys/vm/overcommit_memory 内存分配策略 linux对大部分申请内存的请求都回复\"yes\"，以便能跑更多更大的程序。因为申请内存后，并不会马上使用内存。这种技术叫做Overcommit。当linux发现内存不足时，会发生OOM killer(OOM=out-of-memory)。它会选择杀死一些进程(用户态进程，不是内核线程)，以便释放内存 $ cat /proc/sys/vm/overcommit_ratio 前沿趋势 [^26] IO出了龙潭又入虎穴，对于基于SATA/SAS SSD的AFA来讲，SCSI层很难绕过，因为这个协议栈太过底层，SCSI指令集异常复杂，协议状态机、设备发现、错误恢复机制等哪一样都够受的，如果抛弃SCSI协议栈自己开发一个新的轻量级SCSI协议栈，那是不切实际的，你会发现倒头来不得不把那些重的代码加回来，因为SCSI体系本身的复杂性已经决定了协议栈实现上的复杂性。 然而，如果使用的是PCIE闪存卡或者2.5寸盘的话，那么就可以完全抛弃SCSI协议栈。有些PCIE闪存卡的驱动中包含了自定义的私有协议栈，其中包含了指令集、错误处理、监控等通用协议栈的大部分功能，其直接注册到块层；而NVMe协议栈迅速成了定海神针， [^27] 调试排查[^29] Reference 磁盘I/O那些事 - 美团技术团队 通用块层 - 简书 浅谈Linux内核IO体系之磁盘IO - 知乎 打通IO栈：一次编译服务器性能优化实战 linux io过程自顶向下分析 - 黑客画家的个人空间 - OSCHINA - 中文开源技术交流社区 Linux Storage Stack Diagram - Thomas-Krenn-Wiki MMAP和DIRECT IO区别 - aitao - 博客园 (79 条消息) Linux 中 mmap() 函数的内存映射问题理解？ - 知乎 (1) 磁盘IO瓶颈_个人文章 - SegmentFault 思否 鸿蒙系统 IO栈和Linux IO栈对比分析-摩尔芯闻 Linux 的IO栈 - 知乎 iscsi:IO操作流程（一）_我的技术笔记-CSDN博客 (79 条消息) NVMe 和 AHCI 到底是接口标准还是接口协议？ - 知乎 SCSI标准分析及linux kernel中scsi_debug模块实现详解(1)-zhenchengjin-ChinaUnix博客 | Forest Understanding Device Mapper and Filter Driver Architecture of Linux Kernel I/O stack | Download Scientific Diagram 打造全用户态高可靠高性能的分布式存储系统-腾讯网 Default Maximum IO Size Change in Linux Kernel | Long White Virtual Clouds linux - Why is the size of my IO requests being limited, to about 512K? - Unix &amp; Linux Stack Exchange 优化磁盘IO调度方式_鲲鹏高性能计算解决方案_调优指南_IO调优_华为云 Linux磁盘I/O优化：vm.dirty_ratio - 米扑博客 Linux机器内核参数理解(二) - 207矿工的个人空间 - OSCHINA - 中文开源技术交流社区 深入理解linux IO - 简书 3.分布式存储系统的大体架构 - 知乎 &lt;大话存储1/2&gt; 冬瓜哥：IO协议栈前沿技术研究动态 - 存储在线 存储极客 | 浅析固态介质在存储系统中的应用方式-黑科技-轻阅读-戴尔易安信(Dell EMC)官网 了解IO协议栈","categories":[{"name":"专业","slug":"pro","permalink":"https://sean10.github.io/categories/pro/"}],"tags":[{"name":"linux","slug":"linux","permalink":"https://sean10.github.io/tags/linux/"},{"name":"IO","slug":"IO","permalink":"https://sean10.github.io/tags/IO/"},{"name":"存储","slug":"存储","permalink":"https://sean10.github.io/tags/%E5%AD%98%E5%82%A8/"}]},{"title":"python日志模块初探","slug":"python日志模块初探","date":"2021-08-13T11:28:12.000Z","updated":"2023-03-18T15:11:14.892Z","comments":true,"path":"2021/08/13/python日志模块初探/","link":"","permalink":"https://sean10.github.io/2021/08/13/python%E6%97%A5%E5%BF%97%E6%A8%A1%E5%9D%97%E5%88%9D%E6%8E%A2/","excerpt":"","text":"标准 \b支持的日志等级 SyslogHandler的syslog协议部分主要遵循RFC5424. 在安装了systemd和rsyslog的设备上, 如果启用了syslog协议, 日志一般会先经由systemd-journald管控的/dev/log套接字, 由rsyslog从systemd-journald的socket中读取日志, 而后根据rsyslog的过滤器写入到/var/log/messages中. 支持能力 基于filter实现的handler和logger, 支持等级控制 基于name的logger字典 仅支持多线程, 不支持多进程 限制 日志紊乱：比如两个进程分别输出xxxx和yyyy两条日志，那么在文件中可能会得到类似xxyxyxyy这样的结果 日志丢失：虽然读写日志是使用O_APPEND模式，保证了写文件的一致性，但是由于buffer的存在（数据先写入buffer，再触发flush机制刷入磁盘），fwrite的操作并不是多进程安全的 日志丢失的另一种情况：使用RotatingFileHandler或者是TimerRotatingFileHandler的时候，在切换文件的时候会导致进程拿到的文件句柄不同，导致新文件被重复创建、数据写入旧文件 使用说明 formatter可用属性 logging --- Python 的日志记录工具 — Python 3.9.6 文档 handler SyslogHandler StreamHandler 场景 作为组件, 整个组件使用一个日志等级, 控制基本的输出等级. 12 对日志性能存在要求的日志组件 作为公有库时的日志记录, 跟随对应的入口日志等级进行控制 自定义能力 LogRecord extra参数 Handler 根据目标的需求, 自定义开发handler. Reference Python面试官：聊聊多进程场景下Logging模块？ - 知乎","categories":[{"name":"专业","slug":"pro","permalink":"https://sean10.github.io/categories/pro/"}],"tags":[{"name":"python","slug":"python","permalink":"https://sean10.github.io/tags/python/"},{"name":"log","slug":"log","permalink":"https://sean10.github.io/tags/log/"},{"name":"library","slug":"library","permalink":"https://sean10.github.io/tags/library/"}]},{"title":"ceph之docker内crimson编译","slug":"ceph之docker内crimson编译","date":"2021-06-23T01:21:25.000Z","updated":"2023-03-18T15:11:14.873Z","comments":true,"path":"2021/06/23/ceph之docker内crimson编译/","link":"","permalink":"https://sean10.github.io/2021/06/23/ceph%E4%B9%8Bdocker%E5%86%85crimson%E7%BC%96%E8%AF%91/","excerpt":"","text":"配置 配置了一个CentOS 8的容器, 执行下以下内容 123456WITH_SEASTAR=true ./install-deps.shmkdir build &amp;&amp; cd build# 以下这步官网里没提, 导致失败的.# . /opt/rh/gcc-toolset-9/enablecmake -DWITH_SEASTAR=ON -DWITH_MGR_DASHBOARD_FRONTEND=OFF -DCMAKE_EXPORT_COMPILE_COMMANDS=on ..make -j18 crimson-osd 用服务器跑很快就失败了...发现主要是少了这个一点. /opt/rh/gcc-toolset-9/enable, 导致默认用的是gcc 8 好像找到个Dockerfile.in, 这里好像匹配了jenkins里面的操作, do_cmake.sh -DWITH_SEASTAR=ON 归档一下docker save sean10/centos_ceph_clion:pacific_v1.0.0 | gzip &gt; centos_ceph_clion_pacific_v1.0.0.tar.gz 提交到[sean10/centos\\_ceph\\_clion Tags](https://hub.docker.com/repository/docker/sean10/centos_ceph_clion/tags?page=1&amp;ordering=last_updated)这里了. 编译内存大概占用了13个g? 4G内存+15G的swap, 用掉了内存+9个G docker压缩优化 1docker history sean10/centos_ceph_clion:pacific_v1.1.1 看了下, 后面我所有ssh上去做的复制操作都没有, 我的代码因为需要clion上做同步然后Cmake, 直接把代码放进去并不能省去上传的操作, image容量在clion重新上传一次之后还是被会拉大, 因此暂时不考虑压缩了. 报错 CMAKE_CXX_COMPILER could be found. 我看了下gcc已经装了8.4版本, 那就是cmake没能识别到gcc的环境变量? 嗯, 我没装gcc-c++, 所以的确识别不到. target \"seastar\" links to target \"lz4::lz4\" but the target was not found. 好像缺失的lz4的库? 姑且试了下, 好像是/usr/lib64/pkgconfig/lz4.pc不存在,但是实际上/usr/lib64/pkgconfig/liblz4.pc存在, 我做了个软链, 过了第一个, 但是后面还是报了上面这条报错. --debug-output CMake Warning (dev) at /usr/share/cmake/Modules/FindPackageHandleStandardArgs.cmake:273 (message): The package name passed to find_package_handle_standard_args (LZ4) does not match the name of the calling package (lz4). This can lead to problems in calling code that expects find_package result variables (e.g., _FOUND) to follow a certain pattern. Call Stack (most recent call first): cmake/modules/Findlz4.cmake:30 (find_package_handle_standard_args) src/CMakeLists.txt:335 (_find_package) src/seastar/cmake/SeastarDependencies.cmake:98 (find_package) src/seastar/CMakeLists.txt:330 (seastar_find_dependencies) This warning is for project developers. Use -Wno-dev to suppress it. Could NOT find LZ4 (missing: LZ4_LIBRARY) 好像是FindPackageHandleStandardArgs这个函数是类似find_package的. 好像是我理解错了, 这个就是单纯在找lz4-devel这个库提供的内容. 而现在我卸载掉这个devel库, 的确还是报相同的错误. 那就是这个库提供的内容没有在他们的搜索路径里导致的 好像FindLZ4.cmake和Findlz4.cmake本身是不一样的. 我试验了一下, 直接把这几个文件作为CMakeLists.txt的时候, 后者那个小写文件是能够找到的, 而第一个则是找不到的... 但是我把第二个文件覆盖掉第一个问题, 则是不工作的. 1234567891011121314-- Checking for one of the modules &#x27;liblz4&#x27; CMake Warning (dev) at /usr/share/cmake/Modules/FindPackageHandleStandardArgs.cmake:273 (message): The package name passed to `find_package_handle_standard_args` (lz4) does not match the name of the calling package (LZ4). This can lead to problems in calling code that expects `find_package` result variables (e.g., `_FOUND`) to follow a certain pattern. Call Stack (most recent call first): cmake/modules/FindLZ4.cmake:45 (find_package_handle_standard_args) CMakeLists.txt:325 (find_package) This warning is for project developers. Use -Wno-dev to suppress it. -- Found lz4: /usr/lib64/liblz4.so (found version &quot;1.8.3&quot;) -- Looking for LZ4_compress_default -- Looking for LZ4_compress_default - found 所以是不是有地方定义了大写的LZ4:LZ4, 所以才导致必须有一个大写的导入. 奇怪, 为什么我的代码里这个目录不存在一个几乎同名的findlz4.cmake, 但是在设备上,却在findLZ4.cmake同目录里有一个findlz4.cmake呢? 这个目录疑似是生成的, 因为我改了以后, 这里的findLZ4.cmake就不存在了. 了解一下cmake的工作机制. 但是按照Cmake的工作机制, 理论上这个位置就不是一个动态生成的路径啊? 这里一直提到的The package name passed to find_package_handle_standard_args (lz4) does not match the name of the calling package (LZ4). This can lead to problems in calling code that expectsfind_packageresult variables (e.g.,这里的calling package到底是什么意思呢? 根据cmake里这段代码 12345678910111213 if (DEFINED CMAKE_FIND_PACKAGE_NAME AND NOT FPHSA_NAME_MISMATCHED AND NOT _NAME STREQUAL CMAKE_FIND_PACKAGE_NAME) message(AUTHOR_WARNING &quot;The package name passed to `find_package_handle_standard_args` &quot; &quot;($&#123;_NAME&#125;) does not match the name of the calling package &quot; &quot;($&#123;CMAKE_FIND_PACKAGE_NAME&#125;). This can lead to problems in clling &quot; &quot;code that expects `find_package` result variables (e.g., `_FOUND`) &quot; &quot;to follow a certain pattern.&quot;) endif ()``CMAKE_FIND_PACKAGE_NAME`` the ``&lt;PackageName&gt;`` which is searched for 也就是调用find_package(LZ4)了. 12src/seastar/cmake/SeastarDependencies.cmake:98 (find_packagesrc/seastar/CMakeLists.txt:330 (seastar_find_dependencies) 所以是来自这个文件, 传递了lz4为要找的包, 但是实际上只找到了findLZ4.cmake. 但是他隶属于seastar目录, 在那个目录里, 有一个findlz4小写的. 所以我怀疑是嵌套的cmake作用域之类的问题? build目录下有一个Makefile.cmake如何理解? 这个文件是从CMakeLists.txt里生成出来的? 的确是生辰出来的... Boost库还没下载下来, 所以直接编译seastar是肯定成功不了的. 最后复制了seastar目录下的cmake/Findlz4.cmake到了cmake/modules目录下, 和FindLZ4.cmake在一起, 就能过了. 不过我推测,应该还有个CMAKE_FIND_ROOT_PATH这种东西可能在工作, 可以让seastar目录在加载时, 自动使用当前目录的cmake来进行find_package操作, 不过目前没找到... cannot deduce template arguments for 'tuple' 这次是编译报错. 看着比较像是c++支持语言版本不足, 看了下, 官方的jenkins里是有安装了gcc-toolset-9这个操作的, 所以按理来说应该是用gcc 9版本编译才对. 果然, 在ceph.spec.in里是有加载这个toolset的操作的. 1. /opt/rh/gcc-toolset-9/enable 这个ceph.spec.in是怎么生成的暂时没找到, 不过有个make-dist的脚本,这里有生成的操作, 这里触发应该有用吧 通过make -n可以看到使用的c++的路径不对, 是低版本的, 果然, 我用的Makefile版本不对. 必须得更新一下. 删掉整个build目录, 先执行. /opt/rh/gcc-toolset-9/enable, 这次生成的Makefile版本对了. 从虚拟机开始 123456789# 找一下怎么直接触发grep -rn &quot;SEASTAR&quot;git submodule foreach --recursive git reset --hardexport WITH_SEASTAR=ON;bash install-deps.shcmake ..ccache ninja stream 9 编译 Feature #51156: qa: Teuthology Testing on Centos 9 Stream - Ceph - Ceph ktdreyer/ceph-el9 1dnf copr enable -y ceph/el9 centos-stream-9 通过操作该项即可正常执行install-deps.sh Reference Crimson developer documentation — Ceph Documentation crimson — Ceph Documentation","categories":[{"name":"专业","slug":"pro","permalink":"https://sean10.github.io/categories/pro/"}],"tags":[{"name":"ceph","slug":"ceph","permalink":"https://sean10.github.io/tags/ceph/"},{"name":"docker","slug":"docker","permalink":"https://sean10.github.io/tags/docker/"},{"name":"编译","slug":"编译","permalink":"https://sean10.github.io/tags/%E7%BC%96%E8%AF%91/"}]},{"title":"ceph之luminous_github版本编译问题整理","slug":"ceph之luminous-github版本编译","date":"2021-05-15T13:34:46.000Z","updated":"2023-04-17T12:01:27.748Z","comments":true,"path":"2021/05/15/ceph之luminous-github版本编译/","link":"","permalink":"https://sean10.github.io/2021/05/15/ceph%E4%B9%8Bluminous-github%E7%89%88%E6%9C%AC%E7%BC%96%E8%AF%91/","excerpt":"","text":"luminous 早起记录 主要问题是从svn下载的最新版的luminous分支, 编译时报这个错误 1234567891011121314151617181920undefined reference to OSD::HeartbeatInfo::HEARTBEAT_MAX_CONN``这条修复了这个问题[osd: make OSD::HEARTBEAT\\_MAX\\_CONN inline by tchaikov · Pull Request \\#23424 · ceph/ceph](https://github.com/ceph/ceph/pull/23424)但是只合入了`master`分支, luminos分支没有合入.但是上面这个好像是高版本解决的问题`static constexpr int`.[C\\+\\+ Linker Error With Class static constexpr \\- Stack Overflow](https://stackoverflow.com/questions/8452952/c-linker-error-with-class-static-constexpr)好像是c++17才修复的问题,最后我参照下面这个, 在常量外侧加一层int转换. 原理目前不懂``` c++return std::min(int(S::X), 0); pacific分支记录 rpmbuild src.rpm归档 1cmake .. -DCMAKE_INSTALL_PREFIX=/usr -DCMAKE_INSTALL_LIBDIR=/usr/lib64 -DCMAKE_INSTALL_LIBEXECDIR=/usr/libexec -DCMAKE_INSTALL_LOCALSTATEDIR=/var -DCMAKE_INSTALL_SYSCONFDIR=/etc -DCMAKE_INSTALL_MANDIR=/usr/share/man -DCMAKE_INSTALL_DOCDIR=/usr/share/doc/ceph -DCMAKE_INSTALL_INCLUDEDIR=/usr/include -DCMAKE_INSTALL_SYSTEMD_SERVICEDIR=/usr/lib/systemd/system -DWITH_MANPAGE=ON -DWITH_PYTHON3=3.10 -DWITH_MGR_DASHBOARD_FRONTEND=OFF -DWITH_SELINUX=ON -DWITH_LTTNG=ON -DWITH_BABELTRACE=ON -DWITH_OCF=ON -DWITH_LIBRADOSSTRIPER=ON -DWITH_RADOSGW_AMQP_ENDPOINT=ON -DWITH_RADOSGW_KAFKA_ENDPOINT=ON -DBOOST_J=2 -DWITH_GRAFANA=ON -DCMAKE_EXPORT_COMPILE_COMMANDS=on linux macros定义位置/usr/lib/rpm/macros.d/macros.python\u0000","categories":[{"name":"专业","slug":"pro","permalink":"https://sean10.github.io/categories/pro/"}],"tags":[{"name":"ceph","slug":"ceph","permalink":"https://sean10.github.io/tags/ceph/"}]},{"title":"ceph之mon_client时间长排查","slug":"ceph之mon-client时间长排查","date":"2021-04-26T11:56:42.000Z","updated":"2023-05-20T16:21:01.113Z","comments":true,"path":"2021/04/26/ceph之mon-client时间长排查/","link":"","permalink":"https://sean10.github.io/2021/04/26/ceph%E4%B9%8Bmon-client%E6%97%B6%E9%97%B4%E9%95%BF%E6%8E%92%E6%9F%A5/","excerpt":"","text":"背景 在使用12.2.1版本时, 发现经常会出现需要10+秒才能返回ceph -s的现象, 偶尔又1s内就返回了. 排查 首先, time ceph -s --debug_monc 40 --debug_ms 40看下详细日志有没有记录在哪呢? 看了下, 应该是在跟mon通信过程, 但是好像不知道发生了什么. 咨询了一下大神给了个关键词, objecter, 打开debug后看到一部分内容了. 有resend_mon_ops的操作, 那就代表第一次picked到的ip, 有些没正常工作? ## 异常日志 1234567891011121314151617181920212021-03-08 17:46:40.591805 7ff668ff9700 1 monclient(hunting): continuing hunt [47/3291]2021-03-08 17:46:40.591809 7ff668ff9700 10 monclient(hunting): _reopen_session rank -12021-03-08 17:46:40.592032 7ff668ff9700 10 monclient(hunting): picked mon.noname-b con 0x7ff640001210 addr 10.192.89.63:6789/02021-03-08 17:46:40.592112 7ff668ff9700 10 monclient(hunting): picked mon.noname-c con 0x7ff640005ad0 addr 10.192.89.61:6789/02021-03-08 17:46:40.592194 7ff668ff9700 10 monclient(hunting): _renew_subs2021-03-08 17:46:40.593008 7ff669ffb700 10 client.?.objecter ms_handle_connect 0x7ff640005ad02021-03-08 17:46:40.593072 7ff669ffb700 10 client.?.objecter resend_mon_ops2021-03-08 17:46:40.593083 7ff669ffb700 10 client.?.objecter ms_handle_connect 0x7ff6400012102021-03-08 17:46:40.593104 7ff669ffb700 10 client.?.objecter resend_mon_ops2021-03-08 17:46:42.592257 7ff668ff9700 10 monclient(hunting): tick2021-03-08 17:46:42.592283 7ff668ff9700 1 monclient(hunting): continuing hunt2021-03-08 17:46:42.592287 7ff668ff9700 10 monclient(hunting): _reopen_session rank -12021-03-08 17:46:42.592435 7ff668ff9700 10 monclient(hunting): picked mon.noname-a con 0x7ff64000d0b0 addr 10.192.89.60:6789/02021-03-08 17:46:42.592468 7ff668ff9700 10 monclient(hunting): picked mon.noname-c con 0x7ff6400106f0 addr 10.192.89.61:6789/02021-03-08 17:46:42.592536 7ff668ff9700 10 monclient(hunting): _renew_subs2021-03-08 17:46:42.593106 7ff669ffb700 10 client.?.objecter ms_handle_connect 0x7ff64000d0b02021-03-08 17:46:42.593133 7ff669ffb700 10 client.?.objecter resend_mon_ops2021-03-08 17:46:42.593140 7ff669ffb700 10 client.?.objecter ms_handle_connect 0x7ff6400106f02021-03-08 17:46:42.593142 7ff669ffb700 10 client.?.objecter resend_mon_ops2021-03-08 17:46:42.593596 7ff669ffb700 10 monclient(hunting): handle_monmap mon_map magic: 0 v12021-03-08 17:46:42.593638 7ff669ffb700 10 monclient(hunting): got monmap 1, mon.noname-a is now rank -12021-03-08 17:46:42.593643 7ff669ffb700 10 monclient(hunting): dump: ### 正常的op日志 1234567891011121314d = 02021-03-08 18:50:37.595153 7fe83ffff700 30 Event(0x7fe8400e8650 nevent=5000 time_id=2).create_time_event id=1 trigger after 900000000us2021-03-08 18:50:37.595151 7fe83f7fe700 20 -- 10.192.89.60:0/288270703 &gt;&gt; 10.192.89.60:6789/0 conn(0x7fe8403a2660 :-1 s=STATE_OPEN_MESSAGE_READ_FOOTER_AND_DISPATCH pgs=50114 cs=1 l=1).process got 397 + 0 + 0 byte message2021-03-08 18:50:37.595158 7fe83ffff700 30 Event(0x7fe8400e8650 nevent=5000 time_id=2).dispatch_event_external 0x7fe84039c280 pending 12021-03-08 18:50:37.595160 7fe80affd700 10 client.?.objecter ms_handle_connect 0x7fe84039ef302021-03-08 18:50:37.595162 7fe80affd700 10 client.?.objecter resend_mon_ops2021-03-08 18:50:37.595174 7fe83ffff700 20 -- 10.192.89.60:0/288270703 &gt;&gt; 10.192.89.63:6789/0 conn(0x7fe84039ef30 :-1 s=STATE_OPEN pgs=27784 cs=1 l=1).process prev state is STATE_CONNECTING_READY2021-03-08 18:50:37.595181 7fe83ffff700 25 -- 10.192.89.60:0/288270703 &gt;&gt; 10.192.89.63:6789/0 conn(0x7fe84039ef30 :-1 s=STATE_OPEN pgs=27784 cs=1 l=1).read_until len is 1 state_offset is 02021-03-08 18:50:37.595184 7fe83f7fe700 10 -- 10.192.89.60:0/288270703 &gt;&gt; 10.192.89.60:6789/0 conn(0x7fe8403a2660 :-1 s=STATE_OPEN_MESSAGE_READ_FOOTER_AND_DISPATCH pgs=50114 cs=1 l=1).process no session security set2021-03-08 18:50:37.595190 7fe83ffff700 25 -- 10.192.89.60:0/288270703 &gt;&gt; 10.192.89.63:6789/0 conn(0x7fe84039ef30 :-1 s=STATE_OPEN pgs=27784 cs=1 l=1).read_until read_bulk recv_end is 0 left is 1 got 02021-03-08 18:50:37.595196 7fe83ffff700 25 -- 10.192.89.60:0/288270703 &gt;&gt; 10.192.89.63:6789/0 conn(0x7fe84039ef30 :-1 s=STATE_OPEN pgs=27784 cs=1 l=1).read_until need len 1 remaining 1 bytes2021-03-08 18:50:37.595193 7fe83f7fe700 5 -- 10.192.89.60:0/288270703 &gt;&gt; 10.192.89.60:6789/0 conn(0x7fe8403a2660 :-1 s=STATE_OPEN_MESSAGE_READ_FOOTER_AND_DISPATCH pgs=50114 cs=1 l=1). rx mon.0 seq1 0x7fe83000b830 mon_map magic: 0 v12021-03-08 18:50:37.595203 7fe83ffff700 10 -- 10.192.89.60:0/288270703 &gt;&gt; 10.192.89.63:6789/0 conn(0x7fe84039ef30 :-1 s=STATE_OPEN pgs=27784 cs=1 l=1).handle_write 刚才忽然想到的, 会不会是因为有些时候先去访问了非主节点, 所以没响应, 直到去访问主节点为止. mon为什么非主节点就不能提供信息呢?理论上应该是全节点都可以(PS. 后来试了下12.2.12版本, 全节点都正常, 就这个版本不正常, 暂时没去查这个版本到12.2.12改了什么) 所以monclient是怎么选择mon_host的呢? mon_client是怎么触发的呢? m_client-&gt;dump_status(f); bool Client::CommandHook::call 这个是怎么进来的呢? rados什么时候会进入这个client::init? static CephContext rados_create_cct(const char const clustername, CephInitParameters *iparams) CephContext::CephContext(uint32_t module_type_, enum code_environment_t code_env, int init_flags_) * _admin_hook = new CephContextHook(this); *pcluster = reinterpret_cast(new librados::RadosClient(cct)); librados::RadosClient::RadosClient(CephContext *cct_) MonClient::MonClient(CephContext *cct_) 现在问题就是init之外, ceph -s怎么调用的status了. 按理来说, 只是把status发送给了mon, 来进行mon_command 但是现在mon_host, 他其实是不知道的. emm, 按这个来说, 应该再init阶段, 或者connect阶段知道的 rados_connect int MonMap::build_initial(CephContext *cct, ostream&amp; errout) 的确是在connect阶段, 从build_initial中取得的. 123456int MonMap::build_from_host_list(std::string hostlist, std::string prefix) void add(const string &amp;name, const entity_addr_t &amp;addr) &#123; add(mon_info_t(name, addr)); struct mon_info_t &#123; 接下来就逐渐进到这个pick阶段了 1 ldout(cct, 10) &lt;&lt; &quot;picked mon.&quot; &lt;&lt; monmap.get_name(rank) 开始反查 12345678void MonClient::_add_conns(uint64_t global_id) std::random_device rd; std::mt19937 rng(rd()); std::shuffle(ranks.begin(), ranks.end(), rng);void MonClient::_reopen_session(int rank) 这里的n如果一开始就是集群size, 好像即便shuffle也不会有问题了. cat /etc/ceph/ceph.conf | grep mon_client_hunt_parallel unsigned n = cct-&gt;_conf-&gt;mon_client_hunt_parallel; 的确找到了对应的,我把这个size改成mon_host的size, 一开始就一定能选中主节点, 就不卡了. kernel 的mon client选择mon逻辑相近 net/ceph/mon_clinet.c:pick_new_mon中, 主要支持多个mon选择是在这条提交libceph: pick a different monitor when reconnecting · torvalds/linux@0e04dc2 对应的patch [4/9] libceph: pick a different monitor when reconnecting - Patchwork","categories":[{"name":"专业","slug":"pro","permalink":"https://sean10.github.io/categories/pro/"}],"tags":[{"name":"ceph","slug":"ceph","permalink":"https://sean10.github.io/tags/ceph/"},{"name":"mon","slug":"mon","permalink":"https://sean10.github.io/tags/mon/"},{"name":"超时","slug":"超时","permalink":"https://sean10.github.io/tags/%E8%B6%85%E6%97%B6/"}]},{"title":"systemd之systemd-tty-ask-password-agent卡住.md","slug":"systemd之systemd-tty-ask-password-agent卡住-md","date":"2021-04-10T15:47:41.000Z","updated":"2023-03-18T15:11:14.818Z","comments":true,"path":"2021/04/10/systemd之systemd-tty-ask-password-agent卡住-md/","link":"","permalink":"https://sean10.github.io/2021/04/10/systemd%E4%B9%8Bsystemd-tty-ask-password-agent%E5%8D%A1%E4%BD%8F-md/","excerpt":"","text":"背景 这个问题其实之前遇到的还挺多的, 简单来说, 就是某个A服务启动B服务, 但是B服务又必须等待另一个服务启动完毕(比如A服务), 产生了一定的死锁. 而在ps的进程表中看到的就是systemd-tty-ask-password-agent这样一个agent进程卡住. 一般查一下当前卡住的service和他依赖的after,before的几个服务, 就知道了, 一般就是循环死锁了. 具体理论这块还没去查源码, 暂时只能给个结论.有大佬看过的话, 希望也能分享下~ 样例 ``` bash # new2.service [Unit] Description=System Logging Service Documentation=man:rsyslogd(8) Documentation=https://www.rsyslog.com/doc/ [Service] Type=forking EnvironmentFile=-/etc/sysconfig/rsyslog ExecStart=/root/new2.sh Increase the default a bit in order to allow many simultaneous files to be monitored, we might need a lot of fds. [Install] WantedBy=multi-user.target new2.sh #!/bin/bash echo \"heelo\" sleep 1000 &amp; systemctl restart new1 new1.service [Unit] Description=System Logging Service Documentation=man:rsyslogd(8) Documentation=https://www.rsyslog.com/doc/ After=new2.service [Service] Type=forking EnvironmentFile=-/etc/sysconfig/rsyslog ExecStart=/root/new1.sh Increase the default a bit in order to allow many simultaneous files to be monitored, we might need a lot of fds. [Install] WantedBy=multi-user.target new.sh #!/bin/bash echo \"heelo\" sleep 1000 &amp; ``` bash","categories":[{"name":"专业","slug":"pro","permalink":"https://sean10.github.io/categories/pro/"}],"tags":[{"name":"linux","slug":"linux","permalink":"https://sean10.github.io/tags/linux/"},{"name":"systemd","slug":"systemd","permalink":"https://sean10.github.io/tags/systemd/"},{"name":"service","slug":"service","permalink":"https://sean10.github.io/tags/service/"}]},{"title":"分布式时钟之向量时钟","slug":"分布式时钟之向量时钟","date":"2021-04-10T12:44:10.000Z","updated":"2023-03-18T15:11:14.868Z","comments":true,"path":"2021/04/10/分布式时钟之向量时钟/","link":"","permalink":"https://sean10.github.io/2021/04/10/%E5%88%86%E5%B8%83%E5%BC%8F%E6%97%B6%E9%92%9F%E4%B9%8B%E5%90%91%E9%87%8F%E6%97%B6%E9%92%9F/","excerpt":"","text":"向量时钟 vector clock 可能有人会有疑问：向量时钟到底有什么用呢？举一个常见的工程应用：数据冲突检测。分布式系统中数据一般存在多个副本，多个副本可能被同时更新，这会引起副本间数据不一致，此时冲突检测就非常重要。基于向量时钟我们可以获得任意两个事件的顺序关系，结果要么是有因果关系（先后顺序），要么是没有因果关系（同时发生）。通过向量时钟，我们能够识别到如果两个数据更新操作是同时发生的关系，那么说明出现了数据冲突。 向量时钟算法利用了向量这种数据结构将全局各个进程的逻辑时间戳广播给各个进程：每个进程发送事件时都会将当前进程已知的所有进程时间写入到一个向量中，附带在消息中 如何实现向量时钟 假设分布式系统中有 N 个进程，每个进程都有一个本地的向量时间戳 Ti，向量时钟算法实现如下： 对于进程 i 来说，Ti[i] 是进程 i 本地的逻辑时间 当进程 i 当有新的事件发生时，Ti[i] = Ti[i] + 1 当进程 i 发送消息时将它的向量时间戳(MT=Ti)附带在消息中。 接受消息的进程 j 更新本地的向量时间戳：Tj[k] = max(Tj[k], MT[k]) for k = 1 to N。（MT即消息中附带的向量时间戳） 假设有事件 a、b 分别在节点 P、Q 上发生，向量时钟分别为 Ta、Tb，如果 Tb[Q] &gt; Ta[Q] 并且 Tb[P] &gt;= Ta[P]，则a发生于b之前，记作 a -&gt; b，此时说明事件 a、b 有因果关系； 反之，如果 Tb[Q] &gt; Ta[Q] 并且 Tb[P] &lt; Ta[P]，则认为a、b同时发生，记作 a &lt;-&gt; b。例如上图中节点 B 上的第 4 个事件 (A:2，B:4，C:1) 与节点 C 上的第 2 个事件 (B:3，C:2) 没有因果关系，属于同时发生事件。 数据冲突检测 根据这个, ceph里的last_epoch_started版本号应该也是起这个效果的吧, 具体分析待阅读到那个部分的代码再展开. Reference 分布式系统：向量时钟 - 知乎","categories":[{"name":"专业","slug":"pro","permalink":"https://sean10.github.io/categories/pro/"}],"tags":[{"name":"分布式","slug":"分布式","permalink":"https://sean10.github.io/tags/%E5%88%86%E5%B8%83%E5%BC%8F/"},{"name":"摘录","slug":"摘录","permalink":"https://sean10.github.io/tags/%E6%91%98%E5%BD%95/"},{"name":"时钟","slug":"时钟","permalink":"https://sean10.github.io/tags/%E6%97%B6%E9%92%9F/"}]},{"title":"分布式时钟之Lamport逻辑时钟","slug":"分布式时钟之Lamport逻辑时钟","date":"2021-04-08T11:50:07.000Z","updated":"2023-03-18T15:11:14.819Z","comments":true,"path":"2021/04/08/分布式时钟之Lamport逻辑时钟/","link":"","permalink":"https://sean10.github.io/2021/04/08/%E5%88%86%E5%B8%83%E5%BC%8F%E6%97%B6%E9%92%9F%E4%B9%8BLamport%E9%80%BB%E8%BE%91%E6%97%B6%E9%92%9F/","excerpt":"","text":"背景 在看到这篇论文之前, 我所知道的只是linux上自带的时间戳和ntp协议, 以及内核里有一个每次开机启动时开始记录的monotonic clock可以用来保障时间一定是连续的. 但是对于分布式设备之间怎么判断互相的时间先后性, \b这块是未知的. 比如针对leader节点发送一次自己的认证失效时间, 假如自己的物理时间戳比那个时间还早, 但真实世界的时间戳已经超期了, 到底是按失效还是有效来进行呢? 不过这个问题似乎可以通过失效后统一发送失效请求, 只要收到了, 或者自身参与选举时的时间加一个超时时间来判断超时来做. 所以, 跟大佬们说的一样, 因此问题的关键点在于节点间的交互要在事件的发生顺序上达成一致，而不是对于时间达成一致。 在一个分布式系统中，你无法判断事件A是否发生在事件B之前，除非A和B存在某种依赖关系，即分布式系统中的事件仅仅是部分有序的。 逻辑时钟(Time, clocks, and the ordering of events in a distributed system ) \b 基于Happended Before偏序关系(因果一致性), 扩展出强一致性的全序关系. \b根据[^1]可以得知下述概念. 尝试使用逻辑时钟来解决分布式锁问题。 分布式锁问题本质上是对于共享资源的抢占问题，我们先对问题进行定义： 已经获得资源授权的进程，必须在资源分配给其他进程之前释放掉它； 资源请求必须按照请求发生的顺序进行授权； 在获得资源授权的所有进程最终释放资源后，所有的资源请求必须都已经被授权了。 首先我们假设，对于任意的两个进程Pi和Pj，它们之间传递的消息是按照发送顺序被接收到的, 并且所有的消息最终都会被接收到。每个进程会维护一个它自己的对其他所有进程都不可见的请求队列。我们假设该请求队列初始时刻只有一个消息（T0:P0）资源请求，P0代表初始时刻获得资源授权的那个进程，T0小于任意时钟初始值 为请求该项资源，进程Pi发送一个（Tm:Pi）资源请求（请求锁）消息给其他所有进程，并将该消息放入自己的请求队列，在这里Tm代表了消息的时间戳 当进程Pj收到（Tm:Pi）资源请求消息后，将它放到自己的请求队列中，并发送一个带时间戳的确认消息给Pi。(注：如果Pj已经发送了一个时间戳大于Tm的消息，那就可以不发送) 释放该项资源（释放锁）时，进程Pi从自己的消息队列中删除所有的（Tm:Pi）资源请求，同时给其他所有进程发送一个带有时间戳的Pi资源释放消息 当进程Pj收到Pi资源释放消息后，它就从自己的消息队列中删除所有的（Tm:Pi）资源请求 当同时满足如下两个条件时，就将资源分配（锁占用）给进程Pi： 按照全序关系排序后，（Tm:Pi）资源请求排在它的请求队列的最前面 i已经从所有其他进程都收到了时间戳&gt;Tm的消息 按照大佬说的, 这个其实算得上是分布式一致性算法的雏形. 每次请求都带上一个逻辑时间戳. Reference 分布式系统：Lamport 逻辑时钟 - 知乎","categories":[{"name":"专业","slug":"pro","permalink":"https://sean10.github.io/categories/pro/"}],"tags":[{"name":"分布式","slug":"分布式","permalink":"https://sean10.github.io/tags/%E5%88%86%E5%B8%83%E5%BC%8F/"},{"name":"论文","slug":"论文","permalink":"https://sean10.github.io/tags/%E8%AE%BA%E6%96%87/"},{"name":"摘录","slug":"摘录","permalink":"https://sean10.github.io/tags/%E6%91%98%E5%BD%95/"},{"name":"时钟","slug":"时钟","permalink":"https://sean10.github.io/tags/%E6%97%B6%E9%92%9F/"}]},{"title":"DistCache分布式缓存","slug":"DistCache分布式缓存","date":"2021-04-07T12:29:19.000Z","updated":"2023-03-18T15:11:14.837Z","comments":true,"path":"2021/04/07/DistCache分布式缓存/","link":"","permalink":"https://sean10.github.io/2021/04/07/DistCache%E5%88%86%E5%B8%83%E5%BC%8F%E7%BC%93%E5%AD%98/","excerpt":"","text":"DistCache: Provable Load Balancing for LargeScale Storage Systems with Distributed Caching[^1] Small Cache解决的Ball into bins 问题 Balls into bins 问题讲的是如果有 M 个小球随机等概率地扔进 N 个垃圾桶, 那么装球最多的那个垃圾桶大概率会有多少个球? \\[O(\\frac{logn}{loglogn})\\] 结果并不是正态分布的. 上面那个公式计算的是 max load. 假设有 64 个 node, LB 随机分配流量, 那么 load 最大的 node, 负载将会是平均负载的 log 32 / log log 32 = 2.7 倍. 解决方案出奇的简单(起码理论上是这样的), 这就引出了 The Power of Two Random Choices. LB 在分流的时候, 随机比较两台(d = 2)后端服务器的 load, 选最小, 得到新 bound. \\[ O(loglogn/logd) \\] log d是常数, 可忽略. \\[ O(loglogn) \\] log log 32 = 1.2, 所以只需要预留20%. 2 choices 可以解决无状态的 load balance 问题, 但这对存储不起作用. 因为 LB 没有办法按 load 分流, 比如 key A 存在服务器 S 上, S 跑满了, LB 就能把 query redirect 到别的机器上吗? Small Cache, Big Effect 这篇 paper 很大程度上解决了这个问题. LB 与 cache layer 存在很强的互补关系. LB 讨厌 imbalance, 但 cache 喜欢. query 越 skew, cache 效率越高. 在一个多 node 的存储系统, cache 至少要多少才有足够的信心说这个系统没有热点呢? paper 给出的答案吓死人了! 居然只要 \\(O(nlogn)\\) !n 是 node 数量. DistCache Introduction：存储系统的工作负载高度倾斜，过载节点成为系统性能瓶颈，SoCC11[1]一篇文章证明了，n个存储节点，无论query是怎样的分布，缓存最热的O(nlogn)个对象即可均衡负载。SwitchKV和NetCache都使用该机制均衡KV存储集群的负载。单个缓存可以完成集群内的负载均衡（比如一个机柜），但集群规模不断扩展，集群间会出现负载不均的问题，也即过载集群的工作负载远高于其他集群，超过了该集群cache提供的缓存能力，该集群成为大规模集群的性能瓶颈。将一个集群视为One Big Server，m个集群视为m个Server，按照一个cache的机制进行扩展，采用更大的cache提供缓存功能，不具有可扩展性，即伴随着系统工作负载增加，heavy hitter需要的吞吐量势必超过One Big Cache的吞吐能力。 One Big Cache性能不足，扩展机制从One-Cache到Multi-Cache扩展，形成一层Cache Layer。现在就有两层cache，第一层cache layer，每个cache在所属集群中均衡负载，第二层cache均衡集群间的负载。怎么缓存heavy hitter和怎么在两层cache间query item成为了新的问题。如果采用replication机制，将第一层中最热的item复制到第二层的每个cache中，可以提供很强的读性能，但是在写的情况下，会带来很大的缓存一致性开销。如果采用partition机制，过载的cache热点无法打散，依旧是性能瓶颈。如何在partition和replication之间做trade off，平衡读写性能，是本文的关键。 缓存热点时使用independent hash function，如图3，ABC三个热点hash到同一个cache中，在第二层hash时采用不同的hash函数，旨在将热点打散，如图中，ABC分别被打散到第二层的cache中了。查询时采用power-of-two-choices，如图3，query A时观察C1和C3的工作负载，查询工作负载小的cache节点。 作者给出的方案很简单, 就是双层 cache. 当前所有 cache server 的所有 KV 用一个新的 hash function 存在另一层 cache layer 里. 从数学和直觉上可以确保, 任意一层的 cache server 出现了热点, 那么这个热点的 KV 数据在另一个 cache layer 是分散的, 无热点的. 然后在哪一层 cache 找 key 的问题又可以转化为 The Power of Two Random Choices 问题, 选负载最低的. 系统 系统搭建承接了SOSP17的NetCache[2]工作，要具体理解本文的系统，还需追溯到NetCache去 这篇NetCache里提到的主要架构应该是利用交换机和路由器来进行缓存读请求, 通过实现一套协议, 让存储服务器和交换机之间完成这个缓存数据的交互(读:查询, 写:write-through). Reference FAST 2019 DistCache · 阿吉的博客 [Paper Review]FAST'19 DistCache - 知乎 X. Jin, X. Li, H. Zhang, R. Soulé, J. Lee, N. Foster, C. Kim, and I. Stoica, “NetCache: Balancing key-value stores with fast in-network caching,” in ACM SOSP, October 2017. NetCache -- Balancing Key-Value Stores with Fast In-Network Caching · Columba M71's Blog","categories":[{"name":"专业","slug":"pro","permalink":"https://sean10.github.io/categories/pro/"}],"tags":[{"name":"缓存","slug":"缓存","permalink":"https://sean10.github.io/tags/%E7%BC%93%E5%AD%98/"},{"name":"分布式","slug":"分布式","permalink":"https://sean10.github.io/tags/%E5%88%86%E5%B8%83%E5%BC%8F/"},{"name":"论文","slug":"论文","permalink":"https://sean10.github.io/tags/%E8%AE%BA%E6%96%87/"},{"name":"摘录","slug":"摘录","permalink":"https://sean10.github.io/tags/%E6%91%98%E5%BD%95/"}]},{"title":"SWIM协议","slug":"SWIM协议","date":"2021-04-06T15:07:08.000Z","updated":"2023-03-18T15:11:14.827Z","comments":true,"path":"2021/04/06/SWIM协议/","link":"","permalink":"https://sean10.github.io/2021/04/06/SWIM%E5%8D%8F%E8%AE%AE/","excerpt":"","text":"论文 可扩展弱一致性感染型进程组成员协议 进程组的成员关系协议 可伸缩性 弱一致性 感染性 用于分布式系统中进程的健康检测或者说错误检测 SWIM是通过Gossip实现的Membership保持协议，也就是维护分布式系统节点的状态 成员资格协议 成员资格协议的可伸缩型和执行效率主要由以下几个方面确定： 完备性：是不是每个失效的进程最终都能够检测到？ 失效节点的检测速度：一个节点失效到它被非失效节点检测到的平均时间间隔是多长？ 准确性：实际上进程未失效但却被认为是失效的频度（即误判率）是多少？ 信息量：每个节点生成的网络通信的信息量有多大，它是否也是分布式的？ 理想情况下，我们需要这样的协议：它一定要完全100%准确，这就意味着可以检测到每一个失效进程，而且不存在任何误判。然而，像分布式系统里的其他协议一样，存在这样的事实：在异步网络上保证100%的完备和准确是不可能的。因此许多成员资格协议（包括SWIM)为了完备性就会降低准确性，同时尽最大可能降低误判率。 模块 Failure Detector, 用于Node失败检测 概念： T’: 协议周期，2次探测的时间间隔 k: k个节点 该协议中，若Mi检测Mj状态，则先发一个ping包到Mj，若Mj未在超时时间内ack，则Mi随机选择k个节点，发送间接探测ping-req包，k个节点如Mh收到ping-req请求，将会ping Mj并将结果返回给Mi。若任意一个ping-req返回Mj存活，则Mj存活。 上述过程，包含3个round-trip的网络过程，Mi-&gt;Mj, Mi-&gt;Mh, Mh-&gt;Mj，所以T’ 要大于3个超时；如T’=1s, timeout=200ms \b这里故障监测, 也存在一篇论文讲到[SRDS 2004] The Phi Accrual Failure Detector讲到可以通过概率模型来判断都次未响应后到底该节点是否已经离线, 还是只是网络波动缘由导致. 这个还挺可靠的, 的确某个设备的链路存在波动问题时, 常常代表他的响应会是长期离线的. 假设 heartbeat message 符合某一概率模型。例如定期发送的 heartbeat message 在有网络延迟的情况下，接收到消息的 interval 符合正态分布。 利用接收到的历史数据（滑动窗口），对概率模型参数进行极大似然估计。 利用估计得出的参数带入模型，计算在当前时刻接收到 heartbeat message 的概率 区别于传统方法，此时不直接得出对端是否存活的判断，而是直接向上层应用返回这一概率，由上层应用自行进行解释，是这篇论文中提出的另一个“亮点\"。 Dissemination 模块，用于将Node主动加入、退出或失败的信息传播出去 当Mi检测到Mj失败，会利用IP多播等方式，发送一条 failed(Mj) 的消息，收到消息的Node，会把Mj从本地Node表中踢除。 思考 所以理论上, 基于这个的linux集群网络稳定性监控机制应该是有的吧. Reference Scalable Weakly | 大专栏 [致远的 BLOG](http://understars.ltd/archives/swim.md 分布式系统中的 SWIM 成员协议 - OSCHINA - 中文开源技术交流社区) 论文笔记：[SRDS 2004] The Phi Accrual Failure Detector - 知乎","categories":[{"name":"专业","slug":"pro","permalink":"https://sean10.github.io/categories/pro/"}],"tags":[{"name":"分布式","slug":"分布式","permalink":"https://sean10.github.io/tags/%E5%88%86%E5%B8%83%E5%BC%8F/"},{"name":"论文","slug":"论文","permalink":"https://sean10.github.io/tags/%E8%AE%BA%E6%96%87/"},{"name":"gossip","slug":"gossip","permalink":"https://sean10.github.io/tags/gossip/"}]},{"title":"ceph之Arch部署Octopus版本","slug":"ceph之Arch部署Octopus版本","date":"2021-03-21T13:55:55.000Z","updated":"2023-03-18T15:11:14.838Z","comments":true,"path":"2021/03/21/ceph之Arch部署Octopus版本/","link":"","permalink":"https://sean10.github.io/2021/03/21/ceph%E4%B9%8BArch%E9%83%A8%E7%BD%B2Octopus%E7%89%88%E6%9C%AC/","excerpt":"","text":"arch安装实验 1pacman -Syy ceph 安装完发生了一个奇怪的问题, ceph -v执行报缺rados库, python3-rados装到了python3.9的site-package里, 但是我设备里pacman目前只装了python3.8, 这个的包里没有看到这个库 执行了pacman -Syy python升级到3.9, 可以用了, 升级过程中python3.9的库里少了好多我之前安装图形界面用到的python库. 我最后是把3.8的site-package里的包不重复的复制进去安装的. arch有一个好处, 大佬们多, 源里最新版的东西很多. 虽然pacman里没有, 但是AUR源里有. yay -Syy cephadm就安装上了. 部署 cephadm bootstrap --mon-ip 192.168.115.130 发现官方文档里没提需要安装chrony, docker,配置hostname, 配置/etc/hosts. 都配置完之后. 很可惜还是出现了失败. 通过ceph log last cephadm查到, 失败原因是ssh连不上, 然后我发现我的arch默认没装openssh导致的. 安装之后就通过了. i 然后创建几块虚拟盘进行操作. 不过我这里用默认的自动对全盘进行创建的逻辑无效, ceph orch apply osd --all-available-devices --dry-run扫了下,我的环境好像不符合条件. 我猜是盘的格式化问题(我没有用sgdisk初始化过, 所以应该还是一个不符合ceph默认用的分区表的盘) 不过通过单独指定ceph orch daemon add osd ceph01:/dev/sdb, 还是可以成功的. 成功建出来了, 发现默认就有一个device_health_metrics的名字的资源池. 重设 sudo cephadm rm-cluster --fsid d9850914-866a-11eb-8eec-000c2934ee39 --force 一些小问题 我居然在没清理干净集群的情况下, 成功部署了一次? 快速启动ceph调试环境 \b源码版本是有vstart的, 不知道生产版本有没有, emm, 没有. Reference 使用cephadm快速搭建ceph集群-胡源的博客-51CTO博客","categories":[{"name":"专业","slug":"pro","permalink":"https://sean10.github.io/categories/pro/"}],"tags":[{"name":"ceph","slug":"ceph","permalink":"https://sean10.github.io/tags/ceph/"},{"name":"arch","slug":"arch","permalink":"https://sean10.github.io/tags/arch/"}]},{"title":"ceph之ansible理解","slug":"ceph之ansible理解","date":"2021-02-18T11:36:07.000Z","updated":"2025-02-23T22:31:43.813Z","comments":true,"path":"2021/02/18/ceph之ansible理解/","link":"","permalink":"https://sean10.github.io/2021/02/18/ceph%E4%B9%8Bansible%E7%90%86%E8%A7%A3/","excerpt":"","text":"理解 大家最受影响的就是一半时间开发, 一半时间运维的这个问题. 利用一个成熟的配置文件, 快速部署起自己需要的环境, 而不是一步步通过页面控制点击, 这是一个很省力的事情. 将运维中与部署相关的事情通过一些成熟的模板化的配置文件来提供, 最好不过了. ansible比较大的几个优点 由于是开源框架, 基于ansible的针对其他开源软件的配套代价较多 比如集成钉钉等 配置文件化管理部署成熟 可针对不同的环境, 使用不同的配置文件快速部署 可以使用开源插件快捷对接配置管理服务 因为 Ansible2.0以上的版本已经原生集成了consule: consul_module 不建议的操作 建议遵循unix思想, 一个工具只做该做的事情, ansible虽然提供了能力, 但是能由脚本来完成的事情, 没必要在ansible中进行处理 根据[^10]终于意识到我现在所处理的最别扭的地方在哪里了...这篇文章中说了下述几点. 在 ansible 中使用复杂的语法规则 更推荐直接封装成脚本, 由脚本来进行这些操作.但是脚本的粒度拆分, 什么应该让ansible来操作, 什么应该让脚本来处理, 是个边界. 明明几行 Shell 就可以搞定的事情，为什么一定要使用 Ansible 来做呢？ 明明一个 Shell 脚本就可以完成的环境监察，为什么一定要使用 Ansible Playbook 来做呢？要知道 Playbook 编写语法虽然是 YAML，但是使用起来并不简单，有很多特殊的语法需要去注意，完全没有必要花费精力去学习一个新的工具去完成。 如果脚本中存在较多判断，不宜使用 Playbook 实现逻辑 如果脚本中存在部分参数解析功能，不宜使用 Playbook 实现逻辑 不要过度拆分 task，保证每个 task 完整性 从个人使用上来说，Ansible 还是很好用的，至少它无需 Agent，SSH 连接等特性，使用起来很友好。 但是我们也不应该过分使用 Playbook，编写 Playbook 解析 json 花费了不少的时间，远不如直接在被执行脚本中完成的成本低。 tidb开发计划 deploy.yml 用来部署集群。执行 deploy 操作会自动将配置文件、binary 等分发到对应的节点上；如果是已经存在的集群，执行时会对比配置文件、binary 等信息，如果有变更就会覆盖原来的文件并且将原来的文件备份到 backup（默认） 目录。 start.yml 用来启动集群。注意：这个操作只是 start 集群，不会对配置等信息做任何更改 stop.yml 用来停止集群。与 start 一样，不会对配置等做任何修改。 rolling_update.yml 用来逐个更新集群内的节点。此操作会按 PD、TiKV、TiDB 的顺序以 1 并发对集群内的节点逐个做 stop → deploy → start 操作，其中对 PD 和 TiKV 操作时会先迁移掉 leader，将对集群的影响降到最低。一般用来对集群做配置更新或者升级。 rolling_update_monitor.yml 用来逐个更新监控组件，与 rolling_update.yml 功能一样，面向的组件有区别。 unsafe_cleanup.yml 用来清掉整个集群。这个操作会先将整个集群停掉服务，然后删除掉相关的目录，操作不可逆，需要谨慎。 unsafe_cleanup_data.yml 用来清理掉 PD、TiKV、TiDB 的数据。执行时会先将对应服务停止，然后再清理数据，操作不可逆，需要谨慎。这个操作不涉及监控。 并行任务引擎 作业编排：可以自由选择相应的原子化操作，编排和发布新的作业流程 可视化: 通过拖拽鼠标编排作业流程和参数表单，作业运行与任务的状态可视化 并行调度: 同一个作业中的任务支持并行执行，在很多场景下能极大的缩短执行时间 实时监控: 任务的运行状态在页面上实时更新 断点执行: 执行错误的任务在修复错误后可以继续执行，不需要重新执行整个作业 任务回滚: 遇到错误，可以支持回滚作业中已经执行过的任务，恢复执行环境 作业模板: 可定制作业模板，用模板创建作业实例，避免重复工作 任务组: 在作业模板中把任务分组，在创建任务实例时候可以动态的复制任务组，相似的作业使用同样的模板，但又不限制于模板 计算表达式: 使用表达式动态的计算任务的参数值，能够极大的简化重复参数的输入以及复杂参数的拼接 动态参数：前面任务的输出作为后续任务的输入参数 同类比较 fabric 快速入门使用 puppet C/S架构 大部分付费功能 Chef ansible 语义多层架构 基于ssh, push/pull均支持 cephadm是使用工具的配置语法进行部署后, 为了更强程度的自定义而进阶开发的产物. TODO:设计角度, 为什么cephadm用了docker? 另外, cephadm支持所有业务的部署能力是否和这个有关? SaltStack 基于python的开源CM工具 CS架构 学习曲线低 cephadm之后有配套saltstack的 ceph/ceph-salt: Deploy Ceph clusters using cephadm Kolla-ansible? 应该是openstack用的 苏宁的产品化Hull思路 基于上面的, 设计标准的RESTAPI 定义Workflow 可视化安装 增加Data Center, cluster, region等逻辑概念, 更好的满足用户的部署需求. 遵循的设计模式理念 开闭原则 将分配策略, osd与故障域拓扑的关联, 更改为基于osd的属性进行策略分配, 策略为可扩展 借助ansible, 使各个团队之间的组件, 仅基于yaml的定义进行插拔, 配置文件存在对应key, 触发对应的role. 且各个模块上下文之间存在公用属性, 直接从基础变量中加载. 扁平化传递, 无需封装. 最佳实践 重试逻辑 --start-at-task 这里采用的方案是自定义一个callback的插件, 将failed的task记录下来,见callback, 然后封装一个CLI, 在下次执行的时候增加--start-at-task &#123;task_name&#125;来进行调度. ### 优化方案 和一开始调研时的目的有点不一样, 现在发现的主要问题在于ansible做的预处理的逻辑太多了, 而且主要框架严重依赖单独的ssd和shell, 这样带来的问题你就是部署的性能较差. 需要找一些优化的方案 facts收集 关闭 设置缓存 增加并发 修改运行策略为free等. ssd长连接 开启pipelining. 原本的逻辑是将library,role等生成一个脚本, 复制到远程主机上, 再执行. 现在改为通过pipe直接传递给ssh会话. 开启accelerate模式, 是需要对面的远程服务, 预计是通过rpc类似? 通过poll设置一段时间后再来查询, 不阻塞着等待了. 插件开发 callback 主要目的是支持可以解析出当前失败的任务, 然后给另一个进行重试的接口进行使用. rolling upgrade什么意思 好像应该叫做rolling update模型, 哦,滚动升级 哦, 忽然明白为什么是loop结合delegate_to了, 因为要的不是并发,而是滚动操作. 继承的方法 v2_runner_on_failed runner_on_failed 这俩函数有什么区别呢? 目前看起来v2版本并没有加强多少? 那就随意使用了先. 理解开发方式 感觉[^3]这种插件的阅读方式能提供一些参考. python调用ansible python3.8 调用ansible 2.9.4 api | 经验分享&amp;服务器代维 ansible使用 开源许可证 根据GPL license implies that my plugins are also GPL (MPD's note: it does not) · Issue #8864 · ansible/ansible可知, 虽然ansible是GPL 3.0, 但是由于我们编写的部署脚本是被ansible读取执行, 并非链接. 因此可自行决定使用的许可证. 调试方式 epdb -vvvvvv 虽然文档中只写了-vvv, 但是实际上代码里有一部分写了vvvvvv的函数. 达到这个等级的时候, library里写的logging日志就能输出了. 设置ANSIBLE_KEEP_REMOTTE_FILES=1, 然后再运行Ansbile命令 ansible运行前生成的临时脚本就会保存下来, 不会被删除了. 有时候还是用syslog比较省事 其次这次说的raise Exception, 像是facts/system/distribution.py里的依旧没打印出来, 看着像是被拦截直接跳过的 Debugging modules — Ansible Documentation\u0000 tower付费部分 workflow? workflow和任务队列的区别应该在于低代码吧? 还是说图形界面的任务的图形化操纵叫做workflow? 练习方式 chusiang/ansible-jupyter.dockerfile: Building the Docker image with Ansible and Jupyter. Ansible 用 Docker Compose 练习 Ansible_w3cschool 执行 通过playbook调度role的task, 来进行批量任务执行. ### workflow操作多个playbook是否有开源替代方案? 还是直接写playbook, 通过role控制. 目前来看, 不算特别关键. 语法 playbook 1234ansible-playbook -i &#123;inventory host&#125; add-osd.yml# checkansible-playbook foo.yml --check delegate_to 这里为什么看到和loop一起使用? delegate_to不支持直接指定组嘛?为什么要loop 这个的主要用途难道不是到一个只需要一个组内的一个节点执行的时候, 直接选中某一个吗? ansible解析参数的过程, 和delegate_to这种指定某个节点只执行一次的逻辑, 是哪个优先呢? 如果是后者, 那是否这个的目的是用来让这个组内只在第一个节点执行一次? 但是感觉有点像是后者 123delegate_to: &quot;&#123;&#123; item &#125;&#125;&quot;loop: &quot;&#123;&#123; xxx &#125;&#125;&quot; run_once 当我不需要指定哪个节点来执行一个集群任务的时候, 直接用run_once就可以ile,他会直接指定第一台 group_vars 自定义相对路径? 不可以, 只能是当前执行hosts所在的目录的相对路径 roles搜搜路径 可以修改ansible.cfg内的配置 shell模块指定路径 1234name: xxxshell: xxxargs: chdir: /home/ role 自定义模块, 内部包含具体的task 依赖管理 在 playbook 中存在多个 roles，且其中有相互依赖关系时，合理使用 meta 配置，填写其所依赖的 roles。注意，被依赖的 roles 会优先执行 include_task 在role内使用include_task无法使用start-at-task直接跳转, 而import_task可以 配合tags需注意使用apply 1234567- name: Include and run an inner and an outer task include_tasks: file: install.yml apply: tags: install tags: install Ansible include_tasks will not run when tags are specified - Stack Overflow ad-hoc 全节点临时执行的命令, 这个对于排查问题全节点查日志的时候还是用的比较多的. 1ansible 主机或组 -m command -a &#x27;模块参数&#x27; ansible参数 ceph-ansile [^2]里稍微解释了一部分. 问题 根据目前的调研结果来看, 存在两个问题 * osd层无法支持用于db,wal分区之后剩余空间创建osd * crush rule无法自由指定 * 不支持tier创建 * 不支持针对ec模式下的资源池,通过创建副本的元数据资源池进行创建rbd. 二次开发问题 开发环境到底怎么才能部署起来呢?如果不使用实机已经装好ceph和ceph-ansible的环境, 就没有办法了? 为什么看vagrant.yml.sample里, 都是从一个裸机开始呢?怎么里面就不能装好ceph依赖吗? 姑且按照[^5]先启动看看.` osism/ceph-ansible Tags - Docker Hub vagrant 启动失败了, 似乎我用的centos景象不太一样, 找个docker hub里的试试 Ceph — OSISM documentation 所以library其实完成的任务就是拼接command? AnsibleAPI 开发 - 简书 参考上面这篇文章基本可以说明怎么使用ansible提供的库 实践中的一些疑问 command和 debug冲突? 对应的是不同的Task, 因此的确会冲突 shell和command有没有区别? 一个是启动shell, 一个是启动sh 默认ansible使用的module 是 command，这个模块并不支持 shell 变量和管道等，若想使用shell 来执行模块，请使用-m 参数指定 shell 模块,但是值得注意的是普通的命令执行模块是通过python的ssh执行。 changed 是用来标记task的幂等性满足与否? 的确, 用来标记这个任务是否对环境产生了修改? groups保留字 属于ansible自身的保留字段 变量和inventory还是有点区别的, 虽然是这个主机组的, 但是单纯的变量其实没有主机组的概念的. 为什么ceph没有提供给ansible基于rados的接口呢? 是否是因为使用的是ssh等协议, 所以用Rados其实并不太方便? 并没有设计这个connection?如果要开发, 其实是开发一个connection机制吧? 主要用途是部署, 而在部署阶段, rados得在mon部署完毕后才能工作, 因此如果要切换connection, 还必须分阶段. 还不如直接ssh全套 You cannot register a variable, but you can set a fact (which in most use cases, including yours, will be equivalent to a variable): 12- set_fact: the_output: &quot;&#123;&#123; restdata.json.parameter[1] &#125;&#125;&quot; set_fact 是注册到hostvars , 即注册到不同的host里变量. 要使用json_query , 需要安装jmespath ansible使用register就会被标记成changed? 为什么我用filter, 带上2个大括号就无法识别出对象了呢? 因为filter是jinja2语法, 外面需要先带上双引号. * You are using the debug: module with the option var: and this expects a variable, not a jinja2 template. 对于您的模块支持检查模式，您必须在实例化AnsibleModule对象时传递supports_check_mode = True。 当启用检查模式时，AnsibleModule.check_mode属性将计算为True。 对task进行检查模式 ### ansible的模块里打印大量内容, 即便他不显示,也会记录到warning里? 有垃圾产生? ansible的library不允许使用print, 居然就会报错. 没有日志, 需要之后再找怎么记录日志的方式 通过logging直接往其他文件, 或者通过Syslog协议等输出是一种方案. 或者可以记录到stderr中, ansible只检查stdout是否被污染, 然后报错. 不推荐用这个library, 将来自改造都不方便. out不能是变量? 只能是字符串? 这个还需要找一下 通过debug可以打印出Ansible_facts, 但是直接引用就一直打印不出来, 忽然脑子过了一下, 想通了, ansible_facts应该是上层概念, 对于使用的应该直接填key就可以了, 然后的确拿出来了. 字符串输出转换, 坑 &#123;&#125; 会把字符串转换成object, 导致即便to_json了, 双引号也没了, 其他程序无法识别了. jinja2的语法问题 Double quotes are converted to single quotes on variable assignment if contents look like JSON · Issue #44897 · ansible/ansible Ansible - passing JSON string in environment to shell module - Stack Overflow ansibleSequence是什么东西? 字典的key索引不会被Jinja2解析, 这个真的是深坑 感觉看了下, 这个坑很大啊...一点都不方便debug 莫名其妙的module failure 没有提示的时候, 实际上问题就是在于你的模块里用了print... ansible 是只检测stdout是否被污染, 所以如果我把信息写到Stderr里是没问题的. python3支持问题 我们目前用的ansible 2.6, 我指望使用python3来进行操作, 避免一些问题. 按照[^13]里提到的来说, 理论上会按照从哪个python版本安装的ansible, 就从哪个版本启动的功能. 根据[^11]发现的问题就是, 我用的2.6通过ansible.cfg中的设置, 并没能生效, 而通过-e传入的参数倒是有效. 暂时通过上层传入来覆盖下层使用的解释器 group_vars的读取时间是什么时候嗯 只会在执行role的时候去读取对应的group_vars中的变量 以上是错误的, 根据Ansible Configuration Settings — Ansible Documentation通过ansible.cfg里增加debug = True, 发现group_vars的load过程, 在plugins/vars/host_group_vars.py代码中, 实际上在初始化阶段, 就根据每个执行任务的节点在哪些主机组里, 把对应的group_vars目录下的主机组的配置给load了. 并不是运行阶段才进行... 怎么将当前读入的配置及收集到的facts配置导出呢 怎么执行Export呢? template - Templates a file out to a remote server copy content output from json and a variable is not idempotent under py3 · Issue #34595 · ansible/ansible 另外, 其实我并不需要ansible原生的gather_facts, 因为他能够给出来的ip, 现在我知道一些python的原生库获取, 重点在于, 我怎么把多个节点的数据给聚合到一个节点上. 通过set_fact去一起设置到一个字典里? 我通过vars聚合完了. 有个map('extract'功能可以满足这套 12345678910111213141516171819- hosts: all vars: uuids: | &#123;%- set o=[] %&#125; &#123;%- for i in play_hosts %&#125; &#123;%- if o.append(hostvars[i].uuid) %&#125; &#123;%- endif %&#125; &#123;%- endfor %&#125; &#123;&#123; o &#125;&#125; tasks: - name: get uuids for existing cluster nodes shell: mysql -N -B -u &#123;&#123; db_user &#125;&#125; -p &#123;&#123; db_user_password &#125;&#125; -e &quot;SHOW GLOBAL STATUS LIKE &#x27;wsrep_cluster_state_uuid&#x27;;&quot; | sed &#x27;s/\\t/,/g&#x27; | cut -f2 -d&#x27;,&#x27; register: maria_cluster_uuids - set_fact: uuid: &quot;&#123;&#123; maria_cluster_uuids.stdout &#125;&#125;&quot; - debug: var: uuids run_once: true delegate_to: 127.0.0.1 Is it possible combine remote results to local a register in Ansible? - Server Fault vars选项的运行时间是什么时候呢? 如果我采用task, 他能在我指定task前自动运行吗? vars的调用时间是什么时候呢? 写个代码模拟一下? 目前来看, 是当用到这个变量的时候, 才会去计算 有没有办法把list的tuple转成dict呢? jinja2模板导出yaml 并不能自动识别缩进. 需要自己来控制order, 使用Jinja2的filter可以完成这个步骤. 123pools:&#123;&#123; pools | to_yaml | indent(2, true) &#125;&#125; to_nice_yaml output not as expected · Issue #16707 · ansible/ansible 当我需要with_items内部针对每个循环做一个检查, 然后这个检查结果给下一个任务的每个循环使用时, 应该怎么做呢? 如果我把这个封装成一个block, 然后每个block只处理其中一个任务的时候, 这个每个循环的变量怎么穿进去呢? 比如register和with_items混用时, 是什么效果呢? 拿到的好像就是每条任务注册结果的列表. when和with_items一起使用时, 是每次都执行一次when 好像可以利用changed这个 import_playbook可以组合多个playbook import_playbook不支持传入指定参数. refresh_inventory 强制重新读取inventory 12- name: refresh meta: refresh_inventory 如何将set_fact的host级别的变量转发到其他host里 123456- name: set fact on swarm nodes set_fact: docker_worker_token=&quot;&#123;&#123; some_var &#125;&#125;&quot; delegate_to: &quot;&#123;&#123; item &#125;&#125;&quot; delegate_facts: True with_items: &quot;&#123;&#123; groups[&#x27;all&#x27;] &#125;&#125;&quot; ansible - If set_fact is scoped to a host, can I use 'dummy' host as a global variable map? - Stack Overflow all.yml里的group_vars能被其他host的task读取吗? 修改hosts文件之后的refresh_inventory之后的task没有输出在日志中 根据这个(1) meta: refresh_inventory does not include previously absent hosts in task execution : ansible 和我的实际结果, 当我在多个Task中间加了一个meta: refresh_inventory之后, 后面的任务就一个都不执行了. 如果import_playbook了, playbook倒是还会执行. 目前还没怎么看到代码, 为什么会失败. 解决方案目前是知道了, 写两个host, 上一个playbook的最后一步就是refresh_inventory, 下一个playbook再使用这个group include_vars加载远程节点的配置 , 配合delegate_to疑问 结论, 不支持远程节点. 所以只能自己先把文件复制到本节点, 再进行导入 查找 Controlling where tasks run: delegation and local actions — Ansible Documentation 好像有remote_src选项 To assign included variables to a different host than inventory_hostname, use delegate_to and set delegate_facts=yes. include_vars is unable to load files from remote · Issue #58169 · ansible/ansible 根据上面这篇issue可以知道, remote_src是不准备支持的. The error message is on a generic function, was added for users that were using actions that did allow remote_src, though clearly when added they missed the confusion possible for other actions. We should fix the error message, but i would not try to personalize it too much or we will end up with similar ticket for other actions. 同步远程节点的配置文件到指定节点 synchronize 复制文件到本地 fetch 12345tasks: - name: Fetch the file from the mwiapp01 to master run_once: yes fetch: src=/tmp/app01-to-app02.jar dest=buffer/ flat=yes when: &quot;&#123;&#123; inventory_hostname == &#x27;mwiapp01&#x27; &#125;&#125;&quot; 被跳过的任务依旧注册了变量, 导致覆盖了 ansible skipped task still register value 可以用以下方式绕过, 或者register不同名字变量, set_fact到同一个上(set_fact支持when) 12register: &quot;&#123;&#123; &#x27;real_variable&#x27; if some_condition else &#x27;cool_story_bro&#x27; &#125;&#125;&quot;when: some_condition gather_fact 缓存数据失效 我遇到了修改了系统的hostname, 不过在有些节点, fact结果还被缓存了, 没有重新收集的问题 在运行中重新收集可以用以下命令 12- name: do facts module to get latest information setup: 我试了下, 重新创建playbook即便是同主机组好像也清理不干净, 我直接在原来的playbook里加了下述任务, 然后再注释掉重新执行就可以了. 1234tasks: - name: clear facts meta: clear_facts ansible的changed_when属性, 设置为false时, 当某个节点任务失败, 会让这个节点退出后续的任务执行? 目前是遇到这样一个问题, 直接导致后续的任务执行时节点缺失. 看概念就只是: A boolean indicating if the task had to make changes to the target or delegated host. dynamic playbook hosts How to dynamically set the hosts field in Ansible playbooks with a variable generated during execution? - Stack Overflow 通过hostvars['localhost']['xxx']可以实现 Reference ceph-ansible 使用 | Bolog 干货｜基于Ansible的Ceph自动化部署解析_中兴开发者社区-CSDN博客 第八章: 扩展ansible_个人文章 - SegmentFault 思否 Full support for · Issue #2195 · ceph/ceph-ansible Easily deploy containerized Ceph daemons with Vagrant | Sébastien Han ansible debug模块学习笔记-行者之路-51CTO博客 一文搞懂 ansible 变量配置 - biglittleant - 博客园 Ansible 面向企业大规模使用探究 – IBM Developer 可能是最强网工ansible入门及深入教程之 ansible杂谈 - 知乎 Ansible最佳实践 | Yiran's Blog ansible/python_3_support.rst at stable-2.6 · ansible/ansible Interpreter Discovery — Ansible Documentation Wrong python2 interpreter instead of python3 · Issue #69494 · ansible/ansible 一些小团队的自动化运维实践经验 | 程序猿DD How to Manage Multistage Environments with Ansible | DigitalOcean 基于Ansible自研的可视化和并行自动化运维引擎 - 知乎 Ansible 实现原理（源码分析） – Tiantian Gao ( gtt116 )","categories":[{"name":"专业","slug":"pro","permalink":"https://sean10.github.io/categories/pro/"}],"tags":[{"name":"ceph","slug":"ceph","permalink":"https://sean10.github.io/tags/ceph/"},{"name":"linux","slug":"linux","permalink":"https://sean10.github.io/tags/linux/"},{"name":"ansible","slug":"ansible","permalink":"https://sean10.github.io/tags/ansible/"}]},{"title":"vscode相关技巧","slug":"vscode相关技巧","date":"2021-01-31T08:32:59.000Z","updated":"2025-08-25T07:47:14.000Z","comments":true,"path":"2021/01/31/vscode相关技巧/","link":"","permalink":"https://sean10.github.io/2021/01/31/vscode%E7%9B%B8%E5%85%B3%E6%8A%80%E5%B7%A7/","excerpt":"","text":"支持 类似typora的所见即所得插件支持 即时渲染 有一些unote之类的web editor嵌入到vscode中打开, 这样的话也算是实现了一个所见即所得的编辑器, 不过不是基于Vscode的倒是了. 不过这种情况下有些vscode配置的快捷键应该还是可以用的. 目前基于markless自己维护了一个markless_sean10. 暂时用起来还是不错的. 同义词模糊搜索功能(fuzzy search) fzf fuzzy search 只能搜索文件名, 还是有点欠缺的 不知道这个模糊搜索能不能做到NLP的水平呢? 中文的似乎暂时没有, 别的都是直接基于fzf的 目录搜索窗口显示搜索结果的行号 已经支持了, search.showLineNumbers打开这个选项即可, 默认未开 是不是有什么功能能够搜索整个目录里所有的todo内容呢? todo 不支持根据tag或priority folding 根据Support folding things other than subtasks, like folding by tag · Issue #85 · fabiospampinato/vscode-todo-plus, 目前还是缺少API的. 搜索窗口 search tab , 在主窗口显示出搜出内容的上下文, 基本类似source insight和clion了 search editor: Default number of context lines 然后触发Open in Editor就可以了. (done20220601)目前vscode似乎还没有支持一个当前文件所有搜索项的列表显示的功能 以前是通过左侧的全局搜索, 定位到当前文件来进行搜索的. 现在通过下述方案即可 open new search editor to the side vim插件使用 vim覆盖了vscode的CMD和Ctrl的快捷键 可以通过 File -&gt; Preference -&gt; Settings中 vim.useCtrlKeys 选项设置为 false vim无法使用系统剪切板 打开设置中的vim的Use System Clipboard 窗口之间的焦点切换 ctrl + M 使用tab键切换焦点模式tab move foucs ctrl + ~ 聚焦到TERMINAL(展开/收起TERMINAL) ctrl + 聚焦到editor Ctrl + Shift + E 资源视图和编辑视图的焦点切换 Ctrl + Shift + V 预览Markdown文件【编译后】 Ctrl + K v 在边栏打开渲染后的视图【新建】 cmd+1 主窗口 cmd+2 terminal 搜索窗口切换到下一个匹配对象 F4 shift+F4 回到上一个 visual studio code - vscode key binding for \"goto next search result on the search results pane\"? - Stack Overflow ## vscode将cursor从左侧搜索窗口切换到主窗口的快捷键是啥? cmt+1 将cursor切换到terminal cmd+2 TODO:terminal 出现一次cmd+v重复粘贴 问题主要出现在source了一次init.sh, 怀疑是shell终端之类的重复问题上. vim neovim 据说最多人用的vim插件冲突太多, 但是neovim就会好转很多. 更换之后, 至少Ctrl+c是没有问题的, 在insert模式下 配置默认insertmode 12&quot; 添加vim开启默认insertautocmt WinEnter * startinsert Setting to open editors in insert mode by default · Issue #613 · asvetliakov/vscode-neovim vim插件快速打开关闭 1Command-&gt;toggleVim vscode 插件资源占用排查 打开Help-&gt;Process Explorer, 这里会显示出每个窗口的CPU和内存的占用. 中文输入markdown时, 需要2次backspace才能删除掉在输入法中的字符 编辑器不会跟随同步删除. 根据[^2]来看,似乎是electron和chromium的问题. 但是我用的1.51的vscode还是存在这样的问题呀?为什么关闭了呢? 似乎我升级了下搜狗输入法就好了, 至少5.9.0.11685目前没什么问题. 所见即所得插件(markless) 哇, 今天偶然看到的这个插件, 太厉害了, 完全兼容我其他的插件的快捷键, 不需要学习成本, 直接就能享受typora的效果. 开发修改 关闭回车会触发自动补全, 修改为tab. 避免无需补充时, 不得不补充问题 在Suggestions里的Accept Suggestion On Enter. 修改为Off即可 快捷键 快速切换tab, Option+Cmd+左右方向键 通过Cmd+1等切换主窗口cursor. 主要目的是全键盘控制 搜索之后, 如何在搜索结果中切换? cmd+shift+f 则可以通过F4和shift+F4切换结果 但是好像这个没有像vimimum那种先切换焦点, 等确认了再点击的效果. cmd+f 可以通过cmd+g控制 中文分词[^4] 因为最近写文字记录比较多, 有时候词写错了, 想快点删的时候只能一个个删, 不像因为单词可以直接删, 就忽然意识到. 现在分词做的这么好了, 理论上这种插件应该已经有了. 果然, 搜到了这个CJK Word Handler - Visual Studio Marketplace, 试了下, 还挺好用. markdown的Cmd+B覆盖了vscode的outline打开和关闭. 被markdown覆盖掉了怎么办? 我暂时选择删除markdown的这个快捷键 自动补全 TabNine AI自动补全 git gitlens remote develop remote ssh配置环境变量的时候 需要配置一下~/.profile, 因为~/.bashrc在非交互式窗口不会被初始化. Intelligence python 一开始用的pylance和jedi. 这次看pyx代码的时候这俩都不支持, 就换回了microsoft python. C/C++索引 vscode插件安装clangd centos8及以上服务器安装 clang-tools-extra, 其中包含了clangd这个程序 代码生成compile_commands.json, 用于查找代码文件对应的索引 1cmake -DCMAKE_EXPORT_COMPILE_COMMANDS=True .. 会生成compile_commands.json, 放到加载的根目录即可. vscode使用compile_commands.json - TruthHell - 博客园 ### 让vscode的clangd查找知道json文件位置, 当在build目录下生成的文件时, 可以通过--compile-commands-dir=/mnt/qemu/bin/debug/native指定让clangd搜索该目录下的compile_commands.json数据库文件 针对autoconf等GNU make套件 rizsotto/Bear: Bear is a tool that generates a compilation database for clang tooling. 通过这个工具可以转换出一部分. CentOS 7/8 可以用2.4.4版本的bear生成compile_commands.json 1234567891011Consolidate compiler generated dependencies of target ear[100%] Built target earInstall the project...-- Install configuration: &quot;Release&quot;-- Installing: /usr/local/share/doc/bear/COPYING-- Installing: /usr/local/share/doc/bear/README.md-- Installing: /usr/local/share/doc/bear/ChangeLog.md-- Installing: /usr/local/lib64/bear/libear.so-- Installing: /usr/local/bin/bear-- Installing: /usr/local/share/man/man1/bear.1-- Installing: /usr/share/bash-completion/completions/bear C/C++ 手动 在settings.json中增加下述 1234567&quot;files.exclude&quot;: &#123; &quot;**/.xxxx&quot;: true&#125;,&quot;search.exclude&quot;: &#123; &quot;**/.xxxx&quot;: true &#125;, 而不用在c_cpp_properties.json中增加任何处理. 但是最好创建个这个文件, 好像就能够索引了. clangd - Visual Studio Marketplace 安装clangd就能够支持call Hierarchy了. 放弃cpptools就行. 不过似乎需要时linux. No matching member function for call to 'then' Candidate template ignored: substitution failure 不知道为啥, 其他几个目录的代码这里都不报这个错的. TODO:cpu/内存限制 MaskRay/ccls: C/C++/ObjC language server supporting cross references, hierarchies, completion and semantic highlighting ccls 和 vscode 一种在vscode以外的c++方案 - 知乎 &gt; ccls的优势一方面是跳转到定义和代码重命名，这个可以完全放心的交给ccls，clangd经常就无法跨编译单元做这些事情，尤其是在使用clang-tidy修复名字的时候，我曾经失手修改了一个工程根命名空间的名字，体验了ccls的绝对强大（笑;另一方面是基于语义的高亮，高亮种类齐全，基本上有高亮就不需要额外的精力判断词义了，clangd这方面的功能不知道是不是我的问题，始终没有什么作用。 &gt; &gt; ccls的劣势主要在补全速度上，这方面比起clangd差了至少一个数量级，工程越大越明显（clangd的自动头文件补全真的牛逼）另一方面加载cache文件，clangd也要快很多，clangd在分析编译的时候似乎会智能判断当前状况。不过ccls可以纠正.和-&gt;误用的情况，这里是比clangd强的。clangd集成clang-tidy以及提供代码fix也是ccls没有的功能，不过我认为跳转定义和改名是更加重要的功能 &gt; &gt; 总之clangd性能好，ccls功能强。 &gt; &gt; 另外，ccls可以指定编译额外的编译参数，这个在mac下非常好用，你可以开启额外的编译检查，或者修复头文件的缺失，clangd就需要手动了，尤其是使用compile_commands.json的时候，ccls可以不管里面的小问题，自己加两个参数，clangd就傻眼了，必须额外指定一次cmake生成compile database ccls 和 vscode 一种在vscode以外的c++方案 - 知乎 highlight shift+f8高亮, 应该类似SourceInsight的效果. 喜欢过的主题 Dracula 深色系 solarized light 黄色系, 感觉一直用黑色, 有点色散的感觉, 切换成浅色就舒服不少. Eva 找代码高亮主题的时候发现这个还不错. VS Code Themes fense code blocks in markdown highlight 支持 这块需要看下markdown渲染时, 到底是插件还是Vscode自身做的highlight, 可以找下, 换个. 试验了下, 切换不同Color Theme就可以切换出不同的渲染效果, 所以应该是在各自的color theme里控制的? 结论: 最后找了个Eva Theme装了下, 高亮的contrast还挺足. 分析方式 通过执行Ctrl+Shift+P -&gt; Developer: Inspect Editor Tokens and Scopes 可以看到下图 Markdown code block highlight consistency - what is \"s\" alias - Stack Overflow 代码应该是这块指定的 vscode/markdown.tmLanguage.json at 1a9016d0a4aa0eb98fd6dce3baf1678a3ccc35b9 · microsoft/vscode container使用 Developing inside a Container using Visual Studio Code Remote Development Get started with development Containers in Visual Studio Code container版本就是在满足的linux开发容器里再装一个vscode-server remote版本, 就是单纯的自己选一个编译环境, 然后装好vscode-server的服务器上连接上. 插件安装失败, 指定代理地址. visual studio code - VSCode Remote Container - extensions not installing on dev container using docker-compose - Stack Overflow mac上的Docker是跑在虚拟机里的, 所以即便设置--net=host, 实际上还是和宿主机差一级, 所以这里指定宿主机的内网ip的话, 其实是可以通讯了的. 在devcontainer.json里增加下述代理, 让容器里要下的插件可以通过代理下载. 1234&quot;containerEnv&quot;: &#123; &quot;http_proxy&quot;: &quot;http://192.168.31.36:7890&quot;, &quot;https_proxy&quot;: &quot;http://192.168.31.36:7890&quot; &#125;, vscode 卡顿, process Explorer中显示extension Host cpu 100%+ . performance调试 根据这个Performance Issues · microsoft/vscode Wiki定位方式, 打开Developer: Show Running Extensions, 查到profiling time中todo tree插件占用了4s多, 可能是因为这个文件中内容太多, 导致慢了. 把这个插件禁用, 就不卡顿了. 捕捉cpu profile后, 去掉.txt后缀然后用vscode打开即可看到下图 目前单从这张图看不出啥... code --status排查 打包 vscode的插件应该可以直接打包, How do I back up my VS Code settings and list of installed extensions? - Super User 即便直接打包这个~/.vscode/extensions目录不行, 直接根据列表下载vsix应该也可以 Extension Packs 能力 根据这里How to build and publish a vscode extension pack - DEV Community这篇, 在package.json中添加publisher之后就可以vsce publish了. 不过这个单纯只是存了元数据...我还需要他能够离线化保存. 看起来这个不是extension pack官方预计提供的能力. 有没有办法recursively下载的方式呢? 1234567891011121314151617181920212223242526272829303132333435363738394041code --list-extensions https://marketplace.visualstudio.com/_apis/public/gallery/publishers/sean10/vsextensions/sean10-extension-pack/0.0.1/vspackagecode --list-extensions | awk -F. &#x27;&#123;url=&quot;https://marketplace.visualstudio.com/_apis/public/gallery/publishers/&quot;$1&quot;/vsextensions/&quot;$2&quot;/latest/vspackage&quot;; print url&#125;&#x27;code --list-extensions --show-versions | awk -F &#x27;[.@]&#x27; &#x27;&#123;url=&quot;https://marketplace.visualstudio.com/_apis/public/gallery/publishers/&quot;$1&quot;/vsextensions/&quot;$2&quot;/&quot;$3&quot;.&quot;$4&quot;.&quot;$5&quot;/vspackage&quot;; print $2&quot;@&quot;$1&quot;.vsix&quot; &quot; &quot;url&#125;&#x27;再拼接一下改下名字就能下载了.由于这个url里没有提供名字, 可能浏览器端是基于其他信息重命名的, 姑且先手动拼接了.wget -O a https://marketplace.visualstudio.com/_apis/public/gallery/publishers/wayou/vsextensions/vscode-todo-highlight/1.0.5/vspackage code --list-extensions --show-versions | awk -F &#x27;[.@]&#x27; &#x27;&#123;url=&quot;https://marketplace.visualstudio.com/_apis/public/gallery/publishers/&quot;$1&quot;/vsextensions/&quot;$2&quot;/&quot;$3&quot;.&quot;$4&quot;.&quot;$5&quot;/vspackage&quot;; print $2&quot;@&quot;$1&quot;.vsix&quot; &quot; &quot;url&#125;&#x27; &gt; package.listcat package.list | while read line ; do name=$(echo $line | awk &#x27;&#123;print $1&#125;&#x27;); url=$(echo $line | awk &#x27;&#123;print $2&#125;&#x27;);echo $&#123;name&#125;&quot;, url:&quot;$url ; wget -O $name $url; sleep 1; done根据这个[Resource limits &amp; constraints \\- Azure DevOps \\| Microsoft Docs](https://docs.microsoft.com/en-us/azure/devops/integrate/concepts/rate-limits?view=azure-devops), 所以才下载不下来, 得登录下载了下面这个登录下载即可.cat package.list | while read line ; do name=$(echo $line | awk &#x27;&#123;print $1&#125;&#x27;); url=$(echo $line | awk &#x27;&#123;print $2&#125;&#x27;);echo $&#123;name&#125;&quot;, url:&quot;$url ; curl $url \\ -H &#x27;authority: marketplace.visualstudio.com&#x27; \\ -H &#x27;sec-ch-ua: &quot;Google Chrome&quot;;v=&quot;95&quot;, &quot;Chromium&quot;;v=&quot;95&quot;, &quot;;Not A Brand&quot;;v=&quot;99&quot;&#x27; \\ -H &#x27;sec-ch-ua-mobile: ?0&#x27; \\ -H &#x27;sec-ch-ua-platform: &quot;macOS&quot;&#x27; \\ -H &#x27;upgrade-insecure-requests: 1&#x27; \\ -H &#x27;dnt: 1&#x27; \\ -H &#x27;user-agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/95.0.4638.69 Safari/537.36&#x27; \\ -H &#x27;accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.9&#x27; \\ -H &#x27;sec-fetch-site: same-origin&#x27; \\ -H &#x27;sec-fetch-mode: navigate&#x27; \\ -H &#x27;sec-fetch-user: ?1&#x27; \\ -H &#x27;sec-fetch-dest: document&#x27; \\ -H &#x27;referer: https://marketplace.visualstudio.com/items?itemName=esbenp.prettier-vscode&#x27; \\ -H &#x27;accept-language: en-US,en;q=0.9&#x27; \\ -H &#x27;cookie: &#123;from chrome copy as curl&#125;&#x27; --compressed -o $name ; sleep 1; done gitlens 如果开启git codelens, 会出现...一会显示, 一会不显示, 导致我当前行所在的焦点位置一会在屏幕中间, 一会跳到别的位置的情况. API DecorationRenderOptions https://d.shikey.com/jike/已完结的课程/34 玩转VS Code/35讲插件开发（四）：Decorations装饰器.html # layout 好像1.64 支持了右侧, 可以拖拽窗口显示在那里的能力? tab显示indent 需要\"editor.detectIndentation\": false设置了这个之后, Tab-Size这个设置才能生效. vim的 tab代表8个空格, 默认缩进2个空格可以这么配置 123&quot;editor.detectIndentation&quot;: false,&quot;editor.indentSize&quot;: 2,&quot;editor.tabSize&quot;: 8 remote-develop 远端数据同步 1234rsync -rlptzv --progress --delete --exclude=.git &quot;user@hostname:/remote/source/code/path&quot; .rsync -rlptzv --progress --delete --exclude=.git . &quot;user@hostname:/remote/source/code/path&quot; Visual Studio Code Remote Development Troubleshooting Tips and Tricks 合盖休眠恢复后, 自动reload Automatically reload window after SSH disconnection · Issue #5875 · microsoft/vscode-remote-release 根据这条来看官方没有实现, 但是有人实现了这个插件Remreload - Visual Studio Marketplace 插件开发 如何开发时拉出一个未安装插件的vscode, 避免其他插件的干扰? 通过使用insider版本, 这样一个环境里同时有一个未装外部插件的开发调试用, 一个日常用. 好像说可以通过容器装vscode? 如何可以跑起vscode的demo. F5启动插件时 报 property engines is mandatory and must be of type string with non-empty value 需要package.json是在这次打开的根目录里, 即可. outline 大纲 Gerrnperl/outline-map: A visual, interactive outline map that combines the clarity of the outline with the intuitive overview of the minimap. Alternative Minimap. outline 滚动, 自动展开 outline-map.follow设置为viewport 代理及网络 http.proxy http.proxy strict ssl 可以考虑关闭 todo 存在一个问题, 不知道为什么有时候cmd+c和cmd+v在比如find或者ctrl+p的窗口无法粘贴. 不知道为什么, mac切换window的时候, 有个vscode remote develop老是自己弹到最上面. 有时候, comments(markless用来preview图片的模块)会自动弹出来. 就仿佛触发了一次toggle maximum TODO:vscode的输入窗口里, 按shift切换输入法的时候, 输入的内容会不见, 不像浏览器里会自动输入上. Reference (2) vscode控制字符引起的问题以及解决思路_洞香春 - SegmentFault 思否 Backspace can not erase the last one character during Chinese/Japanese IME conversion (macOS) · Issue #24981 · microsoft/vscode Backspace can not erase the last one character during Japanese IME conversion (macOS) · Issue #9173 · electron/electron VSCode 中文分词插件：CJK Word Handler - 知乎","categories":[{"name":"专业","slug":"pro","permalink":"https://sean10.github.io/categories/pro/"}],"tags":[{"name":"vscode","slug":"vscode","permalink":"https://sean10.github.io/tags/vscode/"}]},{"title":"openAPI初探","slug":"openAPI初探","date":"2021-01-31T07:29:57.000Z","updated":"2023-03-18T15:11:14.884Z","comments":true,"path":"2021/01/31/openAPI初探/","link":"","permalink":"https://sean10.github.io/2021/01/31/openAPI%E5%88%9D%E6%8E%A2/","excerpt":"","text":"todo(未理解的问题) 既然作为一个规范文档, 那么引导的example肯定得提供吧? 提供了之后, 那为什么不能多几个example? 直接做成支持测试框架的呢? 虽然现在测试框架的确支持导入openAPI的文档, 但是这些测试框架中需要用的参数数据是另外填写的, 为什么openAPI不集成在里面呢? 一个初步的结论: OpenAPI只做规范特定领域的事情, 单元测试及更进一步的测试领域的功能, 应该由测试方面的工具来进行扩展,而不是一揽子全包含了. 也算是一个合理的解答了. 概念 OpenAPI是一种机器可读的接口文件的规范. 基于这个规范的文档可以提供的信息, 将原本需要开源人员处理的工作转移到工具上. 主要功能 基于规范 生成服务端Stub和客户端代码 构建自动Mock 生成可供开发人员你是用的API文档等 开发人员可以花更少的时间去了解API的底层细节, 只关心API的上层重点即可. 基于代码 对于已经有API实现的情况, 可以使用工具从代码中导出OpenAPI规范. 从而生成文档. 当代码版本较多等场景时, 能从对应的代码导出对应的API文档 让代码与文档产生联动关系. api文档是本身就要的, openAPI完成的只是直接基于这个工具设计, 测试接口和文档都可以基于这个工具产生了, 写完代码直接就用工具验证, 在调试接口的时候, 测试的文件也跟着变了. 这样文档跟代码具有一致性, 且不需要单独分离写. openAPI流程上做到了将文档与代码绑定的效果, 只是代码优先还是设计优先就可以侧重各研发者自身了 扩展性 完全可以基于这套规范根据自己公司的需求进行扩展开发, 开发出对应的DSL.[^9] 配合postman, 自动化测试 参照下面这篇文章, 其实就可以做到我们想要的效果. 使用 Postman 测试你的 API_json 使用Jmeter和Jenkins自动化测试OpenAPI – 小工蚁 ET应该可以做到API 自动化测试：零代码自动化、数据驱动测试、自动生成报告 - Eolinker API 全生命周期管理这个的程度才对. CI 非常适合应用单元测试、应用代码覆盖以及做到daily build/tes Reference Open API测试畅想 - 阿里巴巴一个测试架构师 - 51Testing软件测试网 51Testing软件测试网-软件测试人的精神家园 使用 Postman 测试你的 API_json 使用Jmeter和Jenkins自动化测试OpenAPI – 小工蚁 OpenAPI Map OpenAPI：为传统机器构建智能API-InfoQ 使用OpenAPI构建更智能的API - EOLINEKR BLOG API 自动化测试 - 自动化测试 文档驱动开发模式在 AIMS 中的应用与实践 - InfoQ 写作平台 听说，阿里云给它的 OpenAPI 开发了一套编程语言 - InfoQ 写作平台 聊聊OpenAPI Specification（OAS） - InfoQ 写作平台","categories":[{"name":"专业","slug":"pro","permalink":"https://sean10.github.io/categories/pro/"}],"tags":[{"name":"OpenAPI","slug":"OpenAPI","permalink":"https://sean10.github.io/tags/OpenAPI/"},{"name":"API","slug":"API","permalink":"https://sean10.github.io/tags/API/"},{"name":"SDK","slug":"SDK","permalink":"https://sean10.github.io/tags/SDK/"}]},{"title":"卡牌游戏之再玩ygocore.md","slug":"卡牌游戏之再玩ygocore-md","date":"2021-01-17T10:59:45.000Z","updated":"2023-03-18T15:11:14.901Z","comments":true,"path":"2021/01/17/卡牌游戏之再玩ygocore-md/","link":"","permalink":"https://sean10.github.io/2021/01/17/%E5%8D%A1%E7%89%8C%E6%B8%B8%E6%88%8F%E4%B9%8B%E5%86%8D%E7%8E%A9ygocore-md/","excerpt":"","text":"背景 万智牌看着是不是跟D&amp;D有点关系?, 旅法师之类的. 看起来是集卡式游戏的始祖级别? 看大家的评论中, 这个的设计师考虑的比较好, 平衡性等都考虑的不错. 游戏王嘛, 动画, 漫画, 实体卡的宣传都非常广, 只不过实体卡等那部分不是官方, 而是盗版, 在国内的市场里占了很大一部分, 相当部分的人的童年基本上都看过游戏王, 至少我是这样的. 而万智牌我就到了大学才看到同学在玩, 才知道这个名词. 游戏王虽然宣传范畴上知道的人很多, 不过最大的诟病就是娱乐性较强, 平衡性较差吧, 新卡基本都非常强, 似乎是说每个时代的上位卡组基本都是一致的, 主流用户都玩同一套卡组, 只有玩娱乐场的时候大家能发散一点? 不过上面这都是大佬们为了整个游戏氛围的玩耍而考虑的. 对于我这种菜鸟来说, 光是很容易进行线上入门的ygo的整个社区就已经很好了. 暂时先从主流卡组入手之类的. 记得大学的时候搜到过, 当时好像应该移动端还没怎么有,当时至少还是ygopro一代的时代. 当时玩了两把, 连机器人都打不过(虽然现在也是). 在现在偏官方的网易的已经发布的现在, 至少我的个人感受是依旧是玩的远比那种闯关式要舒服的多的. 游戏 万智牌 emm. 似乎也没有线上服务, 也是需要收集实体卡的, 这样的话对于我这种就不太友好了. 暂时先不入门了. 游戏王 有ygocore等的在线任选卡的游戏, 相比其他的要好多的了. 基本上全平台都有ygopro2的游戏了, 安卓用ygomobile即可. 名词解释 禁卡 不允许使用的 限卡 有卡组内数量限制的 TCG 欧美发行正版卡 OCG 亚洲发行正版卡 OTK one turn kill 炉石 需要肝才能收集到想用的卡, 这样还是比较耗时间的. 游戏王规则[^3][^4][^5] 游戏王卡组[^2] 大佬推荐B站视频 和 闪刀姬Sky Striker 雷龙THUNDER DRAGON 自奏圣乐Orcust 英雄(幻影英雄) 电子龙 超魔导龙骑士真红眼龙骑士(单卡超模) 属性实在是太强了 新人随意搭配禁卡, 探索一下兴趣, 在卡牌编辑里搜了几个禁卡/限卡来用用. 发现在人机卡组里的这个龙骑士卡组默认版本稍微有一个问题 解决不了像是那个青蛙卡组, 他的特召之后效果能把免疫破坏效果的龙骑士给返回额外卡组. 我就暂时放弃随机抽卡, 找了个禁卡, 在我第一步就是用真红眼融合把龙骑士招出来之后, 发动, 把特召给禁了. 不过又出现一个时械神, 既不让破坏, 又不受伤害, 就跟我的在那边进入死循环了. 找了个手牌除外的卡, 趁他回到手牌的时候, 给清掉. 不过这个也太艰难了, 毕竟我都已经不洗牌了才能做到. 要是真启动. 不知道使用什么卡才能够解决掉他. Reference (4 条消息) 如何评价炉石、游戏王和万智牌这三款集换式卡牌游戏？ - 知乎 【图片】萌新的游戏王新手入门（缓更）【游戏王ygocore吧】_百度贴吧 Welcome to ocg-rule’s documentation! — ocg-rule 文档 2020年游戏王《完全规则书》更新规则 - 哔哩哔哩 游戏王集换纸牌游戏 | 遊戲王 Wiki | Fandom","categories":[{"name":"随想","slug":"thinking","permalink":"https://sean10.github.io/categories/thinking/"}],"tags":[{"name":"游戏王","slug":"游戏王","permalink":"https://sean10.github.io/tags/%E6%B8%B8%E6%88%8F%E7%8E%8B/"},{"name":"ygo","slug":"ygo","permalink":"https://sean10.github.io/tags/ygo/"}]},{"title":"vscode之markdown引用zotero参考文献","slug":"vscode之markdown引用zotero参考文献","date":"2021-01-17T08:40:53.000Z","updated":"2023-03-18T15:11:14.892Z","comments":true,"path":"2021/01/17/vscode之markdown引用zotero参考文献/","link":"","permalink":"https://sean10.github.io/2021/01/17/vscode%E4%B9%8Bmarkdown%E5%BC%95%E7%94%A8zotero%E5%8F%82%E8%80%83%E6%96%87%E7%8C%AE/","excerpt":"","text":"需求 我的主要需求, 只是当我需要写引用时, 排序能够自动调整,而不是我手动去填写数字. 如果能够让最后的参考文献也能够像用Latex时一样自动生成就更好不过了. 初步的一个思路是, 因为我主要需要的是纯文本, 然后在使用hexo-render-pandoc生成为网页时, 能够把索引给使用上. 预计是在使用pandoc的生成过程中, 将markdown文件中的引用的key给转换成对应的索引. 目前根据Sci.Fun | 如何使用markdown撰写论文？ - 知乎这些来看, 跟使用pandoc时导入bib的library基本一致. 搜集一下有没有现成的. 暂时好像是没找到这个结论. 一个简易方案12 在引用中使用3, 在参考文献位置则是即可完成链接的功能. 1[^1]:xxx 更进阶的方案应该需要看使用的render, 比如我的是pandoc,就看pandoc的引用相关的文档即可. Pandoc - Pandoc User’s Guide Citation rendering 问题 前面的引用的后面的链接的脚注编号变成从1开始 所以脚注内的内容, 最好不用编号, 而是实际的指代. 且将参考文献直接放在该段后. 通过渲染自动挪到文章/页最后. 5.4 如何用 Markdown 写论文？ - 少数派↩︎ Pandoc - Pandoc User’s Guide↩︎ mblode/vscode-zotero: Zotero Better Bibtex citations for VS Code↩︎","categories":[{"name":"专业","slug":"pro","permalink":"https://sean10.github.io/categories/pro/"}],"tags":[{"name":"zotero","slug":"zotero","permalink":"https://sean10.github.io/tags/zotero/"},{"name":"vscode","slug":"vscode","permalink":"https://sean10.github.io/tags/vscode/"}]},{"title":"mac系统使用小记.md","slug":"mac系统使用小记-md","date":"2021-01-16T11:36:07.000Z","updated":"2025-09-10T12:58:57.000Z","comments":true,"path":"2021/01/16/mac系统使用小记-md/","link":"","permalink":"https://sean10.github.io/2021/01/16/mac%E7%B3%BB%E7%BB%9F%E4%BD%BF%E7%94%A8%E5%B0%8F%E8%AE%B0-md/","excerpt":"","text":"Time Machine mac time machine限速 苹果官方直接就有给出解决方案，关闭限速即可 1sudo sysctl debug.lowpri_throttle_enabled=0 如果想要再开启，输入以下命令即可 1sudo sysctl debug.lowpri_throttle_enabled=1 清理 不能直接删除那个硬盘里的目录, 必须得tmutils来清理, 预计可能是增量备份. 我当时删的时候没意识到这点, 当时手动删的几个目录完全没被识别出已经被释放, 从而腾出空间. 查看time machine日志 12345678910111213141516171819202122232425262728293031323334353637383940414243444546sudo less +F &quot;/Volumes/MacBackup/Backups.backupdb/MacBook Pro/2020-08-05-163227.inProgress/.Backup.618330747.626060.log&quot;``` bash[macbook pro \\- Time Machine in the &quot;Cleaning Up\\.\\.\\.&quot; state forever \\- Ask Different](https://apple.stackexchange.com/questions/382772/time-machine-in-the-cleaning-up-state-forever)## time machine目录terminal无权限在Security * Privacy的Privacy中放开对Full Disk Access的Terminal权限.# 文件系统## APFS&gt; 稀疏文件、改进的 TRIM 操作，内建对扩展属性的支持&gt; 空间共享&gt; 数据加密&gt; 大小写敏感### Volume跟`lvm`那些的逻辑卷是不是差不多呢. 其中最大的亮点功能因为是不同卷组之间共享总体空间的功能了, 看上去应该是依托`COW`实现的. 但是具体机制不知道有没有哪篇文章提到.不知道`Container`和`Volume`两层分别是起什么样的作用呢?### firmlink跟``` bash ✗ cat /usr/share/firmlinks /AppleInternal AppleInternal/Applications Applications/Library Library/System/Library/Caches System/Library/Caches/System/Library/Assets System/Library/Assets/System/Library/PreinstalledAssets System/Library/PreinstalledAssets/System/Library/AssetsV2 System/Library/AssetsV2/System/Library/PreinstalledAssetsV2 System/Library/PreinstalledAssetsV2/System/Library/CoreServices/CoreTypes.bundle/Contents/Library System/Library/CoreServices/CoreTypes.bundle/Contents/Library/System/Library/Speech System/Library/Speech/Users Users/Volumes Volumes/cores cores/opt opt/private private/usr/local usr/local/usr/libexec/cups usr/libexec/cups/usr/share/snmp usr/share/snmp Mac journal extended 目录结构[^4] Mac 根目录下有以下几个文件夹： /System 文件夹，系统文件夹。与Windows 之中的 C: 等文件夹类似。 Library 系统资料库，其中的 Caches 可以删除。 iOSSupport 提供了系统的 iOS 支持。 /Applications GUI软件文件夹，共享的所有软件包都存放在此。 /Library 应用资料库，包括了大部分非核心的系统组件。Caches 可删除。 /Users 文件夹，与 Linux 之中的 /home 文件夹功能类似。而mac 之中的 /home 只是为了与 Linux 兼容，一般不放任何东西。 /Network 和 /net 网络相关，空的。 /Volumes 与 /mnt 类似，其中挂载了全部硬盘、网络硬盘等。 /sbin，/bin，/usr /dev文件夹，与 Linux 基本一致。与 Linux 兼容。 /etc, /var /tmp 文件夹，是位于 /private 之中对应文件夹的软连接。存放系统配置、数据库、缓存等。用于与 Linux 文件结构兼容。 注意，/root, /procfs, /boot, /sysfs 等非必须文件夹均不存在。 遵照freeBSD的/bin,/etc,/lib目录都是不建议修改的, 所以所有程序都是装到/usr/local目录下 开发调试 clang相关 lldb lldb -c /cores/core.99415 这样就可以调试了,不需要指定可执行文件看起来 brew 包管理 brew使用 1234567891011#更新brew到最新版本brew update-reset# 显示这个包内安装的文件的路径。brew list redisbrew cleanup# 查包的依赖包brew deps --installed --tree# 卸载包及其依赖brew rmtree graphviz brew 运行详情 Unsupported special dependency :maximum_macos · Issue #38604 · Homebrew/homebrew-core macOS 使用 Homebrew 的经验分享 | HelloDog 没在文档里找到如何下显示brew update的进度，不然老是以为阻塞了，还好我想起来一般开源软件都用verbose，就试了一下，看了brew的写法也是相当不错的。 不过就是也只能显示到fetching的进度了，fetching快不快应该只能靠监控流量了。 字体[^5] fair code brew tap homebrew/cask-fonts brew cask install font-fira-code brew源配置 mkdir -p $(brew --repo homebrew/core) git -C \"\\((brew --repo)&quot; remote set-url origin https://mirrors.tuna.tsinghua.edu.cn/git/homebrew/brew.git git -C &quot;\\)(brew --repo homebrew/core)\" remote set-url origin https://mirrors.tuna.tsinghua.edu.cn/git/homebrew/homebrew-core.git git -C \"\\((brew --repo homebrew/cask)&quot; remote set-url origin https://mirrors.tuna.tsinghua.edu.cn/git/homebrew/homebrew-cask.git git -C &quot;\\)(brew --repo homebrew/cask-fonts)\" remote set-url origin https://mirrors.tuna.tsinghua.edu.cn/git/homebrew/homebrew-cask-fonts.git git -C \"$(brew --repo homebrew/cask-drivers)\" remote set-url origin https://mirrors.tuna.tsinghua.edu.cn/git/homebrew/homebrew-cask-drivers.git brew底层用的还是Git,git现在通过改host还是不怎么能提速，虽然现在用不了proxychains4，但是似乎可以直接用git config --global http.https://github.com.proxy socks5://127.0.0.1:1086直接用代理，唉，早知道这个就没那么多事情了。 奇怪好像找到我的cask和homebrew不正常的原因了, 不知道为什么, 我执行上面的这堆命令的结果, git和目录的对应都是错的. cask的目录里的git却是什么Font的. /usr/local/Homebrew/Library/Taps/homebrew 奇怪, 怎么好像这个目录下属的子目录里, 还是在brew那个仓库里呢... 是因为装的太早, 不是通过tap安装的? 看起来的确是这个问题, 新装的这个version目录没问题 brew tap homebrew/core brew tap homebrew/cask brew tap homebrew/cask-fonts brew tap homebrew/cask-drivers brew tap homebrew/cask-versions 暂时不配置源了, 用代理下载也挺快. 安装HomeBrew 失败的解决方案(Error: Fetching /usr/local/Homebrew/Library/Taps/homebrew/homebrew-core failed!) - 子钦加油 - 博客园 老是报caskroom/homebrew-cask卡住 实际上不存在这个了, 已经改名成homebrew/homebrew-cask了. macos - Error: caskroom/cask was moved. Tap homebrew/cask-cask instead - Stack Overflow # 降频 机时以 sudo 运行 Turbo Boost Switcher，就不用来回输密码切换了。 如命令行输入：sudo /Applications/Turbo Boost Switcher.app/Contents/MacOS/Turbo Boost Switcher Turbo Boost Switcher 真香，试用了一天立刻买 Pro 了 - V2EX Spotlight 快捷键 Spotlight打开之后，输入单词，按command+b可以直接用浏览器搜索，用command+L可以直接跳到字典项进行查询。 购买+apple care+ 从官网买的时候, 听说官网不像渠道那边, 以开机联网开始激活, 而是以发货时间开始,如果发货到你收货就过了3天, 那就相当于你的保修期已经过了3天, 对于我想从淘宝加3天内的apple care+的需求来说, 这就导致我需要提前查询到序列号. 还好, 虽然大部分地方没提到,但是实际上只要进入发货阶段, 当你邮箱里收到发货信息之后, 序列号已经有了, 可以直接联系客服, 通过一些信息直接询问序列号. 根据客服当时说, 根据正常流程, 发票实际上会自动发出, 只是可能相比你直接去问要晚一点发送. 我问到序列号, 办完apple care+后的一天收到了发票. launchctl 如何通过launchctl控制进程呢?比如App 其实好像也只有pkill一条路. touchbar 一开始我以为必须按照他的提示来使用以前的那些功能按钮. 偶然按了fn的情况下去按touch bar上显示的f12, 发现也能成功调整音量. 所以如果知道原来这个按钮上对应的功能键, 其实还是可以用的. 关闭系统更新提示[^6] Paste this command in the Terminal window, then press Enter to execute it: sudo softwareupdate --ignore \"macOS Catalina\" Next, paste this in Terminal and press the Enter key to run the command: defaults delete com.apple.preferences.softwareupdate Lastly, execute the following command in Terminal: softwareupdate --list 或者设置更新通知时间为未来. 123defaults write com.apple.SoftwareUpdate MajorOSUserNotificationDate -date &quot;2030-02-07 23:22:47 +0000&quot;defaults write com.apple.SoftwareUpdate UserNotificationDate -date &quot;2030-02-07 23:22:47 +0000&quot; 休眠时, 你的前台程序会收到的信息 系统休眠过程中主要是IO超时中断,这部分做过滤处理就好了 CPU会被暂停, 所以可能一些程序如果没做IO超时处理,就会直接触发异常中断了. 的确很对, 像是一些视频网站打开后休眠再次打开, 缓存的连接都失效了, 一般需要刷新再操作了. 输入法(中英文混合输入) 我习惯用搜狗输入法了, 高级-&gt;动态组词, 勾选上之后, 单纯输英文时, 一般都不会显示出中文的候选词了, 直接空格就能够输入了. 在Ctrl + s弹出的save窗口里, shift切换中英文失效[^7] 据说是微信的客户端引起, 重启设备似乎就好了. 我的确打开过微信, 然后没重启过. 试试. 长句 搜狗/百度输入法 输入长句时 有上限 尝试用原生 已给搜狗和百度输入法提供了反馈, 留了邮箱, 不知道有没有反馈了. return可以在中文模式下 直接输入英文 Caps才是切换中英文按钮 类似下面这俩微软输入法的问题一样. 微软拼音长句输入字数限制问题 微软拼音长句输入字数限制问题 输入法 输入卡顿 BigSur 自带中文输入法卡顿 - V2EX 跟这个表现很像. 卡顿的时候window server占用也高. 当前是Monterey 12.6版本. 看到这个愈发感觉还是搞个纯linux笔记本省事... 其原因似乎是 Google Chrome 浏览器自带的一个更新组件 Keystone 触发了 macOS 内部的某种 bug。有很多其他用户也都发现了这两者间的关联。触发这个问题并不要求 Chrome 正在运行，部分用户仅仅是安装 Chrome 就可轻易重现。 降低 WindowServer 的 CPU 占用 - My Nook 确实, 关了chrome, 立马表现就正常了... 开了chrome之后又复现了... 1158402 - Chrome/Keystone causing abnormally high WindowServer CPU usage when not running? - chromium 问题单仍旧在这里. 临时先切换成Edge了. 虽然vscode有我那个markless问题引起的卡顿, 但是应该没延迟到那个程度. mac不自动连接热点 10.15版本, 我点开wifi管理, 发现居然直接就有一个Automatically join this network的选项,而我没有勾选这个. 之前我用10.12版本的时候, 我记得网络设置那里并没有这样这个选项, 导致每次都需要我手动点击. 现在居然完美解决了这个问题... vmware虚拟机不自动休眠[^8]未成功 目前遇到的主要问题是, 我开的linux虚拟机, 用来起Docker的虚拟机, 老是在我电脑合盖之后, 就自动休眠了. 找了下, 搜关键词stop vmware from hibernating linux搜到了. 在虚拟机的vmx文件中添加suspend.disabled = \"TRUE\" emm. 似乎无效. 合盖掉电问题, 基本一个晚上掉50% 123456789pmset -g log | grep Wake | less并没有看到有在睡觉期间被激活的日志...pmset -g custom主要设置了这个sudo pmset -b tcpkeepalive 0因为我试了下, 昨天关Wifi之后耗电就少了很多. 所以试试这个. 本身我合盖以后就对他的自动下载能力不抱期望. BT transmission的tracker添加 主要用的这个[GitHub \\- blind\\-oracle/transmission\\-trackers: Script to automatically add trackers from a list to all torrents in Transmission](https://github.com/blind-oracle/transmission-trackers) CPU/GPU windowsserver的CPU占用高 这个是mac的图形界面展示的进程, 因为是集成显卡, 所以集显能力不足的时候, cpu占用会偏高. 有人说是降低透明度就可以不卡顿, 不知道是否有效. 在System Preferences &gt; Keyboard中， 将Key Repeat跟Delay Until Repeat往左边设置： 有人说这样设计也能好转. 姑且看看吧.[^11] report_crash cpu占用高 关闭 12launchctl unload -w /System/Library/LaunchAgents/com.apple.ReportCrash.plistsudo launchctl unload -w /System/Library/LaunchDaemons/com.apple.ReportCrash.Root.plist 启动 123launchctl load -w /System/Library/LaunchAgents/com.apple.ReportCrash.plistsudo launchctl load -w /System/Library/LaunchDaemons/com.apple.ReportCrash.Root.plist 关闭 ReportCrash 进程防止CPU占用率过高 [OSX] [MacBook]_蜜汁小强的博客-CSDN博客 通过Turbo Boost Switcher暂时关闭睿频, 姑且在cpu满载100%的时候, 风扇不会那么容易转了 通过cpulimit对指定进程的cpu使用进行限制. opsengine/cpulimit: CPU usage limiter for Linux 有没有办法限制某个程序进程的 CPU 占用率呢？ - V2EX 123for i in `ps -ef | grep ceph-osd | grep -v grep | awk &#x27;&#123;print $2&#125;&#x27; `; do nohup cpulimit -l 500 -p $i &amp;&gt;/dev/null &amp; done for i in `ps -ef | grep ceph-osd | grep -v grep | awk &#x27;&#123;print $2&#125;&#x27; `; do kill -SIGCONT $i &amp; done \u0000 cpulimit works by continuously sending SIGSTOP and SIGCONT to the target process to limit it's cpu time. So the program in this case doesn't hang, it's doing it's job. 需要注意cpulimit进程退出时, 需要及时发送SIGCONT信号恢复 linux - cpulimit not working correctly - Stack Overflow 作废, cputhrottle的task_for_pid函数无法使用, appPolice无法显示出我想限制的指定进程 通过appPolice或者cputhrottle等限制指定进程的cpu cputhrottle好像不能用, 源码编译后, sudo运行还是报这个 1cputhrottle libc++abi.dylib: terminating with uncaught exception of type Process::ManipulatorException: Error on task_for_pid 简单看bash - Iterate over pgrep results - Stack Overflow 好像是API在高版本改了? 不能用这个了? app tamer for mac (cpu优化电池管理工具) 资源占用过高 ) automator finder增加右键按钮 参考在 Finder 的右键菜单中添加「Open in VSCode」 | 始终 在automator中可以增加比如open in vscode的能力~ android投屏 [(1 封私信 / 20 条消息) 如何将android手机屏幕投影至Mac？ - 知乎](https://www.zhihu.com/question/38722634 基于DLNA的Macast 装到mac上之后, 可以直接投屏到mac上 万物互联 KDE connect (mac+android) QtScrapy 即Scrapy的图形化版本 barry-ran/QtScrcpy: Android real-time display control software ### 步骤 12345678910无线连接步骤（保证手机和电脑在同一个局域网）：安卓手机端在开发者选项中打开usb调试通过usb连接安卓手机到电脑点击刷新设备，会看到有设备号更新出来点击获取设备IP点击启动adbd无线连接再次点击刷新设备，发现多出了一个IP地址开头的设备，选择这个设备启动服务备注：启动adbd以后不用再连着usb线了，以后连接断开都不再需要，除非安卓adbd停了需要重新启动 控制 MIUI注意除了USB调试还需要开启USB调试(安全设置) linux替代命令 ldd == otool -L 网络 针对不同wifi, 使用不同dns mac, 应该可以做到, 针对不同的wifi, 切换不同的dns服务器 Mac下面的根据场景切换网络配置 我们只需要在连接一个新网络时，添加一个位置描述，然后跟之前一样设置各连接参数，然后应用。 之后在场景发生变化后，如果想切换不同位置的网络配置时，在位置处选择你之前添加好的场景，然后应用就可以了 macOS 自定义场景以快速切换不同的网络连接参数_weixin_33755847的博客-CSDN博客 wifi profile switcher Mac OS 自动根据 WI-FI 名字改变网络位置 - Razeen`s Blog m1 的设备网络延时高, 带宽低 通过下述命令关闭AWDL, 延时显著恢复, 之前间歇百ms, 现在能稳定在3-10ms了 1sudo ifconfig awdl0 down 永久关闭 上面这个从原理上看着还行. macbook pro - 强制禁用 Ventura 或更高版本中的 AWDL - Ask Different --- macbook pro - Force disabling AWDL on Ventura or above - Ask Different jamestut/awdlkiller: Disables macOS AWDL the moment it starts! 下面这个有时候不好用 meterup/awdl_wifi_scripts: Scripts to disable awdl 123456789#!/bin/bashcurl -s https://raw.githubusercontent.com/meterup/awdl_wifi_scripts/main/disable_awdl.sh &gt; ~/disable_awdl.shsudo chmod u+x ~/disable_awdl.shcd /Library/LaunchDaemons/ &amp;&amp; sudo curl -sO https://raw.githubusercontent.com/meterup/awdl_wifi_scripts/main/com.meter.wifi.awdl.plistsudo sed -i -- &quot;s/YOUR_USERNAME/$&#123;USER&#125;/g&quot; /Library/LaunchDaemons/com.meter.wifi.awdl.plistsudo launchctl unload -w /Library/LaunchDaemons/com.meter.wifi.awdl.plist 2&gt; /dev/nullsudo launchctl load -w /Library/LaunchDaemons/com.meter.wifi.awdl.plist 解决由于 AWDL 导致 Mac 的断网问题 | 贾攀的流水账 系统插件功能实现 hammerspoon 参照hammerspoon扩展方式配置. 硬件相关 触控板或者键盘操作一下, 屏幕下半个屏幕闪烁, 外接屏幕也不停刷新. 疑似某个软件引起的? 但是在家里又没有这个问题. 会不会是chrome开几百个窗口, 某个窗口引起的? 重启设备后恢复, 看起来还是跟软件有关. 左上侧的type-c口充不了电了 代理 clash配置 配置proxy-groups设置url-test就自动选最快的了, 就不需要手动更改了. 不过注意需要把直接连接的这个代理从选择的这里去掉, 不然延时一般都是最低 12345678910proxy-groups: - name: 🔰国外流量 type: url-test url: &#x27;http://www.gstatic.com/generate_204&#x27; interval: 300 proxies: - &#x27;广东移动转台湾HiNet[M][倍率:1]&#x27; - &#x27;广东移动转新加坡Azure[倍率:0.9]&#x27; - &#x27;广东移动转日本NTT[倍率:0.8]&#x27; chrome代理问题 我看我的switchOmega已经停用很久了, 这次想考虑easyconnect和clash并存, 好像就要改浏览器的路由. 看到配置的地方了, 是在Wifi的高级选项里设置了的proxies, 这里增加了公司的url bypass之后能共存了. 录屏 终端录屏 asciinema 显示 分辨率 27寸 4K , 1920x1080感觉能显示的窗口太少 Mac 4K 显示器 如何设置缩放？ - V2EX 按option显示成2304x1296 感觉字大小刚好, 又能显示多个窗口了. 邮箱 qq邮箱 mail好像一改密码又登录不上了. mac mail邮箱登录密码必须手动生成授权码 手动输入 且 敲回车 不能复制粘贴, 也不能直接点击验证/ok (1 封私信 / 73 条消息) mac邮件添加邮箱无法验证，求大神帮助？ - 知乎 进程 sysmond: activity monitor的监控进程. GNU tools 1234567891011121314151617181920212223242526 brew install coreutils brew install findutils brew install gnu-sed brew install gnu-indent brew install gnu-tar brew install gnu-which brew install gnutls brew install grep brew install gzip brew install screen brew install watch brew install wdiff --with-gettext brew install wget brew install less brew install unzip export PATH=&quot;/usr/local/opt/coreutils/libexec/gnubin:$PATH&quot;export PATH=&quot;/usr/local/opt/gnu-sed/libexec/gnubin:$PATH&quot;export PATH=&quot;/usr/local/opt/binutils/bin:$PATH&quot;export PATH=&quot;/usr/local/opt/ed/libexec/gnubin:$PATH&quot;export PATH=&quot;/usr/local/opt/findutils/libexec/gnubin:$PATH&quot;export PATH=&quot;/usr/local/opt/gnu-indent/libexec/gnubin:$PATH&quot;export PATH=&quot;/usr/local/opt/gnu-tar/libexec/gnubin:$PATH&quot;export PATH=&quot;/usr/local/opt/gnu-which/libexec/gnubin:$PATH&quot;export PATH=&quot;/usr/local/opt/grep/libexec/gnubin:$PATH&quot; 鼠标 滚动加速度 导致 鼠标滚动会跳来跳去 12defaults write .GlobalPreferences com.apple.mouse.scaling 0 这条疑似有效? (1 封私信 / 80 条消息) mac os 苹果系统如何关闭鼠标滚轮加速？ - 知乎 parallel desktop 虚拟机内鼠标飘: 关闭对鼠标的游戏优化即可 任务栏 小图标过多 对于不需要的, 直接cmd+拖拽下来就能删除该图标 比如搜狗输入法的图标就被我删了. Bartender bar 根据下面大佬安利的, 采用bartender 类似windows的小图标隐藏的效果一样, 可以折叠掉小图标. 这里来看, 确实似乎不够人性化, 程序的应用菜单, 确实会占用不少屏幕, 这样任务栏对于需要大量插件的用户来说, 确实会产生冲突, 这种情况下应该提供一种折叠之类的方案来提供支持. macOS 顶上菜单栏空间不够，右侧小图标满了放不下了，一些图标直接显示不出来直接隐藏了，这种情况怎么解决呢？ - V2EX Mac 選單列空間不夠嗎？Bartender 讓你擁有第二選單，隱藏不需要的圖示 - Rockyhsu Command Line Tools python 1234567891011121314151617181920ll /usr/local/Cellar/python@3.* /usr/local/Cellar/python@3.10:total 0drwxr-xr-x 13 sean10 416 Oct 5 02:45 3.10.7/usr/local/Cellar/python@3.9:total 0drwxr-xr-x 13 sean10 416 Sep 18 2021 3.9.7➜ sean10.github.io git:(hexo) ✗ ll /usr/local/bin/python3*lrwxr-xr-x 1 sean10 40 Oct 5 02:44 /usr/local/bin/python3 -&gt; ../Cellar/python@3.10/3.10.7/bin/python3lrwxr-xr-x 1 sean10 47 Oct 5 02:44 /usr/local/bin/python3-config -&gt; ../Cellar/python@3.10/3.10.7/bin/python3-configlrwxr-xr-x 1 sean10 43 Oct 5 02:44 /usr/local/bin/python3.10 -&gt; ../Cellar/python@3.10/3.10.7/bin/python3.10lrwxr-xr-x 1 sean10 50 Oct 5 02:44 /usr/local/bin/python3.10-config -&gt; ../Cellar/python@3.10/3.10.7/bin/python3.10-configlrwxr-xr-x 1 sean10 40 Sep 18 2021 /usr/local/bin/python3.9 -&gt; ../Cellar/python@3.9/3.9.7/bin/python3.9lrwxr-xr-x 1 sean10 47 Sep 18 2021 /usr/local/bin/python3.9-config -&gt; ../Cellar/python@3.9/3.9.7/bin/python3.9-config 像这里看到的, 其实升级的时候, 旧版本也保留了. 但是发现/usr/bin/python3居然是个python3.8版本, 这里就需要确认下这个环境里之前是咋装进来的了. 12345678910111213141516171819202122➜ sean10.github.io git:(hexo) ✗ pip3 --version pip 20.2.3 from /Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.8/lib/python3.8/site-packages/pip (python 3.8)➜ sean10.github.io git:(hexo) ✗ ll /Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework total 0lrwxr-xr-x 1 root 24 Oct 5 02:40 Headers -&gt; Versions/Current/Headerslrwxr-xr-x 1 root 24 Oct 5 02:40 Python3 -&gt; Versions/Current/Python3lrwxr-xr-x 1 root 26 Oct 5 02:40 Resources -&gt; Versions/Current/Resourcesdrwxr-xr-x 5 root 160 Oct 5 02:42 Versions➜ sean10.github.io git:(hexo) ✗ ll /Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions total 0drwxr-xr-x 10 root 320 May 3 2020 3.7drwxr-xr-x 10 root 320 Apr 30 13:40 3.8lrwxr-xr-x 1 root 3 Oct 5 02:40 Current -&gt; 3.8➜ sean10.github.io git:(hexo) ✗ stat /usr/bin/python3 File: /usr/bin/python3 Size: 167120 Blocks: 24 IO Block: 4096 regular fileDevice: 1,9 Inode: 1152921500312781207 Links: 76Access: (0755/-rwxr-xr-x) Uid: ( 0/ root) Gid: ( 0/ wheel)Access: 2022-08-24 16:59:39.000000000 +0800Modify: 2022-08-24 16:59:39.000000000 +0800Change: 2022-08-24 16:59:39.000000000 +0800 Birth: 2022-08-24 16:59:39.000000000 +0800 根据这段判断, 比较像是CLT装进来的...但是时间戳和我今天装的好像对不上...怎么确认CLT不同版本里对应的python版本呢? From the Xcode 11 release notes... ”In future versions of macOS, scripting language runtimes won’t be available by default, and may require you to install an additional package. If your software depends on scripting languages, it’s recommended that you bundle the runtime within the app.” It might be available in the short term, but not the long term. 根据上面这句可以得知, CLT不再安装python3, 即可以通过brew或者pyenv管理了. 暂时先不管, 但是如果需要清理 /usr/bin/python3 /Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions JDK关闭默认编译 提供禁用“自动构建”的选项 · 问题 #406 · redhat-developer/vscode-java --- Provide an option to disable the 'auto build' · Issue #406 · redhat-developer/vscode-java 否则默认打开比如hadoop就默认开始编译了. OCR, 12版本支持了实况文本, 用mac原生软件预览图片时, 鼠标放过去就自动OCR了. 是否可以直接弹出预览的窗口, 而不要二次手动打开? 通过hammerspoon, 绑定一个快捷键, 截图后自动调用preview去打开预览的图片? 显示器 12.6 升级大概2周后, 外接显示器忽然没信号了. 睡眠后, 尝试激活, 发现无信号了. 解决方式: 拔掉显示器电源几十秒后, 恢复了. 已尝试 type-c转dp线, 插其他人mac和显示器上通过 mac接其他人的拓展坞, 走htmi通过 其他mac接这个type-c转dp和显示器你 ,依旧无信号. 怀疑点 这台电脑的type-c转dp协议出问题 显示器整体出问题 显示器的dp口出问题 下一步尝试type-c转hdmi线, 公司有个, 主要需要出去拿. m1(mac mini和macbook pro都有), 显示器在休眠激活后会黑屏 只有hkc显示器目前存在这个问题, lg没有. 比较怀疑是下面这个问题, 准备买个试试. 最后发现我的显示器是那种交流电, 内置适配器. 而不是外置的, 然后最后换了根type c-dp的线就没问题了. 那倒是不排除是线的问题了 但是这根type-c hdml线给到LG的显示器又没这个问题了. 而且HKC显示器即便是dp之后, 休眠后激活速度依旧没有LG的快. M2pro 外接优派 VX2478-4K-HD 之后，唤醒之后会黑屏 5 分钟之后才亮屏 - V2EX [解决方案] 优派 VX2478-4K-HD 显示器，电脑唤醒之后会黑屏 5-10 分钟之后才亮屏 - V2EX airpods 已修复 支持记忆非ios设备或者ios设备上上一次连接设备 AirPods Pro won't autoconnect to Anroid Phone : airpods AirPods Pro won't autoconnect to Anroid Phone : airpods 投屏 ios设备, 升级即可mirror android 设备 QtScrcpy即可 显示同步(没有难度, 随便点一键连接也可以) wifi连接的延时稍高一点, 还是usb连接比较稳定. 音频同步 点击安装sndcpy, 会报AudioOutput::\" \"/bin/bash: sndcpy.sh: No such file or directory\\n\" \"AudioOutput::\" \"/bin/bash: sndcpy.sh: No such file or directory\\n\" · Issue #643 · barry-ran/QtScrcpy 参考这个\"AudioOutput::\" \"/bin/bash: sndcpy.sh: No such file or directory\\n\" · Issue #643 · barry-ran/QtScrcpy, 接着usb线的情况下, cd /Applications/QtScrcpy.app/Contents/MacOS &amp;&amp; /bin/bash sndcpy.sh即可成功安装. 然后就点击开始音频即可. 电池 ![[Pasted image 20230218225149.png]] 根据这个来看, design好像是5000, 差的有点多. 电池 优化, 充电到80%就停 zackelia/bclm: macOS command-line utility to limit max battery charge dropbox 同步问题 自从升级了Dropbox到了CloudStorage之后, 目录迁移到/Users/sean10/Library/CloudStorage/Dropbox之后, 出现了老是在下载云端文件的情况. 我期望的使用方式是跟之前版本一样, 没有变化时就是操作本地文件, 比如我外部打开整个目录, 直接触发全目录搜索就可以了, 不需要做什么多余的事情. 但是目前的体验就是会出现一直在转圈, 等待从云端同步. 如果真的要做这种逻辑, 那这种在云端的盘还不如hdd呢... No longer have offline access automatically? - Page 5 - Dropbox Community 这里看到的讨论是都遇到了相同的问题. 正常来说右键到dropbox的realpath路径, 会出现设置可offline访问. Dropbox is not searchable in Mac OS Monterey 12.0.1 | The Dropbox Community 系统快速下载 12tail -f /var/log/install.log | grep .pkg 然后去app store触发OS的下载, 此时这里面的installAssistant.pkg就是系统的url 用axel等并发工具触发多线程下载即可. 速度可以跑满带宽了 用腾讯 lemon进行大空间扫描识别 logi option plus depots占用几个G 可以换mac mouse fix. 或者离线版本的logi option plus https://download01.logi.com/web/ftp/pub/techsupport/optionsplus/logioptionsplus_installer_offline.zip terminal粘贴两次 粘贴在 shell 提示符中重复 · Issue #11375 · ohmyzsh/ohmyzsh --- Paste is duplicated in the shell prompt · Issue #11375 · ohmyzsh/ohmyzsh 1~/.zshrc 取消注释后正常了DISABLE_MAGIC_FUNCTIONS=&quot;true&quot; cert证书 x509问题(curl不加载mac的keychain) 即便下载安装了公司的根证书, 但是curl仍旧报无法认证. 通过curl xxx -v看到的pem路径, 似乎并没有在我安装了根证书后发生更新. 那是否说明mac 下brew安装的curl, 使用的证书信任, 并没有遵循mac的keychain? 确实是上述推论, 根据如何让 curl 在 macOS 中访问 SSL 证书？- Unix &amp; Linux Stack Exchange --- How does curl access SSL certs in macOS? - Unix &amp; Linux Stack Exchange , brew install curl并替换一下mac默认加载的curl来源即可. claude code配置通知 1display notification &quot;任务已完成&quot; with title &quot;Claude Code&quot; 本身安装一个https://github.com/devizor/macOS-Notification-MCP, 是可以. 但是他内置用到osascript的权限, 默认高版本的mac 系统, 没有给他通知权限 需要启动 脚本编辑器, 然后复制上面的osascript, 然后运行一次. 他就会弹窗运行了. Reference 当 Mac 升级到 Catalina 时，苹果在硬盘里施了点魔法 - 少数派 闲聊ReFS与APFS - 知乎 Apple新发布的APFS文件系统对用户意味着什么-InfoQ Layton's Blog - 技术摘要| Mac OS 与 Linux 的目录结构比较 Programming Fonts - Test Drive Apple's has brought back the nagging — you can no longer ignore major macOS updates (24 条消息) Macbook中英切换键失效，怎么办？ - 知乎 Disabling the suspend feature for a virtual machine in VMware Fusion and VMware Workstation (2056501) macOS 电源管理修复 MacBook 休眠耗电大问题 - Marco Nie BT种子获取更多连接的方案（增加trackerslist） | Boris的备份库房 Mac系统WindowServer进程占用CPU资源问题 | Hanjie's Blog","categories":[{"name":"专业","slug":"pro","permalink":"https://sean10.github.io/categories/pro/"}],"tags":[{"name":"mac","slug":"mac","permalink":"https://sean10.github.io/tags/mac/"}]},{"title":"2020年终总结","slug":"2020年终总结","date":"2021-01-11T14:28:02.000Z","updated":"2023-03-18T15:11:14.864Z","comments":true,"path":"2021/01/11/2020年终总结/","link":"","permalink":"https://sean10.github.io/2021/01/11/2020%E5%B9%B4%E7%BB%88%E6%80%BB%E7%BB%93/","excerpt":"","text":"今年主要的感触在项目中, 基本上就是一些沟通与落地方面是否双向澄清,全环节负责的人是否都已经理解需求及实现了. 人月神话中的沟通的代价, 想来过程中的人员澄清应该占用了一部分. 即便简单的项目, 也存在SE, DE, 开发者三人的环节. 这种常见的一般都会一个会议, 或直接在工位旁边完成澄清的过程. 而对于今年主要遇到的跨大部门的大型项目, 一个OR基本上就存在了2倍的人员对接. 每个环境都可能是由对应的责任人进行对接, 3人时最多出现的排列组合, 6次也足够了. 而对于6人时, 一旦某个环节的澄清中出现某个细节点未澄清, 最坏的情况, 可能就会出现6!的多次沟通(当然, 大部分情况应该就花个几次.). 在项目之外, 技术方面. 在年初时, 主要针对全链路追踪做了调研和demo的实现. 这个全链路追踪的思想在社区里查看, 针对java的果然还是比较成熟, 翻了翻综合安防平台的报告, 实际上他们的微服务的业务方面的开发框架, 基本上是集成了这部分功能的. 而针对嵌入式相关的编译时语言, 如果原先不是基于某套开发框架开发的背景下, 比如我们的代码大部分都是直接调用的syscall,这种情况下, 我们如果想做无感知的埋点, 就只能利用gcc或者clang方面编译器提供的pre的hook函数的支持--finstrument-functions来设置每个函数执行前后的回调之类的. 不过这个的性能代价相对来说较大, 因为源码文件中所有的函数均会被埋点. 当每个埋点都存在一个rpc通信时, 代价较大. 后续接触到ceph时, 对于pool,crush,pg,rados迅速有了一定的了解. 在这个过程中, 发现ceph基本上是应用了主流大部分的分布式技术方案. 然后, 逐渐意识到, 在分布式领域, 其实针对不同场景下的方案取舍, 存在很多种代价的组合. 在这其中发现虽然是称为分布式, 但是在程度上其实还是有差异的. 就目前的理解来说, mon等元数据管理机制其实都只是单点提供服务, 更多的管理节点完成的只是高可用(避免脑裂等问题). 而mon直接仍然存在单点性能的上限问题, 当然这个性能在一定规模下是不会成为瓶颈的. 比如, 假如说当管理的osd节点数量爆炸的高时, mon节点的性能的确开始成为瓶颈时, 是否就可以开始应用传统的垂直分割技术, 类似数据库垂直分表一般, 将传统技术在分布式领域的某些场景下再次应用, 就又可以突破一点. 诸如此类等等, 像是使用crush算法, 实际上算法始终存在分布不均匀问题.各公司在进行自研时, 是采用元数据管理服务器来提供分布来提供容量和性能, 还是为了让元数据管理服务器不成为功能上的瓶颈, 将选择节点过程迁移到客户端来进行, 暂时通过其他手段来解决crush带来的不均匀问题. 看起来都是根据自身的考量来说. 目前就目前的crush算法的限制, 以及个人的实验结果来看, 企业级产品, 目前可能这个资源占用的代价更愿意放到元数据管理服务器, 因为这个资源消耗相比性能的代价来看, 代价不如价值大. 但是, 对于社区来说, 前沿有意思的技术更有意思, 就像最初的ceph论文, 差异点主打的就是分布式. 且指不定忽然就出现了算法突破(比如可以通过配置不同的算法达成不同的虚节点分布, 一定程度上能够保障均衡), ceph的劣势一下子就不再是短板, 基本就完全碾压了基于元数据管理服务架构下的组件. 回到目前源码的学习中, 一个比较入门的感触, 就是目前组内调试, 可能并没有充分利用起社区提供的工具?主要还是只是增加日志重新运行等方式, 像是比如flame火焰图等排查分析函数调用工具, 甚至其中之前做的全链路追踪, ceph中就有使用用户态链路追踪的工具lttng, 基于这个额外提供了zipkin的埋点对接. ceph采用的方法是目前zipkin社区主要做的, 针对静态编译式语言, 由开发者人工在需要封装的函数位置调用宏tracepoint, 通过编译时宏来进行控制是否启动埋点检测, 预计对于帮助理解代码, 会有比较好的效果.感觉这个是接下来有必要做的事情, 将这种快速学习代码逻辑的工具充分利用起来. 总的来说, 今年在技术上发现了不少新的思路, 可扩展学习的方向希望早日能够打通ceph的整条路径中各节点的竞争方案 希望2021年能将ceph的rbd及下层的IO流程中角色打通~能够逐渐对设计IO路径中某个角色有所思考, 能糅合出较佳的一个方案","categories":[{"name":"专业","slug":"pro","permalink":"https://sean10.github.io/categories/pro/"}],"tags":[{"name":"总结","slug":"总结","permalink":"https://sean10.github.io/tags/%E6%80%BB%E7%BB%93/"},{"name":"ceph","slug":"ceph","permalink":"https://sean10.github.io/tags/ceph/"}]},{"title":"日志分析ELK部署","slug":"日志分析ELK部署","date":"2021-01-10T19:03:17.000Z","updated":"2023-03-18T15:11:14.867Z","comments":true,"path":"2021/01/11/日志分析ELK部署/","link":"","permalink":"https://sean10.github.io/2021/01/11/%E6%97%A5%E5%BF%97%E5%88%86%E6%9E%90ELK%E9%83%A8%E7%BD%B2/","excerpt":"","text":"部署 12345docker pull sebp/elkdocker run -p 5601:5601 -p 9200:9200 -p 5044:5044 \\ -v /Users/sean10/Code/docker-volume/elk:/var/lib/elasticsearch \\ -v /Users/sean10/Code/Algorithm_code/elk/logstash.conf:/etc/logstash/conf.d/logstash.conf\\ --name elk sebp/elk Filebeat 日志数据采集器 与logstash直接配置本地文件的读取是否存在差别呢? 把elk-logstash的证书[^6], 和这个证书对应的域名加到hosts里解析, 成功导入了宿主机里的日志. 不过这种不修改filter的逻辑的日志, 只是把log的每行都记录成message了, 其实索引没利用起来的感觉. 123456789101112131415output: logstash: enabled: true hosts: - elk:5044 timeout: 15 ssl: certificate_authorities: - /etc/certs/logstash-beats.crtfilebeat: inputs: paths: - &quot;/var/log/ceph/*.log&quot; 1docker run --name filebeat --user=root -v /Users/sean10/Code/ceph/ceph-14.2.9/src/out:/var/log/ceph -v /Users/sean10/Code/Algorithm_code/elk/logstash-beats.crt:/etc/certs/logstash-beats.crt -v /Users/sean10/Code/Algorithm_code/elk/filebeat.yml:/usr/share/filebeat/filebeat.yml -v /Users/sean10/Code/Algorithm_code/elk/hosts:/etc/hosts elastic/filebeat:7.10.1 logstash 配置 12345678910111213141516171819202122232425input file &#123; path =&gt; [&quot;/var/log/*.log&quot;, &quot;/var/log/message&quot;] type =&gt; &quot;system&quot; start_position =&gt; &quot;beginning&quot; &#125;&#125;filter &#123;# if [type] == &quot;cephlog&quot; &#123; grok &#123; # https://github.com/ceph/ceph/blob/master/src/log/Entry.h match =&gt; &#123; &quot;message&quot; =&gt; &quot;%&#123;TIMESTAMP_ISO8601:stamp&#125;\\s%&#123;GREEDYDATA:msg&#125;&quot; &#125; match =&gt; &#123; &quot;message&quot; =&gt; &quot;(?m)%&#123;TIMESTAMP_ISO8601:stamp&#125;\\s%&#123;NOTSPACE:thread&#125;\\s*%&#123;INT:prio&#125;\\s(%&#123;WORD:subsys&#125;|):?\\s%&#123;GREEDYDATA:msg&#125;&quot; &#125; # https://github.com/ceph/ceph/blob/master/src/common/LogEntry.h match =&gt; &#123; &quot;message&quot; =&gt; &quot;%&#123;TIMESTAMP_ISO8601:stamp&#125;\\s%&#123;NOTSPACE:name&#125;\\s%&#123;NOTSPACE:who_type&#125;\\s%&#123;NOTSPACE:who_addr&#125;\\s%&#123;INT:seq&#125;\\s:\\s%&#123;PROG:channel&#125;\\s\\[%&#123;WORD:prio&#125;\\]\\s%&#123;GREEDYDATA:msg&#125;&quot; &#125; &#125; date &#123; match =&gt; [ &quot;stamp&quot;, &quot;yyyy-MM-dd HH:mm:ss.SSSSSS&quot;, &quot;ISO8601&quot; ] &#125;# &#125;&#125; 从ceph文档里找来的Filter, 不过好像匹配失败了, 可能跟版本有关系吧.版本太低? 用第一个,至少时间戳出来了. 实验 12/opt/logstash/bin/logstash --path.data /tmp/logstash/data \\ -e &#x27;input &#123; stdin &#123; &#125; &#125; output &#123; elasticsearch &#123; hosts =&gt; [&quot;localhost&quot;] &#125; &#125;&#x27; 导入log 似乎要导入log, 默认的elk的配置不行, 需要修改logstash的配置, 增加一些属性. 一般流程 在日志存储服务器上安装filebeat filebeat将log存储目录下的所有log全部读取，发送到kafka logstash从kafka上读取日志，格式化后发送到elasticsearch elasticsearch正确索引后，response给logstash logstash更新kafka的offset，读取新的记录 一直循环以上步骤，直到所有的log都被写入到elasticsearch当中 可能的问题 索引过多, 导致elasticsearch 429 正确的处理大量历史数据的导入 不过很诧异，我很难在网络上搜到有人提过429的问题。仔细回想以下，一定是我的集群太low了。整个elasticsearch cluster的索引处理能力太弱鸡。。。所以，在你的集群比较弱鸡的情况下该怎么处理？ 当然，最直接的方法就是减少索引的量，比如，你要导入10月1号之前的所有log，你直接把索引的名字命名为platform-2017-10-1，而不是platform-%{+YYYY.MM.dd}。就算是只有一个eleasticsearch node，2C4G，亦能在5分钟之内把1G的log全部索引完。等索引完这些历史数据之后，你再把logstash上的output规则改为platform-%{+YYYY.MM.dd}。 elasticsearch 还是使用volume挂载 123path: data: /var/data/elasticsearch logs: /var/log/elasticsearch kibana 导入是导入成功了, 基本的搜索也有了, 但是显示出来的冗余内容有点多. Reference spujadas/elk-docker: Elasticsearch, Logstash, Kibana (ELK) Docker image elk-docker ELK生态：Logstash增量读取log文件数据，导入到Elasticsearch_alan_liuyue的博客-CSDN博客 用ELK导入历史log的正确姿势_点火三周的专栏-CSDN博客 手把手教你实战docker容器下的ELK环境搭建 - 知乎 fileBeat和Elk整合的问题_xinluke的专栏-CSDN博客","categories":[{"name":"专业","slug":"pro","permalink":"https://sean10.github.io/categories/pro/"}],"tags":[{"name":"ceph","slug":"ceph","permalink":"https://sean10.github.io/tags/ceph/"},{"name":"ELK","slug":"ELK","permalink":"https://sean10.github.io/tags/ELK/"}]},{"title":"arch体验","slug":"arch体验","date":"2021-01-02T15:03:56.000Z","updated":"2025-08-31T12:56:50.532Z","comments":true,"path":"2021/01/02/arch体验/","link":"","permalink":"https://sean10.github.io/2021/01/02/arch%E4%BD%93%E9%AA%8C/","excerpt":"","text":"背景 有点用腻了mbp的mac os系统的感觉,想换arch了. 因为总觉得mac系统里好乱, 好多感知不到的空间管理. 而且终究只是unix, 并不是linux. 但是嘛, 都用了一段时间之后回来想想, 最近我比较倾向于arch的原因主要是最近工作所需一直在用linux规范下的systemd控制下的CentOS, 用的比较熟悉了, 对目录结构比较清楚了, 而对于自己非常不熟悉的freeBSD基础的mac, 有种不在自己控制内的感觉... 现在想了想, 这其实不就是舒适区的问题吗? 学习一下mac的目录结构和日志排查等, 其实也并不会有多费事, 也并不会增加我记忆unix生态的混淆程度. 哎,但是看笔记本的品控上来说,可能还是mac os让人比较省心了. 至少售后给的新笔记本不会像xps那样经常出问题... 硬件 XPS(arch推荐比较多的是这个,但是因为品控问题不推荐的也是这个) 什么电流音之类的,决定还是不选这个了. 虽然好像XPS 7590 15寸或者13寸的直接支持hdmi 2.0接口,不过品控还是太让人担心了. thinkpad x1c emm, 似乎还行,但是触控板的体验还是比不上mac的应该 matebook 好像散热不行, 键盘部分会烫? 听说bios不太行? 安装踩坑 manjaro踩坑 bootloader一直没能正常使用 参照[^3]这个带图片的安装过程终于安装成了. 发现我直接选择第三种systemd-boot的引导,最后是看不到进入系统的东西的,可能兼容性上有问题? 最后我额外安装了Refind这套引导,终于进入桌面了. arch安装 todo 大小写老师被自动切换了 似乎是vmware 15.5这个版本的缺陷 Temporary solution for Ubuntu guest which worked for me was just disabling the Caps Lock key all together with this setxkbmap -option caps:none setxkbmap -option caps:none # (disable the caps lock key) xdotool key Caps_Lock # (toggle caps lock) Caps Lock Issues With Upgrade - VMware Technology Network VMTN 禁用这个按钮倒也是个方案, 反正我基本也不用. 不过就怕他也影响宿主机, 那就很讨厌了. 为啥我安装的虚拟机鼠标放在Linux界面再挪出去，大小写键盘总是自动切换呢？用的vmware ubuntu.如图 为啥我安装的虚拟机鼠标放在Linux界面再挪出去，大小写键盘总_虚拟机吧_百度贴吧 VMware虚拟机中大小写不停切换的问题_helen2977的博客-CSDN博客 好像无解 vmware-tools安装运行 我之前应该是直接pacman -Syy open-vmware-tools 现在发现vmware-tools这个服务没能启动. 好像搜到说是 [SOLVED] Automating installation of vmware-tools 实际上我装的是open-vm-tools ### open-vm-tools vmtoolsd这个服务似乎可以工作 VMware中的Manjaro启用复制粘贴_darkula的博客-CSDN博客 Installation Install open-vm-tools. If the legacy vmhgfs shared folder module is desired, the open-vm-tools-dkmsAUR package must be installed (the new vmhgfs-fuse driver is included in open-vm-tools). Start and/or enable vmtoolsd.service and vmware-vmblock-fuse.service. Try to install gtkmm3 manually if it does not work properly. To enable copy and paste between host and guest gtkmm3 is required. VMware/Install Arch Linux as a guest - ArchWiki 不能复制粘贴的时候, 不知道为什么,执行下这个vmware-user就能用了. Arch Linux / Manjaro 配置 VMware copy/paste vim内没开全局剪切板, 无法向外复制. cat处理吧. 重点 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112# 这里fdisk分区时, 及时将类型修改为EFI类型# 否则会出现错误: cannot find a GRUB drive for mount /dev/mapper/VG_0-root /mntmkdir /mnt/bootmount /dev/sdb1 /mnt/bootswapon /dev/mapper/VG_0-swaptimedatectl set-ntp truevim /​etc/​pacman.d/​mirrorlistpacman -Syypacstrap /mnt base base-devel linux linux-firmware man-db man-pages iwd lvm2 dhcpcd vim systemdgenfstab -U /mnt &gt;&gt; /mnt/etc/fstab arch-chroot /mntln -sf /usr/share/zoneinfo/Asia/Shanghai /etc/localtime/etc/locale.conflocale-gen# 修改/etc/mkinitcpio.confHOOKS=(base systemd ... block sd-lvm2 filesystems)#Initramfsmkinitcpio -P# 安装grubgrub-install --target=x86_64-efi --efi-directory=/boot/efi --bootloader-id=grub# 注意要挂载/boot/efi，见上面挂载boot分区那步grub-mkconfig -o /boot/grub/grub.cfg这次useradd -m -G wheel ccpasswd ccnano /etc/sudoers在 root ALL=(ALL) ALL 下面添加用户名 ALL=(ALL) ALL为你刚才创建的用户 添加sudo权限pacman -S xorg-serverpacman -S i3-wm# useradd的用户无法启动时, 安装一下这个, 创建一下自己这个用户的配置文件就好了.pacman -S xorg-xinit复制 /etc/X11/xinit/xinitrc 到～/.xinitrc。注释掉文件后面的最后的以下几行。twm &amp;xclock -geometry 50x50-1+1 &amp;xterm -geometry 80x50+494+51 &amp;xterm -geometry 80x20+494-0 &amp;exec xterm -geometry 80x66+0+0 -name login然后添加i3启动命令exec i3sudo pacman -S i3sudo pacman -S wqy-microhei adobe-source-code-pro-fonts# i3 Error: Status_command not found (exit 127) : linuxmint[\\(1\\) i3 Error: Status\\_command not found \\(exit 127\\) : linuxmint](https://www.reddit.com/r/linuxmint/comments/3f9k9s/i3_error_status_command_not_found_exit_127/)pacman -S i3status#HIDPI[HiDPI \\(简体中文\\) \\- ArchWiki](https://wiki.archlinux.org/index.php/HiDPI_(%E7%AE%80%E4%BD%93%E4%B8%AD%E6%96%87)#%E9%9D%9E%E6%95%B4%E6%95%B0%E5%80%8D%E7%BC%A9%E6%94%BE%E4%B8%8B%E7%9A%84Bug)Simplified appliance containg one one-linereval $(cvt 2220 1250 60 |sed &#x27;s/Modeline/xrandr --newmode /g&#x27;|sed -n &#x27;1!p&#x27;)as a proper result resolution screen size aspect ratio might be afterwards reevaluated/adjusted, therefore find out the created resolution by xrand command - appended in the end of output,1) assign the resolution to a specific display -xrandr --addmode VGA-1 &quot;2224x1250_60.00&quot;2) output the desired resolution on the displayxrandr --output VGA-1 --mode &quot;2224x1250_60.00&quot;To list all installed shells, run:$ chsh -lAnd to set one as default for your user do:$ chsh -s full-path-to-shellif [[ ! $DISPLAY &amp;&amp; $XDG_VTNR -eq 1 ]]; then exec startxfiyay-git.gitmakepkg -si# 配置dhcpcd自动systemctl enable dhcpcd退出startx方式win+shift+e退出桌面, 这个方式好像会卡住, 输入不来哦东西. 按照这个终于过了. Arch Linux (UEFI with GPT) 安装 | 沈煜的博客 ArchLinux图形界面安装与美化：i3+polybar_盐焗咸鱼的博客-CSDN博客_archlinux安装i3桌面 休眠 systemd-swap Can we use this to enable hibernation? A: Nope as hibernation wants a persistent fs blocks and wants access to swap data directly from disk, this will not work on: swapfs emm, 不能用这个来做休眠用的swap. 手动创建 123456789101112131415sudo fallocate -l 16G /swapfilesudo chmod 600 /swapfilesudo mkswap /swapfilesudo swapon /swapfilesudo echo &quot;/swapfile none swap sw 0 0&quot; | sudo tee -a /etc/fstabswapoff /swapfile# check fstab configswapon -vafilefrag -v /swapfileGRUB_CMDLINE_LINUX_DEFAULT=&quot;quiet resume=/dev/sda1 resume_offset=313344&quot;grub-mkconfig -o /boot/grub/grub.cfg/etc/mkinitcpio.confmkinitcpio -P Arch Linux 使用 Swap File 进行休眠 - xzOS ## 安装vmware VMware (简体中文)/Installing Arch as a guest (简体中文) - ArchWiki systemd-boot和 grub systemd-boot和EFISTUB - 知乎 ### boot manager可以看到有我新建的grub, 但是EFI似乎没法直接从硬盘启动? UEFI启动 /etc/locale.gen ### UEFI和 grub什么关系? 似乎我的/boot分区划分出问题了, efi无法找到s 并不是EFI分区, 导致bootctl无法识别了. bootctl status可以帮助判定 [SOLVED] EFI partition not detected / Installation / Arch Linux Forums grub-install --target=i386-pc /dev/sda 用legacy就尅引导了 用uefi的反而麻烦, 必须分区时gpt符合efi的 分区lvm Installation guide - ArchWiki lvm不能直接被引导? boot分区独立分区的意义? 创建出来之后, 从哪里复制内容过来, 好像这个文档里都没有提啊s Partitioning (简体中文) - ArchWiki /boot分区里的内容在哪里呢? 使用过grub-config来往里面生成内容? mkinitcpio -P 似乎也能生成新的initramfs grub-install --target=x86_64-efi --efi-directory=/boot --bootloader-id=grub grub-mkconfig -o /boot/grub/grub.cfg 将已经存在的archlinux迁移到lvm - 知乎 #### initramfs选择? LVM (简体中文) - ArchWiki archlinux安裝手记（Win10+Arch、GPT+UEFI、lvm） - 停止使用的账户 - 博客园 使用 源 12345678910sudo pacman-mirrors -c Chinapacman -Syypacman -Syu好像说是命令是pacman -Syyupacman -Qi linuxpacman -Qs 在已安装中查询pacman -Ss 在仓库中查询pacman -R 卸载pacman -Ru 循环卸载系统里不依赖的东西 pacman 升级python, 似乎没删掉旧内容? todo 从3.8升级到3.9, 看了下/usr/bin下的确只有新的python3.9了, 但是/usr/lib64/下还存在3.8的目录, 是不是之前pip装的东西没有被自动卸载或者移植? 这是一个疑问句 &gt; 不要用 pip 管理 /usr 下的包，它会和 pacman 打架。要么建 venv 在里边用 pip，要么不用 pip 只用 pacman。 根据这个pacman 安装的python包无法识别 / 应用程序与桌面环境 / Arch Linux 中文论坛, 是建议通过venv来管理python依赖的. 更新python之后, i3-sensible-terminal无法工作了 从TTY2执行了下i3-sensible-terminal, 结果发现是psutils这个库没了, 应该就是我刚才升级引起的了. 怎么让pacman来安装包呢? 12pacman -Syy python-pippacman -Syy python-six 装完pip之后报没有six, 安装了下就能使用了. 执行terminator, 报You need to install gobject, gtk, pango to run Terminator 最后, 我也没找到怎么处理的办法, 就把python3.8里的库复制到了python3.9的里... timeout [Solved] Connection time-out on installation (curl / iPv6 problem) / Installation / Arch Linux Forums 捣鼓了半天, 最后是因为我在Arch里默认开了代理, 代理好像有问题了. 内核异常 卡在loading initial ramdisk There was a kernel update, some element of your initramfs wasn't successfully built and copied to your bootloader. Generally the output of mkinitcpio shows errors, chroot in and make it again. 执行 12mkinitcpio# 就会报出initramfs的错误. (1) Stuck on Loading initial ramdisk : archlinux 打开调试日志 123vim /boot/grub/grub.cfg# 去除quiet和设置log_level=7,rd.log=all# 奇怪,怎么没生效呢? 通过增加set debug=all和set ignore_log_level=all倒是生效了, 看到了一些代码的执行记录. 但是倒是没看到Error信息 General troubleshooting - ArchWiki 为其他不是当前正在运行的内核创建镜像，添加内核版本到命令行， 可以在/usr/lib/modules目录查看支持的内核版本. 12# mkinitcpio -p linux就会以当前安装的linux版本对/boot目录下的initramfs-linux.img进行再次生成了. 捣鼓了2天, 换了个稳定版的内核就正常开机了. #### 进入reach target basic system之前的shell 在linux16那行追加rd.break=pre-trigger 在linux16这行追加rd.debug可以打出initrd中的dracut脚本的内容 周期内核升级 123456789pacman -Sy linux-lts# 下面这个似乎只生成当前运行的内核的initramfs, 如果要生成指定, 需要指定preset mkinitcpio -P# 指定内核版本生成? grub-mkconfig -o /boot/grub/grub.cfg terminal i3-sensible-terminal Mod+shift+q 退出程序 快捷键 shortcuts 不知道为什么alt+f和alt+b没办法快速在单词之间跳 这个快捷键是emulator的还是shell的呢? bash默认是启动了emacs模式的. 哦, 好吧, 是Superkey覆盖掉了alt+f这个操作, 所以把Superkey换成command也就可以了. (1) Can I completely swap the Alt and Super keys? : i3wm set $mod Mod4 Archlabs-i3wm/config at master · alexandrebobkov/Archlabs-i3wm 主要是我之前生成的配置文件里居然都是直接Mod1 + Enter之类的, 而不是$mod + Enter, 导致我直接set $mod没有效果. 网络 systemd-networkd 禁用ipv6 net.ipv6.conf.all.disable_ipv6 = 1 输入法 kde最稳妥 可以和i3结合? bspwm ## 文件系统只读问题 一般都是fstab被改坏了之类的. 桌面:i3wm 毫无疑问,我主要感兴趣的点就是能够尽量完全使用键盘来控制的方式. \\(mod + Enter 启动虚拟终端\\)mod + A 焦点转义到父窗口上 i3lock 歧义性好严重...没有看到输入密码的框, 原来是因为默认就处在接收密码的状态下, verifing和wrong的状态就是密码验证的结果... ### 登录桌面[deprecated] 最后因为vmware里似乎X11的直接配置没能配置生效, 导致sddm始终分辨率都是800x600, 我最后还是选择使用.xinitrc来调用xrandr修改分辨率 1234567891011pacman -S sddmsystemctl enable sddm #vim /etc/sddm.conf.d/hidpi.conf# 虽然我通过`pacman -Ql sddm`查到我装的位置是在`/usr/lib/sddm`里[Wayland]EnableHiDPI=true[X11]EnableHiDPI=true urxvt rxvt-unicode 不知道这个好不好用 (1) Which terminal simulator do you use with i3, and why? : i3wm urxvt 要支持hidpi, 还需要一些特殊配置. 先这样用吧. 已经挺好了. 默认的复制粘贴 Ctrl+alt+c/v unable to load base fontset 因为HiDPI, 所以增加了pixelsize的设置, 结果无法启动了. 看了下, 似乎是缺字体? 图片和壁纸 feh feh feh --bg-scale new.jpg feh (简体中文) - ArchWiki HiDPI[^7] 看起来多屏高分屏支持有点费事, 暂时还是不捣鼓了. xrandr --output eDP-1 --auto --output DP-1 --auto --scale 2x2 这个的scale 和那个~/.Xresources的Xft.dpi=192区别? 是不是xrandr修改了dpi之后, 修改指定程序的字体大小就行了? xrandr --dpi这个好像是xft.dpi的更新的方案 这个设置了以后, 标题栏的确hidpi了, 但是应用程序并没有, 不管是Terminal还是chrome. .Xresources[^8] Xft.dpi: 141 xrdb ~/.Xresources xrdb -merge ~/.Xresources xrdb -query -all 最后成功版本[^9][^10] 最后其实还是按照wifi操作成功的. 我在 .xinitrc中添加xrandr --output Virtual-1 --mode 2560x1600 在.Xresources中添加 1234Xft.dpi: 256export GDK_SCALE=2export GDK_DPI_SCALE=0.5export QT_AUTO_SCREEN_SCALE_FACTOR=1 这次重启之后终于终端字体大小什么的都对了. 远程控制: x11远程和本地渲染不同? 我看到的窗口和颜色不太一样啊,vnc manjaro 先用i3试试. i3wm 使用 [^4]可以看. 不配置de还挺舒服的. 程序启动器 dmenu 和dmenu-manjaro冲突 Wayland仍未成熟 目前来看,虽然Wayland还是在逐渐开发, 不过Xorg的成熟度还是远比其成熟, Wayland存在的问题稍多. Sway 等价于i3wm的管理器,不过这个没能做到i3polybar的程度, 而且也始终是存在部分问题的. 所以如果要用arch, 还是继续Xorg下吧. ## 开关机 shutdown -h now 驱动 【openSUSE】软件源和软件搜索 --- 看了之后 受益匪浅 - 孙愚 - 博客园 Reference Installation guide - ArchWiki i3 (简体中文) - ArchWiki Manjaro-architect 安装指南_兴趣斗士的博客-CSDN博客_manjaro architect i3: i3 User’s Guide xps13(9370) Linux之路 · Kevin的笔记 screen lock / verifying : i3wm Linux 下， hipdi 高分屏外接显示器显示怎么整啊？ - V2EX 安装xdpyinfo在Linux Xresources中设置正确的屏幕DPI-教程-Linux系统学习 HiDPI - ArchWiki Fixing HIDPI on a bare i3 install (in Arch Linux btw)","categories":[{"name":"专业","slug":"pro","permalink":"https://sean10.github.io/categories/pro/"}],"tags":[{"name":"arch","slug":"arch","permalink":"https://sean10.github.io/tags/arch/"},{"name":"laptop","slug":"laptop","permalink":"https://sean10.github.io/tags/laptop/"}]},{"title":"高铁站的技巧小记.md","slug":"高铁站的技巧小记-md","date":"2020-12-20T16:51:21.000Z","updated":"2023-03-18T15:11:14.863Z","comments":true,"path":"2020/12/21/高铁站的技巧小记-md/","link":"","permalink":"https://sean10.github.io/2020/12/21/%E9%AB%98%E9%93%81%E7%AB%99%E7%9A%84%E6%8A%80%E5%B7%A7%E5%B0%8F%E8%AE%B0-md/","excerpt":"","text":"背景 最近难得的出差去了一次杭州, 到了高铁站才用高德打车, 结果因为不知道该从什么地方去找师傅, 第一个打车的师傅说找不到这个地址, 只好取消, 换个试试能不能遇到对路线比较熟悉的师傅. 后来,稍微问了问这个比较熟悉录下你的师傅一些火车站的技巧. 顺便把以前常走的火车站的一些也给记录一下. 通用 要打车又不熟悉上车地点的时候, 可以提前预约, 接预约订单的师傅相比接马上上车的师傅要对火车站的路线要熟悉得多一般. 有时候晚上7点以后的火车没什么人, 但是目前还是没找到完全的规律, 这次同样也是晚上7点的火车, 但是人就坐满了. 上海虹桥 一般情况下, 检票口离1号检票口比较近的话, 坐地铁的时候可以直接坐到虹桥机场的地铁站下, 然后从这边往火车站方向走, 还可以有步道加速, 相比从火车站上楼再从25-26检票口走过去要省力一些. 北京南 地铁站下车直接上京沪快速进站口, 不用上出发层去候车了. 一般2分钟就可以从地铁出口上火车. 不过在非春运期间, 晚上6点就关门了. 另外疫情期间似乎也停止提供服务了, 不过我记得国庆的时候还是有提供服务的, 这块就不太懂了. 杭州东 出站往滨江方向打的车，一般推荐p5和p6停车场上车, 从火车出站口直接两边上楼，p5对应的是18号电梯，p6停车场是19号电梯，大部分司机都应该知道这两个停车场. 杭州东站的南广场和北广场都会有上车地点 北京到杭州飞机 延误 ，航空管制比较多，因为有会议导致航空管制 滨江到萧山机场倒是不会堵, 因为那个方向不会有什么人. 时间上从滨江去萧山机场和去杭州东火车站是一样的 滨江到火车站这条高架, 早上上班时间去滨江堵，下午回东站方向堵，跟工作时间一致 虽然有火车站到滨江的地铁直达，但是要从西湖边绕一圈，所以也要半小时以上 礼拜天滨江往市区(即火车站方向)走的高架会堵死，听说是下午2，3点过后开始会堵","categories":[{"name":"随想","slug":"thinking","permalink":"https://sean10.github.io/categories/thinking/"}],"tags":[{"name":"高铁","slug":"高铁","permalink":"https://sean10.github.io/tags/%E9%AB%98%E9%93%81/"}]},{"title":"ceph之编译时python3.6m符号表错误","slug":"ceph之编译时python3-6m符号表错误","date":"2020-12-02T06:22:56.000Z","updated":"2023-03-18T15:11:14.901Z","comments":true,"path":"2020/12/02/ceph之编译时python3-6m符号表错误/","link":"","permalink":"https://sean10.github.io/2020/12/02/ceph%E4%B9%8B%E7%BC%96%E8%AF%91%E6%97%B6python3-6m%E7%AC%A6%E5%8F%B7%E8%A1%A8%E9%94%99%E8%AF%AF/","excerpt":"","text":"今天在编译ceph时, 发生了libpython3.6m.a: could not read symbols: Bad value的问题, 在这附近有一个疑似相关的具体符号表的提示. 1/usr/binld: /usr/lib/python3.6/config-3.6m-x86_64-linux-gnu/libpython3.6m.a(abstract.o): relocation R_X86_64_32S against `_Py_NotImplementedStruct` can not be used when makeing a shared objectl recompile with -fPIC 第一感觉看上去的意思是ceph编译时尝试去链接的静态库的符号表没有通过-fPIC的方式生成,从而完成共享库代码段复用的功能. 但是回忆一下这个问题发生的背景, \b如果我用的是同一套yum源安装的依赖, 理论上python出现小版本不兼容的可能性较低. 那么, 就存在一个可能性, 这个报错链接找到的库并不是yum源里安装的, 可能是同事通过\b源码编译安装的python的库. 通过rpm -qf /usr/lib/python3.6/config-3.6m-x86_64-linux-gnu/libpython3.6m.a查到这个库并不是\b安装的, 验证了我的猜测. 而rpm -qf /usr/lib64/python3.6/config-3.6m-x86_64-linux-gnu则发现这里的文件才是python36-libs里提供的. 既然如此, 就将/usr/lib下的这个版本错误的库挪走, 重新编译, 这次报的是-lpython3.6m未找到. 查看/usr/lib64/libpython3.6m.so发现这个文件并不存在, 只有/usr/lib64/libpython3.6m.so.1.0存在,而软链并不存在. 通过rpm -ql python36-libs发现的确这个包中并不提供指向的链接. 根据目前对包管理的理解, 怀疑这个缺失的指向真实文件的软链很有可能在python36-devel包中, 安装后果然如此, 链接找到了. 执行编译, 毫无问题了~ 引申的疑问 因为目前出现的python3.6m.so这个库的疑问, python3-libs这个库里没有提供指向.so的链接, 而是在python3-devel包中存在 而python34则都是在python34-libs里. 但是python36应该是能够正常使用的吧? 那是不是其实可以作答哦这样一点, 如果编译时我指定了链接, 然后在符号表中, 他就能找到针对这个链接指向的真实路径 ,然后存起来. 到生产环境里, 如果这个路径中存在, 就不需要ldconfig的默认路径了呢? 会不会有这个选择呢? 还是说这个libpython3.6m.so这个库基本只会在编译C与python之间的库时使用,而且只编倾向于静态的? 然后这样编完到生产环境里就不需要了呢?","categories":[{"name":"专业","slug":"pro","permalink":"https://sean10.github.io/categories/pro/"}],"tags":[{"name":"ceph","slug":"ceph","permalink":"https://sean10.github.io/tags/ceph/"},{"name":"编译","slug":"编译","permalink":"https://sean10.github.io/tags/%E7%BC%96%E8%AF%91/"},{"name":"python","slug":"python","permalink":"https://sean10.github.io/tags/python/"},{"name":"CentOS","slug":"CentOS","permalink":"https://sean10.github.io/tags/CentOS/"}]},{"title":"CLI转为http服务小探","slug":"CLI转为http服务小探","date":"2020-12-01T17:29:22.000Z","updated":"2023-03-18T15:11:14.890Z","comments":true,"path":"2020/12/02/CLI转为http服务小探/","link":"","permalink":"https://sean10.github.io/2020/12/02/CLI%E8%BD%AC%E4%B8%BAhttp%E6%9C%8D%E5%8A%A1%E5%B0%8F%E6%8E%A2/","excerpt":"","text":"背景 需要将现成的CLI转换为web服务的HTTP接口. 这个我记得之前看到哪篇文章推荐过, 但是一时想不起来了 想了想关键词 CLI command line http server web 终于把web这个带上之后, 用CLI to web server终于搜到一个相近的 w2c 这个python 程序 dongyx/c2w: convert CLI programs to Web services 然后用这个里的描述, google终于找到了相似语义的, 我少了program, 导致CLI应该被理解成了终端输入参数的web服务, 也就是常见的web服务... converts a CLI program to a Web service The Return of the CLI: CLIs Being Used by API-Related Companies | Nordic APIs | 初看没看懂 How can I convert my console application to a web service using visual studio 2013 - CodeProject hhh, 一个咨询解决方案的, 问题一致. 只不过我实现了一套, 现在想看看有没有更好的实现方案 adamkewley/jobson: A platform for transforming command-line applications into a job service. 这个东西似乎是转换成任务, 结果不知道有没有返回的地方 (1) [FOSS] Convert any command line tool/service into a asynchronous REST API. [Python] : linux 又拿到一个关键词, shell2http Eshaan7/Flask-Shell2HTTP: Execute shell commands via HTTP server (via flask's endpoints). adnanh/webhook: webhook is a lightweight incoming webhook server to run shell commands 这个比较牛看起来, Star特别高, go实现 The Tech Feast: Expose Any Shell Command or Script as a Web API bash2http, 和上面的shell2http差不多 shell 2 http remote sh这个工具看起来也不错, 只是在页面填写bash 脚本, 然后指定服务器执行, 等同于web终端的感觉. command web server expose shell scripts as web services 又一个关键词 API lukasmartinelli/nigit: Web server that wraps around programs and shell scripts and exposes them as API wrap command to http API phonkee/goexpose: Expose shellscripts, postgres queries, redis commands and other as rest server endpoints 上一个开发者不维护了, 推荐用这个 Andreweweith/Web-Based-Remote-Command-Server: Web server and interface to remotely execute Linux shell commands and display the results 这个是C实现的一个http上输入命令底层执行,然后返回结果的那种. bytestream/Web-Server: During my time at the University of Miami whilst studying CSC524 - Computer Networks I was also asked to build a basic web server using pure C. The web server can be used to process GET and POST requests whereby GET requests will serve a static file and POST requests with the addition of POST data will execute the file as if it were CGI and pipe the output back to the client. Again for security reasons it only serves files in the current working directory, and will also only execute shell programs. 别人的一个大作业的成果.也是C实现的一个把shell通过API暴露. dotnet/command-line-api: Command line parsing, invocation, and rendering of terminal output. .Net实现的, 感觉我的实现架构比较贴近这个 wrap command to http API Soaplab2 看起来有点像需求的? Genivia - Getting Started with C/C++ XML Data Bindings and XML SOAP/REST Web Services gsoap使用总结 - 苦涩的茶 - 博客园 WebService服务基本概念：就是一个应用程序，它向外界暴露出一个可以通过web进行调用的API，是分布式的服务组件。本质上就是要以标准的形式实现企业内外各个不同服务系统之间的互调和集成。 所以以前其实这个实现形式叫做webservice. 只是我们不止是函数, 包括命令. 所以这里其实针对静态语言以前的思路是实现一个DSL, 然后基于编写的DSL生成可编译的代码, 然后再编译出可执行程序, 对, 针对静态语言,其实这也是个思路, 使用yacc等词法分析器? How to wrap a C library so that it can be called from a web service - Stack Overflow 这里也提到了soaplib mod-xmlrpc2 webservice command webservice c# - Consuming Web Service from C++/CLI - Stack Overflow emm. SyBooks Online proxy 忽然想到, proxy其实和wrap在这个场景里是同义词. 小结 所以根据上面的思路来看 流程 初始化 解析配置文件, 其中包含CLI或函数对应的API路由 \b\b\bdecoder\b解析http协议 dispatch根据路由转发, 路由注册 \b\b\b\b\b进入函数或传入命令参数进行执行 可能有前置处理参数逻辑, 一般定制性需要强一些 后置输出格式处理逻辑等 encoder协议拼装返回 思路 针对支持运行时元编程能力的语言(如python, go), 和我实现思路基本一致, 编写一套配置或叫做DSL, 运行时加载然后动态生成函数等. 针对不具有上述能力的语言, 有两种思路 参数传入, 核心调度逻辑的函数基本只有一个 如果是CLI, 则作为参数传入, 有一个统一system调用的函数封装 如果是前置和后置逻辑需要用函数处理, 则像下面一样用字符串找到符号表里的函数指针. 如果是函数, 我想的就是通过动态库的dlysm或者libeffi来根据配置中填写的函数名, 去进行调度. 编写一套DSL, 在进入编译前, 根据编写的DSL生成一套代码, 这样就支持各式各样的函数了, 就是定制性维护可能代码量膨胀的较快? gsoap和soaplib应该是这套思路吧, 好像有点像是10年前的思路, 看snmp代码的时候也是这种思路, 从mib生成代码. 这个的实现方式应该就多种多样了.","categories":[{"name":"专业","slug":"pro","permalink":"https://sean10.github.io/categories/pro/"}],"tags":[{"name":"CLI","slug":"CLI","permalink":"https://sean10.github.io/tags/CLI/"},{"name":"http","slug":"http","permalink":"https://sean10.github.io/tags/http/"},{"name":"system","slug":"system","permalink":"https://sean10.github.io/tags/system/"}]},{"title":"代码分支模式初探","slug":"代码分支模式初探","date":"2020-11-15T16:27:24.000Z","updated":"2023-03-18T15:11:14.808Z","comments":true,"path":"2020/11/16/代码分支模式初探/","link":"","permalink":"https://sean10.github.io/2020/11/16/%E4%BB%A3%E7%A0%81%E5%88%86%E6%94%AF%E6%A8%A1%E5%BC%8F%E5%88%9D%E6%8E%A2/","excerpt":"","text":"背景 最近公司里多项目并行的时候, 发现在以前组管理的感觉比较混乱的分支方式(多个项目并行的时候, 同一个组件的代码需要维护多套分支)居然其实算是一个比较好的实现了... 这里的分支反而更加混乱. 索性梳理一下分支到底应该怎么管理, 才是最佳实现. 下面这部分是我目前的理解. 分支的场景 据我目前接触到和理解的, 会有以下几种常见的场景. 考虑到这里主要的障碍在于分支管理, 暂时假设一个组件的维护人员就是一人, 暂时跳过多人维护一个组件情况下的merge障碍问题(其实这块也比较要求模块设计的解耦, 多人改同一段代码这种情况本就不好合并, 我的理解是从设计上尽量避免对同一行冲突的修改). 根据[^6]中可知, 良好的模块化基本不会遇到代码分支带来的相同行修改的隔离问题. 一个分支对应一个项目, 包含多个组件的并行开发 多个分支对应多个并发项目面向不同业务场景, 同一套组件 一个项目对应多个组件分支, 各组件并行开发 多个组件对应多个主分支, 多个项目再各自开出对应的项目分支 上面几项中, 公共组件在多个项目中的使用 项目中只是用公共组件的发布版本 公共组件维护一个私源库, 每次迭代发布一个版本. 发布后的缺陷通过更新patch, 更新rpm包等形式, 如果各项目有涉及缺陷, 使用最新的组件包更新即可. 优点: 独立性强, 不需要因为业务项目拉出分支, 也进行项目拉出 缺点: 组件调试不便. git subtree 将一个目录自动提交到多个项目分支中的同一个组件目录下 个人只处理一个分支,但是实际上项目有多个分支. 这个感觉是一个比较好的处理手段. 独立分支维护 为了避免其他使用者对公共组件更新的感知不及时, 可以通过webhook等方式进行通知 依赖第三方组件如何管理问题 是单独维护一个分支用来记录使用的库及其版本的下载路径 还是直接把库提交到分支中. 版本发布模式 项目制发布模式: 项目制发布模式, 预先确定功能特性, 在所有功能开发完成后进行版本发布 发布火车模式: 大型套装分发类软件, 各部门之间互相依赖, 约定版本发布的时间 城际快线模式: 固定版本发布时间和质量维度, 时间较短 我理解, 项目制和发布火车模式有点相近. 都是约定一个集成时间, 开始各功能提交进行集成. 而城际快线就是高频集成的持续集成模式那种吧.敏捷开发?因为高频集成, 所以重构代码带来的代价也少, 这种比较贴合代码架构变更频繁的场景倒是. 分支管理的\b用途 一个长期稳定迭代的基线分支 这个分支只有当项目发布完毕时才合入代码. 项目进行中的不稳定的开发分支 这个分支在项目开启时,从基线拉出 项目发布后的缺陷修复所需提交的分支 定制项目的一些特殊需求无需合入基线. 潜在的问题 当一个项目开发中时, 开启了另一个项目, 需要用到目前正在第一个项目的分支中开发的功能 是否应该从项目分支再创建一个分支呢? 还是从基线拉出分支, 然后再从当前正在开发的分支合并功能代码过去呢? 根据现在的理解, 这个选择更合适, 分支统一从基线拉出, 这种分支流图更合理. 当一个功能即将开发完毕时, 但是由于对接方面的人时间计划来不及处理了,他的功能没有上车,这样的话, 对于我们的代码应该怎么处理呢? 我的理解是git的话可以在本地或是自己的一个branches里提交, 然后等到需要合并时, 再合入项目分支 或者可以通过stash暂存区来处理这个问题. 如果是svn, 是不是就只能注释这部分代码了呢? 似乎也可以像git一样, 创建一个自己的分支先提交, 但是这样的话, 如果每个人都有创建的分支的权限的话, 似乎就会比较混乱了把? 但是似乎这个也算是一个比较好的实现了. 毕竟不像git有约定的特性分支, 只能自己拉自己的特性分支了. 公司研发了一套svn插件, 导致通过git-svn来完成本地使用git这个逻辑不太可行. 代码合并的最大成本主要是在于工具吗? 并不是, 是在于开发时, 是否考虑过和基线的兼容性问题, 基线理论上除了缺陷, 不应该有其他的操作合入 通用思考 从主分支里拉了一个新分支出来，在合并回主分支之前，必须持续地把主分支的更改尽早尽快合并到新分支。新分支永远保持 最新主干代码+新模块代码 的状态。 其实的确是对的, 如果基线修改了, 那么就应该尽快把基线的一些修改合并到你当前的分支中去, 避免将来无法合并 因为你merge代码的时候，用BC除非没有冲突的文件，只要有add和delete操作的文件你都要逐个逐行进行处理啊，更别提有冲突的文件了。用git做merge无冲突文件且版本号高于master分支就自动帮你解决了，你只需要解决冲突就行； git合并分支容易的原因是，要经常和master分支merge，这样把冲突消灭在萌芽状态。 git可以合并commit到一个后来被修改过的文件&gt; Git可以修改和重构历史提交：使用Git本身的reset以及 rebase 命令可以修改或者重整/重构历史提交，非常灵活。使用强大的 stg 可以使得历史提交的重构更为简洁，如果您对 stg 或者 Hg/MQ 熟悉的话。 大厂文章 美团单周迭代 定期需求评审 多版本多需求并行开发(在需求分支内开发) 分支 release分支 立项时从stage分支拉出 成果物从这个分支构建. 发版后合入到Stage分支. 其他开发中的分支也合入该分支的最新代码 stage分支 承担稳定的代码功能的归档 通过jenkins job来完成分支的管理 git代码分支模型 git flow 基线分支只合稳定以后的功能 各项目的dev分支, 存放满足需求的feature的开发, 稳定后打tag, 合回基线 release分支, 从dev拉出, 包含所有功能, 处理发布所需, 完毕后打tag合回基线及dev分支 hotfix分支, 修复后, 合入到上述所有分支 优劣势 流程清晰 管理严格 长期分支的同步开销较大, 不适合快速发布 github flow 只有master分支, 只有部分管理员有提交权限, 其他人通过在自己分支完成功能后提交PR, 通过评审和自动化测试进行兜底 各feature及缺陷修复分支 优劣势 分支简单, 适合快速迭代 不适合多环境多版本项目并行产品 gitlab flow 似乎和git flow有点类似, 多出了production, release等分支? TBD flow(Trunk Based Develop) 开发及缺陷修复基于trunk, 只有快速发布, 完全没有分支管理 TBD++ flow 基于功能的主分支 trunk和feature分支需同步更新 trunk分支有自动化测试自动执行 基于发布的release分支 release分支发布后打Tag, 但依旧长期运行, 如果发现缺陷, 往这个分支及master分支合入缺陷修复, 这个发布分支打新的tag todo: patch管理定制/上游代码, 是否可行? 巧用svn create patch（打补丁）方案解决定制版需求_golden_lion的博客-CSDN博客 Reference Git代码分支管理模型 - 简书 (18 条消息) git合并分支，为什么会比svn容易？ - 知乎 一个 Git 分支协作模式的进化故事 – Gitee 官方博客 客户端单周发版下的多分支自动化管理与实践 - 美团技术团队 【读书笔记-017】持续交付2.0之集成分支策略 - 简书 Martin Fowler三万字解读源代码分支管理模式_ITPUB博客 (18 条消息) Git 相比 svn 和其他版本管理工具的核心优势有哪些？ - 知乎","categories":[{"name":"专业","slug":"pro","permalink":"https://sean10.github.io/categories/pro/"}],"tags":[{"name":"git","slug":"git","permalink":"https://sean10.github.io/tags/git/"},{"name":"版本管理","slug":"版本管理","permalink":"https://sean10.github.io/tags/%E7%89%88%E6%9C%AC%E7%AE%A1%E7%90%86/"},{"name":"svn","slug":"svn","permalink":"https://sean10.github.io/tags/svn/"}]},{"title":"文件系统概念初探","slug":"文件系统概念初探","date":"2020-10-18T13:38:26.000Z","updated":"2023-03-18T15:11:14.889Z","comments":true,"path":"2020/10/18/文件系统概念初探/","link":"","permalink":"https://sean10.github.io/2020/10/18/%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E6%A6%82%E5%BF%B5%E5%88%9D%E6%8E%A2/","excerpt":"","text":"todo 为什么文件系统不默认提供每个目录的空间使用量呢? 多文件系统嵌套, 还是需要用户自己去df挂载的位置里去找所在目录在哪个分区里, 然后分区大小多少, 为什么不能直接显示出当前目录使用量及这个文件系统根的容量呢? subvolume btrfs子文件系统支持 说到这个,df默认为啥没有什么超时机制呢?卡在显示所有上? 可能df只提供基本查询, 自己有超时需求自己处理? 文件系统配额, 如果不开启的话, 怎么知道这个文件系统究竟有多少空间可以用呢? 文件系统写满时, 到底是哪层做的错误返回? 分配器提供的吧? 所以对于分布式块设备上建的文件系统, 得是支持扩容的文件系统? 文件系统\b\b中的原子事务如何实现? 幂等性如何保障 extent技术 隐藏的预留容量, 超级块 与块设备相比 问题原因 * 如何找到你想要的信息 * 如何保证一个用户不会读取另一个用户的数据 * 如何得知哪些块是空闲的, 等等 文件是上面这些问题的抽象解决. 文件系统概念[^3] 主要为存储设备提供一致的访问和管理方式. 数据以文件的形式存在 文件以树形目录进行组织. 较为复杂, 扩展性相比现在新增的对象存储较差一些.(各公司自研的应该还好) 文件系统的复杂性导致可扩展性未能跟上互联网的高速发展, 极大简化了的对象存储及时填补了空确. 不过因为对象存储缺乏树状结构, 也不支持原子重命名操作, 跟文件系统差异较大. 关键优化问题 存储大量小文件时, 一次文件多次读取元数据信息的\"长尾效应\" 比如Haystack通过合并多个小文件成一个大文件, 通过减少文件数量的方式解决 文件系统架构对比[^3] MPI 并行文件系统 JuiceFS TODO:JuiceFS 只需要专注元数据的管理，也大大降低了元数据服务的复杂度（GFS 和 MooseFS 的 master 要同时解决元数据的存储和数据块的健康管理）。 盘古 NebulasFS(360) master和datanode 多文件系统关联 挂载时 分配一个新的inode指向新的文件系统的data block. 挂载完成后，将在/proc/self/{mounts,mountstats,mountinfo}这三个文件中写入挂载记录和相关的挂载信息，并会将/proc/self/mounts中的信息同步到/etc/mtab文件中，当然，如果挂载时加了-n参数，将不会同步到/etc/mtab。[^3] FUSE 用户-内核通信协议 splice 零拷贝技术 内核FUSE队列 缓存写回 实现 文件系统布局 引导块 超级块 文件系统的大小 文件系统中的数据块数 指示文件系统状态的标志 分配组大小 空闲空间块 bitmap位图 bit vector 位向量 链表 #### 碎片 #### inode ### 分配 思想 有效利用文件空间 快速访问文件 #### 连续分配 CD-ROM 满的时候, 标记-1之类的. #### 链表分配 随机访问难 #### 使用内存表进行链表分配 引入索引的概念 FAT(File Application Table) 整个链表都在内存中, 表占用空间较大(1T盘 1KB的块, 需要至少3-4个字节的管理, 需要3GB左右的内存) 满的时候, 直接链表最后断开就行了. #### \binode 只有文件打开时, inode才在内存中, 解决FAT的问题 inode在初始化文件系统时就给定了, 多大的块设置一个inode. 128字节整数倍 /etc/mk2fs.conf inode_ratio, 多大的块分配一个inode号 ext4预留了inode用于比如/proc/, lost+found 问题: 文件知道自己的inode之后, inode存储了什么东西,可以让他找到对应的所有块? [^3] inode中保存了块的文件指针 ext2/ext3 最多15个指针, 前12个直接寻址, 第13-15个分别一级,二级,三级间接寻址 一个4K block可以放4096/4=1024个指针. 即1024^3+ 1024^2 + 1024^1+12 = 1.1G个块指针, * 4K= 4T左右的大小 ext4 使用了extent的方案 满的时候, 最后一个磁盘地址不指向数据块, 而是指向一个包含额外磁盘块地址的地址 ### 目录的实现 ### 共享文件 有向无环图 硬链接 软链接 问题: 复制时如果不对符号链接进行区分, 会带来重复写入问题 日志结构文件系统(Log structured File System, LFS) 性能问题 背景: 不断增长的内存 顺序I/O强于随机I/O 现有低效率的文件系统 文件系统不支持RAID(虚拟化) 由于Page cache存在, 读性能基本不是问题 数据结构 Inode Inode Map Segment Segment Usage Table ### 日志文件系统 防止掉电/崩溃问题 幂等性 引入原子事务 虚拟文件系统 VFS 对用户进程的上层接口POSIX接口 下层接口, 各文件系统提供的. vnode 文件系统的管理和优化 磁盘空间管理 分段管理 分页管理 #### 块大小 #### 记录空闲块 位图(bitmap) 磁盘块链表 问题 在内存中保留一个半满的指针块, 这样既处理文件的创建和删除, 又不会为空闲表进行磁盘IO 磁盘处理一些列临时文件, 不需要进行任何磁盘IO 磁盘配额 硬限制 软限制 用于实现警告和用户权限控制的计数 ### 文件系统备份 场景 从灾害中恢复 从错误的操作中恢复 删除-&gt;回收站 设计 备份整个文件系统还是只备份一部分文件 增量转储 压缩 备份过程中出错, 压缩文件是直接损坏还是可以纠正? 正在使用的文件系统如何备份 设置时间点? 瞬时快照 物理转储和逻辑转储 物理转储 全量备份 坏块转储 逻辑转储 维持一个inode为索引的bitmap, 修改过的文件被标记 空洞问题的处理 ### 文件系统的一致性 因为系统调用并不是原子事务的, 写操作复杂, 完全存在不一致可能性. fsck sfc(windows) 块的一致性检查 文件的一致性检查 空闲块和已使用的块的表的对照 块丢失(missing block) 块重复 空闲表中重复 直接标记就行 不同文件使用了这个块 分配一个磁盘快, 把他插入到文件里, 比如文本文件打开中, 出现掉电, 中间插入乱码是不是就是这个做法? 已使用和空闲表中均出现(就是删除过程只执行了一半) 应该也是优先分配一个新块, 插入到文件里 检查目录系统, 维护计数器表 检查inode数量与目录的关系 文件系统性能 高速缓存 block cache buffer cache 逻辑上属于磁盘, 实际通过内存来提供支持 页面置换算法 块提前读 考虑顺序读取, 进行预读取 好像在磁盘驱动那层也有这个设计? 所以其实多层都提供了这样的功能? 减少磁盘臂运动 块簇 以连续块簇来跟踪磁盘存储区. 分配时尽量分配在同一个柱面上 解决一个连续内容被分配在2个柱面上带来的寻道次数翻倍 读文件至少2次磁盘访问 访问inode 访问块 原本inode放在磁盘开始位置, 所以inode到块的平均距离是柱面组的一半 改到中间 磁盘碎片整理 删除文件, 回收磁盘块. defrag, 移动文件, 使空闲块连续分布 ext2/ext3选择磁盘块的方式, 导致不怎么需要处理磁盘碎片整理[^2] 日文件系统分配策略上并不完全连续分布 ext的延迟写入技术 主要是FAT 文件 文件命名 名字 unix 大小写敏感 MS-DOS 大小写不敏感 扩展名 unix 无感知 但是目前是不是也像window一样了 windows 能够在操作系统层面设置不同扩展名对应的程序 文件结构 目前都是字节序列, 用使用者自己进行定位. 这样的话其实和操作裸块也有点像吧? 的确 不知道有没有采用树等结构化关系的, 感觉更适合更上层的应用自己抉择. 文件类型 文件 由内核处理 目录 字符特殊文件 串行I/O设备 块特殊文件 由设备驱动程序处理 操作系统至少能识别自己的可执行文件. 所以文件系统和操作系统还是有一些绑定关系的? 文件访问 文件属性 文件操作 create delete open close read write append seed get attributes set attributes rename 目录 一级目录系统 根目录 层次文件目录 路径名 目录操作 create delete opendir closedir readdir rename link unlink FUSE支持 Reference 简直不要太硬了！一文带你彻底理解文件系统 - 程序员cxuan - 博客园 (80 条消息) 为什么NTFS系统容易产生碎片而ext系列则不会？ - 知乎 ext文件系统机制原理剖析 | 骏马金龙 分布式文件系统架构对比-InfoQ 分布式文件系统浅谈 - 知乎","categories":[{"name":"专业","slug":"pro","permalink":"https://sean10.github.io/categories/pro/"}],"tags":[{"name":"存储","slug":"存储","permalink":"https://sean10.github.io/tags/%E5%AD%98%E5%82%A8/"},{"name":"文件系统","slug":"文件系统","permalink":"https://sean10.github.io/tags/%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/"}]},{"title":"ceph之clion的cmake.md","slug":"ceph之clion的cmake-md","date":"2020-10-17T06:43:31.000Z","updated":"2025-05-10T07:54:15.487Z","comments":true,"path":"2020/10/17/ceph之clion的cmake-md/","link":"","permalink":"https://sean10.github.io/2020/10/17/ceph%E4%B9%8Bclion%E7%9A%84cmake-md/","excerpt":"","text":"调查 按照一般的编译过程, 是可以在CentOS或者Debian系的环境里直接执行do_cmake.sh然后自动安装install-deps.sh, 然后关闭一堆功能触发cmake的. 不过因为暂时没找到可以进行环境隔离比如通过在docker内编译ceph(初步尝试, deps中出现了systemd, 而docker内使用使用的一个fake-systemd, 这俩产生了冲突, 不知道有没有专门针对docker做的一个fake版本), 从而绕过弄坏OSX宿主机的依赖的风险的. 在这个安装依赖的脚本中是有针对freeBSD的pkg安装命令的, 但是和目前主流推荐的brew还是不一样的, pkg还是给服务端使用为主. 怕产生污染, 所以我暂时选择手动来处理这个依赖的问题. 当然, 如果有远程服务器, 可以利用remote develop, 通过服务器编译也能把成功建立索引. docker调试用运行 vstart.sh ceph/daemon[^9] 根据[^11]的image的build仓库来看, 这个docker也是可以来触发编译的? make CEPH_DEVEL=true FLAVORS=\"luminous-12.2.13,centos,7\" build 单看这个脚本, 看起来可以编出来的样子. make CEPH_DEVEL=true FLAVORS=\"nautilus,centos,7\" build 这里为什么这个版本的centos里装的是真实的systemd?, 我之前拿官方的centos的image就是fake-systemd呢... 搜了下, 用fakesystemd是为了cgroup与宿主机的隔离. 手动卸载再安装其实也是可以的. 不对, 这个镜像里是直接配置的yum install -y ceph-mon等...不是编译出来的... 自制Docker调试 1docker run -itd --name centos-test centos:centos7 opensuse ceph-dev-docker [^12], 这个是opensuse的. 123456789101112131415161718192021222324252627282930313233343536#src.rpm 12.2.13docker run -itd \\ -v /Users/sean10/Code/ceph/ceph-12.2.13:/ceph \\ -v /Users/sean10/Code/ceph/ceph-ccache-12.2.13:/root/.ccache \\ -v /Users/sean10/Code/ceph-dev-docker/shared:/shared \\ --net=host \\ --name=ceph-dev \\ --hostname=ceph-dev \\ --add-host=ceph-dev:127.0.0.1 \\ ceph-dev-docker# luminous版本docker run -itd \\ -v /Users/sean10/Code/ceph/ceph-14.2.9:/ceph \\ -v /Users/sean10/Code/ceph/ceph-ccache-14.2.9:/root/.ccache \\ -v /Users/sean10/Code/ceph-dev-docker/shared:/shared \\ --net=host \\ --name=ceph-dev \\ --hostname=ceph-dev \\ --add-host=ceph-dev:127.0.0.1 \\ ceph-dev-docker# nautilusdocker run -itd \\ -v /Users/sean10/Code/ceph/master/ceph:/ceph \\ -v /Users/sean10/Code/ceph/ceph-ccache-branch-luminous:/root/.ccache \\ -v /Users/sean10/Code/ceph-dev-docker/shared:/shared \\ --net=host \\ --name=ceph-dev \\ --hostname=ceph-dev \\ --add-host=ceph-dev:127.0.0.1 \\ ceph-dev-dockerdocker attach ceph-devNPROC=4 ./setup-ceph.shdocker exec -it ceph-dev /bin/zsh 通过传给cmake的CMAKE_BUILD_TYPE来确认编译出来的是否携带debuginfo.[^13] Release —— 不可以打断点调试，程序开发完成后发行使用的版本，占的体积小。 它对代码做了优化，因此速度会非常快， 在编译器中使用命令： -O3 -DNDEBUG 可选择此版本。 Debug ——调试的版本，体积大。 在编译器中使用命令： -g 可选择此版本。 MinSizeRel—— 最小体积版本 在编译器中使用命令：-Os -DNDEBUG可选择此版本。 RelWithDebInfo—— 既优化又能调试。 在编译器中使用命令：-O2 -g -DNDEBUG可选择此版本。 默认是RelWithDebInfo, 我给他传了俩参数-DWITH_LTTNG=ON -DDWITH_BABELTRACE=ON python-devel not found. 结论: 看上去是suse的tumbleweed现在的源里没python2的包了[^14]? 而这个仓库里的master分支如果编ceph还没去除python2的版本, 就会有问题. 根据这个来看Re: [opensuse-factory] Removal of Python2 from openSUSE Tumbleweed 高版本的suse把python2彻底抛弃了, 但是是不是也有办法加回来安装呢? 搜了一圈, 主流的思路是这种大版本迭代, 如果始终要考虑老版本兼容性, 始终去兼容python2, 对于开发的迭代并不利, 不如让开源软件去遵循这个规则, 统一进行大版本升级. 这种在商业产品里, 做法已经比较成熟了, 都是软件去适配系统. 只是linux系统在python以前可能没依赖性这么强的类似基础框架组件性质的部分, 所以对于彻底不兼容的软件会相对少一点. hhh, 说到这个, 这种换到公司里的代码开发, 就是为了兼容性, 当单元测试少时, 就不重构, 变成垃圾代码. 而开源的, \b就看开发者的能力了. 好像见到的一般都有大神在把控代码质量的~ 所以理论上其实ceph应该不完全依赖python2了. 我应该通过其他方式去判断是否要编python2相关. 根据不同版本的ceph的install-deps.sh和ceph.spec, 可知mimic和nautilus的版本还没有完全可以免去python2.7, 而Octopus里彻底去除了python2的编译. tmubleweed 的repo路径 Factory 和 Tumbleweed 合并了, 所以直接使用 factory 的源就好. 不过大多数镜像只提供了 repo-oss 和 repo-non-oss 这两个源 https://download.opensuse.org/repositories/openSUSE:Factory/standard/openSUSE:Factory.repo 搜出来显示这个,但是这个路径实际上已经不存在了...不知道怎么给他们提 Install package devel:languages:python:Factory / python Install package devel:languages:python / python-virtualenv openSUSE:Build Service 仓库详解 - openSUSE Wiki 看上去这上面源里的是src.rpm. 咋Search能看到, 就是提示转不上呢? 我先配置上面这个, 给装上去了. 某些疑似镜像源中似乎还有python2的库 Index of /pub/opensuse/tumbleweed/repo/oss/x86_64/ 但是下面这个源里明明也是oss, 但是却有呢? 稳定的Leap 15版本的nautilus编译 1234567export NAME=ceph-dev-nautilusexport VERSION=nautilusexport CEPH=/Users/sean10/Code/ceph/ceph-14.2.9export CCACHE=/Users/sean10/Code/ceph/ceph-ccache-14.2.9cd /share/bin/nautilusbash -x ./setup.sh 这个倒是安装成功, 开始触发编译了. 不过中间dashboard的frontend在安装pip时报了点Input/Output Error, 暂时不是重点, 在setup-ceph.sh里设置-DWITH_MGR_DASHBOARD_FRONTEND=OFF, 就可以通过编译了. 就是本地编译有点慢... 1234cd /ceph/srcOSD=1 MON=1 MGR=1 RGW=1 CEPH_BUILD_ROOT=/ceph/build bash -x ./vstart.sh -n ../src/stop.sh &amp;&amp; OSD=3 MON=1 MGR=1 RGW=1 bash -x ../src/vstart.sh -n ccache make -j8 ceph-mon [ 97%] Building CXX object src/mon/CMakeFiles/mon.dir/AuthMonitor.cc.o c++: internal compiler error: Killed (program cc1plus) Please submit a full bug report, with preprocessed source if appropriate. See https://bugs.opensuse.org/ for instructions. make[3]: *** [src/mon/CMakeFiles/mon.dir/build.make:351: src/mon/CMakeFiles/mon.dir/MonmapMonitor.cc.o] Error 4 看着跟OOM的表现有点像. 根据linux - make -j 8 g++: internal compiler error: Killed (program cc1plus) - Stack Overflow这篇说的, 可能是我开的线程太多, 给他分配的内存又没那么多引起的? 我试试 降低以后的确编过了. vstart.sh erasure-code load dlopen(/ceph/build/lib/erasure-code/libec_jerasure.so): /ceph/build/lib/erasure-code/libec_jerasure.so: cannot open shared object file: No such file or directory 123╭─root@ceph-dev-nautilus /ceph ╰─# cat src/vstart.sh | grep erasure-code [ -z &quot;$EC_PATH&quot; ] &amp;&amp; EC_PATH=$CEPH_LIB/erasure-code 暂时没找到怎么只是make , 生成到build/lib/erasure-code目录下的功能. vstart.sh ERROR: error creating empty object store in /data/ceph/build/dev/osd0: (22) Invalid argument 根据Support #23433: Ceph cluster doesn't start - ERROR: error creating empty object store in /data/ceph/build/dev/osd0: (22) Invalid argument - bluestore - Ceph这里的回复, 看起来这个是因为毕竟是虚拟化的, 所以指向的/dev/目录下的内容并不是块设备引起的吧? 实践 采用官方给的关闭的大部分配置文件的方案[^1], 可以避过大部分坑, 至少Luminous版本做到了. Docker编译 根据[^7], 还有有参考价值的. 官方CI[^10] \b似乎这里主要运行test和image, 那个dev的镜像看起来是给调试镜像版本用的, 并不是直接提供运行vstart.sh来调试编译版本的. Luminous 最后按照下述方案处理好软链和安装包之后的cmake选项 1-DCMAKE_C_COMPILER=/usr/bin/clang -DCMAKE_CXX_COMPILER=/usr/bin/clang++ -DCMAKE_EXE_LINKER_FLAGS=&quot;-L/usr/local/opt/llvm/lib&quot; -DENABLE_GIT_VERSION=OFF -DSNAPPY_ROOT_DIR=/usr/local/Cellar/snappy/1.1.7_1 -DWITH_BABELTRACE=OFF -DWITH_BLUESTORE=OFF -DWITH_CCACHE=OFF -DWITH_CEPHFS=OFF -DWITH_KRBD=OFF -DWITH_LIBCEPHFS=OFF -DWITH_LTTNG=OFF -DWITH_LZ4=OFF -DWITH_MANPAGE=ON -DWITH_MGR=OFF -DWITH_MGR_DASHBOARD_FRONTEND=OFF -DWITH_RADOSGW=OFF -DWITH_RDMA=OFF -DWITH_SPDK=OFF -DWITH_SYSTEMD=OFF -DWITH_TESTS=OFF -DWITH_XFS=OFF -DCMAKE_C_COMPILER=/usr/bin/clang -DCMAKE_CXX_COMPILER=/usr/bin/clang++ -DCMAKE_EXE_LINKER_FLAGS=&quot;-L/usr/local/opt/llvm/lib&quot; -DENABLE_GIT_VERSION=OFF -DSNAPPY_ROOT_DIR=/usr/local/Cellar/snappy/1.1.7_1 -DWITH_BABELTRACE=OFF -DWITH_BLUESTORE=OFF -DWITH_CCACHE=OFF -DWITH_CEPHFS=OFF -DWITH_KRBD=OFF -DWITH_LIBCEPHFS=OFF -DWITH_LTTNG=OFF -DWITH_LZ4=OFF -DWITH_MANPAGE=ON -DWITH_MGR=OFF -DWITH_MGR_DASHBOARD_FRONTEND=OFF -DWITH_RADOSGW=OFF -DWITH_RDMA=OFF -DWITH_SPDK=OFF -DWITH_SYSTEMD=OFF -DWITH_TESTS=OFF -DWITH_XFS=OFF -DCMAKE_EXPORT_COMPILE_COMMANDS=on -DPYTHON_LIBRARY=$(python-config --prefix)/lib/libpython2.7.dylib -DPYTHON_INCLUDE_DIR=$(python-config --prefix)/include/python2.7 -DPYTHON3_LIBRARY=$(python3-config --prefix)/lib/libpython3.9.dylib -DPYTHON3_INCLUDE_DIR=$(python3-config --prefix)/include/python3.9 -DOPENSSL_ROOT_DIR=/usr/local/Cellar/openssl@1.1/1.1.1o/ 官方文档方案 12345678910111213141516171819202122232425262728293031brew install llvmbrew install snappy ccache cmake pkg-configpip install cythonpip3 install cythonbrew cask install osxfusemkdir buildcd buildexport PKG_CONFIG_PATH=/usr/local/Cellar/nss/3.48/lib/pkgconfig:/usr/local/Cellar/openssl/1.0.2t/lib/pkgconfigcmake .. -DBOOST_J=4 \\ -DCMAKE_C_COMPILER=/usr/local/opt/llvm/bin/clang \\ -DCMAKE_CXX_COMPILER=/usr/local/opt/llvm/bin/clang++ \\ -DCMAKE_EXE_LINKER_FLAGS=&quot;-L/usr/local/opt/llvm/lib&quot; \\ -DENABLE_GIT_VERSION=OFF \\ -DSNAPPY_ROOT_DIR=/usr/local/Cellar/snappy/1.1.7_1 \\ -DWITH_BABELTRACE=OFF \\ -DWITH_BLUESTORE=OFF \\ -DWITH_CCACHE=OFF \\ -DWITH_CEPHFS=OFF \\ -DWITH_KRBD=OFF \\ -DWITH_LIBCEPHFS=OFF \\ -DWITH_LTTNG=OFF \\ -DWITH_LZ4=OFF \\ -DWITH_MANPAGE=ON \\ -DWITH_MGR=OFF \\ -DWITH_MGR_DASHBOARD_FRONTEND=OFF \\ -DWITH_RADOSGW=OFF \\ -DWITH_RDMA=OFF \\ -DWITH_SPDK=OFF \\ -DWITH_SYSTEMD=OFF \\ -DWITH_TESTS=OFF \\ -DWITH_XFS=OFF 由于我的主要目的是在CLion中使用, 所以我在Perference-&gt;Build,Execution,Deployment-&gt;Cmake-&gt;Cmake Options中添加的是上面的配置的单行形式. 出现的报错 BUILD NSS_INCLUDE_DIRS: NSS_INCLUDE_DIR-NOTFOUND 查看find_package(NSS)中调用的其实是pkg-config来查找nss.pc, 使用pkg-config --cflags --libs nss报不存在, 所以说明pkg-config的扫描路径中没有上面这个pc文件. 通过brew list nss查找到nss.pc文件所在, 通过pkg-config --variable pc_path pkg-config找到pc的默认搜索路径, 有两种方案 1. 做个软链到pkg-config的默认搜索路径中 1ln -s /usr/local/Cellar/nss/3.35/lib/pkgconfig/nss.pc /usr/local/lib/pkgconfig/nss.pc 2. pkg_config使用的搜索环境变量PKG_CONFIG_PATH中导入 1export PKG_CONFIG_PATH=/usr/local/Cellar/nss/3.48/lib/pkgconfig:/usr/local/Cellar/ 我采用的第一种方案. 同理,还会出现nspr等需要这样处理的库. NOT find PythonLibs: Found unsuitable version \"2.7.10\", but required[^3] 在CMake选项中增加指定下述的python库和头文件路径 1-DPYTHON_LIBRARY=$(python-config --prefix)/lib/libpython2.7.dylib -DPYTHON_INCLUDE_DIR=$(python-config --prefix)/include/python2.7 TestBigEndian.cmake:49 (message): no suitable type found 暂时看到的资料都是说需要看测试代码和修改cmake文件的样子, 我并不需要编译, 只是需要建立索引, 所以我暂时注释了这部分的检查[^4,5,6] Nautilus 采用同样的方案, 暂时未去推进. 遇到的问题 findboost unknown compiler: AppleClang 报了一个暂时没去尝试解决的错误, 识别不了clang? master 1export PKG_CONFIG_PATH=/usr/local/Cellar/nss/3.35/lib/pkgconfig:/usr/local/Cellar/openssl@1.1/1.1.1o/lib/pkgconfig 把这里unknown compiler这段给屏蔽掉, 试试. 123456789if(CMAKE_CXX_COMPILER_ID STREQUAL GNU) set(toolset gcc)elseif(CMAKE_CXX_COMPILER_ID STREQUAL Clang) set(toolset clang)else()# 换成这个 set(toolset clang)# message(SEND_ERROR &quot;unknown compiler: $&#123;CMAKE_CXX_COMPILER_ID&#125;&quot;)endif() 1cmake -DCMAKE_C_COMPILER=/usr/bin/clang -DCMAKE_CXX_COMPILER=/usr/bin/clang++ -DCMAKE_EXE_LINKER_FLAGS=&quot;-L/usr/local/opt/llvm/lib&quot; -DENABLE_GIT_VERSION=OFF -DSNAPPY_ROOT_DIR=/usr/local/Cellar/snappy/1.1.7_1 -DWITH_BABELTRACE=OFF -DWITH_BLUESTORE=OFF -DWITH_CCACHE=OFF -DWITH_CEPHFS=OFF -DWITH_KRBD=OFF -DWITH_LIBCEPHFS=OFF -DWITH_LTTNG=OFF -DWITH_LZ4=OFF -DWITH_MANPAGE=ON -DWITH_MGR=OFF -DWITH_MGR_DASHBOARD_FRONTEND=OFF -DWITH_RADOSGW=OFF -DWITH_RDMA=OFF -DWITH_SPDK=OFF -DWITH_SYSTEMD=OFF -DWITH_TESTS=OFF -DWITH_XFS=OFF -DCMAKE_C_COMPILER=/usr/bin/clang -DCMAKE_CXX_COMPILER=/usr/bin/clang++ -DCMAKE_EXE_LINKER_FLAGS=&quot;-L/usr/local/opt/llvm/lib&quot; -DENABLE_GIT_VERSION=OFF -DSNAPPY_ROOT_DIR=/usr/local/Cellar/snappy/1.1.7_1 -DWITH_BABELTRACE=OFF -DWITH_BLUESTORE=OFF -DWITH_CCACHE=OFF -DWITH_CEPHFS=OFF -DWITH_KRBD=OFF -DWITH_LIBCEPHFS=OFF -DWITH_LTTNG=OFF -DWITH_LZ4=OFF -DWITH_MANPAGE=ON -DWITH_MGR=OFF -DWITH_MGR_DASHBOARD_FRONTEND=OFF -DWITH_RADOSGW=OFF -DWITH_RDMA=OFF -DWITH_SPDK=OFF -DWITH_SYSTEMD=OFF -DWITH_TESTS=OFF -DWITH_XFS=OFF -DCMAKE_EXPORT_COMPILE_COMMANDS=on -DPYTHON_LIBRARY=$(python-config --prefix)/lib/libpython2.7.dylib -DPYTHON_INCLUDE_DIR=$(python-config --prefix)/include/python2.7 -DPYTHON3_LIBRARY=$(python3-config --prefix)/lib/libpython3.9.dylib -DPYTHON3_INCLUDE_DIR=$(python3-config --prefix)/include/python3.9 -DOPENSSL_ROOT_DIR=/usr/local/Cellar/openssl@1.1/1.1.1o/ .. 用来索引好像还是用的. 调试增加选项 1./configure CFLAGS=&#x27;-g3 -O0&#x27; CXXFLAGS=&#x27;-g3 -O0&#x27;. github版本cmake报缺失rocksdb和zstd git里面有一些submodule, 这部分我没能拖回来, 导致这些目录是空的, 静态编译没能启动. rocksdb zstd civetweb dpdk googletest isa-l lua rapidjson spdk xxHash todo 问题并不是真正的CMakeLists.txt. CLion解析了cmake中引用的所有源文件,以启用大多数功能(导航,code-completion,重构).根据我的经验,索引大型项目可以花费几分钟(十分钟). 减轻这个问题的一种方法是标记项目的“第三方”目录:右键单击您的common目录和Mark directory as... &gt; Libraries.如果需要,您甚至可以将目录排除在项目之外. 还请注意,CLion索引的结果被缓存:在初始索引之后,即使在重新启动项目时,只应修复经修改的文件(注意,修改CMakeLists中的构建选项可能触发完整的reindex) 索引代码理论上只需要选择这些代码文件就可以, 但是实际上像ceph如果我cmake工程没能成功编译,他也是并没有把函数的调用关系给分析出来的. 哎, 静态分析功能还是得依赖clang. 根据CI里的log来看, 的确只是yum install ceph这种形式直接安装成果物构造image. 那src.rpm编译出成果物是在哪个jenkins里做的呢? Reference build on MacOS — Ceph Documentation pkg-config 路径问题 - 采男孩的小蘑菇 - 博客园 CMake finding Python library and Python interpreter mismatch during pybind11 build · Issue #99 · pybind/pybind11 Re: Weird CMake failures building 10.4 on MacOS High Sierra (10.13) TestBigEndian.cmake:51 (messag no suitable type found (#16283) · Issues · CMake / CMake · GitLab windows - CMake internal error (TEST_BIG_ENDIAN) - Stack Overflow dockerize ceph集群和shell脚本编程 - 知乎 CEPH CRUSH algorithm source code analysis ceph/daemon - Docker Hub Quay Container Registry · Quay ceph/ceph-container: Docker files and images to run Ceph in containers ricardoasmarques/ceph-dev-docker Build Ceph — Ceph Documentation TUMBLEWEED Cant install python-lxml Opensuse Tumbleweed ceph luminous版本编译及部署 | itocm.com","categories":[{"name":"专业","slug":"pro","permalink":"https://sean10.github.io/categories/pro/"}],"tags":[{"name":"ceph","slug":"ceph","permalink":"https://sean10.github.io/tags/ceph/"},{"name":"编译","slug":"编译","permalink":"https://sean10.github.io/tags/%E7%BC%96%E8%AF%91/"}]},{"title":"diff与merge实践初探","slug":"diff与merge实践初探","date":"2020-10-08T14:14:57.000Z","updated":"2023-03-18T15:11:14.810Z","comments":true,"path":"2020/10/08/diff与merge实践初探/","link":"","permalink":"https://sean10.github.io/2020/10/08/diff%E4%B8%8Emerge%E5%AE%9E%E8%B7%B5%E5%88%9D%E6%8E%A2/","excerpt":"概念 diff和merge是一回事吗? 实际上是两回事. 如果可以通过已知的规则, 比如同时保留双方不一致内容, 自动merge, 那属于diff可以做到的内容. 但是如果想要手动merge, 比如展示开来, 然后一行行比较人工决定使用哪份, 这个就不属于diff提供的功能了, 需要一个展示diff结果然后保存回原始文件中的工具, 这个就属于编辑器的范畴了. 像beyond compare这种更像是一个集成了差异比较功能的编辑器了.","text":"概念 diff和merge是一回事吗? 实际上是两回事. 如果可以通过已知的规则, 比如同时保留双方不一致内容, 自动merge, 那属于diff可以做到的内容. 但是如果想要手动merge, 比如展示开来, 然后一行行比较人工决定使用哪份, 这个就不属于diff提供的功能了, 需要一个展示diff结果然后保存回原始文件中的工具, 这个就属于编辑器的范畴了. 像beyond compare这种更像是一个集成了差异比较功能的编辑器了. diff和patch和RCS版本控制关系? unified输出的diff就是一个patch, 然后通过patch命令打入. 基于上面的开发出了Source Code Control System和Revision Control System(RCS).RCS新增了lock的功能, 防止文件被其他人checkout之后修改了. 123456789ci a.txt #lockci -l a.txt # checkinci -u a.txt# 查看日志rlog a.txt# 获取patchrcsdiff -u -r1.1 -r1.2 a.txt 执行上面的命令就能把文件纳入版本控制, 会在当前目录生成对应文件的管理. CVS和Subvision的诞生 中心化版本控制系统 都是通过保存diff原型的changeset来保存作为日志. 另外增加了branch, trunk这些概念. Git和Mercurial 分布式版本控制系统 \b基本操作单位从上面的changeset变成了blob(压缩保存的完整文件). 所以在查询diff时是当前做的比较,而不是直接输出结果, git log --patch. diff 支持格式 命令模式(normal) ed命令模式 RCS(Revision Control System) 上下文模式(context) 我们目前默认用的diff和patch用的基本都是这个模式的样子. unified模式 简化了上下文模式同时显示2个文件的操作, 只显示第一个文件的那些行及要做的操作 命令 12345diff -e a.txt b.txt &gt; c.ed# 输出ed脚本, 可以让a文件和b文件一致.diff -n a.txt b.txt &gt; c.rcs# 输出RCS格式的脚本 merge[^5] sdiff和diff3之类的支持merge的操作. diff自身也支持一定的if-then-else的merge操作 样例文件 a.txt 1234567891011The Way that can be told of is not the eternal Way;The name that can be named is not the eternal name.The Nameless is the origin of Heaven and Earth;The Named is the mother of all things.Therefore let there always be non-being, so we may see their subtlety,And let there always be being, so we may see their outcome.The two are the same,But after they are produced, they have different names. b.txt 12345678910111213The Nameless is the origin of Heaven and Earth;The named is the mother of all things.Therefore let there always be non-being, so we may see their subtlety,And let there always be being, so we may see their outcome.The two are the same,But after they are produced, they have different names.They both may be called deep and profound.Deeper and more profound,The door of all subtleties! 自带的配合C语言的 1diff -DTWO a.txt b.txt 等价于下面这段,这段等后面的自定义掌握之后比较好看懂. 1234567891011--old-group-format=&#x27;#ifndef name%&lt;#endif /* ! name */&#x27; \\--new-group-format=&#x27;#ifdef name%&gt;#endif /* name */&#x27; \\--unchanged-group-format=&#x27;%=&#x27; \\--changed-group-format=&#x27;#ifndef name%&lt;#else /* name */%&gt;#endif /* name */&#x27; 输出得到的是以第二个文件为基础的ifndef之类的分支. 1234567891011121314151617181920212223242526#ifndef TWOThe Way that can be told of is not the eternal Way;The name that can be named is not the eternal name.#endif /* ! TWO */The Nameless is the origin of Heaven and Earth;#ifndef TWOThe Named is the mother of all things.#else /* TWO */The named is the mother of all things.#endif /* TWO */Therefore let there always be non-being, so we may see their subtlety,And let there always be being, so we may see their outcome.The two are the same,But after they are produced,#ifndef TWO they have different names.#else /* TWO */ they have different names.They both may be called deep and profound.Deeper and more profound,The door of all subtleties!#endif /* TWO */ group line format (GFMT GTYPE) 基本上这里的区分主要就是多行匹配和单行匹配的区别了. 和LFMT同时运行的时候, 匹配了单行之后, 多行匹配也会触发一次. 具体暂时不知道运行时是先按多行还是单行扫, 总之看到的结果是两项修改均会触发. 主要会有以下几种结果. * --old-group-format=format * --new-group-format=format * --changed-group-format=format * 目前来看,如果配置了这条, 则--new-group-format基本上会被替换成这个. * 只有当这条没设置的时候, 可以让new生效. * --unchanged-group-format=format 1234567891011121314151617181920212223242526diff \\ --old-group-format=&#x27;\\begin&#123;old&#125;%&lt;\\end&#123;old&#125;&#x27; \\ --new-group-format=&#x27;\\begin&#123;bf&#125;%&gt;\\end&#123;bf&#125;&#x27; \\--unchanged-group-format=&#x27;%=&#x27; \\ --changed-group-format=&#x27;\\begin&#123;em&#125;%&lt;\\end&#123;em&#125;\\begin&#123;bf&#125;%&gt;\\end&#123;bf&#125;&#x27; \\ a.txt b.txt diff \\ --unchanged-group-format=&#x27;%%&#x27; \\ --old-group-format=&#x27;-------- %dn line%(n=1?:s) deleted at %df:%&lt;&#x27; \\ --new-group-format=&#x27;-------- %dN line%(N=1?:s) added after %de:%&gt;&#x27; \\ --changed-group-format=&#x27;-------- %dn line%(n=1?:s) changed at %df:%&lt;-------- to:%&gt;&#x27; \\ a.txt b.txt &gt; output.4 上面这段的%(n=1?:s)一开始一点都不理解是啥意思, 突然才反应过来是line和lines的区别...还以为这个N是和前面的%dn有关的... 格式符 ‘%&lt;’ stands for the lines from the first file, including the trailing newline. Each line is formatted according to the old line format (see Line Formats). ‘%&gt;’ stands for the lines from the second file, including the trailing newline. Each line is formatted according to the new line format. ‘%=’ stands for the lines common to both files, including the trailing newline. Each line is formatted according to the unchanged line format. 上面这几个, 分别代表旧文件, 新文件, 两个文件中相同的内容. ‘Fn’ where F is a printf conversion specification and n is one of the following letters, stands for n’s value formatted with F. ‘e’ The line number of the line just before the group in the old file. ‘f’ The line number of the first line in the group in the old file; equals e + 1. ‘l’ The line number of the last line in the group in the old file. ‘m’ The line number of the line just after the group in the old file; equals l + 1. ‘n’ The number of lines in the group in the old file; equals l - f + 1. ‘E, F, L, M, N’ Likewise, for lines in the new file. ‘(A=B?T:E)’ If A equals B then T else E. A and B are each either a decimal constant or a single letter interpreted as above. This format spec is equivalent to T if A’s value equals B’s; otherwise it is equivalent to E. For example, ‘%(N=0?no:%dN) line%(N=1?:s)’ is equivalent to ‘no lines’ if N (the number of lines in the group in the new file) is 0, to ‘1 line’ if N is 1, and to ‘%dN lines’ otherwise. 单纯格式符和行号这部分, 基本按照printf的使用方式就可以了. 输出 12345678910111213141516171819202122232425262728\\begin&#123;old&#125;The Way that can be told of is not the eternal Way;The name that can be named is not the eternal name.\\end&#123;old&#125;The Nameless is the origin of Heaven and Earth;\\begin&#123;old&#125;The Named is the mother of all things.\\end&#123;old&#125;\\begin&#123;bf&#125;The named is the mother of all things.\\end&#123;bf&#125;Therefore let there always be non-being, so we may see their subtlety,And let there always be being, so we may see their outcome.The two are the same,But after they are produced,\\begin&#123;old&#125; they have different names.\\end&#123;old&#125;\\begin&#123;bf&#125; they have different names.They both may be called deep and profound.Deeper and more profound,The door of all subtleties!\\end&#123;bf&#125; Line Format (LFMT LTYPE) 主要做差异有这几种结果. * --old-line-format=format * --new-line-format=format * --unchanged-line-format=format 1234567891011121314diff \\ --old-line-format=&#x27;&lt; %l&#x27; \\ --new-line-format=&#x27;&gt; %l&#x27; \\ --old-group-format=&#x27;%df%(f=l?:,%dl)d%dE%&lt;&#x27; \\ --new-group-format=&#x27;%dea%dF%(F=L?:,%dL)%&gt;&#x27; \\ --changed-group-format=&#x27;%df%(f=l?:,%dl)c%dF%(F=L?:,%dL)%&lt;---%&gt;&#x27; \\ --unchanged-group-format=&#x27;&#x27; \\ a.txt b.txt 使用这个的时候,发生这样一个问题, 只能看到触发了--old-group-format和--changed-group-format, 没变化的那种倒是没发现 输出 123456789101112131415161,2d0&lt; The Way that can be told of is not the eternal Way;&lt; The name that can be named is not the eternal name.4c2,3&lt; The Named is the mother of all things.---&gt; The named is the mother of all things.&gt; 11c10,13&lt; they have different names.---&gt; they have different names.&gt; They both may be called deep and profound.&gt; Deeper and more profound,&gt; The door of all subtleties! 格式符 In a line format, ordinary characters represent themselves; conversion specifications start with ‘%’ and have one of the following forms. ‘%l’ stands for the contents of the line, not counting its trailing newline (if any). This format ignores whether the line is incomplete; See Incomplete Lines. ‘%L’ stands for the contents of the line, including its trailing newline (if any). If a line is incomplete, this format preserves its incompleteness. ‘%%’ stands for ‘%’. ‘%c'C'’ where C is a single character, stands for C. C may not be a backslash or an apostrophe. For example, ‘%c':'’ stands for a colon. ‘%c''’ where O is a string of 1, 2, or 3 octal digits, stands for the character with octal code O. For example, ‘%c'\\0'’ stands for a null character. ‘Fn’ where F is a printf conversion specification, stands for the line number formatted with F. For example, ‘%.5dn’ prints the line number using the printf format \"%.5d\". See Line Group Formats, for more about printf conversion specifications. 自定义需求 合并两个文件, 比如跨平台编辑笔记时, 多个文本都出现了新增内容, 同步盘创建了Conflict文件的时候 1diff --old-line-format=%L --new-line-format=%L a.txt b.txt 直接双向合并就行了. Reference man diff linux - Manually merge two files using diff - Stack Overflow 用Diff和Patch工具维护源码 版本控制 — Unix 即集成开发环境 1.0 文档 If-then-else (Comparing and Merging Files)","categories":[{"name":"专业","slug":"pro","permalink":"https://sean10.github.io/categories/pro/"}],"tags":[{"name":"linux","slug":"linux","permalink":"https://sean10.github.io/tags/linux/"},{"name":"diff","slug":"diff","permalink":"https://sean10.github.io/tags/diff/"},{"name":"merge","slug":"merge","permalink":"https://sean10.github.io/tags/merge/"},{"name":"git","slug":"git","permalink":"https://sean10.github.io/tags/git/"}]},{"title":"vscode之增加quote实现","slug":"vscode之增加quote实现","date":"2020-09-12T08:30:13.000Z","updated":"2023-03-18T15:11:14.892Z","comments":true,"path":"2020/09/12/vscode之增加quote实现/","link":"","permalink":"https://sean10.github.io/2020/09/12/vscode%E4%B9%8B%E5%A2%9E%E5%8A%A0quote%E5%AE%9E%E7%8E%B0/","excerpt":"","text":"增加quote功能 主要有整理笔记时, 有些内容需要注意引用的需求, 在给[^2]提交PR后很可惜作者一直没有上线, 就去提交给了markdown all in one, 在大佬们的讨论中, 发现这样一个场景, markdown的语法中对于引用只要求&gt;符号即可, 但是在各渲染及自动补充的实现中, 追加空格是个优雅的习惯. 然后在[^3]的review中, 大佬发现针对是否增加空格, 针对多级列表, github的markdown渲染的表现还不一致. 这就导致这套实现存在局限性了, 轻易引入存在较大bug风险了. 所以这个插件暂时主要用于下述需求的场景, 对于需要对多级列表等进行引用的场景, 还没有一个比较好的方案. 自己先单独封装了一个来使用. 场景 当cursor在某个位置, 未选中任何内容 需求: 该行行首增加&gt;即可 当选中了单行中的部分文本 该文本所在行首增加&gt; 当选中了多行文本 每行选中文本的行首增加&gt;即可. 或者根据每行行首绝对如何反转,是增加还是删除 不对,根据我个人的需求, 应该是三种状态, 如果存在未补全的, 则补全. 如果全部补全了才需要进行反转. 针对一些非标准格式的quote是否需要支持修改? 增加一个修正吧. 只要是匹配规则的, 都进行修正. 主要只针对缩进的吧. 实现 1. 找一下该插件中提供文本内容的显示的接口 123let editor = window.activeTextEditor;let lineIndex = editor.selection.active.line;let lineText = editor.document.lineAt(lineIndex).text; 上面的接口似乎满足了第一需求 2. 寻找如何根据获取选中内容部分的当前行内容的行首指针. 这个通过获取到start所在line的Start就可以了. 3. 针对第三种需求的三种状态切换 进行简化 场景一和场景二的最终动作都是在该行增加&gt; 场景一和场景二? 增加一个循环, 一开始获取到selection的时候就可以设置为循环, 最后处理为循环内每行遍历. 如果是场景一和场景二那就是处理当行 都是根据遍历后的状态进行处理. 首先一开始,场景一可以提取为场景二, 获取到指针所在行的全部内容, 场景三, 由于我们不关心尾部内容,因此其实也就是场景二的状态,只需要处理start所在指针的内容.(PS, 后来发现如果不关心尾部内容,也是存在问题的, 插入内容的时候直接导致尾部的文字会被替换一部分)","categories":[{"name":"专业","slug":"pro","permalink":"https://sean10.github.io/categories/pro/"}],"tags":[{"name":"vscode","slug":"vscode","permalink":"https://sean10.github.io/tags/vscode/"},{"name":"typescript","slug":"typescript","permalink":"https://sean10.github.io/tags/typescript/"}]},{"title":"mac远程桌面踩坑","slug":"mac远程桌面踩坑","date":"2020-07-11T04:12:23.000Z","updated":"2023-03-18T15:11:14.886Z","comments":true,"path":"2020/07/11/mac远程桌面踩坑/","link":"","permalink":"https://sean10.github.io/2020/07/11/mac%E8%BF%9C%E7%A8%8B%E6%A1%8C%E9%9D%A2%E8%B8%A9%E5%9D%91/","excerpt":"","text":"背景 最近要做痔疮手术, 术后有一段时间估计是还不能坐着的. 台式机就没有办法用上了, 但是笔记本的性能还是有点差,内存也不太够. \b工具 主要有以下以及更多的访问方式 vnc的一系统访问方式 Apple Remote Desktop VNC等工具 封装了vnc协议的类似xrdp的工具 Jump Desktop 踩坑实验记录 vnc直接修改分辨率 一开始我直接用的\b\b自带的finder里的vnc访问的, 效果还可以.不过因为笔记本只有13寸,访问3840*2160的台式机, 分辨率用系统配置的display最低也只能设计成拟合1920*1080的, 相比我一般设置成2560*1440拟合1280*720的笔记本的字实在是小太多了. 据我所知, windows的rdp是可以做到让渲染在客户端设备执行的逻辑的, 这样就无所谓我目标设备分辨率到底是多少了. 然而,很可惜, 经过调查, mac端主要也就上面这几种工具. apple remote desktop主要也只是基于vnc进行的封装,而vnc的渲染主要是在服务端进行的, 客户端只是直接显示的效果. 对于基于这种协议的远程访问工具只能直接修改服务端设备的分辨率来适应客户端, linux端至少看到的一般的解决方式都是这样的. 原生设置能够控制的分辨率还是有限, 最后我用了SwitchResX来进行的分辨率修改, 修改成拟合1440*900在客户端上用的. 无显示器操作方案[^2] 偶然看到好像有人提到没有接显示器的mac mini, 有人试着远程连接直接修改分辨率. 看到针对没有显示器连接的时候, 分辨率也能够修改. 我就试验了下SwitchResx, 发现居然的确显示了一个Virtual Desktop,可以修改的分辨率基本上都是客户端\b\b\b的分辨率. 基本上达到我的目的了. 无显示器竖屏方案[^3] 12345678910111213141516171819202122232425262728293031323334353637383940414243#displayplacer➜ ~ displayplacer listPersistent screen id: FFFFFFFF-FFFF-FFFF-FFFF-FFFFFFFFFFFFContextual screen id: 1104977160Type: MacBook built in screenResolution: 1440x900Hertz: 60Color Depth: 4Scaling:onOrigin: (0,0) - main displayRotation: 0 - rotate internal screen example (may crash computer, but will be rotated after rebooting): `displayplacer &quot;id:FFFFFFFF-FFFF-FFFF-FFFF-FFFFFFFFFFFF degree:90&quot;`Resolutions for rotation 0: mode 0: res:1x1 hz:60 color_depth:4 mode 1: res:800x600 hz:60 color_depth:4 mode 2: res:1024x768 hz:60 color_depth:4 mode 3: res:1280x720 hz:60 color_depth:4 mode 4: res:1280x1024 hz:60 color_depth:4 mode 5: res:1440x900 hz:60 color_depth:4 mode 6: res:1680x1050 hz:60 color_depth:4 mode 7: res:1920x1080 hz:60 color_depth:4 mode 8: res:2560x1440 hz:60 color_depth:4 mode 9: res:2560x1600 hz:60 color_depth:4 mode 10: res:3840x2160 hz:60 color_depth:4 mode 11: res:1024x640 hz:60 color_depth:4 scaling:on mode 12: res:1152x720 hz:60 color_depth:4 scaling:on mode 13: res:1152x800 hz:60 color_depth:4 scaling:on mode 14: res:1440x900 hz:60 color_depth:4 scaling:on &lt;-- current mode mode 15: res:1680x1050 hz:60 color_depth:4 scaling:on mode 16: res:1920x1200 hz:60 color_depth:4 scaling:on mode 17: res:1504x846 hz:60 color_depth:4 scaling:on mode 18: res:1920x1080 hz:60 color_depth:4 scaling:on mode 19: res:2048x1152 hz:60 color_depth:4 scaling:on mode 20: res:2304x1296 hz:60 color_depth:4 scaling:on mode 21: res:2560x1440 hz:60 color_depth:4 scaling:on mode 22: res:3008x1692 hz:60 color_depth:4 scaling:on mode 23: res:3360x1890 hz:60 color_depth:4 scaling:on mode 24: res:3840x2160 hz:60 color_depth:4 scaling:on mode 25: res:4096x2160 hz:60 color_depth:4 scaling:on mode 26: res:1280x1024 hz:60 color_depth:4Execute the command below to set your screens to the current arrangement:displayplacer &quot;id:FFFFFFFF-FFFF-FFFF-FFFF-FFFFFFFFFFFF res:1440x900 hz:60 color_depth:4 scaling:on origin:(0,0) degree:0&quot; 1234#Example:displayplacer &quot;id:18173D22-3EC6-E735-EEB4-B003BF681F30+F466F621-B5FA-04A0-0800-CFA6C258DECD res:1440x900 scaling:on origin:(0,0) degree:0&quot;displayplacer &quot;id:FFFFFFFF-FFFF-FFFF-FFFF-FFFFFFFFFFFF res:1440x900 scaling:on origin:(0,0) degree:90&quot; fb-rotate 12fb-rotate -l 方案 最后总结的方案主要就是下述两种了. 1. 基于SwitchResX直接修改服务端的分辨率 2. 拔掉服务端连接的显示器,这个时候用SwitchResX基本上就可以设置成客户端的分辨率了. 目前我主要用的就是第二套方案了. Reference Apple Remote Desktop 真是垃圾中的战斗机 - V2EX Force the resolution on a headless mac mini server - Ask Different jakehilborn/displayplacer: macOS command line utility to configure multi-display resolutions and arrangements. Essentially XRandR for macOS. CdLbB/fb-rotate: A Unix utility to rotate the display on any Mac and switch the primary display back and forth between displays.","categories":[{"name":"专业","slug":"pro","permalink":"https://sean10.github.io/categories/pro/"}],"tags":[{"name":"mac","slug":"mac","permalink":"https://sean10.github.io/tags/mac/"},{"name":"rdp","slug":"rdp","permalink":"https://sean10.github.io/tags/rdp/"},{"name":"vnc","slug":"vnc","permalink":"https://sean10.github.io/tags/vnc/"}]},{"title":"ceph之Nautilus版本引入的Perf统计","slug":"ceph之Nautilus版本引入的Perf统计","date":"2020-07-05T16:15:48.000Z","updated":"2023-03-18T15:11:14.895Z","comments":true,"path":"2020/07/06/ceph之Nautilus版本引入的Perf统计/","link":"","permalink":"https://sean10.github.io/2020/07/06/ceph%E4%B9%8BNautilus%E7%89%88%E6%9C%AC%E5%BC%95%E5%85%A5%E7%9A%84Perf%E7%BB%9F%E8%AE%A1/","excerpt":"","text":"背景 Nautilus在OSD和MGR中合并了通用的度量收集框架，以提供内置的监视，并且在该框架之上构建了新的RBD性能监视工具，以将各个RADOS对象度量转换为针对IOPS，吞吐量和性能的聚合RBD镜像度量。这些指标都是在Ceph集群本身内部生成和处理的，因此无需访问客户端节点即可获取指标。 源码阅读过程 新增接口 12rbd perf image iostat rbd perf image iotop 根据这里v14.2.9 Nautilus — Ceph Documentation New rbd perf image iotop and rbd perf image iostat commands provide an iotop- and iostat-like IO monitor for all RBD images. The ceph-mgr Prometheus exporter now optionally includes an IO monitor for all RBD images. 应该是在14.2.0的发布里完成的，那这次大版本包含了什么？小版本更新会包含pr和issue链接 14版本还增加了ceph config全局配置修改的功能。 ceph14支持pg数减小和pg数根据pool容量自动调整 ceph telemetry命令用ceph mgr module enable telemetry启用，但是对telemetry不了解也跳过了。 这个应该就是我要看到的openTelemetry Ceph v12.2.13 Luminous released - Ceph 这个应该是12版本最后一次补丁升级吧 这个里不包含大版本开发的代码 rbd: implement new 'rbd perf image iostat/iotop' commands by dillaman · Pull Request #26133 · ceph/ceph 就这个提交来看，大部分代码都在处理上下文的接口适配,增加选项，假如说这套代码里只是使用已经增加的接口，那么代码里就应该有调用的API 这个问题怎么才能验证? src/toos/rbd/action/Perf.cc这个新增文件，依赖的是rbd perf image stats。 然后rbd perf image stats也是这次commit里增加的，是继承MgrModule使用API实现的，看看这里面用的哪些api. 应该就是这里拿的了 register_osd_perf_queries好像有点像了。 这里使用了mgr_module.py提供的add_osd_perf_query 从这里拿到了osd层面的ops,write_ops, read_ops, bytes, write_bytes, latency这些内容 拿到osd的结果，怎么计算出rbd层的？ 他这里只查appplication_metadata里有rbd这个的资源池，然后拿到资源池的osd_map user_query变量里，QUERY_POOL_ID_MAP拿到了 在PerfHandler里进行的周期查询perf数据。 在这里周期获取数据时又调用了mgr-module的get_osd_perf_counters。emm，这个函数在12版本我们的代码里还没有，不过单论这部分呼出，其实我们可以。这个函数在14版本里，prometheus也调用了这个，那就有意思了，prometheus刚好在这个版本支持了rbd performance monitor, ceph-export输出了这部分数据。那是不是就是从这里拿到的呢？（osd_perf_query_support 在这里ceph-mgr里面的_ceph_get_osd_perf_counters的内容。这个函数就是Cython的封装了。 get_osd_perf_counters这个封装，好像还是在ceph-mgr里提供的，果然。 在ActivePyModules.cc里又封装了一层，这里应该是从DaemonServer.cc里封装的实际逻辑了。 果然，在ActivePyModules里实例化了DaemonServer这个对象， 这里调用osd_perf_metric_collector的get_counters。OSDPerfMetricCollector这个类，应该是12版本之后给mgr好好梳理时更新出来的。 在OSDPerfMetricSubKeyDescriptor这个struct里，封装了支持的类型 卧槽，好像这里全覆盖了,在下面这里做的扩充。从Client，牛皮 osd: support more dynamic perf query subkey types by trociny · Pull Request #25371 · ceph/ceph 那OSDPerfMetricCollector呢，是在这个PR里增加的？ mgr: create shell OSD performance query class by trociny · Pull Request #24117 · ceph/ceph 在下面这里提到了，开启这个收集功能之后，这套功能会遇到rbd images数据过于庞大的问题， osd: collect client perf stats when query is enabled by trociny · Pull Request #24265 · ceph/ceph 再在这个类下面继续探究就有点难的感觉了。下面就越来越细，估计需要实机环境验证了。 Prior to Red Hat Storage 4, Ceph storage administrators have not had access to built-in RBD performance monitoring and metrics gathering tools. Ceph Storage 4 now incorporates a generic metrics gathering framework within the OSDs and MGRs to provide built-in monitoring, and new RBD performance monitoring tools are built on top of this framework to translate individual RADOS object metrics into aggregated RBD image metrics for Input/Output Operations per Second (IOPS), throughput, and latency. 好像在这篇文章里要解释到底是怎么计算的了。哦，没解释 eph ceph mgr module enable rbd_support Noisy Neighbors and QoS看到好几次，。 到底这部分是怎么计算出来的呢？ß Ceph Block Performance Monitoring the OSD-based statistical stats are the end solution since that can never provide the latencies that the client is actually experiencing. 这篇里提到这个链接，有点意思？ Live Performance Probes - Ceph - Ceph mgr, rbd: report rbd images perf stats to mgr by Yan-waller · Pull Request #16071 · ceph/ceph (看这篇) 目前的怀疑点是在Nautilus的版本里在osd那层新增了不少埋点数据收集 这里提到了SLA（服务等级协议service level agreement) （提问题的人说到了想要这种客户端级别的IOPSjiankong ） As we know, one perfcounter metric was created in ImageCtx when we opened a rbd image , but these metrics data is scattered and reside in kinds of clients, furthermore, a rbd image could be opened simultaneously by more than one client. report these information (especially ops, bytes, latency ) to MGR may be useful. Ultimately, I still expect that operational indicators that we send up to mgr will mostly get reported onwards to something else (nagios, zabbix, snmp, etc), so for O(clients) monitoring jobs we should consider skipping the middleman. 这个@jcsp大佬推荐是在mgr的插件层完成这个监控的操作，然后实际上好像也的确完成了。support-rbd啊，osd-perf-count啊，都是基于ceph-mgr的插件。 monitoring that gives them per-client throughput, latency and op type breakdown, I'm not sure how strong the push would be to implement the separate monitoring path to go get the client's view of the same set of stats. 待看mgr/prometheus: provide RBD stats via osd dynamic perf counters by trociny · Pull Request #25358 · ceph/ceph 在module.py里通过OSD_PERF_QUERY_COUNTERS_INDICES这个来把一个counter按照我们要的key导出数据。 extract_pool_key是用来提取像pool1/image0这样的spec字符串里的pool name的， user_queries到底是放了什么内容？ OSDPerfMetricCollectorListener这个应该是才是真实被Ceph-mgr实例化的内容。、 123class OSDPerfMetricCollectorListener : public OSDPerfMetricCollector::Listener 在DaemonServer初始化的时候 12345678910111213141516171819202122232425262728293031323334osd_perf_metric_collector_listener(this), osd_perf_metric_collector(osd_perf_metric_collector_listener)typedef int OSDPerfMetricQueryID;typedef std::pair&lt;uint64_t,uint64_t&gt; PerformanceCounter;typedef std::vector&lt;PerformanceCounter&gt; PerformanceCounters;struct PerformanceCounterDescriptor &#123; case PerformanceCounterType::OPS: case PerformanceCounterType::WRITE_OPS: case PerformanceCounterType::READ_OPS: case PerformanceCounterType::BYTES: case PerformanceCounterType::WRITE_BYTES: case PerformanceCounterType::READ_BYTES: case PerformanceCounterType::LATENCY: case PerformanceCounterType::WRITE_LATENCY: case PerformanceCounterType::READ_LATENCY:typedef std::vector&lt;std::string&gt; OSDPerfMetricSubKey; // array of regex matchtypedef std::vector&lt;OSDPerfMetricSubKey&gt; OSDPerfMetricKey;enum class OSDPerfMetricSubKeyType : uint8_t &#123; CLIENT_ID = 0, CLIENT_ADDRESS = 1, POOL_ID = 2, NAMESPACE = 3, OSD_ID = 4, PG_ID = 5, OBJECT_NAME = 6, SNAP_ID = 7,&#125;; 根据这里来看，果然是在Nautuil版本里，给ceph-mgr里增加了很多功能。 123456789 typedef std::map&lt;OSDPerfMetricQueryID, std::map&lt;OSDPerfMetricKey, PerformanceCounters&gt;&gt; Counters;int OSDPerfMetricCollector::get_counters( OSDPerfMetricQueryID query_id, std::map&lt;OSDPerfMetricKey, PerformanceCounters&gt; *c) &#123;int DaemonServer::get_osd_perf_counters( 这里调用到get_counter.这个接口被封装进pybind里了。 这里面的数据都是从哪里手机的呢？这个collector只是作为一个接口层提供收集的函数，手机的内容是通过指针穿进去的。还是存在了DaemonServer这个类里。 这里面到底调用了什么接口来收集osd？ OSDPerfMetricQueryID OSDPerfMetricCollector::add_query( 在这个函数里添加的到底是任务，还是收集的值呢？应该是任务吧？ 12typedef std::map&lt;OSDPerfMetricQuery, std::map&lt;OSDPerfMetricQueryID, OptionalLimit&gt;&gt; Queries; 这个和queries有什么关系呢？ 12345678910 typedef std::optional&lt;OSDPerfMetricLimit&gt; OptionalLimit; typedef std::map&lt;OSDPerfMetricQuery, std::map&lt;OSDPerfMetricQueryID, OptionalLimit&gt;&gt; Queries; typedef std::map&lt;OSDPerfMetricQueryID, std::map&lt;OSDPerfMetricKey, PerformanceCounters&gt;&gt; Counters; struct OSDPerfMetricLimit &#123; PerformanceCounterDescriptor order_by; uint64_t max_count = 0; 在bool DaemonServer::handle_report(MMgrReport *m)这个里 osd_perf_metric_collector.process_reports(m-&gt;osd_perf_metric_reports); 123456789class OSDPerfMetricCollectorListener : public OSDPerfMetricCollector::Listener &#123;public: OSDPerfMetricCollectorListener(DaemonServer *server) : server(server) &#123; &#125; void handle_query_updated() override &#123; server-&gt;handle_osd_perf_metric_query_updated(); &#125; 这里继承了Listener里的虚函数接口 12345678910111213141516171819202122232425void DaemonServer::handle_osd_perf_metric_query_updated()&#123; dout(10) &lt;&lt; dendl; // Send a fresh MMgrConfigure to all clients, so that they can follow // the new policy for transmitting stats finisher.queue(new FunctionContext([this](int r) &#123; std::lock_guard l(lock); for (auto &amp;c : daemon_connections) &#123; if (c-&gt;peer_is_osd()) &#123; _send_configure(c); &#125; &#125; &#125;));&#125;/** * This message is sent from ceph-mgr to MgrClient, instructing it * it about what data to send back to ceph-mgr at what frequency. */class MMgrConfigure : public MessageInstance&lt;MMgrConfigure&gt; &#123; mgr: update MMgrConfigure message to include optional OSD perf queries by colletj · Pull Request #24180 · ceph/ceph 可能数据是从MgrClient里来的？嗯，忘了之前看过, 现在也才意识到mgr其实分成了Server和client， osd和pg都看到了，但是其他的呢？如果只有这两个数据，那其他的rados那些是怎么算出来的？ set_perf_queries_cb(m-&gt;osd_perf_metric_queries); Ceph Manager Overview 这篇里主要讲的mgr的代码 以osd daemon为例，在启动过程中，会发送消息MMgrOpen，mgr收到后，会回复MMgrConfigure消息，主要是返回一个period时间，后续osd就根据设定的period， 定期将状态信息上报给mgr，即消息MMgrReport和MPGStats: 本以为这段代码里不涉及image的信息了 但是下面这段查询到的数据里显然带上了rbd的image信息 123456res = self.module.get_osd_perf_counters(query_id)for counter in res[&#x27;counters&#x27;]: raw_image[0] = None if not raw_image[0]: raw_image[0] = [now_ts, [int(x[0]) for x in counter[&#x27;c&#x27;]]] mgr: templatize metrics collection interface by vshankar · Pull Request #29214 · ceph/ceph 这里做了一层封装模板化 blame Daemon里的这个函数get_osd_perf_counters是下面这条里加的 mgr: make dynamic osd perf counters accessible from modules · vshankar/ceph@b8362d9 get_counters这个实际工作的方法呢？ mgr: store osd perf counters received in osd reports · vshankar/ceph@438a3f7 又没头绪了 还是回到prometheus这里使用上看看阿布 mgr/prometheus: provide RBD stats via osd dynamic perf counters by trociny · Pull Request #25358 · ceph/ceph 12345678910111213141516171819202122232425262728293031# Per RBD image stats is collected by registering a dynamic osd perf # stats query that tells OSDs to group stats for requests associated # with RBD objects by pool, namespace, and image id, which are # extracted from the request object names or other attributes. # The RBD object names have the following prefixes: # - rbd_data.&#123;image_id&#125;. (data stored in the same pool as metadata) # - rbd_data.&#123;pool_id&#125;.&#123;image_id&#125;. (data stored in a dedicated data pool) # - journal_data.&#123;pool_id&#125;.&#123;image_id&#125;. (journal if journaling is enabled) # The pool_id in the object name is the id of the pool with the image # metdata, and should be used in the image spec. If there is no pool_id # in the object name, the image pool is the pool where the object is # located. if &#x27;query_id&#x27; not in self.rbd_stats: query = &#123; &#x27;key_descriptor&#x27;: [ &#123;&#x27;type&#x27;: &#x27;pool_id&#x27;, &#x27;regex&#x27;: pool_id_regex&#125;, &#123;&#x27;type&#x27;: &#x27;namespace&#x27;, &#x27;regex&#x27;: namespace_regex&#125;, &#123;&#x27;type&#x27;: &#x27;object_name&#x27;, &#x27;regex&#x27;: &#x27;^(?:rbd|journal)_data\\.(?:([0-9]+)\\.)?([^.]+)\\.&#x27;&#125;, ], &#x27;performance_counter_descriptors&#x27;: list(counters_info), &#125; query_id = self.add_osd_perf_query(query) if query_id is None: self.log.error(&#x27;failed to add query %s&#x27; % query) return self.rbd_stats[&#x27;query&#x27;] = query self.rbd_stats[&#x27;query_id&#x27;] = query_id res = self.get_osd_perf_counters(self.rbd_stats[&#x27;query_id&#x27;]) 这段注释写的是真的好 所以其实还是这个借口的功能，类似mon_command，提供了根据传入的数据进行收集的操作。 这里也的确用上赋值逻辑 queryID到底是怎么期作用的？ 来自add_osd_perf_query OSDPerfMetricQueryID DaemonServer::add_osd_perf_query( 12345678910 query = &#123; &#x27;key_descriptor&#x27;: [ &#123;&#x27;type&#x27;: &#x27;pool_id&#x27;, &#x27;regex&#x27;: pool_id_regex&#125;, &#123;&#x27;type&#x27;: &#x27;namespace&#x27;, &#x27;regex&#x27;: namespace_regex&#125;, &#123;&#x27;type&#x27;: &#x27;object_name&#x27;, &#x27;regex&#x27;: &#x27;^(?:rbd|journal)_data\\.(?:([0-9]+)\\.)?([^.]+)\\.&#x27;&#125;, ], &#x27;performance_counter_descriptors&#x27;: list(counters_info),&#125;query_id = self.add_osd_perf_query(query) 使用上 mgr: create shell OSD performance query class · vshankar/ceph@a6c3390 这个add_osd_perf_query是在这里加的 add_query也是他家的。 1234567891011static PyObject*ceph_add_osd_perf_query(BaseMgrModule *self, PyObject *args)&#123; static const std::string NAME_KEY_DESCRIPTOR = &quot;key_descriptor&quot;; static const std::string NAME_COUNTERS_DESCRIPTORS = &quot;performance_counter_descriptors&quot;; static const std::string NAME_LIMIT = &quot;limit&quot;; static const std::string NAME_SUB_KEY_TYPE = &quot;type&quot;; static const std::string NAME_SUB_KEY_REGEX = &quot;regex&quot;; static const std::string NAME_LIMIT_ORDER_BY = &quot;order_by&quot;; static const std::string NAME_LIMIT_MAX_COUNT = &quot;max_count&quot;; 在封装python这里做的参数解析 1auto query_id = self-&gt;py_modules-&gt;add_osd_perf_query(query, limit); 所有属性都传到了limit里 在_send_configure的时候，把limit里的任务传给了MgrClient 1234567891011121314151617181920212223242526struct OSDPerfMetricLimit &#123; PerformanceCounterDescriptor order_by; uint64_t max_count = 0; OSDPerfMetricLimit() &#123; &#125; OSDPerfMetricLimit(const PerformanceCounterDescriptor &amp;order_by, uint64_t max_count) : order_by(order_by), max_count(max_count) &#123; &#125; bool operator&lt;(const OSDPerfMetricLimit &amp;other) const &#123; if (order_by != other.order_by) &#123; return order_by &lt; other.order_by; &#125; return max_count &lt; other.max_count; &#125; DENC(OSDPerfMetricLimit, v, p) &#123; DENC_START(1, 1, p); denc(v.order_by, p); denc(v.max_count, p); DENC_FINISH(p); &#125;&#125;; 传过去的应该是这个OptionalLimit吧，这个有啥用？ 里面有个order_by里申明是哪种type,是pg还是rados了好像 encode之后发送到mgrclient 看看怎么解码 std::function&lt;void(const std::map&lt;OSDPerfMetricQuery, OSDPerfMetricLimits&gt; &amp;)&gt; set_perf_queries_cb; 在这个MgrClient.cc里居然有2个set_perf_queries_cb 一个是封装的MgrClient对外暴露的函数，就是用来赋值的？ 一个是private的值，与mgr的Daemon沟通时进行调用。 但是这里好像只看到了osd.cc触发啊 这个被osd.cc里调用了 12void OSD::set_perf_queries( const std::map&lt;OSDPerfMetricQuery, OSDPerfMetricLimits&gt; &amp;queries) &#123; 怎么看上去osd.cc里不止负责普通的osd信息收集 在12版本里，这个OSD.cc里也有mgrc 在14版本里， std::list m_perf_queries;属于OSD这个class 123456789101112131415161718192021222324private: void set_perf_queries( const std::map&lt;OSDPerfMetricQuery, OSDPerfMetricLimits&gt; &amp;queries); void get_perf_reports( std::map&lt;OSDPerfMetricQuery, OSDPerfMetricReport&gt; *reports); Mutex m_perf_queries_lock = &#123;&quot;OSD::m_perf_queries_lock&quot;&#125;; std::list&lt;OSDPerfMetricQuery&gt; m_perf_queries; std::map&lt;OSDPerfMetricQuery, OSDPerfMetricLimits&gt; m_perf_limits; void get_perf_reports( std::map&lt;OSDPerfMetricQuery, OSDPerfMetricReport&gt; *reports); mgrc.set_pgstats_cb([this]()&#123; return collect_pg_stats(); &#125;); mgrc.set_perf_metric_query_cb( [this](const std::map&lt;OSDPerfMetricQuery, OSDPerfMetricLimits&gt; &amp;queries) &#123; set_perf_queries(queries); &#125;, [this](std::map&lt;OSDPerfMetricQuery, OSDPerfMetricReport&gt; *reports) &#123; get_perf_reports(reports); &#125;); mgrc.init(); osd把收集pg信息的回调函数设置到mgrc里,接下来应该是由mgrc来调用了把 在void MgrClient::_send_report()这里会触发调用. 理论上应该是 1234567891011121314151617181920void OSD::get_perf_reports( std::map&lt;OSDPerfMetricQuery, OSDPerfMetricReport&gt; *reports) &#123; std::vector&lt;PGRef&gt; pgs; _get_pgs(&amp;pgs); DynamicPerfStats dps; for (auto&amp; pg : pgs) &#123; // m_perf_queries can be modified only in set_perf_queries by mgr client // request, and it is protected by by mgr client&#x27;s lock, which is held // when set_perf_queries/get_perf_reports are called, so we may not hold // m_perf_queries_lock here. DynamicPerfStats pg_dps(m_perf_queries); pg-&gt;lock(); pg-&gt;get_dynamic_perf_stats(&amp;pg_dps); pg-&gt;unlock(); dps.merge(pg_dps); &#125; dps.add_to_reports(m_perf_limits, reports); dout(20) &lt;&lt; &quot;reports for &quot; &lt;&lt; reports-&gt;size() &lt;&lt; &quot; queries&quot; &lt;&lt; dendl;&#125; void add_to_reports( 下面这个数据在primary_log的里 12345678class PrimaryLogPG : public PG, public PGBackend::Listener &#123; DynamicPerfStats m_dynamic_perf_stats;void PrimaryLogPG::get_dynamic_perf_stats(DynamicPerfStats *stats) std::swap(m_dynamic_perf_stats, *stats); 而这个value在下面这里更新的 123void PrimaryLogPG::log_op_stats(const OpRequest&amp; op, m_dynamic_perf_stats.add(osd, info, op, inb, outb, latency); 差别可能真在这?在12版本的这个log_op_stats函数里,没有记录perf信息的. 123456789101112131415161718192021222324252627282930 auto m = static_cast&lt;const MOSDOp*&gt;(op.get_req());std::string match_string; switch(d.type) &#123; case OSDPerfMetricSubKeyType::CLIENT_ID: match_string = stringify(m-&gt;get_reqid().name); break; case OSDPerfMetricSubKeyType::CLIENT_ADDRESS: match_string = stringify(m-&gt;get_connection()-&gt;get_peer_addr()); break; case OSDPerfMetricSubKeyType::POOL_ID: match_string = stringify(m-&gt;get_spg().pool()); break; case OSDPerfMetricSubKeyType::NAMESPACE: match_string = m-&gt;get_hobj().nspace; break; case OSDPerfMetricSubKeyType::OSD_ID: match_string = stringify(osd-&gt;get_nodeid()); break; case OSDPerfMetricSubKeyType::PG_ID: match_string = stringify(pg_info.pgid); break; case OSDPerfMetricSubKeyType::OBJECT_NAME: match_string = m-&gt;get_oid().name; break; case OSDPerfMetricSubKeyType::SNAP_ID: match_string = stringify(m-&gt;get_snapid()); break; default: ceph_abort_msg(&quot;unknown counter type&quot;); &#125; 的确是在这个add这里加的,奇怪了.这里的m是怎么拿到所谓的snapobject这些信息的呢? 1234567891011121314151617181920212223 auto m = static_cast&lt;const MOSDOp*&gt;(op.get_req());Requests are MOSDOp messages. Replies are MOSDOpReply messages.An object request is targeted at an hobject_t, which includes a pool,hash value, object name, placement key (usually empty), and snapid.The hash value is a 32-bit hash value, normally generated by hashingthe object name. The hobject_t can be arbitrarily constructed,though, with any hash value and name. Note that in the MOSDOp thesecomponents are spread across several fields and not logicallyassembled in an actual hobject_t member (mainly historical reasons).A request can also target a PG. In this case, the *ps* value matchesa specific PG, the object name is empty, and (hopefully) the ops inthe request are PG ops.Either way, the request ultimately targets a PG, either by using theexplicit pgid or by folding the hash value onto the current number ofpgs in the pool. The client sends the request to the primary for theassociated PG.Each request is assigned a unique tid. 原来这里是osd的落盘请求链路,这里能通过req() 12345class MOSDOp : public MessageInstance&lt;MOSDOp, MOSDFastDispatchOp&gt; &#123; std::map&lt;OSDPerfMetricQuery, std::map&lt;OSDPerfMetricKey, PerformanceCounters&gt;&gt; data; osd: collect client perf stats when query is enabled by trociny · Pull Request #24265 · ceph/ceph 找到了,是在这个pr里增加的数据收集, 又是trociny这个大佬提交的. ceph tell mgr osd perf query add simple the mgr starts to receive perf report, writing to the log: 简单点说原理是在osd的最下层通过request的MOSDop这个类,查到这次request各层的名字,然后在对应的计数器数加一 123void PrimaryLogPG::log_op_stats(const OpRequest&amp; op, const uint64_t inb, const uint64_t outb) 在这的时候传入的op. 这个DynamicPerfStats.h的文件是在osd目录里. dps.merge(pg_dps);","categories":[{"name":"专业","slug":"pro","permalink":"https://sean10.github.io/categories/pro/"}],"tags":[{"name":"ceph","slug":"ceph","permalink":"https://sean10.github.io/tags/ceph/"},{"name":"perf","slug":"perf","permalink":"https://sean10.github.io/tags/perf/"},{"name":"rbd","slug":"rbd","permalink":"https://sean10.github.io/tags/rbd/"},{"name":"源码","slug":"源码","permalink":"https://sean10.github.io/tags/%E6%BA%90%E7%A0%81/"}]},{"title":"ceph之tier数据源码初探","slug":"ceph之tier数据源码初探","date":"2020-07-04T13:07:29.000Z","updated":"2023-03-18T15:11:14.882Z","comments":true,"path":"2020/07/04/ceph之tier数据源码初探/","link":"","permalink":"https://sean10.github.io/2020/07/04/ceph%E4%B9%8Btier%E6%95%B0%E6%8D%AE%E6%BA%90%E7%A0%81%E5%88%9D%E6%8E%A2/","excerpt":"","text":"理解 rados实现思路 TODO: rados对象相比一个文件, 其实差别就在于rados对象自带了offset位置的概念. 并不存在太多其他的元数据信息. 所以基本可以忽略rados对象的元数据信息? onode等可能不行? rados层的聚合, 即在tier上的时候, 表现就是存在这个rados对象, 但是这个rados对象只被识别出几K实际写入的对象大小. 而如果是聚合拼接时, 则意味着, 上层其实访问的也是这个大对象. 但是只访问这个对象中的一部分的时候, 怎么办呢? tier层访问的rados对象还是小的. 但是每次落下去会合并成大的. 那问题就来了. 读上来的时候读上来一批小对象, 第二次合并的时候的小对象必然不会是第一次那种组合了. 会是一个新的组合. 这个时候要落hdd, 如果直接合并, 那就是一批新的. 除非有一个journal的实现, 每次请求都是一种journal. tier的删和读, 写, 都以4M为粒度最好? 这些索引数据, 预计是需要放在ssd上的. 除非是对象存储那种, 只写一次, 所以他的小对象聚合, 不用考虑修改的问题. 只有写和读. 都是写少读多. 那理论上写完, 读的时候涉及部分小对象的逻辑? 难道通过预读来减少大合并文件中只有几个小文件才是用户要读的文件的问题? 所以针对这种通用场景, 只有一种办法, 那就是日志层级. 将随机写转换为顺序写, 然后通过compaction等方式把日志转化成实际的对象? 适合写多读少场景. 通过拆分整块写, 可以避免读那个被写了部分的offset的问题. 改数据的时候没问题, 通过gc来处理, 每次都写新的大对象. 读的时候, 就通过预读, 调整预读的大小等来完成覆盖. 如果预读的效果不好, 那其实还不如直接就读这个4K对象, 如果能够分析出行为, 则可以试试预读512K, 1M等方式. tier理解边界 如果是以短时间的访问粒度, 拆解全随机和存在热数据比例? 即存取周期 无热数据, db,wal分离的hdd性能好. 关键延时点: promote 有热数据, 开命中集tier好, 则tier能作为热数据访问的介质, 其他数据依旧访问hdd 关键延时点proxy 待定 有部分热数据, tier远比每日访问的数据大, 关闭命中集此时能让ssd提供比hdd更多的IOPS 主要拆解为 * 目标小io IOPS高, 延时低. 尽量让任意组合的ssd和hdd, 均能用出ssd的能力? 延时 读延时 写延时 命中率 淘汰算法 缓存大小, 热数据大小 命中率 ssd的容量大小, 其实取决于热数据到底有多少? 刚好卡在热数据范围最好. 如果完全没有热数据情况下, 即便都落ssd, 也价值不大? 缓存击穿时, 我感觉还是一种关键, 但是主要是需要硬盘不成为瓶颈的情况下, 这样按理论上就不会受到flush和evict影响, 剩下的就是writeback和writethrough的差异了 TODO: 单纯命令集的效果的话, 应该就是ssd承接部分命中的请求, 未命中的请求全落hdd. 这样ssd的使用率如果命中的请求打不满, 那就浪费很大. 所以可能需要配合小对象都落ssd的方案, 这样就可以提高ssd的利用率? 这个方案应该是主流方案吧? 问题 所有rbd, 超出tier大小性能差, 随着越大, 性能越差, 直到下限 多个rbd, 并不会存储冷热数据(指的是淘汰策略), 命中次数多的依旧会被踢掉. 表现是flush /evict很多 tier不满的情况下, 对象不存在的第一次写时, 缓存层应该能全部缓住. 但是启动hit_set时, 存在与刚才那句预期不符. promote应该只产生一次请求就可以了. 缓存击穿定义是? 目前现场的压力时确实有点大. 导致IOPS上不去的一个因素, 是否就是这种击穿状态下, IOPS被flush和evict占用的? G5那种, 每天预计访问1-2T数据, 而缓存池20T以上, 总数据100T+, 是否能保障使用? 1个T数据, 今天, 因为tier足够大, 在ceph的热数据概念下, 其实这批数据不算热数据. 这种其实也是一种智能promote的能力, 如果缓存池比较大的情况下.(持疑问) 拆解 性能 跟延时有关, 以及队列深度. IOPS, 1ms=1000IOPS 多队列情况下, 就有一定的放大. 固态, 支持多队列, 一般队列深度是8, 总IOPS会相比单队列强很多. 在平均延时可能上涨一部分的情况下. 多队列. nvme的队列深度一般是32/64. 软件层面, 内核提供的aio的syscall, aio_submit, aio_getevent这套能把一个队列中的多个op异步下发. 软件层面的这种多队列怎么实现, 应该还是依托上面固态的硬件的. promote 对象进入blocked状态, 等待取上来 flush+evict flush本身, 如果盘的压力没满, 会阻塞write. (这个是个影响点, 可能影响的是evict) flush和write同一个对象, 会阻塞. (待定) 这种情况下如果发现阻塞了, 重新入队, 如果稳态测试这个场景, 理论上性能应该会相比普通场景性能会下降一笔. evict是目前影响最大的, 淘汰算法. 跟hit_set有关 应该是会阻塞write. 状态定义 写满 常态 指的是访问的部分对象需要从底下promote 淘汰算法已经在常态生效 即我们场景里的flush+evict状态 击穿, 最差性能 因为底下太多, 实际上基本命中不了了, 每次都是promote. 即底下hdd的性能. 让他直接落hdd反而更好 tier的大小, 是应该跟着业务, 让他起到部分命中的效果. 根据上面的evict, 应该就需要针对业务, 提高命中率的方案, 在对象粒度不变的情况下, 可以提高性能. 开了命中集之后的方案来进行. 新写对象的性能 其实可以当做问题来解决, 这些对象不应该落到hdd上. 全写新对象的测试场景, 4K, 只要没被flush过一次, 就不会走到需要hdd读一遍的情况 fio 新对象 这批对象全部写满了, 小于tier大小, 然后全部不在tier上. 手动写的librbd, 每个4M只写其中1个4K, 延时肯定都是hdd+ssd的延时, 那IOPS比裸压hdd的IOPS更低. rados flush-and-evict. 走自己的librbd的下入, 每个4M, 1024次4K. 第一次肯定是不命中. 第一遍所有请求都是不重复的4M的. 第二次才开始剩下的. 剩下的平均延时应该就是1次hdd+1023次ssd . 理论上限. rbd_index分离, rbd_header一整个rbd也才读一次, 应该不至于有什么影响. 常态逻辑下需要支持的场景 分散对象, 即大部分场景不存在重复命中, 可能是将来深度学习模型能够解决的问题 重复命中的问题, 然后控制重复命中的频次和比例, 比如说100%对象都重复1次, 或者60%的对象重复一次, LRU的命中效率是多少. 1G的内存 和 2G的对象,,LRU: 可能60% 几个用来的计算的参数 tier大小与业务总数据大小关系 重复对象的比例, 以及重复次数 现在的管理对象粒度(现在是固定的4M) 加个指标, 命中的范围. 只是举例 0-1ms, 10% 1-10ms, 20% 10ms-20ms, 10% 小对象, 提高对象粒度 分析 分析关键点 埋点统计接口 123456# tier_flush\\tier_promote等数据ceph daemon osd.&#123;id&#125; perf dump | grep tier# num_write\\num_read\\num_promote等数据ceph pg dump_json tier主要触发任务 数据迁移 下面的flush和evict动作主要根据热度命中集和当前空间占用的ratio有关. * flush * evict * 主要zero, 因此主要是在ssd上的写. * 置零, 从op的角度应该也有什么东西能够观察到吧. * promote(感觉只和这个有关系了) IO操作 根据flush_mode和evict_mode状态判断触发下面的may_read,can_proxy_write等操作的成功与否. 下面的每一个操作好像都是may或者can的, 看上去像是有开关之类的. write_back 读: 缓存不存在 read proxy(osd层的proxy_read怎么转换到pg层上?) read forward(会redirct, 统计数据应该是直接记录到base pool上的pg层的read_num上) 这两个是怎么选择的呢? 缓存命中 (cache pool的read) 写 缓存不命中 write_proxy(proxy_write) promote_object 缓存命中 (cache pool的write) 源码阅读过程 tier_proxy_read数据来源 tier_proxy_read这个数据是哪里统计增加的?是在finish_proxy_read里增加的,那么同理 osd: tiering: add proxy read support · ceph/ceph@70d3d08 这次提交好像是个核心开发者的提交,当时不是走的github的pr? 看了下代码,这里好像没有计数器,inc 虽然是在ceph daemon osd.x perf dump里拿到的数据,但实际上还是pg层的,只是这个数据pg那边的接口暂时没找到能直接打印出来的方式.不对,这里虽然是PG类里的,但是数据记在了这个pg所属的osd上. osd: add proxy write perf counter · ceph/ceph@b9ec7e6 Revision b9ec7e64 - osd: add proxy write perf counter Signed-off-by: Zhiqiang Wang &lt;zhiqiang.wan... - Ceph - Ceph tracker单里咋也啥都没有呢?那他们怎么决定的呢? 在这个提交里增加的计数器.这个是直接提交在master分支里的了...哎 int PrimaryLogPG::do_osd_ops(OpContext *ctx, vector&amp; ops) write这边是尝试写,或者跟tier有关的都会进行计数 而read这边则是读一些元数据信息会触发读计数 这样的话,write和read数据就没有那么准确了. pg的counter好像不够实时, 有一个类似pg map的同步周期的样子,待核对. rmw_flags flags这个是判断到底要不要promote,和may_proxy_write的结果判断的 bool can_proxy_write = get_osdmap()-&gt;get_up_osd_features() &amp; CEPH_FEATURE_OSD_PROXY_WRITE_FEATURES; uint64_t OSDMap::get_up_osd_features() const { return cached_up_osd_features; } void OSDMap::_calc_up_osd_features() 在这个函数里做的赋值, osd/OSDMap: cache get_up_osd_features · Mirantis/ceph@e0e765f 在这次提交里做的改名,改成cached_up_osd_features,之前叫uint64_t OSDMap::get_up_osd_features() const, 每次都是重新查. osd/OSDMap: get_up_osd_features() · Mirantis/ceph@1d8429d age Weil authored and Yan, Zheng committed on Dec 29, 2013 struct osd_xinfo_t { 变量在osdMap这个class里 mempool::osdmap::vector osd_xinfo; pg stats pool stat方向 dump时用的iops_wr和iops_rd int64_t iops_wr = pos_delta 是从pg_sum_delta来的 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596 mempool::pgmap::list&lt; pair&lt;pool_stat_t, utime_t&gt; &gt; pg_sum_deltas;void PGMap::update_global_delta(CephContext *cct, const utime_t ts, const pool_stat_t&amp; pg_sum_old)&#123; update_delta(cct, ts, pg_sum_old, &amp;stamp, pg_sum, &amp;pg_sum_delta, &amp;stamp_delta, &amp;pg_sum_deltas);&#125; /* Aggregate current delta, and take out the last seen delta (if any) to * average it out. * Skip calculating delta while sum was not synchronized. */ if(!old_pool_sum.stats.sum.is_zero()) &#123; delta_avg_list-&gt;push_back(make_pair(d,delta_t)); *result_ts_delta += delta_t; result_pool_delta-&gt;stats.add(d.stats); &#125; size_t s = cct ? cct-&gt;_conf-&gt;get_val&lt;uint64_t&gt;(&quot;mon_stat_smooth_intervals&quot;) : 1; if (delta_avg_list-&gt;size() &gt; s) &#123; result_pool_delta-&gt;stats.sub(delta_avg_list-&gt;front().first.stats); *result_ts_delta -= delta_avg_list-&gt;front().second; delta_avg_list-&gt;pop_front(); &#125;//这里add,实际对应的就是底层对每个num_write之类的变量做加减. mempool::pgmap::list&lt;pair&lt;pool_stat_t,utime_t&gt; &gt; *delta_avg_list)//这里的减,减去的是上一次收集的数据? auto ts = per_pool_sum_deltas_stamps.find(p-&gt;first); assert(ts != per_pool_sum_deltas_stamps.end()); client_io_rate_summary(f, out, p-&gt;second.first, ts-&gt;second);//这里应该是pgmap维持那张pg_sum_deltas list里的stamp if (!stamp.is_zero() &amp;&amp; !pg_sum_old.stats.sum.is_zero()) &#123; utime_t delta_t; delta_t = inc.stamp; delta_t -= stamp; // calculate a delta, and average over the last 2 deltas. pool_stat_t d = pg_sum; d.stats.sub(pg_sum_old.stats); pg_sum_deltas.push_back(make_pair(d, delta_t)); stamp_delta += delta_t;//这里的inc.stamp是什么东西? list&lt;Incremental*&gt; inc; Incremental::generate_test_instances(inc); class Incremental &#123; public: MEMPOOL_CLASS_HELPERS(); version_t version; mempool::pgmap::map&lt;pg_t,pg_stat_t&gt; pg_stat_updates; epoch_t osdmap_epoch; epoch_t pg_scan; // osdmap epoch mempool::pgmap::set&lt;pg_t&gt; pg_remove; float full_ratio; float nearfull_ratio; utime_t stamp; pool_stat_t d = pg_sum;void PGMapDigest::decode(bufferlist::iterator&amp; p)void ClusterState::update_delta_stats()&#123; pending_inc.stamp = ceph_clock_now(); pending_inc.version = pg_map.version + 1; // to make apply_incremental happy dout(10) &lt;&lt; &quot; v&quot; &lt;&lt; pending_inc.version &lt;&lt; dendl; dout(30) &lt;&lt; &quot; pg_map before:\\n&quot;; JSONFormatter jf(true); jf.dump_object(&quot;pg_map&quot;, pg_map); jf.flush(*_dout); *_dout &lt;&lt; dendl; dout(30) &lt;&lt; &quot; incremental:\\n&quot;; JSONFormatter jf(true); jf.dump_object(&quot;pending_inc&quot;, pending_inc); jf.flush(*_dout); *_dout &lt;&lt; dendl; pg_map.apply_incremental(g_ceph_context, pending_inc); pending_inc = PGMap::Incremental();&#125; 所以pool_stat数据的更新,基本上就是和这个pg_sum数据的更新一致的. 这里的stamp周期到底是多长呢? PGMap::apply_incremental 像是在这merge的数据? 在PGMonitor::tick里会更新这个delta的数据. 理论 因为太多人不推荐这个方案了, 所以看看有没有推荐的. 推荐ssd用于WAL, 然后剩下的根据热数据大小控制缓存分层的大小[^3] 所以理论上控制好, 还是有用的? 下刷 flush_target evict_target PrimaryLogPG.cc:13468 cache_target_full_ratio_micro uint64_t flush_target = pool.info.cache_target_dirty_ratio_micro; uint64_t flush_high_target = pool.info.cache_target_dirty_high_ratio_micro; uint64_t flush_slop = (float) flush_target * cct-&gt;_conf-&gt;osd_agent_slop; uint64_t evict_target = pool.info.cache_target_full_ratio_micro; uint64_t evict_slop = (float) evict_target * cct-&gt;_conf-&gt;osd_agent_slop; agent_choose_mode 这次新增了flush_high &gt; commit 8f6056aebbabcbe236d332f546d075e06a14c0ca &gt; Author: MingXin Liu mingxin.liu@kylin-cloud.com &gt; Date: Thu May 28 14:33:10 2015 +0800 &gt; &gt; Osd: revise agent_choose_mode() to track the flush mode &gt; &gt; Signed-off-by: Mingxin Liu mingxinliu@ubuntukylin.com &gt; Reviewed-by: Li Wang liwang@ubuntukylin.com &gt; Suggested-by: Nick Fisk nick@fisk.me.uk commit c9daf8e5ea401f5bc2aafd4025991fb4903ffcd4 Author: Sage Weil sage@inktank.com Date: Mon Jan 27 17:57:53 2014 -0800 osd/ReplicatedPG: add slop to agent mode selection We want to avoid a situation where the agent clicks on and off when the system hovers around a utilization threshold. Particularly for trim, the system can expend a lot of energy doing a minimal amount of work when the effort level is low. To avoid this, enable when we are some amount above the threshold, and do not turn off until we are the same amount below the target. Signed-off-by: Sage Weil &lt;sage@inktank.com&gt; 理解 该值需要根据缓存池的容量大小以及副本个数来设置，以三副本为例，target_max_bytes 不应该超过容量的 1/3，如果实际的负载使得存储池中的数据大小达到了容量的 1/3，后续的 IO 将被阻塞，所以需要设置别的参数来避免池中的数据到达该阈值。 为什么是1/3? 该类参数的设计目的： 作为刷回淘汰操作的触发条件，避免 OSD 被数据撑满。 为什么不直接使用存储池的容量作为该参数，是为了考虑另外一种场景，存在多个缓存池，使用相同的磁盘。 flush 逻辑[^5] Agent will be always in idle state if target_max_bytes or target_max_objects not set on the pool irrespective of other tiering params set in the pool. dirty_micro and full_micro will not be calculated if those two params are zero which is by default I guess. Now, flush will be activated if dirty_micro is &gt; flush_target. My understanding is, once it is activated it will iterate through all the dirty objects and flush all the dirty objects which is &gt; cache_min_flush_age. Am I right ? The cache_min_flush_age will only be applicable if the flush is triggered after crossing the dirty_threshold, right ? If dirty_threshold is not breached, the flush age param is never checked. evict逻辑 I saw the cache_min_evict_age is not been used anywhere, am I missing anything ? It's possible. The min params are a bit dangerous because they can potentially confuse the cache agent (e.g., what if all objects are under the min? How/when do we decide to ignore the min, or, how/when do we give up trying to find an older object?). blocked 时间 1234uint64_t over = full_micro - evict_target;uint64_t span = 1000000 - evict_target;evict_effort = MAX(over * 1000000 / span, (unsigned) (1000000.0 * cct-&gt;_conf-&gt;osd_agent_min_evict_effort)); 123full_micro = num_user_objects * avg_size * 1000000 / MAX(pool.info.target_max_bytes / divisor, 1) 根据目前的理解, 当full_ratio达到1000000时, 根据上文, 也就是只有当达到target_max_bytes的时候才会彻底阻塞, 在这之前都是不会停止写io的. TODO: 目前看到的是, flush和evict的速度, 基本取决于osd的业务压力, 会让存储空间瓶颈停留在80%. evict_effort与实际速度的计算 根据默认配置可知, osd_agent_min_evict_effort默认值为0.1,即默认的evict_effort为0.1. osd_agent_quantize_effort默认值同样为0.1 1234567uint64_t inc = cct-&gt;_conf-&gt;osd_agent_quantize_effort * 1000000; assert(inc &gt; 0); uint64_t was = evict_effort; evict_effort -= evict_effort % inc; if (evict_effort &lt; inc) evict_effort = inc; assert(evict_effort &gt;= inc &amp;&amp; evict_effort &lt;= 1000000); 看起来这段只是在凑0.1-1以0.1为单元. if (full_micro &gt; evict_target), the mode is set as TierAgentState::EVICT_MODE_SOME. In this scenario evict_effort is calculated and based on hit_set and temp calculation some clean objects are evicted. My question is , can we quantify this value ? For ex, if the target_full_ratio = 50%, once the eviction is triggered, what %objects will be evicted ? The effort is calculated based on how far between target_full and 100% we are. This is mapped onto the estimation of atime. We generate a histogram of age for the objects we have examined, so after the agent has run a bit we'll have a reasonable idea how the current object's age compares to others and can decide whether this is older or newer than the others; based on that we decide what to do. maybe_handle_cache see maybe_handle_cache(). That's not strictly agent behavior per se. Also, there is now a readforward mode that doesn't promote on read ever, based on our discussion about the performance of flash on read. 调用链 agent_choose_mode OSDService::agent_entry() PrimaryLogPG::agent_work PG::agent_work(int max, int agent_flush_quota) = 0 PG::agent_work(int max) = 0 agent_maybe_evict agent_maybe_flush 命中集 12345if (hit_set) agent_estimate_temp(soid, &amp;temp);agent_state-&gt;temp_hist.add(temp);agent_state-&gt;temp_hist.get_position_micro(temp, &amp;temp_lower, &amp;temp_upper); pow2_hist_t: histogram of ages we've encountered. 应该是位运算. cbits, 64字节, 值为1, bin得到的就是1, 值为2, 则得到的是2, 因为要去除前导的0, 值为4, 得到3, 8得到4. hist_t里存的啥? 好像low和up得到的就是bin前面的, 和加上bin之后的差值. agent_estimate_temp这里添加的热度? 迭代历史的热度, 增加热度统计 int last_n = pool.info.hit_set_search_last_n; grade_table 看以下代码, 历史的所有命中集的热度是统一对待的. 12345678void calc_grade_table() &#123; unsigned v = 1000000; grade_table.resize(hit_set_count); for (unsigned i = 0; i &lt; hit_set_count; i++) &#123; v = v * (1 - (hit_set_grade_decay_rate / 100.0)); grade_table[i] = v; &#125; &#125; 如果历史几次命中集都有命中, 则热度偏高一点. 穿进去的热度v应该是1000000以上或者0. 这里应该是牺牲准确度, 但是减少空间消耗. 1000000应该会被归在20位, 即bin[20] = 1 然后算upper和lower的时候, 如果没有其他的命中过, 则是lower 0 , upper 1 total = 1 即lowwer 0, upper 1000000 如果前面有个热度不高的, 不考虑具体热度多少, 只考虑当前这个热度, 在那个阶段的比例?比如, 命中了比较多的, 那1000000有20次, 2000000有4次, 此次这个对象的热度是1500000 则lower 20 , upper 4 lower 20/44*1000000, upper 24/44*1000000, 最后得到一个450000 和 550000这种比例. TODO: 这里的hist是以什么为单位的? 热度统一控制的目的? 好像又回到evict_effort了, 假设当前evict_effort是500000, 则这种因为upper较高, , 按照说的是统一正交化了的. 只有当前对象所处热度的那个位时较高时, 才不会被踢掉. agent_state这个对象的粒度? PrimaryLogPG为单位的, 那就是pg为粒度. 这个pg每处理一个对象就Add一下. 每agent_work一次就加一次hist_age, 默认参数1000, 也就是1000次读写, 就降级一次hist?... 所以这里关心的是pg内全局的对象热度, 是命中的比较多, 还是不命中的比较多.命中的比较多时, 为啥就会被evict? osd_agent_min_evict_effort这个默认是0.1, 即如果是0.81的数据量, 0.8为水线, 则取较大的, 即0.1, 而不是0.01/0.2=0.05的比例作为effort. 这里应该是为了取要踢多少对象. 超过full_ratio的情况, 需要均一化. 但是下面这段并没有完全做均一化, 默认只处理掉0.1的话, 完全存在超过1.1的比例的情况. 这里其实是把比例按100000为粒度合并, 避免太多差异值. 所以full_ratio那里有计算, 如果直接进入FULL状态, 就不判断热度了. 另外这里的这个按位运算方式, 肯定有个什么术语...热度梯度统计? 12345678// quantize effort to avoid too much reordering in the agent_queue.uint64_t inc = cct-&gt;_conf-&gt;osd_agent_quantize_effort * 1000000;ceph_assert(inc &gt; 0);uint64_t was = evict_effort;evict_effort -= evict_effort % inc;if (evict_effort &lt; inc) evict_effort = inc;ceph_assert(evict_effort &gt;= inc &amp;&amp; evict_effort &lt;= 1000000); 比如2000000对应21位, 如果这个命中热度的对象, 出现频次较高时, TierAgentState, hitset的淘汰逻辑? Todo write_full? pg counter有类似pg map的同步周期? 计算什么时候会达到平衡的时候, 预计应该是会与tier的flush速度+evict速度 是否等同于上层下发的写io速度相平衡? 也就是我们需要得到evict速度的增长曲线, 得到evict与容量占比的计算公式, 然后计算上flush的计算速度与osd, 盘性能的相关性, 再计算一下业务的压力, 就可以得到到底设置多大的上水线可以让这个缓存池满足使用了. TierAgentState ignore_cache和ignore_overlay逻辑 flush try_flush redirect_reply do_proxy_read do_proxy_write 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849标签: OPERATION_IGNORE_CACHE op.tier_flush(); unsigned flags = librados::OPERATION_IGNORE_CACHE; int r = context-&gt;io_ctx.aio_operate(context-&gt;prefix+oid, completion, &amp;op, flags, NULL);static int do_cache_try_flush(IoCtx&amp; io_ctx, string oid)&#123; ObjectReadOperation op; op.cache_try_flush(); librados::AioCompletion *completion = librados::Rados::aio_create_completion(); io_ctx.aio_operate(oid.c_str(), completion, &amp;op, librados::OPERATION_IGNORE_CACHE | librados::OPERATION_IGNORE_OVERLAY | librados::OPERATION_SKIPRWLOCKS, NULL); completion-&gt;wait_for_complete(); int r = completion-&gt;get_return_value(); completion-&gt;release(); return r;&#125;do_cache_evict switch (obc-&gt;obs.oi.manifest.type) &#123; case object_manifest_t::TYPE_REDIRECT: if (op-&gt;may_write() || write_ordered) &#123; do_proxy_write(op, obc); if (op-&gt;may_write() || op-&gt;may_cache()) &#123; do_proxy_write(op); // Promote too? if (!op-&gt;need_skip_promote() &amp;&amp; maybe_promote(obc, missing_oid, oloc, in_hit_set, pool.info.min_write_recency_for_promote, OpRequestRef(), promote_obc)) &#123; return cache_result_t::BLOCKED_PROMOTE; &#125; return cache_result_t::HANDLED_PROXY; &#125; histgram算法 分位数近似计算 分位数近似算法有很多种，比如 HdrHistogram 算法、q-digest 算法、GK 算法、CKMS 算法、T-Digest 算法等，其中 HdrHistogram 算法和 T-Digest 算法在软件系统中使用的比较多，T-Digest 算法用于 ElasticSearch、Kylin 等系统中，HdrHistogram 的简化版用于 Prometheus 中。下面我们简单介绍一下这两种常用算法： 静态分桶 思想：将整个存储区域以规律性的区间划分为多个桶，整个规律性的区间可以是线性增长，也可以是指数增长。每个桶只记录落在该区间的采样数量，计算分位数时，会假设每个区间也是线性分布，从而计算出具体的百分位点的数值。这样通过牺牲小部分精度，达到减小空间占用，并且统计结果大致准确的结果。 典型的实现是：https://github.com/HdrHistogram/HdrHistogram。所以后续也称之为 Histogram 算法。 缺点：统计范围有限，需要预先确定，不能改变 两种数据增长算法：Linear 和 Log2，Linear 是线性增长，适合对百分位数精度要求比较高，而且数据范围比较小的场景。Log2 是指数增长，适合对百分位数精度要求相对低，而且总的数据范围跨度较大的场景。当然精度大小还依赖于坐标增长单元 Ceph RBD 性能及 IO 模型统计追踪功能设计与实现 原文链接： https://www.infoq.cn/article/2ojeh5jgo4s1xkxiztcg tier实践讨论 [ceph-users] SSDs for journals vs SSDs for a cache tier, which is better? Reference Ceph 学习——OSD读写流程与源码分析（一）_SEU_PAN的博客-CSDN博客_primarylogpg openstack - What is the best size for cache tier in Ceph? - Stack Overflow Ceph Tiring Cache 调优 | Elvis Zhang Re: [ceph-users] Regarding cache tier understanding","categories":[{"name":"专业","slug":"pro","permalink":"https://sean10.github.io/categories/pro/"}],"tags":[{"name":"ceph","slug":"ceph","permalink":"https://sean10.github.io/tags/ceph/"},{"name":"源码","slug":"源码","permalink":"https://sean10.github.io/tags/%E6%BA%90%E7%A0%81/"},{"name":"tier","slug":"tier","permalink":"https://sean10.github.io/tags/tier/"}]},{"title":"ceph之tier效果收集","slug":"ceph之tier效果收集","date":"2020-06-29T06:01:18.000Z","updated":"2023-03-18T15:11:14.904Z","comments":true,"path":"2020/06/29/ceph之tier效果收集/","link":"","permalink":"https://sean10.github.io/2020/06/29/ceph%E4%B9%8Btier%E6%95%88%E6%9E%9C%E6%94%B6%E9%9B%86/","excerpt":"","text":"数据整理 写入效果统计 \\[ \\frac{num\\_write_{cache}}{num\\_write_{cache} + num\\_write_{base}} \\] 读取效果统计 \\[ \\frac{num\\_read_{cache}}{num\\_read_{cache} + num\\_read_{base}} \\] 数据收集 osd daemon tier perf 实际还是pg的数据, 只是没有在pg那里直接对外暴露 123456789101112131415161718192021222324252627282930&#123; &quot;cache&quot;: &#123; &quot;tier_whiteout&quot;: 0, &quot;tier_try_flush_fail&quot;: 0, &quot;tier_proxy_read&quot;: 0, &quot;tier_dirty&quot;: 2, &quot;tier_promote&quot;: 3, &quot;tier_clean&quot;: 0, &quot;tier_delay&quot;: 0, &quot;tier_flush_fail&quot;: 0, &quot;tier_flush&quot;: 0, &quot;tier_try_flush&quot;: 0, &quot;tier_evict&quot;: 0, &quot;tier_proxy_write&quot;: 3 &#125;, &quot;base&quot;: &#123; &quot;tier_whiteout&quot;: 0, &quot;tier_try_flush_fail&quot;: 0, &quot;tier_proxy_read&quot;: 0, &quot;tier_dirty&quot;: 3, &quot;tier_promote&quot;: 0, &quot;tier_clean&quot;: 0, &quot;tier_delay&quot;: 0, &quot;tier_flush_fail&quot;: 0, &quot;tier_flush&quot;: 0, &quot;tier_try_flush&quot;: 0, &quot;tier_evict&quot;: 0, &quot;tier_proxy_write&quot;: 3 &#125;&#125; pg perf 12345678910111213141516171819202122232425262728293031323334353637383940&#123; &quot;cache&quot;: &#123; &quot;num_write_kb&quot;: 3, &quot;num_evict_mode_full&quot;: 0, &quot;num_write&quot;: 8, &quot;num_bytes_hit_set_archive&quot;: 83, &quot;num_promote&quot;: 3, &quot;num_whiteouts&quot;: -1, &quot;num_bytes&quot;: 6991, &quot;num_read_kb&quot;: 53, &quot;num_flush_kb&quot;: 0, &quot;num_evict&quot;: 0, &quot;num_flush&quot;: 0, &quot;num_evict_kb&quot;: 0, &quot;num_read&quot;: 61, &quot;num_objects_hit_set_archive&quot;: 1, &quot;num_flush_mode_high&quot;: 0, &quot;num_flush_mode_low&quot;: 0, &quot;num_objects_dirty&quot;: 2 &#125;, &quot;base&quot;: &#123; &quot;num_write_kb&quot;: 8, &quot;num_evict_mode_full&quot;: 0, &quot;num_write&quot;: 3, &quot;num_bytes_hit_set_archive&quot;: 0, &quot;num_promote&quot;: 0, &quot;num_whiteouts&quot;: 0, &quot;num_bytes&quot;: 6890, &quot;num_read_kb&quot;: 1, &quot;num_flush_kb&quot;: 0, &quot;num_evict&quot;: 0, &quot;num_flush&quot;: 0, &quot;num_evict_kb&quot;: 0, &quot;num_read&quot;: 5, &quot;num_objects_hit_set_archive&quot;: 0, &quot;num_flush_mode_high&quot;: 0, &quot;num_flush_mode_low&quot;: 0, &quot;num_objects_dirty&quot;: 3 &#125;&#125; 统计指标所在场景 根据上面这张图以及&lt;ceph源码分析&gt;可知, 主要的最后执行任务场景如下 read cache pool read op -&gt; num_read(cache)+ do_proxy_read -&gt; tier_proxy_read(cache) + num_read(base)+ num_read(cache)+ do_cache_redirect -&gt; num_read(base) + promote_object -&gt; num_promote(cache) + num_read(base)+ num_read(cache)+ write wait_queue(block) -&gt; 重新进入下面3个逻辑 promote_object -&gt; num_promote+ num_write(base)+ num_write(cache)+ num_read(base)+ num_write(cache)+ do_cache_redirect num_write(base)+ num_read(base)+ num_read(write)+ do_proxy_write tier_proxy_write(cache)+ num_write(base)+ num_write(cache)+ num_read(base)+ num_read(cache)+ 汇总 可知, promote和proxy并不是强相关的,只有实际的op的read和write存在强相关性. 只是由于read类型和write类型,可知元数据的读写也被统计了. 不过在总体上来说, 每个对象相关的元数据是存在正比关系(理论上应该是), 所以这个比值应该也是可靠的. num_read计数OP类型 1234567891011121314151617181920case CEPH_OSD_OP_CMPEXT:case CEPH_OSD_OP_READ:case CEPH_OSD_OP_CHECKSUM:case CEPH_OSD_OP_MAPEXT:case CEPH_OSD_OP_CALL:case CEPH_OSD_OP_ISDIRTY:case CEPH_OSD_OP_GETXATTR:case CEPH_OSD_OP_GETXATTRS:case CEPH_OSD_OP_CMPXATTR:case CEPH_OSD_OP_ASSERT_VER:case CEPH_OSD_OP_LIST_WATCHERS:case CEPH_OSD_OP_LIST_SNAPS:case CEPH_OSD_OP_NOTIFY:case CEPH_OSD_OP_NOTIFY_ACK:case CEPH_OSD_OP_OMAPGETKEYS:case CEPH_OSD_OP_OMAPGETVALS:case CEPH_OSD_OP_OMAPGETHEADER:case CEPH_OSD_OP_OMAPGETVALSBYKEYS:case CEPH_OSD_OP_OMAP_CMP:case CEPH_OSD_OP_COPY_GET: num_write计数OP类型 1234567891011121314151617181920212223242526case CEPH_OSD_OP_UNDIRTY:case CEPH_OSD_OP_CACHE_TRY_FLUSH:case CEPH_OSD_OP_CACHE_FLUSH:case CEPH_OSD_OP_CACHE_EVICT:case CEPH_OSD_OP_SETALLOCHINT:case CEPH_OSD_OP_WRITE:case CEPH_OSD_OP_WRITEFULL:case CEPH_OSD_OP_WRITESAME:case CEPH_OSD_OP_ROLLBACK :case CEPH_OSD_OP_ZERO:case CEPH_OSD_OP_CREATE:case CEPH_OSD_OP_TRUNCATE:case CEPH_OSD_OP_DELETE:case CEPH_OSD_OP_WATCH:case CEPH_OSD_OP_CACHE_PIN:case CEPH_OSD_OP_CACHE_UNPIN:case CEPH_OSD_OP_SET_REDIRECT:case CEPH_OSD_OP_SETXATTR:case CEPH_OSD_OP_RMXATTR:case CEPH_OSD_OP_TMAPUP:case CEPH_OSD_OP_TMAP2OMAP:case CEPH_OSD_OP_OMAPSETVALS:case CEPH_OSD_OP_OMAPSETHEADER:case CEPH_OSD_OP_OMAPCLEAR:case CEPH_OSD_OP_OMAPRMKEYS:case CEPH_OSD_OP_COPY_FROM: Todo问题 针对当cache资源池满的时候,write的请求会进入block_write_on_full_cache, 等到不满以后,再调用requeue_ops重新加入,因此对于num_write和num_read是体现不出这里的block的过程的. 可能需要增加一个latency的数据展示. 该统计方式, 需要分场景独立统计后使用 cache为空时的写入 cache上数据写入始终在cache_target_dirty_ratio下 cache上数据写入始终在cache_target_dirty_high_ratio下 cache上数据写入始终在cache_target_full_ratio下 超过cache_target_full_ratio时,主要只有延时需要关注了应该 Reference","categories":[{"name":"专业","slug":"pro","permalink":"https://sean10.github.io/categories/pro/"}],"tags":[{"name":"ceph","slug":"ceph","permalink":"https://sean10.github.io/tags/ceph/"},{"name":"源码","slug":"源码","permalink":"https://sean10.github.io/tags/%E6%BA%90%E7%A0%81/"},{"name":"tier","slug":"tier","permalink":"https://sean10.github.io/tags/tier/"}]},{"title":"hexo开启atom订阅","slug":"hexo开启atom订阅","date":"2020-06-27T14:45:43.000Z","updated":"2023-03-18T15:11:14.895Z","comments":true,"path":"2020/06/27/hexo开启atom订阅/","link":"","permalink":"https://sean10.github.io/2020/06/27/hexo%E5%BC%80%E5%90%AFatom%E8%AE%A2%E9%98%85/","excerpt":"","text":"最近想起来, 收藏的博客都没怎么看, 最近全靠公众号在提供一些有意思的内容,但是这个渠道还是太单薄了. 想起来之前用inoreader订阅过一些频道, 现在把最近一段时间收藏的博客再给补充进去, 顺便把自己博客的atom源也给打开. PS. 扫了一遍,好多用自定义域名的博客都已经不再维护, 这些不怎么常见的域名像是被专门去买别人未续费的域名机构给收集了,跳转到了一些做SEO. 还是github这种基本有几乎永久保障的二级域名好,. 123456# npm install hexo-generator-feed --savefeed: type: atom path: atom.xml limit: 0 在打开生成的atom.xml时输出这样一个错误PCDATA invalid Char value 8, 最后发现是md文件中多出了^H这个符号, vs code暂时不展示这种字符. 暂时也不知道是在什么情况下被添加进来的. 总之, 按照[^1]通过vim找到并删除之后就可以了. vs code render 按照有些大佬说的,设置Render Whitespace成all可以看到一些字符了,但是这个里还是只显示space和tab,似乎并不能显示换行符及像上面这种^H符号. 遇到问题 本来想着常开这个,至少能起到看我有没有在某些文件里错用tab,发现这个功能在markdown文件编写标题时,会出现和输入法重复的问题, 会出现下述这种效果. Refernence Hexo 的 RSS 生成错误 - ouyangsong - 博客园","categories":[{"name":"专业","slug":"pro","permalink":"https://sean10.github.io/categories/pro/"}],"tags":[{"name":"hexo","slug":"hexo","permalink":"https://sean10.github.io/tags/hexo/"}]},{"title":"异常处理实践初探","slug":"异常处理实践初探","date":"2020-06-24T16:26:46.000Z","updated":"2023-03-18T15:11:14.888Z","comments":true,"path":"2020/06/25/异常处理实践初探/","link":"","permalink":"https://sean10.github.io/2020/06/25/%E5%BC%82%E5%B8%B8%E5%A4%84%E7%90%86%E5%AE%9E%E8%B7%B5%E5%88%9D%E6%8E%A2/","excerpt":"","text":"背景 在用异常的时候,会有这么几个疑问 * 异常是直接raise,让程序退出,还是捕获记录到日志中后继续运行 * 异常的代码影响到了代码的可读性, 有没有更合适的解决方式? 异常的使用场景 详见if-else与try-catch初理解 面向切面编程(AOP)[^6] Todo:异常的代码可读性 像是如果一个业务逻辑里要执行多种封装的接口调用 123456789try: # code 1except CustomException: passtry: # code 2except CustomException2: pass 这种应该是有些类似装饰器,阅读代码中 捕获异常记录到日志里 一直有一个疑问，究竟是捕获异常,然后按照约定的接口输出错误信息，还是直接抛出,让程序直接退出呢? 根据目前写的比较多的几种场景的程序来看 * 守护程序, 进程间通信运作 * 接口程序,执行完即退出 无论是上面哪种场景,按照接口交互的开发标准来说,已知的异常都应该按照拟定的接口格式,错误时输出约定的错误码及信息,而不应该直接将exception直接抛出, 这样对其他调用解析你的接口的人来说,会产生未知错误. 只不过,这里的封装只在最上层封装, 然后在内部依旧可以使用raise,便于直接从底层快速将问题抛到上层的try...except处.(这里主要是相比return, 能快速退出多层接口调用) 注意点 PS. 虽然直接把异常抛到上层是很便捷的做法,但是对于一个公有库来说,最好还是在自己的抽象层定义自己的异常, 一个层次只处理他调用的层次的异常,而不是直接向上暴露底层异常. 当然,这里封装的异常同样也是已知异常,对于未知异常,只能尽可能靠单元测试来发现并捕捉,不然就只能抛到最上层捕获记录到日志里,修缺陷时再进行补全捕获了. 单元测试不可疏忽 而对于未知的错误, 肯定就是直接抛出了,但是这部分是需要在单元测试中尽可能覆盖完全来避免出现的. 样例 那么,怎么才能把traceback栈信息记录到日志里呢? 目前我用的比较多的是python3.6, 这个版本的logging.log提供了exc_info的选项 123456try: # coode in hereexcept Exception as e: logging.error(e, exc_info=True) # or logging.exception(e) 接口拟定正常 直接抛出Exception打断运行 正常来说,我们提供接口时,会约定一套返回值及内容格式,以及这个接口执行出现问题时的反应,如抛出什么异常,来让调用者捕获.这是Python的推荐做法. exception作为返回值 但是我看到[^4]这样一篇文章,里面提到了将Exception作为返回值,并且还存在一套针对这种用法的比较完备的库returns. 就仿佛静态类型里的非0值 单纯就这个做法来说,可能不是比较Pythonic的,但是按照readme来看,比较贴合目前python对静态类型的青睐?因为可以完全利用上类型标注的检查效果. 对于遗漏的异常返回值检查,可以做到很好的效果. 而且这样,又不会丢失Exception饱含的错误信息. 但是,又有一个问题,程序调用栈可能就会被破坏了,就像下面说的. 我调用一个库要一个int类型的结果,结果这个库里的接口在失败时并不会直接抛出,打断运行,而是返回一个Exception,我必须增加额外的判断检查,才能使用,否则一定会让调用者出错,这样其实也是违背了静态类型的接口设计的吧. 谁的问题应该由谁抛出更合适吧. 不捕获异常,上层也不做捕获,直接抛出 但是又看到一种说法[^5],有人说是由于python底层针对各种语句,存在各式各样的异常,基本不可能捕获,这个语言就是这么脆弱,捕获异常也只能做到非常有限的效果的话, 直接让程序出错直接退出就好了,如果这个场景没有考虑到的话. 但是按照我的理解, 如果底层的异常太多没处理好,其实就说明底层就开始有问题吧,应该一层层逐渐封装异常,最上层的使用不应该直接接触底层异常,而是下层逻辑的抽象异常才对. 这本就属于业务异常要考虑的逻辑. 这里python之父居然参与讨论了,回答了问题了. Let me draw a line in the sand. The PEP will not support any form of exception checking. The only thing possibly under discussion here is whether there is some other use of stubs (maybe an IDE suggesting a raise or try/except) that might benefit from declaring exceptions. But so far everything brought up has just been about the relative advantages of checked exceptions, and on that issue is close. We won't do it. The PEP doesn't mandate any particular behavior from a type checker, so I'm not prohibiting you from doing something you find useful. Whether it is actually useful may well depend on the codebase you are checking. I just don't want to have to put anything in the PEP that would seem to make checked exceptions part of the signature of a function. Maybe as a compromise we can just say in the PEP that a conformant type checker should not interpret the body of functions in stubs, and you can have a non-conformant option that interprets raise statements in stub function bodies. PEP里是不是没有这样的讨论? Never throw an exception of my own Always catch any possible exception that might be thrown by a library I’m using on the same line as it is thrown and deal with it immediately. It's all well and good that exceptions are widely used in core Python constructs, but why is a different question. Reference python - Log exception with traceback - Stack Overflow logging — Logging facility for Python — Python 3.8.3 documentation Python 工匠： 异常处理的三个好习惯 - 掘金 Python exceptions considered an anti-pattern - DEV declaring exceptions in stubs · Issue #71 · python/typing Python小书4-统一异常处理 - 知乎","categories":[{"name":"专业","slug":"pro","permalink":"https://sean10.github.io/categories/pro/"}],"tags":[{"name":"python","slug":"python","permalink":"https://sean10.github.io/tags/python/"},{"name":"编程范式","slug":"编程范式","permalink":"https://sean10.github.io/tags/%E7%BC%96%E7%A8%8B%E8%8C%83%E5%BC%8F/"},{"name":"code","slug":"code","permalink":"https://sean10.github.io/tags/code/"},{"name":"paradigm","slug":"paradigm","permalink":"https://sean10.github.io/tags/paradigm/"},{"name":"exception","slug":"exception","permalink":"https://sean10.github.io/tags/exception/"}]},{"title":"静态类型检查价值初认识","slug":"静态类型检查价值初认识","date":"2020-06-23T17:09:40.000Z","updated":"2023-03-18T15:11:14.840Z","comments":true,"path":"2020/06/24/静态类型检查价值初认识/","link":"","permalink":"https://sean10.github.io/2020/06/24/%E9%9D%99%E6%80%81%E7%B1%BB%E5%9E%8B%E6%A3%80%E6%9F%A5%E4%BB%B7%E5%80%BC%E5%88%9D%E8%AE%A4%E8%AF%86/","excerpt":"","text":"现在接触了一些类型和风格的代码之后，稍稍发现，其实以前讨厌的静态类型风格才是大势所趋，以前最喜欢的灵活的python依旧喜欢，但是作为工程代码时，也希望对接的人也利用起最新的类型标注等特性开发。 以前python编写接口时, 只能在用类型注释或者注释来告知使用的人,这套接口的入参. 现在python3.6开始可以用typing的类型标注功能了. 简单举个例子, 返回的是什么样的generator都可以定义了,利用mypy可以在IDE中编写时直接做检查了.虽然还是不能做到运行时强制检查. 12345def function(a: str, b: int) -&gt; Generator[ptional[str, int]]: c: list = [a, b] for k in c: yield k 对于愈发庞大的代码来说,静态类型声明带来的直观的类型阅读及清晰的调用逻辑,在后续维护时带来的好处非常大. 当然,即便原先没有这种类型标注,对于一套良好的动态类型代码,也是会说明清楚所有的类型的, 只是因为不像静态语言编译时会自动检查, 因为当时还没有类型标注这样的标准,开发自动检查的插件的难度也非常庞大, 这种情况下全靠开发者自觉. 对于一套大型代码, 最主要的是不能依赖开发者的个人素质, 要通过各式各样的检查工具,来提高开发者们的下限水平. 所以, 相比于依赖注释,这个只能靠认为review或不标准的检查工具的形式, 标准支持的类型标注的价值要大得多了. 再之后,对于类型检查,准备在防御式编程初探中讨论. Reference typing — Support for type hints — Python 3.8.3 documentation Python 有必要自己写类型判断吗？ - V2EX","categories":[{"name":"专业","slug":"pro","permalink":"https://sean10.github.io/categories/pro/"}],"tags":[{"name":"编程范式","slug":"编程范式","permalink":"https://sean10.github.io/tags/%E7%BC%96%E7%A8%8B%E8%8C%83%E5%BC%8F/"},{"name":"code","slug":"code","permalink":"https://sean10.github.io/tags/code/"},{"name":"paradigm","slug":"paradigm","permalink":"https://sean10.github.io/tags/paradigm/"}]},{"title":"if...else(LBYL)与try...catch(EAFP)初理解","slug":"if-else与try-catch初理解","date":"2020-06-23T17:00:36.000Z","updated":"2023-12-17T14:53:21.849Z","comments":true,"path":"2020/06/24/if-else与try-catch初理解/","link":"","permalink":"https://sean10.github.io/2020/06/24/if-else%E4%B8%8Etry-catch%E5%88%9D%E7%90%86%E8%A7%A3/","excerpt":"","text":"这两种其实在python里属于防御性编程下属的两种风格 if...else属于LBYL(Look before you leap) try...catch属于EAFP(easier to ask for forgiveness than permission) 就代码风格上差异来说，主要的差异点好像在于以下 总结 针对不同类型的业务代码，其实是根据场景都适用的。 当业务逻辑中，异常场景不少见的时候，用LBYL处理更合适 当业务逻辑中，大部分场景是走的正常分支，只有少部分时候由于环境、网络波动等因素出现异常时，用EAFP更合适。 按python哲学, 是更推荐EAFP的, 但是也不排斥利用静态语言的特性做一定程度的防御式编程 也有人更推荐LBYL[^5] Python 的动态类型（duck typing）决定了 EAFP，而 Java等强类型（strong typing）决定了 LBYL。语言之间的设计哲学差异，Java 对类型要求非常严格，要求明确，类/方法等，它假定你应该知道，任何时候你正在使用的对象类型，以及它能做什么。相反，Python 的鸭子类型意味着你不必明确的知道对象的显示类型是什么，你只需要关心你在使用时候它能有相应的反馈。在这种宽松的限制下，唯一明确的态度就是认为代码会工作，准备面对结果。 这无关语言的好坏，每一门语言都有自己的哲学与态度，正确的对待，理解。 上面这句话说的很对, 对于python来说, 他提供了动态/静态语言的能力, 剩下的取决于开发者自身的运用了. 类型 预计成功比例 业务逻辑可阅读性 存在潜在不可控问题时的处理逻辑 预检查成本 多线程race condtion 风险 EAFP 高 高(异常拆分恰当) 省力. 通过父异常统一拦截 低 无 LBYL 低 高(在python3.6, mypy之后, 参数校验可从业务逻辑中去除) 费力. 需要一个个异常判定, 工作量大, 风险高 一般低, 偶尔高 有 EAFP 一旦出现异常，存在性能上较差的问题，但是如果在正常逻辑，倒是没有固定成本 即预期大多数时间会是成功的 业务逻辑代码阅读会非常顺畅，所有的异常判断全部在业务逻辑外 这里应该有一点前提，业务逻辑封装的足够合适，否则每行做异常封装的话，看上去也并不美观 潜在不可控的问题: 如各种 io 操作，包括但不限于网络请求、文件读者、数据库 crud... 预检查成本高: 如对下层产生的压力足以等同于正常请求, 为了性能可能更推荐EAFP. FAQ 如果是EAFP，因为未进行各种检查引起的问题，是否会需要回滚？ EAFP每个独立的exception针对对应的逻辑其实都应该做到幂等性, 进行独立rollback. 即EAFP的逻辑其实也是要拆分的恰当的, 不能通过一个大的try...catch...全包裹住, 异常 如果拆分的足够合适，做了基本的入参检查之后，代码中在调用其他函数时，进行异常处理就可以. 建议捕捉下层收到的系统层级异常，然后抛出一个自定义的异常. 而不是将底层异常直接上传. 因为每个逻辑层次的错误代表不同的含义, 如最下层收到的参数的类型错误, 对应上层其实是某个逻辑错误. LBYL 固定的检查耗时成本，但是其实消耗不大，因为if是最适合编译器和处理器做分支预测优化的部分了*。 仅部分正常校验也会对下层业务产生较大压力时, 性能优化可解 存在多线程race condition的潜在问题 预检查会混杂在业务逻辑中 不过这里其实也取决于代码内聚解耦能力, 如果封装的恰当，应该很多逻辑都是在函数入口封装掉，这样的话倒也不会影响到业务逻辑部分的阅读。 参数类型检查, 在python3.6前的开始推行type annotion后, 通过typing特性的类型标注后, LBYL的参数检查可以不用再显式isinstance来判断了, 即解除了一个缺点: 参数检查会混杂在业务逻辑中的劣势. 预计操作失败的时间占比较高时 静态分析对Exception的支持 好像在mypy里这个是在计划支持中, 具体进展暂未了解到. 但大致的趋势是2者皆可用. 并不绝对. ceph社区的某个提交的意见 we should not use exception in the normal code path. in C++, exception is not designed to be efficient or semantically a language facility to be part of the normal code path. so, from the readability perspective, we should not use exception here. as all encoded KeyRings are in plaintext. Reference Python Tips - 防御性编程风格 EAFP vs LBYL - 知乎 如何理解 EAFP 和 LBYL 两种编程风格的区别？ - 知乎 方式 1 和方式 2 的却别到底在哪里？ - V2EX Write Cleaner Python: Use Exceptions 13 – Joel on Software Python鸭子类型 duck typing_Keyboard Interrupt的博客-CSDN博客 Python and EAFP principle: any way of differentiating betweeen 2 exceptions of the same type? - Stack Overflow","categories":[{"name":"专业","slug":"pro","permalink":"https://sean10.github.io/categories/pro/"}],"tags":[{"name":"编程范式","slug":"编程范式","permalink":"https://sean10.github.io/tags/%E7%BC%96%E7%A8%8B%E8%8C%83%E5%BC%8F/"},{"name":"code","slug":"code","permalink":"https://sean10.github.io/tags/code/"},{"name":"paradigm","slug":"paradigm","permalink":"https://sean10.github.io/tags/paradigm/"}]},{"title":"hexo结合PasteImage使用相对路径图片","slug":"hexo结合PasteImage使用本地图片","date":"2020-06-23T16:46:35.000Z","updated":"2023-03-18T15:11:14.823Z","comments":true,"path":"2020/06/24/hexo结合PasteImage使用本地图片/","link":"","permalink":"https://sean10.github.io/2020/06/24/hexo%E7%BB%93%E5%90%88PasteImage%E4%BD%BF%E7%94%A8%E6%9C%AC%E5%9C%B0%E5%9B%BE%E7%89%87/","excerpt":"","text":"背景 最近发现用外部OSS图床，在本地处理归档文件资源时，不是那么的方便。且自己用的腾讯云COS的上传插件没做对剪切板中图片上传的功能，导致每次粘贴图片都得多一步去获取文件的绝对路径或者选中文件。 然后发现vs code有个Paste Image的插件可以做到直接将剪切板的图片放到本地指定相对路径的功能。 但是对于发布到github page上的文章呢，图片资源怎么才能使用相对路径呢？ 就发现hexo 3提供了一部分功能（即便现在4了，好像也暂时没有更进一步优化的计划，relative path没怎么搜到有人提PR了）。 按照hexo的意思是不使用标准markdown语法，而是使用下面这种提供的外部语法来处理…… 123&#123;% asset_path slug %&#125;&#123;% asset_img slug [title] %&#125;&#123;% asset_link slug [title] %&#125; 不太能接受，然后发现配合一个好多年前的插件hexo-asset-image就可以做到对于用户可以无感知的使用相对路径的图片了。 hexo配置 hexo版本大于3，node版本不知道有没有影响（我本地14.4版本无法正常工作，9.5可以） _config.yaml中post_assets_folder设置为true npm install hexo-asset-image vim node_modules/hexo-asset-image/index.js 按照[^2]修改代码 原因在于作者不再维护了，npm源里一直没有重新打包的内容 12- var endPos = link.lastIndexOf(&#x27;.&#x27;);+ var endPos = link.length-1; 原始的md文件中的图片路径依旧可以用正常的相对路径&#123;% asset_img \"hexo结合PasteImage使用本地图片_2020-06-24-00-47-39.png\" \"\" %&#125;， 在hexo g时生成的文件中的图片资源路径会被这个插件自动转换成url后静态文件相对于静态文件根目录的绝对路径。 PasteImage配置 1234567&#123; &quot;pasteImage.namePrefix&quot;: &quot;$&#123;currentFileNameWithoutExt&#125;_&quot;, &quot;pasteImage.defaultName&quot;: &quot;YMMDDHHmmss&quot;, &quot;pasteImage.path&quot;: &quot;$&#123;currentFileDir&#125;/$&#123;currentFileNameWithoutExt&#125;&quot;, &quot;pasteImage.basePath&quot;: &quot;$&#123;currentFileDir&#125;&quot;, &quot;pasteImage.forceUnixStyleSeparator&quot;: true,&#125; 图示配置如下 Reference Hexo开启post_asset_folder后, 安装hexo-asset-image,不起作用的问题 | Tomtan's Blog 域名是xxx.io的情况下，图片路径会从原本/xxx.jpg变成 /.io/xxx.jpg · Issue #47 · xcodebuild/hexo-asset-image","categories":[{"name":"专业","slug":"pro","permalink":"https://sean10.github.io/categories/pro/"}],"tags":[{"name":"hexo","slug":"hexo","permalink":"https://sean10.github.io/tags/hexo/"},{"name":"vs code","slug":"vs-code","permalink":"https://sean10.github.io/tags/vs-code/"}]},{"title":"python单元测试mock和stub小记","slug":"python单元测试mock","date":"2020-06-23T13:06:11.000Z","updated":"2023-03-18T15:11:14.892Z","comments":true,"path":"2020/06/23/python单元测试mock/","link":"","permalink":"https://sean10.github.io/2020/06/23/python%E5%8D%95%E5%85%83%E6%B5%8B%E8%AF%95mock/","excerpt":"","text":"背景 单测主要遇到需要mock数据的场景目前遇到比较多的是两类 * HTTP接口 * 对底层业务逻辑API HTTP接口相关的mock工具非常多了，暂时就不具体说了。这篇主要记录的是针对依赖的API的mock。 在python单元测试数据mock有两座山，一个是unittest.mock，一个是pytest的mockeypatch。当然，还有一些easymock之类的库，但是没去研究，暂时搁置。 很多文章里提到Test Double at XUnitPatterns.com，好像TDD开发中的概念，这里做了非常详细的划分。 不过，主体上其实对数据的模拟主要是2点。 * mock * stub mock与stub mock主要用于测试对象的行为验证 stub主要用于提供模拟数据 mock使用 虽然上面的理论上是这样说，但是对于python的unittest库里，并没有按照这两个来分开实现，统一都是叫做mock.patch。 不过使用的方法上的确有差异 123456# mockmock_instance.assert_called_with# stubmock_instance.return_value = &#x27;xxx&#x27;mock_instance.side_effect = &#123;&#x27;a&#x27;: &#x27;xxx&#x27;&#125; mock应该主要指的是检查函数的调用、异常的触发情况，而stub主要就负责提供我们要的模拟数据 具体使用方式 主要使用的是pytest及pytest-mock，pytest-mock提供了一个mocker的fixture。 PS. fixture是pytest的一个封装，将一个函数封装，作为全局参数使用，在被写入某些函数的参数时，这些被封装的函数会执行一遍（对于像patch这类修改运行时的操作，能够保留） patch基本使用 1 patch调用封装的接口 a使用b模块中提供的接口，而单元测试脚本patch掉b模块，手动封装b模块会提供的数据 123456789101112131415161718192021222324252627# a.pyfrom b import Bclass A: def output(self): b = B() print(b.get_data())# b.pyclass B: def __init__(self): pass def get_data(self): return &quot;B&quot;# test_a.pyfrom pytest_mock import mockerdef test_A_output(mocker): # Important!!这里要注意，你要patch掉的内容是在这个模块被导入的地方，而不是这个模块定义的地方 inst = mocker.patch(&quot;a.B&quot;) inst.get_data().return_value = &quot;A&quot; a = A() a.output() # A 上面要注意的地方，原因主要在于模块使用时的运行时上下文，在这个模块被导入前，这个模块是不存在于代码的运行时中，只有当这个模块被导入了，这个模块才存在于运行时，patch的操作才能生效。除非是在你的当前文件中，这样定义和导入默认都已经完成了，就不会遇到这个问题了。 样例 return_value 下面所有的mock都可以用上面提到的mocker替换 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748# mymodule.py#!/usr/bin/env python# -*- coding: utf-8 -*-import osimport os.pathclass RemovalService(object): &quot;&quot;&quot;A service for removing objects from the filesystem.&quot;&quot;&quot; def rm(filename): if os.path.isfile(filename): os.remove(filename) return True return False# test_mymodule.pyfrom mymodule import RemovalServiceimport mockimport unittestclass RemovalServiceTestCase(unittest.TestCase): @mock.patch(&#x27;mymodule.os.path&#x27;) @mock.patch(&#x27;mymodule.os&#x27;) def test_rm(self, mock_os, mock_path): # instantiate our service reference = RemovalService() # set up the mock mock_path.isfile.return_value = False ret = reference.rm(&quot;any path&quot;) assert ret == False # test that the remove call was NOT called. self.assertFalse(mock_os.remove.called, &quot;Failed to not remove the file if not present.&quot;) # make the file &#x27;exist&#x27; mock_path.isfile.return_value = True ret = reference.rm(&quot;any path&quot;) mock_os.remove.assert_called_with(&quot;any path&quot;) assert ret == True side_effect 根据入参返回不同的结果 123456789101112131415161718192021def my_side_effect(*args, **kwargs): if args[0] == 42: return &quot;Called with 42&quot; elif args[0] == 43: return &quot;Called with 43&quot; elif kwargs[&#x27;foo&#x27;] == 7: return &quot;Foo is seven&quot;temp = mock.patch(&quot;myModule.mod&quot;)temp.get_value.side_effect = my_side_effectprint(temp.get_value(42))# 或者直接用匿名函数my_side_dict = &#123; &quot;42&quot;: &quot;Called with 42&quot;, &quot;43&quot;: &quot;Called with 43&quot;&#125;temp = mock.patch(&quot;myModule.mod&quot;)temp.get_value.side_effect = lambda x: my_side_dict[x]print(temp.get_value(42)) 测试是否返回异常 123myMethod = Mock(side_effect=KeyError(&#x27;whatever&#x27;))with self.assertRaises(KeyError): myMethod() Reference 浅谈mock和stub | 忆桐之家的博客 unittest.mock — mock object library — Python 3.8.3 documentation Monkeypatching/mocking modules and environments — pytest documentation Python Mocking: A Guide to Better Unit Tests | Toptal 简述软件开发中的单元测试 | 无人之岛","categories":[{"name":"专业","slug":"pro","permalink":"https://sean10.github.io/categories/pro/"}],"tags":[{"name":"python","slug":"python","permalink":"https://sean10.github.io/tags/python/"},{"name":"mock","slug":"mock","permalink":"https://sean10.github.io/tags/mock/"},{"name":"unittest","slug":"unittest","permalink":"https://sean10.github.io/tags/unittest/"}]},{"title":"python常用调试","slug":"python常用调试","date":"2020-06-23T12:17:08.000Z","updated":"2023-03-18T15:11:14.887Z","comments":true,"path":"2020/06/23/python常用调试/","link":"","permalink":"https://sean10.github.io/2020/06/23/python%E5%B8%B8%E7%94%A8%E8%B0%83%E8%AF%95/","excerpt":"","text":"Python常用调试方式 pdb 1python3 -m pdb xxx.py break 或 b 设置断点 设置断点 continue 或 c 继续执行程序 list 或 l 查看当前行的代码段 step 或 s 进入函数 return 或 r 执行代码直到从当前函数返回 exit 或 q 中止并退出 next 或 n 执行下一行 pp 打印变量的值 help 帮助 批量执行输出 123456(Pdb) commands 1(com) p some_variable(com) p another(com) end(Pdb) c# 会打印出some_variable和another 侵入式断点 断点 12import pdbpdb.set_trace() 条件断点 1234while a &gt; 0: if a == 15: print(a) pdb.set_trace() 条件断点 12# b(reak) [([filename:]lineno | function) [, condition]]b temp.py:13, a == 15 多线程调试 pdb原生不支持多线程调试，但是基于这个开发的不少第三方库支持, 可能rpdb？详见下述 PythonDebuggingTools - Python Wiki 稍后讲下pycharm多线程调试 pycharm常用 条件断点 多线程调试 pycharm是开发了pydevd这个插件来完成的远程调试、多线程调试的功能 健壮的logging机制 对于代码量一大，手动gdb肯定不方便，又不像二进制程序会出现coredump，所以gdb的backtrace经常需要用来排查段错误。 日志才是最主要的排查手段，通过等级控制，打开debug日志复现一次，日志足够详细就能直接定位到问题行。如果不够详细，就需要补充了。 Example 123456789101112131415import loggingfrom logging.handlers import RotatingFileHandlerlog_path = &quot;./res/a.log&quot;logger = logging.getLogger(&quot;a&quot;)logger.setLevel(logging.DEBUG)fh = RotatingFileHandler(log_path, maxBytes=200000, backupCount=7, encoding=&quot;utf-8&quot;)fh.setLevel(logging.INFO)console = logging.StreamHandler()console.setLevel(logging.DEBUG)fomatter = logging.Formatter(&#x27;%(asctime)s\\t%(module)s\\t%(message)s&#x27;, &#x27;%Y-%m-%d %H:%M:%S&#x27;)fh.setFormatter(fomatter)console.setFormatter(fomatter)logger.addHandler(fh)logger.addHandler(console) 远程同步 vscode: sftp pycharm: deployment vscode:sftp Example 1234567891011&#123; &quot;name&quot;: &quot;Profile Name&quot;, &quot;host&quot;: &quot;name_of_remote_host&quot;, &quot;protocol&quot;: &quot;ftp&quot;, &quot;port&quot;: 21, &quot;secure&quot;: true, &quot;username&quot;: &quot;username&quot;, &quot;remotePath&quot;: &quot;/public_html/project&quot;, &quot;password&quot;: &quot;password&quot;, &quot;uploadOnSave&quot;: true&#125; 基于pycharm的deployment 配置 参考文档 pdb — The Python Debugger — Python 3.8.3 documentation 段错误分析 12345py-bt FAQ py-bt Unable to locate python frame","categories":[{"name":"专业","slug":"pro","permalink":"https://sean10.github.io/categories/pro/"}],"tags":[{"name":"python","slug":"python","permalink":"https://sean10.github.io/tags/python/"},{"name":"debug","slug":"debug","permalink":"https://sean10.github.io/tags/debug/"}]},{"title":"ceph之SafeTimer定时器受系统时钟跳变影响","slug":"ceph之SafeTimer定时器受系统时钟跳变影响","date":"2020-06-21T16:18:28.000Z","updated":"2023-03-18T15:11:14.811Z","comments":true,"path":"2020/06/22/ceph之SafeTimer定时器受系统时钟跳变影响/","link":"","permalink":"https://sean10.github.io/2020/06/22/ceph%E4%B9%8BSafeTimer%E5%AE%9A%E6%97%B6%E5%99%A8%E5%8F%97%E7%B3%BB%E7%BB%9F%E6%97%B6%E9%92%9F%E8%B7%B3%E5%8F%98%E5%BD%B1%E5%93%8D/","excerpt":"最近遇到这样一个情况，ceph运行环境里时间被修改到以前的时间之后，ceph -s和ceph df都看不到在这之后创建的资源池了。 在大佬的带领下，得知了这部分数据来源于ceph-mgr的pgmap例行同步。时间出现变化之后，debug日志里也的确不再出现pgmap的同步日志了。从这个方向找到了入手点。","text":"最近遇到这样一个情况，ceph运行环境里时间被修改到以前的时间之后，ceph -s和ceph df都看不到在这之后创建的资源池了。 在大佬的带领下，得知了这部分数据来源于ceph-mgr的pgmap例行同步。时间出现变化之后，debug日志里也的确不再出现pgmap的同步日志了。从这个方向找到了入手点。 ceph-mgr pgmap日志代码溯源（基于Luminous版本） 根据打开调试信息后, 看到的日志中大量的pgmap v137057: 565 pgs: 576 active+clean 搜索日志pgmap v，是在DaemonServer.cc中调用的send_report 自底向上 MgrStandby和Mgr是组合关系，MgrStandby里实例化了一个active的Mgr 在触发一次tick之后，还会记录一个事件，好像让下一次触发timer.add_event_adter(g_conf-&gt;get_val&lt;int64_t&gt;(\"mgr_tick_period\") new FunctionContext([this](int r)))&#123; tick();&#125;的逻辑 对，在MgrStandby启动时调用init,触发第一次tick。之后应该就是这个计时器在工作。 这个mgr_tick_period的功能，看看咋工作的，好像只是std::chrono::seconds的封装。 这个mgr_tick_period应该只是个配置文件，记录多久同步的吧，果然，ceph daemon里可以看到是2s一次。 timer.add_event_after应该才是重头戏，这里居然是设置的根据时间戳来调用add_event_at添加回调的任务……当timer_thread执行到ceph_clock_now，用gettimeofday拿到系统时间，如果当前时间大于设置的时间，就是永远不会触发了? 所以这里存在一个潜在问题，是不是所有使用这个计时器的地方都存在会直接受到这个时钟往回调影响的问题。目前来看定时器应该只有这一个。 SafeTimer理解 12345678910111213141516171819202122232425262728class SafeTimer&#123; CephContext *cct; Mutex&amp; lock; Cond cond; bool safe_callbacks; // 是否是safe_callbacks friend class SafeTimerThread; SafeTimerThread *thread; //定时器执行线程 void timer_thread(); //本函数一次检查scheduler中的任务是否到期，其循环检查任务是否到期执行。 void _shutdown(); std::multimap&lt;utime_t, Context*&gt; schedule; //目标时间和定时任务执行函数Context std::map&lt;Context*, std::multimap&lt;utime_t, Context*&gt;::iterator&gt; events; //定时任务&lt;--&gt;定时任务在shedule中的位置映射 bool stopping; //是否停止// 下面这个应该才是真实在后台不停刷新检查定时器任务的线程class SafeTimerThread : public Thread &#123; SafeTimer *parent;public: explicit SafeTimerThread(SafeTimer *s) : parent(s) &#123;&#125; void *entry() override &#123; parent-&gt;timer_thread(); return NULL; &#125;&#125;; 以ceph-mgr为例，调用顺序是这样的。 ceph_mgr.cc里实例化MgrStandby，MgrStandby实例化SafeTimer,然后ceph_mgr.cc调用mgr.init，里面调用SafeTimer实例的init，在这里 12thread = new SafeTimerThread(this);thread-&gt;create(&quot;safe_timer&quot;); mgr的定时器任务就开始周期执行了。根据safe_callbacks这把锁的状态决定是否要申请到锁阻塞式执行任务，还是非阻塞式。 时间的触发基于cond.WaitUnitl(lock, schedule.begin()-&gt;first这个的实现。这个中主要依赖的应该是pthread_cond_timedwait这个超时等待接口。似乎有些库里的sleep就是通过这个实现的。 pthread_cond_timedwait()函数阻塞住调用该函数的线程，等待由cond指定的条件被触发（pthread_cond_broadcast() or pthread_cond_signal()）。如果超时了，就可以作为定时器使用。这里传入的是当前的abstime。 是否可能使用monotonic运行时间，而不是绝对时间？ 但是这块我好像看到，这个函数其实是支持传入monotonic时钟的，这个时钟开机开始计数，不受外部影响。 根据 12345678910111213141516#man 3 pthread_condattrDESCRIPTION Condition attribute objects are used to specify parameters to the pthread_cond_init(3) function. The pthread_condattr_init() function initializes a condition attribute object with the default attributes and the pthread_condattr_destroy() function destroys a condition attribute object. The pthread_condattr_getclock() function shall obtain the value of the clock attributes object referenced by attr. The pthread_condattr_setclock() function sets the system clock to be used for time comparisons to the one specified in clock. Valid clock values are **CLOCK_MONOTONIC** and **CLOCK_REALTIME** (the default). The pthread_condattr_getpshared() function shall obtain the value of the process-shared attribute from the attributes object referenced by attr. The pthread_condattr_setpshared() function shall set the process-shared attribute in an initialized attributes object referenced by attr. 可见应该是支持的，但是这个时钟不知道在分布式环境，能不能保证多节点内及时被chrony或者ntp协调一致。根据这个[^5]来看，应该是能通过ntp服务来保障长时间稳定一致的。 ceph社区是否存在相关思路的方案 根据[^6]的结果来说，mds是应用上了这套，也向下移植到了Luminous版本。 根据[^7]，在bluestore的perf上也用上了这个时钟来进行latency延时统计。在Nautilus版本里增加的功能。 在Luminous版本里，我也搜到了这个在[^7]里使用的coarse_mono_clock::now()时钟。 根据[^8]，在Mimic版本里，好像mon也迁移了部分。 根据[^10]，在Mimic版本里，rados bench也开始使用这个时钟。 所以都只是部分组件已支持, 只是mgr没有支持, 目前来看也没有统一迁移到支持的计划. 官方已提供common/Timer: use mono_clock for clock_t by tchaikov · Pull Request #39273 · ceph/ceph Reference 《Ceph源码分析》 ceph中的SafeTimer类详解_turou3442的博客-CSDN博客_ceph mds 定时器safe_timer线程cpu占用率高 ceph中的SafeTimer 用法和分析_jason的笔记-CSDN博客_safe_timer linux多线程编程，你还在用sleep么？用pthread_cond_timedwait吧 - shzwork的个人空间 - OSCHINA linux - What is the difference between CLOCK_MONOTONIC &amp; CLOCK_MONOTONIC_RAW? - Stack Overflow Bug #26959: mds: use monotonic clock for beacon message timekeeping - fs - Ceph os/bluestore: use the monotonic clock for perf counters latencies by mogeb · Pull Request #22121 · ceph/ceph Ceph v14.2.0 Nautilus released - Ceph mon: a few conversions to monotonic clock by batrick · Pull Request #18595 · ceph/ceph tools/rados: use the monotonic clock in rados bench by mogeb · Pull Request #18588 · ceph/ceph 附录 123456789101112131415161718192021digraph G &#123; splines=&quot;FALSE&quot;; // rankdir=&quot;BT&quot;; node [shape=&quot;cds&quot;, color=&quot;#dddddd&quot;, penwidth=&quot;1&quot;,style=&quot;filled&quot;, height=0.5, fontname=&quot;Futura&quot;, fontsize=10] /* Relationships */ &quot;ceph_mgr.cc&quot; -&gt; &quot;ceph_mgr.cc:MgrStandby mgr&quot; &quot;ceph_mgr.cc&quot; -&gt; &quot;ceph_mgr.cc:mgr.init()&quot; -&gt; &quot;MgrStandby.cc:MgrStandby::init()&quot; &quot;ceph_mgr.cc:MgrStandby mgr&quot; -&gt; &quot;MgrStandby.cc:MgrStandby::MgrStandby()&quot; &quot;MgrStandby.cc:MgrStandby::init()&quot; -&gt; &quot;timer.init();&quot; &quot;timer.init();&quot; -&gt; &quot;thread = new SafeTimerThread(this);&quot; -&gt; &quot;parent-&gt;timer_thread();&quot; -&gt; &quot;cond.WaitUntil(lock, schedule.begin()-&gt;first);&quot; -&gt; t_c t_c [label=&quot;pthread_cond_timedwait(&amp;_c, &amp;mutex._m, &amp;ts)&quot;, color=&quot;#dfc1c1&quot;] &quot;MgrStandby.cc:MgrStandby::init()&quot; -&gt; &quot;MgrStandby.cc:MgrStandby::handle_mgr_map(MMgrMap* mmap)&quot; &quot;MgrStandby.cc:MgrStandby::init()&quot; -&gt; &quot;tick();&quot; &quot;tick();&quot; -&gt; &quot;add_event_adter(g_conf-&gt;get_val&lt;int64_t&gt;(\\&quot;mgr_tick_period\\&quot;) new FunctionContext([this](int r)))&#123;tick();&quot; -&gt; &quot;SafeTimer::add_event_after&quot; -&gt; &quot;add_event_at(when, callback);&quot; &quot;SafeTimer::add_event_after&quot; -&gt; &quot;utime_t when = ceph_clock_now(); when += seconds;&quot; -&gt; &quot;gettimeofday(&amp;tv, NULL);&quot; &quot;MgrStandby.cc:MgrStandby::handle_mgr_map(MMgrMap* mmap)&quot; -&gt; &quot;active_mgr.reset(new Mgr...&quot; [label = &quot;组合,实例化&quot;]; &quot;add_event_adter(g_conf-&gt;get_val&lt;int64_t&gt;(\\&quot;mgr_tick_period\\&quot;) new FunctionContext([this](int r)))&#123;tick();&quot; -&gt; &quot;Mgr.cc:Mgr::tick()&quot;-&gt; &quot;DaemonServer.cc:void DaemonServer::send_report()&quot;&#125;","categories":[{"name":"专业","slug":"pro","permalink":"https://sean10.github.io/categories/pro/"}],"tags":[{"name":"ceph","slug":"ceph","permalink":"https://sean10.github.io/tags/ceph/"},{"name":"C++","slug":"C","permalink":"https://sean10.github.io/tags/C/"},{"name":"源码","slug":"源码","permalink":"https://sean10.github.io/tags/%E6%BA%90%E7%A0%81/"},{"name":"定时器","slug":"定时器","permalink":"https://sean10.github.io/tags/%E5%AE%9A%E6%97%B6%E5%99%A8/"}]},{"title":"使用reveal-md将markdown转slides","slug":"使用reveal-md将markdown转slides","date":"2020-06-21T08:57:16.000Z","updated":"2023-03-18T15:11:14.891Z","comments":true,"path":"2020/06/21/使用reveal-md将markdown转slides/","link":"","permalink":"https://sean10.github.io/2020/06/21/%E4%BD%BF%E7%94%A8reveal-md%E5%B0%86markdown%E8%BD%ACslides/","excerpt":"","text":"前段时间看到了vue-mark-display这套功能，直接基于markdown生成slides，都不用去专门学习beamer那套，直接就能基于现有的markdown生成，感觉相当不错。 不过在折腾这套工具的时候，遇到一个问题，自己展示的时候用html没有问题，但是归档发布给其他人的时候，当然最好还是以pdf的形式嘛。这套工具不知道是以为没适配高分屏还是什么原因，通过Chrome和decktype导出pdf时，文字布局一定会与页面上看到的不一致。 具体也没细看了，这套工具终究是个人使用为主，可能开发者的使用场景不怎么需要导出，比如纯外网或内网部署了自己的静态网站之类的情况下。 考虑到这套工具偏个性化，于是去找找适用性较广，功能做的比较完善的这类产品。 发现了reveal.js这套目前来看star数应该是最多的，也支持所有我需要的功能，如markdown。还有人基于这套，做了一个一键使用的reveal-md，更加满足我的需求了。 这篇文章主要讲的就是针对我的几个痛点，我怎么使用这套工具了。 emm，发现几个问题，看看remark和remark-slide和spectacle这俩star更多的有没有解决这个问题呢？reveal-md作者没兴趣修这些问题…… 指定主题 1234# 指定官方提供的reveal-md slides.md --theme solarized# 自定义scssreveal-md slides.md --theme theme/my-custom.css 文件内嵌yaml输出参数 1234567891011121314151617---title: temptheme: solarizedrevealOptions: transition: &#x27;fade&#x27;---## slide 1slide ---## slide 2这种效果 输出pdf（不建议使用，不支持mathjax） 1reveal-md slides.md --print slides.pdf html看到的公式和图片都是正常的。但是基于Puppeteer导出的时候，公式无法加载。按照reveal.js里说的，是已经支持了部分版本的mathjax了的，所以只能从这个工具使用的导出方式上来怀疑了。 可能因为headless浏览器那边加载的问题？没加载指定的js之类的？导致无法解析出mathjax公式。可能是这个reveal-md里对puppeteer的使用上存在一些问题？因为看decktape底层应该也是基于puppeteer来做的。 使用reveal.js的print-pdf（推荐使用） emm，有人说reveal.js原生的?print-pdf已经修复了这些问题，但是reveal-md，怎么像是css不加载？ 123reveal-md temp.md --static staticpython3 -m http.server#然后在打开的页面里按下面增加print-pdf，保存成pdf 要在html后的#前增加?print-pdf，在#后面加是没用的……总算是意识到了 1http://localhost:8000/index.html?print-pdf#/ 遇到因为文件头部的yaml导致生成的html都无法使用的问题 奇怪，前两天操作的时候怎么好像没遇到这个问题呢？ node版本的问题嘛？不像啊 123是因为我去掉了水平Separator的设置，但是保留了下面这个verticalSeparator: &lt;!--v--&gt; 通过Decktape输出pdf(支持mathjax，但暂时存在标题与图片间隙过大问题未修复，pinned状态) 使用reveal-md提供的生成Static文件的方式，再通过decktape将静态网页转成pdf。 12reveal-md temp.md --static staticdecktape index.html new.pdf 根据下面[^2]里提到的问题，目前找到的有两种解决方式 1. 使用screenshots输出，再写个脚本拼接成pdf，可能会丢失一些动态效果？如果尺寸比图片小，也会丢失下面的内容……不过这个和html是表现一致的，所以如果图片在html有问题，还可以调整。 2. 使用增加size的方式，直到找到可以正确显示的方式。但是这样的size针对不同的图片大小，还需要手动调整…… 3. 使用1.0.0版本的decktape，这个版本还在使用phantomjs，但是我发现在高分屏幕环境，似乎存在一点问题.只能显示一部分，原本的中间的内容跑到了右下角去了。 4. 使用原生的print-pdf，但是好像我这边生成的好像怎么都加载不了css，位置始终在左侧. 常用尺寸： * 2048x1536 * 1920x1080 * 2560x1440(screenshots) 存在图片和标题间距过大问题[^2] 绕过方式如下: A workaround seems to be increasing (very much) the size. For example using --size='2048x1536' instead of --size='1024x768' works for me. 但是这个存在一个问题，因为图片分辨率一旦超过设置的宽度，他这边就会无法显示了。 可能相比之下还不如刚才那样直接输出。如果使用screenshots输出倒是没有一点问题。 备注 在markdown文件每页中增加Note:，这页的剩下的部分就都会显示在注释中，打开本地web端访问slides后，按s会弹出注释页面，放到其他屏幕上就可以了。然后分别按Cmd+Ctrl+f全屏即可了。[^5] 只不过这种只适合多屏幕场景了吧，不过对于投屏来说，的确就是多屏幕 生成的目录结构 本以为Reveal.js生成的slides是顺序的，但是发现实际是具有上下左右四个方向的…… 本以为直接是按照目录结构保证的，但是实际上来看，和我写的目录结构并不是完全匹配的。 还得具体了解一下。 横向的幻灯片代表一章, 纵向的幻灯片代表一章中的一节。那么横向的幻灯片在播放时是左右切换的, 而纵向的幻灯片是上下切换的。 Reveal.js 里页面有两种页面类型，横向的一级页面、纵向的子页面。后者务必嵌套在前者里面。所谓的纵横比较好理解，键盘上的左右箭头控制一级页面，上下键移动子页面。 说是这么说的.根据[^7]也是有人直接改了，让可以在section切换时，能够直接进入下一个section的开头，而不是按Esc看到的布局的右侧位置。 又仔细翻了下文档，其实是由开关控制，决定是否要继承当前所在的section下属的纵向index的，关闭navigationMode就可以了。[^8]的Navigation Mode有提开关,既然有空格可以工作，暂时就不动这个了。 还是暂时使用空格顺序切换吧。 scss编写 123cd reveal.jsyarnyarn run build -- css-themes 在调试过程中，发现主要痛点在于默认主题的标题全部被强制大写了，导致看上去不是很符合我的预期，找了下可以在英文外增加代码符号```来完成绕过。 Reference webpro/reveal-md: reveal.js on steroids! Get beautiful reveal.js presentations from any Markdown file weird spacing with reveal · Issue #151 · astefanutti/decktape astefanutti/decktape: PDF exporter for HTML presentations remark vs remark-slide vs reveal-md vs reveal.js vs spectacle | npm trends Presenter mode · Issue #404 · hakimel/reveal.js Reveal.js：把你的 Markdown 文稿变成 PPT - 少数派 Forces left/right to go to top of previous/next section · Issue #2504 · hakimel/reveal.js Vertical Slides | reveal.js","categories":[{"name":"专业","slug":"pro","permalink":"https://sean10.github.io/categories/pro/"}],"tags":[{"name":"markdown","slug":"markdown","permalink":"https://sean10.github.io/tags/markdown/"},{"name":"工具","slug":"工具","permalink":"https://sean10.github.io/tags/%E5%B7%A5%E5%85%B7/"},{"name":"node-js","slug":"node-js","permalink":"https://sean10.github.io/tags/node-js/"},{"name":"pdf","slug":"pdf","permalink":"https://sean10.github.io/tags/pdf/"}]},{"title":"python单元测试框架比较","slug":"python单元测试框架比较","date":"2020-06-02T07:00:38.000Z","updated":"2023-03-18T15:11:14.819Z","comments":true,"path":"2020/06/02/python单元测试框架比较/","link":"","permalink":"https://sean10.github.io/2020/06/02/python%E5%8D%95%E5%85%83%E6%B5%8B%E8%AF%95%E6%A1%86%E6%9E%B6%E6%AF%94%E8%BE%83/","excerpt":"旧文简单整理","text":"旧文简单整理 ## 背景 主要测试框架: unittest，和在unittest基础上开发而来的pytest和nose 定位 pytest The pytest framework makes it easy to write small tests, yet scales to support complex functional testing for applications and libraries. nose2 It’s unittest with plugins. nose2’s purpose is to extend unittest to make testing nicer and easier to understand. nose2的主要目的是扩展Python的标准单元测试库unittest，因此它的定位是“带插件的unittest”。 nose2 vs pytest nose2 may or may not be a good fit for your project. If you are new to python testing, we encourage you to also consider pytest, a popular testing framework. 官方对于\b\b新使用单元测试的更推荐使用pytest。 上一个大版本功能 nose（已进入维护阶段，不再开发新功能） 功能 共同点 都是基于unittest原生库开发而来。 差异点 详见[转]Python测试框架对比----unittest, pytest, nose, robot framework对比 - bonelee - 博客园[^5] 基于测试功能上来说，均具有。 总体来说，pytest入门、扩展性最强，nose2比较要求写单元测试的功底的样子？ 社区生态 pytest 6K+的star数量，518个贡献者。 名字中含有pytest的python库 5308个 nose2 625个star, 58个贡献者。 nose[已进入维护阶段，不再开发新功能] 1.3K的star, 70个贡献者 名字中含有nose的python库，707个。 结论 毫无疑问，用py.test就完事了。 Reference pytest-dev/pytest: The pytest framework makes it easy to write small tests, yet scales to support complex functional testing nose-devs/nose2: The successor to nose, based on unittest2 三种最流行的Python测试框架，我该用哪一个？ - 知乎 【pytest】（二） pytest与unittest的比较 - 知乎 [转]Python测试框架对比----unittest, pytest, nose, robot framework对比 - bonelee - 博客园 pytest vs nose detailed comparison as of 2020 - Slant","categories":[{"name":"专业","slug":"pro","permalink":"https://sean10.github.io/categories/pro/"}],"tags":[{"name":"python","slug":"python","permalink":"https://sean10.github.io/tags/python/"},{"name":"pytest","slug":"pytest","permalink":"https://sean10.github.io/tags/pytest/"}]},{"title":"上海新版社保卡办理因支付宝被迫踩坑","slug":"上海新版社保卡办理因支付宝被迫踩坑","date":"2020-05-30T04:46:26.000Z","updated":"2023-03-18T15:11:14.868Z","comments":true,"path":"2020/05/30/上海新版社保卡办理因支付宝被迫踩坑/","link":"","permalink":"https://sean10.github.io/2020/05/30/%E4%B8%8A%E6%B5%B7%E6%96%B0%E7%89%88%E7%A4%BE%E4%BF%9D%E5%8D%A1%E5%8A%9E%E7%90%86%E5%9B%A0%E6%94%AF%E4%BB%98%E5%AE%9D%E8%A2%AB%E8%BF%AB%E8%B8%A9%E5%9D%91/","excerpt":"背景 网上申办上海新版社保卡，设备小米 8，支付宝一直提示此设备不支持刷脸，请更换设备后再试。官方没有任何其他的可以不使用支付宝的办理方式。","text":"背景 网上申办上海新版社保卡，设备小米 8，支付宝一直提示此设备不支持刷脸，请更换设备后再试。官方没有任何其他的可以不使用支付宝的办理方式。 更新 主任信箱回复了 尝试 搜了半天，有说支付宝这么报是因为下述等原因 * 设备root了 （我这台已经没root了，不过以前root过，直接移机的） * 设备上存在了xposed之类的软件，被判断不安全，不让刷脸 （的确以前root的时候装过，现在卸了也不行，难道支付宝的匹配规则这么严格？） * 就是设备不支持（小米8都不支持的话，这能线上办理的设备得多新啊） * 账户黑了（支付宝连政务办理都给卡？） 我是不能理解为什么小米8支持红外人脸识别（支持不支持3D人脸识别，是足够用在大部分非支付级别的人脸识别上了的）且没有root的设备也不能使用刷脸的。 这个刷脸只是这个办理的第一步，就直接被卡死了。 根据官网的说明（下图） 15813162114102da1db5c-aeb3-42d8-abd2-420399d9f3b4.jpg (600×3318) 网页开通，全都是让用支付宝进行刷脸认证。 https://www.962222.net/ 不管是网站还是”上海社保卡“APP第一步就是打开支付宝，然后支付宝直接给我打回了…… 短时间内肯定是不会回上海的，线下办理完全不现实。 也暂时没有按支付宝说的，换手机的想法。 以前学信网那些都能允许笔记本摄像头验证，现在的业务办理必须走人脸了？ 成功方式 最后，有个大佬回复说用工行的app可以办理，我照着做成功了，这个阶段里根本没有用到人脸识别，只需要提交照片就可以了。看来社保负责的部门只提供了一个由银行申办的通道，至于银行有没有提供线上功能，根本不关心…… 头疼点 唉，这还只是新版社保卡的办理，要不是有银行的通道，我肯定是最后只能线下去处理这个事。要是以后别的身份证之类的事情也是这类全部用了支付宝之类的接口，然后这些接口的使用上做了限制，部分人始终没办法使用可怎么办呢…… 猜测吧，支付宝这个刷脸接口做成通用功能了，导致自家支付程序要求严格的安全，金融级别嘛，不够安全的设备不用，这个属于正常。毕竟只是额外功能，刷脸支付可以不用。 但是这个接口如果同时也开给了政府部门，对于不要求金融级别的安全的情况下，却必须先满足这个级别的条件，才能使用政府提供的功能，那这种场景是不能接受的吧。毕竟我这种还算年轻的人都没有找到刷脸过不了的情况下的其他办理手段，那年纪更大的人呢？岂不是反而给很多人带来办理的负担了？ 论人群来说，刷脸支付占全国比例，和使用政府提供的线上功能的人的比例，是存在绝对差距的（毕竟，政府功能除了线下没有其他通道了）。但是又没有渠道反馈这样的情况……试试962222这个官网提供的热线吧 尝试反馈 962222，联通提示号码不存在 猜测是因为手机号是外地的，需要加区号021. 962222， 电话拨号中，只有咨询选项，没有信息反馈选项 尝试主任信箱 https://www.962222.net/pages/cms/zrxx.html 发送了一封上面写的总结，不知道能不能收到反馈。 主任信箱回复 回复：您好！非常抱歉给您带来了不便，我们已将您反应的情况提交至相关部门，如有不便，敬请谅解。有关新版社保卡办理相关事宜，您也可以拨打我们的服务热线962222。","categories":[{"name":"随想","slug":"thinking","permalink":"https://sean10.github.io/categories/thinking/"}],"tags":[{"name":"生活","slug":"生活","permalink":"https://sean10.github.io/tags/%E7%94%9F%E6%B4%BB/"},{"name":"支付宝","slug":"支付宝","permalink":"https://sean10.github.io/tags/%E6%94%AF%E4%BB%98%E5%AE%9D/"}]},{"title":"C语言的magic宏定义","slug":"C语言的magic宏定义","date":"2020-05-28T17:07:01.000Z","updated":"2023-03-18T15:11:14.894Z","comments":true,"path":"2020/05/29/C语言的magic宏定义/","link":"","permalink":"https://sean10.github.io/2020/05/29/C%E8%AF%AD%E8%A8%80%E7%9A%84magic%E5%AE%8F%E5%AE%9A%E4%B9%89/","excerpt":"可变参...和 ##__VA_ARGS 基本使用方式如下，我主要用来记日志了","text":"可变参...和 ##__VA_ARGS 基本使用方式如下，我主要用来记日志了 1234567891011121314151617181920212223242526272829#include &lt;syslog.h&gt;#include &lt;stdarg.h&gt;#include &lt;stdio.h&gt;#define BUFF_LEN_O 1024#define LOGGER(priority, format, ...) do&#123; \\ logger(priority, format, __FUNCTION__, __LINE__, ##__VA_ARGS__); \\ &#125;while(0)#define PRINT(x, a) printf(&quot;\\n&quot;)static void logger(int priority, const char *format, ...)&#123; openlog(&quot;test_log&quot;, LOG_PID | LOG_NDELAY, LOG_LOCAL0); va_list ap; char buff[BUFF_LEN_O] = &#123;0&#125;; char placeholder[] = &quot;function&#123;%s&#125;,line&#123;%d&#125;&quot;; va_start(ap, format); snprintf(buff, sizeof(buff) - 1, &quot;%s %s&quot;, placeholder, format); vsyslog(priority, buff, ap); va_end(ap);&#125;int main()&#123; LOGGER(LOG_INFO, &quot;hello world %s&quot;, &quot;123&quot;); LOGGER(LOG_ERR, &quot;new&quot;); logger(LOG_INFO, &quot;hello world %s&quot;, __FUNCTION__, __LINE__, &quot;123&quot;); return 0;&#125; #字符串化 会直接把表达式按照字符串输出，并过滤掉注释部分以及前后的空白。 12345678#include &lt;stdio.h&gt;#define PRINT(x) do &#123;printf(&quot;\\n&quot;#x&quot;\\n&quot;);&#125;while(0)int main()&#123; PRINT(print(&quot;hello world&quot;)/*new*/); return 0;&#125; ##Token拼接符号[^4] 这个就比较有意思了，可以通过这个结合gcc的typeof模拟出不少泛型的方式，在编译前预处理时扩展出不少函数或变量定义。参考[^4]文章的大佬用宏扩展出了弱图灵完备的函数。 按照大佬说的，这个库Cloak/cloak.h at master · pfultz2/Cloak非常多的例子 延迟展开 123456789#define EXPAND(...) __VA_ARGS__#define EMPTY()#define DEFER(id) id EMPTY()#define FOO() printf(&quot;macro\\n&quot;);DEFER(FOO)() /*这个解到最后就是FOO()*/// DEFER(FOO)();EXPAND(DEFER(FOO)()); /*这个最后输出macro*/ _Generic[^6] 使用方式，_Generic((var), type1 : ..., type2 : ..., ……, default : ...)，感觉果然和大佬们说的一样，比较像是对基本类型进行switch。 比起这个，可能gcc内建的像typeof这些关键字用起来更具有扩展性。 12345678910111213141516171819202122232425262728293031323334353637#include &lt;stdio.h&gt;#include &lt;complex.h&gt; #define CUSTOM_GENERIC(_var_) _Generic((_var_), \\/*signed char*/ signed char : printf(&quot;type signed char, var:%d\\n&quot;, _var_), \\/*signed short*/ signed short : printf(&quot;type signed short, var:%hd\\n&quot;, _var_), \\/*signed int*/ signed int : printf(&quot;type signed int, var:%d\\n&quot;, _var_), \\/*signed long int */ signed long int : printf(&quot;type signed long int, var:%ld\\n&quot;, _var_), \\/*signed long long int*/ signed long long int : printf(&quot;type signed long long int, var:%lld\\n&quot;, _var_), \\/*unsigned char*/ unsigned char : printf(&quot;type unsigned char, var:%c\\n&quot;, _var_), \\/*unsigned short*/ unsigned short : printf(&quot;type unsigned short, var:%hu\\n&quot;, _var_), \\/*unsigned int*/ unsigned int : printf(&quot;type unsigned int, var:%u\\n&quot;, _var_), \\/*unsigned long int*/ unsigned long int : printf(&quot;type unsigned long int, var:%lu\\n&quot;, _var_), \\/*unsigned long long int*/ unsigned long long int : printf(&quot;type unsigned long long int, var:%llu\\n&quot;, _var_), \\/*float*/ float : printf(&quot;type float, var:%f\\n&quot;, _var_), \\/*double*/ double : printf(&quot;type double, var:%lf\\n&quot;, _var_), \\/*long double*/ long double : printf(&quot;type long double, var:%llf\\n&quot;, _var_), \\/*_Bool*/ _Bool : printf(&quot;type _Bool, var:%d\\n&quot;, _var_), \\/*float _Complex*/ float _Complex : printf(&quot;type float _Complex, var:%f+%fi\\n&quot;, crealf(_var_), cimagf(_var_)), \\/*double _Complex*/ double _Complex : printf(&quot;type double _Complex, var:%f+%fi\\n&quot;, creal(_var_), cimag(_var_)), \\/*long double _Complex*/ long double _Complex : printf(&quot;type long double _Complex, var:%lf+%lfi\\n&quot;, creall(_var_), cimagl(_var_)), \\/*default*/ default : printf(&quot;type default!&quot;) \\) int main(void)&#123; int a = 10; float f = 100.0f; float _Complex fCex = 100.0f + 1.0if; CUSTOM_GENERIC(a); //type signed int, var:10 CUSTOM_GENERIC(f); //type float, var:100.000000 CUSTOM_GENERIC(fCex); //type float _Complex, var:100.000000+1.000000i CUSTOM_GENERIC(12); //type signed int, var:12 return 0;&#125; Reference 宏定义的黑魔法 - 宏菜鸟起飞手册 C preprocessor - Wikipedia C11新增关键字：_Generic(泛型)_c/c++_南雨兮-CSDN博客 宏定义黑魔法-从入门到奇技淫巧 (3) | Feng.Zone","categories":[{"name":"专业","slug":"pro","permalink":"https://sean10.github.io/categories/pro/"}],"tags":[{"name":"C","slug":"C","permalink":"https://sean10.github.io/tags/C/"},{"name":"macro","slug":"macro","permalink":"https://sean10.github.io/tags/macro/"}]},{"title":"黑苹果AMD显卡风扇降速","slug":"黑苹果AMD显卡风扇降速","date":"2020-05-28T15:14:10.000Z","updated":"2023-03-18T15:11:14.902Z","comments":true,"path":"2020/05/28/黑苹果AMD显卡风扇降速/","link":"","permalink":"https://sean10.github.io/2020/05/28/%E9%BB%91%E8%8B%B9%E6%9E%9CAMD%E6%98%BE%E5%8D%A1%E9%A3%8E%E6%89%87%E9%99%8D%E9%80%9F/","excerpt":"旧文补发 在第一次尝试黑苹果的时候，按照大佬们的经验之谈，配置一个A卡，这样配置核显做硬解就能充分利用起显卡的性能来了。 但是很可惜的是，在做教程的时候，这些大佬们没提到关于温控的问题。","text":"旧文补发 在第一次尝试黑苹果的时候，按照大佬们的经验之谈，配置一个A卡，这样配置核显做硬解就能充分利用起显卡的性能来了。 但是很可惜的是，在做教程的时候，这些大佬们没提到关于温控的问题。 方案1 对于黑苹果来说，A卡独显的风扇默认是无法通过软件控制到的，即便注入了驱动，也只能控制机箱风扇。 对于A卡的风扇来说，需要单独定制操作。翻遍黑锅论坛，发现有大佬开发了针对AMD Vega64显卡风扇的温控操作。而rx系列就没有了…… 在搜索过程中，发现除了直接软件接管控制之外，似乎还有一种直接写入到驱动的方法，不过这个难度可能稍大，也可能挺费时间…… 我姑且选择了拔掉独显，单纯使用集显驱动了。但是方案姑且记录在这里吧。 方案2 如果你在 Windows 下使用过 AMD 显卡驱动程序，则你一定对于 AMD Watt Man 有印象。这是随驱动程序安装的用于用户自定义性能模式的工具。你可以调整风扇转速方案，设定核心和内存频率以及电压。其实质就是生成一个自定义的 Power Table 供 GPU 加载使用以控制其行为模式。如果我们可以将这个 Power Table 设定好并抽取出来，然后注入到 macOS 对于该显卡的驱动当中，就可以完成对于显卡行为的自定义控制。[^2] embed the Soft Power Table in the kext. 上面两句是关键，根据上面两句来看，我之前构思的，能够切换到win10把显卡的bios里设置的参数改了，用北极星编辑器和flash工具刷进去，然后切回mac来使用的思路，是不是不太可行呢。因为从上面来看，这些参数可能实际是在驱动加载的时候生效的，而不是在硬件上。但是从刷bios这一个动作来看，应该也是存在于bios中的。可能这是2种方式吧。根据[^3]来看，的确是有2种方式了。 Reference MacOS – AMD’s Radeon Adrenalin Software | GPU, Monitor &amp; Peripherals Knock me down, and I’ll keep getting back up - 知乎 【心得】MSI ARMOR RX580 8G 降壓降頻心得 @電腦應用綜合討論 哈啦板 - 巴哈姆特","categories":[{"name":"随想","slug":"thinking","permalink":"https://sean10.github.io/categories/thinking/"}],"tags":[{"name":"hacintosh","slug":"hacintosh","permalink":"https://sean10.github.io/tags/hacintosh/"},{"name":"AMD","slug":"AMD","permalink":"https://sean10.github.io/tags/AMD/"}]},{"title":"ceph之df的MAX AVAIL","slug":"ceph之df的MAX-AVAIL","date":"2020-05-28T10:50:05.000Z","updated":"2023-03-18T15:11:14.863Z","comments":true,"path":"2020/05/28/ceph之df的MAX-AVAIL/","link":"","permalink":"https://sean10.github.io/2020/05/28/ceph%E4%B9%8Bdf%E7%9A%84MAX-AVAIL/","excerpt":"ceph df输出的统计数据的计算法昂是比我一眼以为的要复杂一些。 尤其是MAX AVAIL这个值。目前遇到的问题是发现在L版本,当osd out了之后，ceph df拿到的MAX AVAIL始终没有变化。","text":"ceph df输出的统计数据的计算法昂是比我一眼以为的要复杂一些。 尤其是MAX AVAIL这个值。目前遇到的问题是发现在L版本,当osd out了之后，ceph df拿到的MAX AVAIL始终没有变化。 这样对于使用者来说是存在问题的，当出现降级的情况时，若业务层使用这个接口看到资源池仍有可用空间，但实际上依旧up的osd并不能提供这些空间，是会导致业务人员出现误判……直接导致业务数据写不下去的情况的。 代码里是这样写了，但是是否上面的想法只是我们理解错误产生的误用呢？ 向上追溯一下这段关键计算的提交记录吧，看看有没有相关场景。 先搜索主要代码 12// PGMap.ccint64_t proj = (int64_t)(avail / (double)p-&gt;second); 利用blame查找每行的记录，还是不错的。 Bug #10257: Ceph df doesn't report MAX AVAIL correctly when using rulesets and OSD in ruleset is down and out - Ceph - Ceph 这篇里只加了跳过kb=0的选项 mon: incorrect MAX AVAIL in \"ceph df\" by liuchang0812 · Pull Request #17513 · ceph/ceph 这篇里好像是之前漏了/raw_used_rate这个副本size mon/PGMap: factor mon_osd_full_ratio into MAX AVAIL calc by liewegas · Pull Request #12923 · ceph/ceph 这个操作引入的full_ratio参数到MAX AVAIL计算中 mon/PGMap: Fix %USED calculation bug. · ceph/ceph@d10c6c2 修复%USED（raw的应该) 没有乘以副本数的问题。 osd,os,mon: extend 'ceph df' report to provide both USED and RAW_USED · ceph/ceph@7ca25df 这个应该是在L之后的版本，在这次commit中引入Statfs这个中间结构用来存储total、avail，免于直接接触kb mon/PGMap: GLOBAL -&gt; RAW STORAGE in 'df' output · ceph/ceph@738789b 这个也是L之后的版本，把ceph df输出的GLOBAL改成了RAW，防止错误理解 get_rule_weight_osd_map这个函数的新增并没有看出有立刻被用在计算资源池容量这里。 应该可以从这个接口被调用的地方来分析，新增的人是否没考虑过osd异常的场景？ mon/PGMap: move summary information into parent PGMapDigest object · ceph/ceph@8f25216 这里被重构，挪了一下位置…… mon/PGMap: factor mon_osd_full_ratio into MAX AVAIL calc · ceph/ceph@f223ac9 这里又被做了格式化，哎 mon: move \"df\" dump code from PGMonitor to PGMap · ceph/ceph@519a01d 这里又重构了…… 在这次提交以前这部分代码在src/mon/PGMonitor.cc mon/pgmonitor: use appropriate forced conversions in get_rule_avail · ceph/ceph@024caa7 哎，这次对这行改了下显式类型转换，从float改成double Bug #10257: Ceph df doesn't report MAX AVAIL correctly when using rulesets and OSD in ruleset is down and out - Ceph - Ceph 这个看起来和OSD out相关，但很可惜，只处理了错误计算为0的问题，并没有考虑正常场景？ mon: include 'max avail' in df output · ceph/ceph@7a9652b 终于找到了引入的地方,这里增加的max avail的值。 PGMonitor: fix bug in caculating pool avail space · ceph/ceph@04d0526 这里处理的那个osd_map 提交 在最新的分支里，也没有相关信息。看起来得提个ISSUE看看有没有答复了。 12345678910111213Environment: Luminous 12.2.12I have a question about the pool&#x27;s `MAX AVAIL` of `ceph df`.When i out a osd, the `MAX AVAIL` doesn&#x27;t change. Only when i remove the osd from the crush map of the pool, the `MAX AVAIL` decrese.For example, I have a pool with 10 osd. When 9 osds out, `ceph df` still output the MAX AVAIL with 10 osds, not the remained 1 osd. Only when i remove the out osds from the crush map, the MAX AVAIL changed to the remained size. But in my understanding, when the osd out, the recovery begin. When the recovery begins, the out osd has no use for the pool. If `MAX AVAIL` doesn&#x27;t change, It may provide error avail size for the users.The calculate logic is in `PGMap::get_rules_avail`. Maybe after called `get_rule_weight_osd_map`, we could recalculate the weight map to remove the osd which `osd_info.kb` is zero. Or could modify the `get_rule_weight_osd_map`, but i don&#x27;t know whether there is some other impact. 新建了这个issue, 希望能得到回复吧。 Bug #45809: When out a osd, the `MAX AVAIL` doesn't change. - Ceph - Ceph crushmap变更时, df容量不准确 看资源池为什么df输出的不对, 是否是osd_stat此时没收集完? 如何判断? 怀疑是pg peer完毕之前引起的. 以前创建的慢感知不到,现在可以感知了 osd_stat TODO: 为什么网卡异常会引起应用层乱序? 资源池Df的信息, 目前来看, 其实是从crush rule里读的, 这里似乎维持了一个缓存? crush_rule显示了一个3副本前的raw 容量. 如果是新建的rule, 则重新计算. 但是如果只是crush map变更呢? 如何感知重新计算呢? 不对啊, 看着是每次df都重新计算的, 那个avail_by_rule是个函数内变量. 没有调用啊? 我建了个新的crush rule ,为啥日志里没变更呢? 一点没有? 难道走的这个avail_space_by_rule 理解错了, 的确是通过这个变量缓存的. dump_pool_stats_full在这里才会真实的去触发? 大致知道了, 如果这个crush rule的容量还没被加载, 返回就是0 1234567int64_t get_rule_avail(int ruleno) const &#123; auto i = avail_space_by_rule.find(ruleno); if (i != avail_space_by_rule.end()) return avail_space_by_rule[ruleno]; else return 0;&#125; 所以, 其实就是这个容量触发更新的地方怀疑不够及时? 目前疑似PGMapStatService的dump_pool_stats触发PGMap的dump_pool_stats_full 只有这一个地方触发更新. pgservice-&gt;dump_pool_stats(osdmon()-&gt;osdmap, &amp;ds, f.get(), verbose);需要的是这个. mgr的接口和mon的ceph df函数理论上触发更新? 根据这个const MonPGStatService *pgservice;, 其实就一个触发来源才对呀? 走mgr的service, 似乎的确不走那个更新的地方, 那我理解错了. 不对, PGMapStatService这里的调用是会走到PGMap里的dump_pool_stats. 这里其实继承了?class PGMonStatService : public MonPGStatService, public PGMapStatService MonPGStatService这个和上面这几个什么关联性呢? 和PGMapStatService同时被继承到一个class里? 所以关键应该是在这个共同的派生类上? 123class PGMonitor : public PaxosService &#123; PGMap pg_map; std::unique_ptr&lt;PGMonStatService&gt; pgservice; PGMonStatService的构造函数里会传入这个, PGMonitor是这个class PGMonitor : public PaxosService, 有点遗忘了, 负责的是PaxosService 是不是可以理解为, 这个就是PGMap的更新的一致性代码管理方. TODO: 比如这个PGMonStatService使用了PGMonitor的哪些函数接口? TODO: 题外话, PaxosService的is_readable不知道怎么理解. 获取pgmap的元数据的时候, 好像是通过这个来查的 12345void dump_info(Formatter *f) const override &#123; f-&gt;dump_object(&quot;pgmap&quot;, pgmap); f-&gt;dump_unsigned(&quot;pgmap_first_committed&quot;, pgmon-&gt;get_first_committed()); f-&gt;dump_unsigned(&quot;pgmap_last_committed&quot;, pgmon-&gt;get_last_committed());&#125; 所以刚才继承的那俩类, 还有在单独提供使用吗? MonPGStatService Monitor里搞了个这个const MonPGStatService *pgservice; 现在看来这个并不是pg的paxosservice TODO: MgrStatMonitor和MonStatMonitor有什么关联性? MgrPGStatService : public MonPGStatService继承关系 似乎这个是在MgrStatMonitor这里初始化的, 所以又到了mgr这里? 根据下面这个, 是12版本及以后用MgrStatMonitor, PGMonitor是以前的呢? 12345678// make sure we&#x27;re using the right pg service.. remove me post-luminous!if (osdmap.require_osd_release &gt;= CEPH_RELEASE_LUMINOUS) &#123; dout(10) &lt;&lt; __func__ &lt;&lt; &quot; pgservice is mgrstat&quot; &lt;&lt; dendl; mon-&gt;pgservice = mon-&gt;mgrstatmon()-&gt;get_pg_stat_service();&#125; else &#123; dout(10) &lt;&lt; __func__ &lt;&lt; &quot; pgservice is pg&quot; &lt;&lt; dendl; mon-&gt;pgservice = mon-&gt;pgmon()-&gt;get_pg_stat_service();&#125; require_osd_release luminous, 所以实际上走进的代码应该是MgrStatMonitor? 走的其实是digest的dump_pool_stats // FIXME: we don't guarantee avail_space_by_rule is up-to-date before this function is invoked 官方在这里其实也写了, 等待修复. 目前来看, 只有触发一下PGMap的get_rules_avail才能够更新数据. 所以在Digest里有办法更新嘛? 目前初步看, 只有ActivePyModules里会触发PGmap的 class ClusterState这里是干啥的呢? PGMapStatService里也会. 但是这个目前只在ClusterState里使用了, mon里实际上并不使用PGMonitor的查询接口了. 似乎只有PGMonitor使用PGMap 那digest这个到底? mon/PGMap: move summary information into parent PGMapDigest object Everything summary-ish that we need to send to the mon is moved into a parent class. The child PGMap retains the detail. The parent gets its own encode(), and PGMap::encode_digest() will call it to encode just the summary info. Squashed in here is a new num_pg_by_osd that could have been done in a preceding patch but I did things in the wrong order. :( Signed-off-by: Sage Weil sage@redhat.com 所以其实这个digest就是pgmap的一个封装版本. 在void DaemonServer::send_report这里会触发 1234 cluster_state.with_osdmap([&amp;](const OSDMap&amp; osdmap) &#123;// FIXME: no easy way to get mon features here. this will do for// now, though, as long as we don&#x27;t make a backward-incompat change.pg_map.encode_digest(osdmap, m-&gt;get_data(), CEPH_FEATURES_ALL); 这里会定时将pgmap给更新? mgr的捕捉得通过asok的文件链接直接找. mgr_tick_period 2s更新一次, 那问题就是这个日志在哪? 忘记重新编译mgr了, 重新编了之后抓到了. 现在要找的是触发的地方. mgr_tick_period 根据下面的记录来看,确实就是2s更新一次. 如果这个间隔被我改大了之后, ceph df的结果是查不到. 所以关键问题还是crush的更新阶段? 抓一下那次异常时的osd map看看 11-12 10:38:55 1234567891011ceph osd getmap 110 -o osdmap.110osdmaptool osdmap.110 --export-crush crush.110crushtool -d crush.110 -o crush.110.txt##测试均衡分布osdmaptool osdmap.1034 --test-map-pgs-dump --pool 10osdmaptool osdmap.1034 --tree#打印ceph osd treeceph osd getcrushmap -o &#123;compiled-crushmap-filename&#125; ceph-objectstore-tool --data-path /var/lib/ceph/osd/ceph-3/ --pgid 4.0 obj4 dump 2021-11-12 10:38:54.756557 7f87acd59700 0 log_channel(cluster) log [DBG] : osdmap e76: 6 total, 6 up, 6 in ceph osd dump 76 得到的没有容量 osdmon()-&gt;osdmap 123class OSDMonitor *osdmon() &#123; return (class OSDMonitor *)paxos_service[PAXOS_OSDMAP];&#125; 其实计算的时候, 还需要一个osd_stat 所以有没有办法得到完整的PGMap? 资源池存在,但是crush rule是新建的这种. 复现了. emm. 第一种: 12345678910111213141516171819(gdb) bt#0 PGMap::get_rules_avail (this=this@entry=0x5627ee1b9f90, osdmap=..., avail_map=avail_map@entry=0x5627ee1b9fc0) at /home/wangchao/rpmbuild/BUILD/ceph-12.2.12/src/mon/PGMap.cc:940#1 0x00005627e27d4846 in PGMap::encode_digest (this=this@entry=0x5627ee1b9f90, osdmap=..., bl=..., features=features@entry=4611087853746454523) at /home/wangchao/rpmbuild/BUILD/ceph-12.2.12/src/mon/PGMap.cc:1579#2 0x00005627e28193a3 in operator() (osdmap=..., __closure=&lt;optimized out&gt;) at /home/wangchao/rpmbuild/BUILD/ceph-12.2.12/src/mgr/DaemonServer.cc:1454#3 with_osdmap&lt;DaemonServer::send_report()::__lambda31::__lambda32&gt; (cb=&lt;optimized out&gt;, this=0x7ffe277a5fa0) at /home/wangchao/rpmbuild/BUILD/ceph-12.2.12/src/osdc/Objecter.h:2045#4 with_osdmap&lt;DaemonServer::send_report()::__lambda31::__lambda32&gt; (this=&lt;optimized out&gt;) at /home/wangchao/rpmbuild/BUILD/ceph-12.2.12/src/mgr/ClusterState.h:129#5 operator() (pg_map=..., __closure=&lt;optimized out&gt;) at /home/wangchao/rpmbuild/BUILD/ceph-12.2.12/src/mgr/DaemonServer.cc:1470#6 with_pgmap&lt;DaemonServer::send_report()::__lambda31&gt; (cb=&lt;optimized out&gt;, this=0x5627ee1b9c30) at /home/wangchao/rpmbuild/BUILD/ceph-12.2.12/src/mgr/ClusterState.h:105#7 DaemonServer::send_report (this=this@entry=0x5627ee1ba930) at /home/wangchao/rpmbuild/BUILD/ceph-12.2.12/src/mgr/DaemonServer.cc:1471#8 0x00005627e286ba2e in Mgr::tick (this=0x5627ee1b9800) at /home/wangchao/rpmbuild/BUILD/ceph-12.2.12/src/mgr/Mgr.cc:626#9 0x00005627e28621fd in MgrStandby::tick (this=0x7ffe277a59e0) at /home/wangchao/rpmbuild/BUILD/ceph-12.2.12/src/mgr/MgrStandby.cc:197#10 0x00005627e282668a in operator() (a0=&lt;optimized out&gt;, this=&lt;optimized out&gt;) at /home/wangchao/rpmbuild/BUILD/ceph-12.2.12/build/boost/include/boost/function/function_template.hpp:760#11 FunctionContext::finish (this=&lt;optimized out&gt;, r=&lt;optimized out&gt;) at /home/wangchao/rpmbuild/BUILD/ceph-12.2.12/src/include/Context.h:493#12 0x00005627e2821bc9 in Context::complete (this=0x5627ed8f6c30, r=&lt;optimized out&gt;) at /home/wangchao/rpmbuild/BUILD/ceph-12.2.12/src/include/Context.h:70#13 0x00005627e2999074 in SafeTimer::timer_thread (this=0x7ffe277a76f0) at /home/wangchao/rpmbuild/BUILD/ceph-12.2.12/src/common/Timer.cc:97#14 0x00005627e299aa9d in SafeTimerThread::entry (this=&lt;optimized out&gt;) at /home/wangchao/rpmbuild/BUILD/ceph-12.2.12/src/common/Timer.cc:30#15 0x00007f365a1dedd5 in start_thread () from /lib64/libpthread.so.0#16 0x00007f36592b9ead in clone () from /lib64/libc.so.6 第二种 12345678910111213141516171819202122232425262728(gdb) bt#0 PGMap::get_rules_avail (this=this@entry=0x559f786fff90, osdmap=..., avail_map=avail_map@entry=0x559f786fffc0) at /home/wangchao/rpmbuild/BUILD/ceph-12.2.12/src/mon/PGMap.cc:940#1 0x0000559f6d4bbe50 in PGMap::dump_pool_stats_full (this=0x559f786fff90, osd_map=..., ss=0x0, f=0x7ff400f95f60, verbose=&lt;optimized out&gt;) at /home/wangchao/rpmbuild/BUILD/ceph-12.2.12/src/mon/PGMap.h:454#2 0x0000559f6d4ecb7d in operator() (osd_map=..., __closure=&lt;optimized out&gt;) at /home/wangchao/rpmbuild/BUILD/ceph-12.2.12/src/mgr/ActivePyModules.cc:296#3 with_osdmap&lt;ActivePyModules::get_python(const string&amp;)::__lambda17::__lambda18&gt; (cb=&lt;optimized out&gt;, this=&lt;optimized out&gt;) at /home/wangchao/rpmbuild/BUILD/ceph-12.2.12/src/osdc/Objecter.h:2045#4 with_osdmap&lt;ActivePyModules::get_python(const string&amp;)::__lambda17::__lambda18&gt; (this=&lt;optimized out&gt;) at /home/wangchao/rpmbuild/BUILD/ceph-12.2.12/src/mgr/ClusterState.h:129#5 operator() (pg_map=..., __closure=&lt;optimized out&gt;) at /home/wangchao/rpmbuild/BUILD/ceph-12.2.12/src/mgr/ActivePyModules.cc:297#6 with_pgmap&lt;ActivePyModules::get_python(const string&amp;)::__lambda17&gt; (cb=&lt;optimized out&gt;, this=0x559f786ffc30) at /home/wangchao/rpmbuild/BUILD/ceph-12.2.12/src/mgr/ClusterState.h:105#7 ActivePyModules::get_python (this=0x559f779abe00, what=&quot;df&quot;) at /home/wangchao/rpmbuild/BUILD/ceph-12.2.12/src/mgr/ActivePyModules.cc:298#8 0x0000559f6d50b1fd in ceph_state_get (self=0x7ff4015c10a0, args=&lt;optimized out&gt;) at /home/wangchao/rpmbuild/BUILD/ceph-12.2.12/src/mgr/BaseMgrModule.cc:334#9 0x00007ff42b518cf0 in PyEval_EvalFrameEx () from /lib64/libpython2.7.so.1.0#10 0x00007ff42b5186bd in PyEval_EvalFrameEx () from /lib64/libpython2.7.so.1.0#11 0x00007ff42b5186bd in PyEval_EvalFrameEx () from /lib64/libpython2.7.so.1.0#12 0x00007ff42b51b03d in PyEval_EvalCodeEx () from /lib64/libpython2.7.so.1.0#13 0x00007ff42b4a4978 in function_call () from /lib64/libpython2.7.so.1.0#14 0x00007ff42b47fa63 in PyObject_Call () from /lib64/libpython2.7.so.1.0#15 0x00007ff42b48ea55 in instancemethod_call () from /lib64/libpython2.7.so.1.0#16 0x00007ff42b47fa63 in PyObject_Call () from /lib64/libpython2.7.so.1.0#17 0x00007ff42b47fb45 in call_function_tail () from /lib64/libpython2.7.so.1.0#18 0x00007ff42b47fe7b in PyObject_CallMethod () from /lib64/libpython2.7.so.1.0#19 0x0000559f6d50fcff in ActivePyModule::notify (this=0x559f7841f440, notify_type=&quot;pg_summary&quot;, notify_id=&quot;&quot;) at /home/wangchao/rpmbuild/BUILD/ceph-12.2.12/src/mgr/ActivePyModule.cc:90#20 0x0000559f6d4da68a in operator() (a0=&lt;optimized out&gt;, this=&lt;optimized out&gt;) at /home/wangchao/rpmbuild/BUILD/ceph-12.2.12/build/boost/include/boost/function/function_template.hpp:760#21 FunctionContext::finish (this=&lt;optimized out&gt;, r=&lt;optimized out&gt;) at /home/wangchao/rpmbuild/BUILD/ceph-12.2.12/src/include/Context.h:493#22 0x0000559f6d4d5bc9 in Context::complete (this=0x559f78b0e6f0, r=&lt;optimized out&gt;) at /home/wangchao/rpmbuild/BUILD/ceph-12.2.12/src/include/Context.h:70#23 0x0000559f6d64f748 in Finisher::finisher_thread_entry (this=0x559f786ff940) at /home/wangchao/rpmbuild/BUILD/ceph-12.2.12/src/common/Finisher.cc:72#24 0x00007ff4295a9dd5 in start_thread () from /lib64/libpthread.so.0#25 0x00007ff428684ead in clone () from /lib64/libc.so.6 ceph mon remove {mon-id} 奇怪, 现阶段的问题是, 资源池都不显示. 而不是单纯不显示数字. osdmap意思是也没更新引起的? 资源池名字和crush rule也都是从osd map里拿的. 那为啥会出现容量为0, 但是资源池存在的情况呢? 那就代表上一次的osd map里还存在crush rule为0, 但是pool存在的那次. TODO: 这中间也没干啥, 数字在变化? 默认的元数据? 2021-11-15 10:00:02.105074 7f0947dbe700 4 wc 1: 128092917534 2021-11-15 10:02:01.659658 7f0947dbe700 4 wc 1: 128092671774 2021-11-15 10:03:01.454611 7f0947dbe700 4 wc 1: 128092426014 2021-11-15 10:10:01.699644 7f2e29b8c700 4 wc 1: 128092770078 2021-11-15 10:10:01.854774 7f2e29b8c700 4 wc 1: 128092770078 2021-11-15 10:11:01.675594 7f2e29b8c700 4 wc 1: 128092917534 TODO: 待整理本片的内容. pgmap 是怎么知道他用的哪个pgmap_digest的变量的呢? 是全局只会有一个嘛? 还是怎么做到的呢? Mgr里似乎做的初始化DaemonServer, DaemonServer初始化的时候从上级收到ClusterState对象. 1234567891011121314151617181920Mgr::Mgr(MonClient *monc_, const MgrMap&amp; mgrmap, PyModuleRegistry *py_module_registry_, Messenger *clientm_, Objecter *objecter_, Client* client_, LogChannelRef clog_, LogChannelRef audit_clog_) : monc(monc_), objecter(objecter_), client(client_), client_messenger(clientm_), lock(&quot;Mgr::lock&quot;), timer(g_ceph_context, lock), finisher(g_ceph_context, &quot;Mgr&quot;, &quot;mgr-fin&quot;), digest_received(false), py_module_registry(py_module_registry_), cluster_state(monc, nullptr, mgrmap), server(monc, finisher, daemon_state, cluster_state, *py_module_registry, clog_, audit_clog_), clog(clog_), audit_clog(audit_clog_), initialized(false), initializing(false) TODO:cluster_state是从monc来的? \bc++ // ceph_mgr.c MgrStandby mgr(argc, argv); int rc = mgr.init();","categories":[{"name":"专业","slug":"pro","permalink":"https://sean10.github.io/categories/pro/"}],"tags":[{"name":"ceph","slug":"ceph","permalink":"https://sean10.github.io/tags/ceph/"}]},{"title":"windows terminal1.0暂时还无法替代tmux","slug":"windows-terminal1-0暂时还无法替代tmux","date":"2020-05-25T05:57:05.000Z","updated":"2023-03-18T15:11:14.825Z","comments":true,"path":"2020/05/25/windows-terminal1-0暂时还无法替代tmux/","link":"","permalink":"https://sean10.github.io/2020/05/25/windows-terminal1-0%E6%9A%82%E6%97%B6%E8%BF%98%E6%97%A0%E6%B3%95%E6%9B%BF%E4%BB%A3tmux/","excerpt":"前段时间, windows Terminal 1.0发布了，其实我知道这个的时候，还是非常期待的。毕竟公司的开发机是windows，需要一直连接着linux设备做开发。","text":"前段时间, windows Terminal 1.0发布了，其实我知道这个的时候，还是非常期待的。毕竟公司的开发机是windows，需要一直连接着linux设备做开发。 我之前的方案是自己搭了个本地虚拟机做跳板，这个虚拟机里装了tmux，然后我通过windows上可以ssh的工具ssh上去使用tmux， 再开多个panessh开发机。 tmux通过快捷键切换、创建、分割、临时全屏化pane来操作还是非常便捷的。 目前我是使用的putty作为ssh工具。之前使用过cygwin（MSYS)，不过在这些环境下启动tmux，当时是在创建切换pane上有些或多或少的问题。听说MSYS2之前也已经出了，似乎已经比较成熟了，大佬们也可以试试。 我最近已经比较图稳定了，之前遇到的或多或少的问题有比如我需要显示编码从UTF-8临时切换到GBK，在这个时候有些工具会把分隔栏变成错误字符。还有我需要简洁的全屏，只需要通过tmux来控制和切换窗口，像xshell和CRT等工具对我来说就有些功能过冗余了。当然，像能和这两个工具结合在一起的文件传输插件还是挺不错的，不过也可以通过samba和IDE的remote devetop的sync功能将就将就，对于偶尔才会有代码以外的文件需要替换时，winscp足够使用了。 去年好像windows 10 开始官方提供OpenSSH支持，我立马也就升级了。不过很可惜在powershell和cmd环境中，像Ctrl+C等快捷键会直接被powershell给捕获，导致即便用这两个窗口ssh到了设备上，表现也并不是那么好。另外powershell和cmd的默认字体和高亮的美观度也不是很喜欢…… 根据windows terminal的文档[^2]中所说的快捷键使用，基本上我用到的tmux功能都可以修改windows terminal的profile来模拟一致。且针对windows上需要临时复制单pane的内容时，这个相比putty能够不用单独全屏化窗口再复制，算是一个优势。 不过现在唯一的不足就在于，在这个版本暂时没有临时zoom全屏化单个pane的功能，根据[^1]中说的，#996暂时也没有纳入1.x的计划中，在2.0中才会发布。这就有点可惜了，只能再期待了。 tmux 12345678910111213141516git clone https://github.com/tmux-plugins/tpm ~/.tmux/plugins/tpm~/.tmux.confset -g mode-keys viset -g @plugin &#x27;tmux-plugins/tpm&#x27;set -g @plugin &#x27;tmux-plugins/tmux-resurrect&#x27;set -g @plugin &#x27;tmux-plugins/tmux-continuum&#x27;​set -g @continuum-save-interval &#x27;15&#x27;set -g @continuum-restore &#x27;on&#x27;set -g @resurrect-capture-pane-contents &#x27;on&#x27;​# Other config ...​run -b &#x27;~/.tmux/plugins/tpm/tpm&#x27; Reference Scenario: Add support for panes · Issue #1000 · microsoft/terminal Windows Terminal Key Bindings | Microsoft Docs","categories":[{"name":"专业","slug":"pro","permalink":"https://sean10.github.io/categories/pro/"}],"tags":[{"name":"windows","slug":"windows","permalink":"https://sean10.github.io/tags/windows/"},{"name":"terminal","slug":"terminal","permalink":"https://sean10.github.io/tags/terminal/"},{"name":"tmux","slug":"tmux","permalink":"https://sean10.github.io/tags/tmux/"}]},{"title":"ceph之df原理","slug":"ceph之df原理","date":"2020-05-24T12:04:33.000Z","updated":"2023-03-18T15:11:14.894Z","comments":true,"path":"2020/05/24/ceph之df原理/","link":"","permalink":"https://sean10.github.io/2020/05/24/ceph%E4%B9%8Bdf%E5%8E%9F%E7%90%86/","excerpt":"ceph df主要得到的是global以及每个pool的used以及max_available.","text":"ceph df主要得到的是global以及每个pool的used以及max_available. 123#Montor.cc文件入口ceph dfpgservice-&gt;dump_fs_stats(&amp;ds, f.get(), verbose);pgservice-&gt;dump_pool_stats(osdmon()-&gt;osdmap, &amp;ds, f.get(), verbose); global FileStore ceph上个版本使用filestore时，计算是基于osd的所在磁盘的statfs来计算的。因此，rbd层面的大的稀疏文件，在落到osd层上之后实际就并不占用那么多了。 12345678# 主体函数PGMapDigest::dump_fs_stats osd_sumPGMap::calc_stats osd_sum = osd_stat_t();OSDService::update_osd_statKStore::statfs BlueStore 1234567891011PGMapDigest::dump_fs_stats osd_sumPGMap::calc_stats osd_sum = osd_stat_t();#疑似现在只有这个函数会刷新数据了OSD::tick_without_osd_lock()OSDService::set_statfsBlueStore::statfs（找不到怎么那边怎么调用到bluestore的，直接来找同名函数了，理论上应该是继承的接口吧？）BlueFS::get_freebluefs这块还不太理解…… pool 是否可以理解为，如果不使用ceph df提供的接口，手动去计算可用pg的容量，就可以直接代表可用容量？ FileStore 1234PGMapDigest::dump_pool_stats_fullPGMapDigest::dump_object_stat_sum疑似是在osd写入时做的更新？PrimaryLogPG::write_update_size_and_usage BlueStore 待阅读 123456789PGMapDigest::dump_pool_stats_full PGMap.cc: pool_raw_used_ratePGMapDigest::dump_object_stat_sum 这里似乎计算的是去除降级后的？仅在MgrStatMonitor::preprocess_statfs中出现了PGMapDigest::get_statfs（这个像是已经deprecated?) PGMapDiest::get_pool_free_space Nautilus变化 根据[^5]可以知道 ceph df [detail] output (POOLS section) has been modified in json format: 'bytes used' column renamed to 'stored'. Represents amount of data stored by the user. 'raw bytes used' column renamed to \"stored_raw\". Totals of user data over all OSD excluding degraded. new 'bytes_used' column now represent amount of space allocated by all OSD nodes. 'kb_used' column - the same as 'bytes_used' but in KB. new column 'compress_bytes_used' - amount of space allocated for compressed data. I.e. comrpessed data plus all the allocation, replication and erasure coding overhead. new column 'compress_under_bytes' amount of data passed through compression (summed over all replicas) and beneficial enough to be stored in a compressed form. 所以在这个版本中将之前版本中存在的多种容量统计给分类了. pool级别分为 * stored(old bytes used) 逻辑空间占用量, 主要针对的是写入多少, 不考虑由于COW引起的实际占用量较小 * store_nromalized = pool_stat.get_user_bytes(raw_used_rate, per_pool) * store_stats.data_stored / raw_used_rate * Bluestore.cc * res_statfs-&gt;data_stored += l.length * 传统模式 stats.sum.num_bytes + stats.sum.num_bytes_hit_set_archive; * 12版本好像没加命中集归档的容量 * 12版本这里直接拿的sum.num_bytes * 通过ceph report可以看到资源池的这个统计 * stored_raw(old raw bytes used) 用户使用的总容量, 包含所有osd除去降级的(这个应该是带副本的吧) * pool_stat.get_user_bytes(1.0, per_pool) * 这里应该是统计store_stats.data_stored的时候一些down的osd就不统计了, 所以为1.0的raw_used_rate. * new bytes used 实际这个资源池里的OSD分配的空间大小(这里应该是不包含其他资源池因为复用osd占用的空间吧?) * pool_stat.get_allocated_bytes * store_stats.allocated; * compress_bytes_used compress的数据 , 分配的空间大小(包含副本/EC的开销), 也就是说除去副本数就是用户数据实际在设备里存储吧 * statfs.data_compressed_allocated * comprress_under_bytes compress的用户数据大小? * statfs.compressed_original 123456789diagraph calltrace &#123; Monitor::handle_command -&gt; mgrstatmon()-&gt;dump_cluster_stats Monitor::handle_command -&gt; mgrstatmon()-&gt;dump_pool_stats -&gt; PGMapDigest::dump_pool_stats_full -&gt; pool_stat_t &amp;stat = pg_pool_sum.at(pool_id) pool_stat_t &amp;stat = pg_pool_sum.at(pool_id) -&gt; pool_stat.get_allocated_bytes pool_stat_t &amp;stat = pg_pool_sum.at(pool_id) -&gt; store_nromalized = pool_stat.get_user_bytes(raw_used_rate, per_pool) pool_stat_t &amp;stat = pg_pool_sum.at(pool_id) -&gt; pool_stat.get_used_bytes(1.0, per_pool) pool_stat_t &amp;stat = pg_pool_sum.at(pool_id) -&gt; statfs.data_compressed_allocated pool_stat_t &amp;stat = pg_pool_sum.at(pool_id) -&gt; statfs.compressed_original&#125; 12345struct pool_stat_t &#123; object_stat_collection_t stats; store_statfs_t store_stats; ...&#125; 变量解释 raw_used_rate num_object_copies num_object_degraded per_pool osd_sum.num_osds == osd_sum.num_per_pool_osds mon: use per-pool stats only when all OSDs are reporting · ceph/ceph@5dcb6d8 osd: per-pool osd stats collection by ifed01 · Pull Request #19454 · ceph/ceph 这里应该是引入点, 为了解决压缩率统计的问题? Backport #37565: luminous: OSD compression: incorrect display of the used disk space - bluestore - Ceph Luminous无法被backport. 哎 data_stored num_bytes 这个还是在PrimaryLogPG.cc里进行统计 PG::_update_calc_stats OSD::send_pg_stats todo 问题: * 资源池显示的使用量实际上并不是osd上实际分配和占用的, 那为什么资源池显示已用满了基本上就不让用了呢? 还是说这两个基本上是一致的? * 按照bluestore这层应该也是和FileStore时一样, 实际上是有洞的,这种情况下, 为什么不默认提供更多的空间呢? 是怕出问题吧? 只有当压缩的时候, 才提供? * compressed的容量是否 * used和 objects数量是否有关呢 * 像是rbd上层4K随机写, 在rados层看到的就是写了2W5的对象以后就100G了, rados还是按照4M对象创建了... * 按照之前我们看pg的op, 理论上应该和objects数量无关才对. * pg处理的是Rados层的请求, 所以其实问题在于rbd层的4k 是怎么转换到4M的. * 问题其实是写了这些对象以后, df看到的容量就满了, 而实际上osd还没满. * mon如何打印出他当前收集的容量信息呢? * ### Luminous pool可用量计算 在代码中，在计算max_avail容量时，在PGMap::get_rules_avail函数中，mon会去迭代所有的资源池，根据pool_id拿到pool的如使用的ruleno的rule id、类型和size信息。拿到上述信息后，使用ruleno找到crush map信息，在这里建立一张基于crush map对各级bucket及osd进行广度优先搜索查找到的map&lt;int, float&gt;的id为key,crush weight为value的表，并进行归一化，让key更新为weight/sum的值。 然后在计算资源池整体可用时，使用上面拿到的osd的kb_avail除以此处拿到的表中osd id对应的归一化结果，取得资源池原始的最大可用空间。 现在要根据当前配置的副本数来获得对于资源池来说可用的空间，在PGMapDigest::dump_pool_stats_full函数中副本数变量为raw_used_rate。 针对Replicated类型，直接赋为资源池size 针对Erasure类型，从erasure_code_profile中获取到k和m，赋为\\((k+m)/k\\) 最后直接得到资源池可用空间\\(\\frac{max_avail}{raw_used_rate}\\) pool使用量计算 在PGMapDigest的成员变量mempool::pgmap::unordered_map&lt;int32_t,pool_stat_t&gt; pg_pool_sum中保存着pool的pg的对应资源池中的使用量num_bytes的和。该数据在ceph df detail中进行汇总 可以用下面这个命令看到这些统计 1ceph report 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455struct pool_stat_t &#123; object_stat_collection_t stats; ...&#125;;struct object_stat_collection_t &#123; /************************************************************************** * WARNING: be sure to update the operator== when adding/removing fields! * **************************************************************************/ object_stat_sum_t sum; ...&#125;;struct object_stat_sum_t &#123; /************************************************************************** * WARNING: be sure to update operator==, floor, and split when * adding/removing fields! **************************************************************************/ int64_t num_bytes; // in bytes int64_t num_objects; int64_t num_object_clones; int64_t num_object_copies; // num_objects * num_replicas int64_t num_objects_missing_on_primary; int64_t num_objects_degraded; int64_t num_objects_unfound; int64_t num_rd; int64_t num_rd_kb; int64_t num_wr; int64_t num_wr_kb; int64_t num_scrub_errors; // total deep and shallow scrub errors int64_t num_objects_recovered; int64_t num_bytes_recovered; int64_t num_keys_recovered; int64_t num_shallow_scrub_errors; int64_t num_deep_scrub_errors; int64_t num_objects_dirty; int64_t num_whiteouts; int64_t num_objects_omap; int64_t num_objects_hit_set_archive; int64_t num_objects_misplaced; int64_t num_bytes_hit_set_archive; int64_t num_flush; int64_t num_flush_kb; int64_t num_evict; int64_t num_evict_kb; int64_t num_promote; int32_t num_flush_mode_high; // 1 when in high flush mode, otherwise 0 int32_t num_flush_mode_low; // 1 when in low flush mode, otherwise 0 int32_t num_evict_mode_some; // 1 when in evict some mode, otherwise 0 int32_t num_evict_mode_full; // 1 when in evict full mode, otherwise 0 int64_t num_objects_pinned; int64_t num_objects_missing; int64_t num_legacy_snapsets; ///&lt; upper bound on pre-luminous-style SnapSets int64_t num_large_omap_objects = 0;&#125; osd使用的空间 12.2.13这部分函数似乎被重构了, update_osd_stat没有入参了. 12345678void OSD::heartbeat()-&gt;void OSDService::update_osd_stat(vector&lt;int&gt;&amp; hb_peers)-&gt; int BlueStore::statfs(struct store_statfs_t *buf)这里通过指针设置了`Compress`和`compress_origin`的变量. 这里有个available, 为什么压缩后, 这里显示的减去之后获取到的容量还是实际使用了compress_origin的空间? 1struct store_statfs_t 这里的available是什么时候计算的? 1ceph daemon osd.1 pref dump | grep bluestore bluestore_allocated bluestore_stored bluestore_compressed bluestore_compressed_allocated bluestore_compressed_original 这里的容量分别是什么意思? 11.76-9.89=1.86g 这个compressed容量只有在占用正式结束了才会统计? 在流式使用空间的过程中, osd_used在逐渐增加, 但是这个compress一直没变. 似乎这里把struct store_statfs_t stbuf拿到的stbuf给通过OSDService::set_osd_stat给传过去了, 然后这里的值就是osd_stat的计数器里的值了. 稍后就直接传给mon了. 好像初始化的时候, osd默认就占用1.01G空间? num_bytes似乎和osd_stat里的used和available没什么关系?目前看到的现象是ceph osd df里看到的osd的used只有18.8G, 但是ceph df看到的资源池的使用量是61.6G, 3个osd, 2副本. 而我真实写入的文件大小是用/dev/zero生成的21G文件+ 一堆之前的, ceph df看到的是用户的操作 我关闭Compress之后, osd的used增加大概是3个G, 差不多欸, 我写的是10G对象, 拆到每个osd上. 理论上应该有7个G左右. 而那几个开了compress的大概是增加1个G. sum.num_bytes在哪里计算的呢? PGMapDigest下的public成员变量mempoool::pgmap::unordered_map&lt;int32_t,pool_stat_t&gt; pg_pool_sum. 应该是这里更新的. auto it2 = pg_pool_sum.find(it.first)-&gt;const pool_stat_t *pstat-&gt;const object_stat_sum_t&amp; sum void PGMap::update_pool_deltas(这个有点像, 不过这里计算的应该是差值吧? pg_pool_sum里的差值有哪些?应该不是 尝试搜索num_bytes =, 搜了下, 没有, 那应该意味着是通过聚合性质的做的计算, 按照C++的限制,应该是会通过字符串作为key的列表, 转换成对应的变量. emm, 只找到dump时的字符串与原始计数器 和 一个mon这里的pcb.add_u64(的任务, 这里的这个mon的东西是全局统计, 通过PGMonitor::update_logger这里更新. 啊, 忘了, 应该搜num_bytes +=, 在PrimaryLogPG.cc里出现了osd的统计ctx-&gt;delta_stats-&gt;num_bytes, 在osd_types.cc里也出现了操作符重载的void object_stat_sum_t::add的操作. 然后publish_stats_to_osd pg_info_t -&gt; pg_stat_t -&gt; pg_stats_publish -&gt; osd_stat_updated = true -&gt; send_pg_stats -&gt; m-&gt;pg_stat[pg-&gt;info.pgid.pgid] = pg-&gt;pg_stats_publish; 这里会将变化的pg的stat_queue_item入队到pg_stat_queue中。然后设置osd_stat_updated为True。入队之后，由tick_timer在C_Tick_WithoutOSDLock这个ctx中通过send_pg_stats()将PG的状态发送给Monitor。这样Monitor就可以知道pg的的变化了。 mon哪里处理这个接收到的最新的pg数据呢? 搜索这个msg结构体中的.pg_stat, 看到个下面这个, 是不是ClusterState::ingest_pgstats呢, 的确是这个, 在DaemonServer::ms_dispatch中调用这个更新的数据 在ClusterState中定义了PGMap::Incremental pending_inc;这里填充的pg_stat_updates 在比如PGMap::apply_incremental的好多地方都直接处理了这个更新的数据. 这样我就不好找到底把df的内容存哪去了. 最后应该是存到了PGMap里的`mempool::pgmap::unordered_map&lt;pg_t,pg_stat_t&gt; pg_stat里. 这个pgmap应该是哪里实例化的呢? PGMonitor ? 这个的初始化的Monitor在ceph_mon.cc里, 似乎初始化ceph-mon的时候只读取了version_t v = store-&gt;get(\"monmap\", \"last_committed\");? 那数据难道还是在osd上? 而且mon数据丢失似乎是可以恢复过来的. 通过ceph pg dump --format json-pretty是可以导出num_bytes的, 而daemon osd.x perf dump反而拿不到. 通过ceph-objectstore-tool可以拿到OSD里存的pg的信息 ceph-objectstore-tool查看OSD数据库中bluestore pg信息 如何解密然后修改呢 export pg信息似乎走的是RadosDump 欸,如果我要修改某个值, 要停掉这个pg所在的所有osd? ObjectStoreTool::do_export get_log PGLog::IndexedLog 这个为啥不能用pg_log_t解码呢? 根据[^9这个来看,其实还是遵守了kv数据结构的,只是好像在哪层被过滤掉了? 试了下, get-bytes拿到的是对象的内容 那么是否说明其实也是计算, 而不是累加的呢? info这个数据似乎无从修改, 只有pg的元数据可以修改的样子? 这个疑似PGLog::IndexedLog, 不知道怎么改 按照现在看到的objects的问题, 是不是这个pg提供的objects指标全都是负数,所以上层统计的也都是 但是现在在数据库里list, list不出这个pg, 是代表什么呢? 我应该只能从代码到底是怎么list, 用的什么接口然后查不到这个pg来看吧? 用rados ls -p data02, 因为这个资源池理论上其实不应该有任何object, 所以应该也是查不到东西, 但是实际存在了几个对象信息为负数的object. 以osd级别来显示object, 看看带不带pg的信息. pg上面统计的信息, 感觉像是以object为单位处理的啊. 假如说真是以pg自己来存储自己的信息, 那么object和pg之间就存在歧义性了. ceph pg dump显示的pg id不完整, 被坑了. scrub是一个方案, 看看能不能修复他, 根据EC 现在pg的指标是负数, 还有什么信息能够用来处理呢?object无法查到 rados ls 卡住,无论哪个, 可能受影响了 ceph-objectstore-tool 查询这个pg, list也是空的 ceph pg repair pg.$id 居然就修复了. 所以repair过程发生了什么 todo pgid居然是As1 librados: wait_for_osdmap done waiting 是否代表某个客户端占用了这个吧所? 打开--debug_objecter 40 --debug_rados 40看到的内容就是上述的. objecter给出的信息更多一点, 看着 这中间慢在哪里呢?ms_dispatch ceph osd df SIZE 没问题 USE 是上面的store呢还是allocated? AVAIL 又是哪种呢? 在正常情况下ceph osd df 看到的osd的used是跟ceph df看到的stored一致的, 但是这个数据是在osd这里实际存储的, 而ceph df却并不是 这里看到的osd的容量是 pgs-&gt;get_osd_sum().kb PGStatService *pgs PGMapStatService get_osd_sum() return pgmap.osd_sum; pgmap怎么更新? 指向的是ClusterState中的pg_map mgr ClusterState::ingest_pgstats ClusterState::notify_osdmap mon tick() send_report() 根据[^8]里可以看到这个MonPGStatService是\b\b\b\b\bceph-mon把内容转嫁到ceph-mgr的中间层. pool使用的空间 used 所以根据上面来看, 这边的容量并不是根据osd_stat汇总的了, 而是pg这层自己维护的? 根据[^7] bytes used 逻辑空间占用量, 主要针对的是写入多少, 不考虑由于COW引起的实际占用量较小 12版本这里直接拿的sum.num_bytes 通过ceph report可以看到资源池的这个统计 raw bytes used 用户使用的总容量, 包含所有osd除去降级的(这个应该是带副本的吧) pool_stat.get_user_bytes(1.0, per_pool) compress_bytes_used compress的数据 , 分配的空间大小(包含副本/EC的开销), 也就是说除去副本数就是用户数据实际在设备里存储吧 statfs.data_compressed_allocated 12版本还在osd里 comprress_under_bytes compress的用户数据大小? statfs.compressed_original sum.num_bytes属于pool_stat_t里的object_stat_collection_t stats, 这个东西怎么从pg_map里得到的? 在PGMap::calc_stats里似乎pg_sum = pool_stat_t(), 但是这个pool_stat_t的构造函数里只是构造并初始化为0, emm, 只在decode的时候被调用, 倒是的确没什么影响. cephfs使用的空间 cephfs上删除太多文件, 出现了ceph df看到的used为EiB的情况, 通过json打印出来, 看到实际上统计的bytes为负数, 引起的. 根据[^6], 好像说是和cephfs文件系统有关系? osd特殊场景 在osd out之后，该osd在2.4.1中提到的kb_avail会变成0，因此可用容量不需要计算 max_avaible 单pool计算公式 资源池容量计算，主要在osd容量的基础上，遵循下述公式进行 \\[max.avail = min(\\frac{osd\\_avail_0}{\\frac{weight_0}{\\sum_{i=0}^nweight_i}}, \\frac{osd\\_avail_1}{\\frac{weight_1}{\\sum_{i=0}^nweight_i}}, \\dots, \\frac{osd\\_avail_j}{\\frac{weight_j}{\\sum_{i=0}^nweight_i}})/pool.size\\] max_avail: 该资源池最大可用空间 min: 取括号范围内的最小值 osd_avail: 表示某个编号osd对应的可用空间 weight: 表示对应某个编号osd对应的crush weight pool_size: 表示pool对应副本数(或纠删码经计算后的数值) rbd rbd du 需要开启object-map fast-diff功能之后统计拿到的数据才是正确的，否则就会出现每层快照占用的容量都会比原始数据要大 根据[^4], 好像rbd的discard选项, 影响这个容量的问题. rbd diff 1rbd diff rbd/zp | awk &#x27;&#123; SUM += $2 &#125; END &#123; print SUM/1024/1024 &quot; MB&quot; &#125;&#x27; 异常情况 osd down 对容量无影响 ### osd out 在未达到min size阶段可继续使用的pool，只有osd正式out了，容量才会变更。 仅当被从crush中挪走或不存在in的osd，才会真的容量变化。 Reference Ceph df分析_运维_weixin_44389885的博客-CSDN博客 ceph全局GLOBAL容量和POOLS级别容量计算_awk_pansaky的博客-CSDN博客$$ Ceph中的容量计算与管理 - gold叠 - 博客园 kubernetes - How to explain Ceph space usage - Stack Overflow osd: per-pool osd stats collection by ifed01 · Pull Request #19454 · ceph/ceph Bug #16671: \"ceph df\"object num is negative - Ceph - Ceph Ceph中的容量计算与管理 - gold叠 - 博客园 https://runsisi.com/2019-02-27/ceph-pg-stat pglog出错导致osd启动失败的解决办法 - 简书","categories":[{"name":"专业","slug":"pro","permalink":"https://sean10.github.io/categories/pro/"}],"tags":[{"name":"ceph","slug":"ceph","permalink":"https://sean10.github.io/tags/ceph/"},{"name":"存储","slug":"存储","permalink":"https://sean10.github.io/tags/%E5%AD%98%E5%82%A8/"}]},{"title":"ceph之librados使用","slug":"ceph之librados使用","date":"2020-05-20T19:43:44.000Z","updated":"2023-07-18T03:12:18.001Z","comments":true,"path":"2020/05/21/ceph之librados使用/","link":"","permalink":"https://sean10.github.io/2020/05/21/ceph%E4%B9%8Blibrados%E4%BD%BF%E7%94%A8/","excerpt":"librados是ceph各组件对外暴露的模块，藉由librados接口，可以高效的使用ceph内的组件进行CRUD等操作。","text":"librados是ceph各组件对外暴露的模块，藉由librados接口，可以高效的使用ceph内的组件进行CRUD等操作。 12345import radoscluster = rados.Rados(conffile = &#x27;ceph.conf&#x27;, conf = dict (keyring = &#x27;/path/to/keyring&#x27;))cluster.connect()cmd = json.dumps(&#123;&quot;prefix&quot;: &quot;osd safe-to-destroy&quot;, &quot;ids&quot;: [&quot;2&quot;], &quot;format&quot;: &quot;json&quot;&#125;)c.mon_command(cmd, b&#x27;&#x27;) 这里的conf=keyring主要用于当打开了cephx等认证措施时，ceph.conf中又没有记录认证所用到的keyring文件路径时，进行额外设置使用。 最近我在参照python的librados使用，调用C的接口时，就一直遇到cephx认证打开之后，无法成功rados_connect的情况，具体原理还得细看，但应该和cephx及这个keyring存在强相关性是可以确认的了。 连接成功之后，主要使用下属这几个接口来查询pool,osd,pg等一些信息。 1234Rados.mon_command(self, cmd, inbuf, timeout=0, target=None)Rados.osd_command(self, osdid, cmd, inbuf, timeout=0)Rados.mgr_command(self, cmd, inbuf, timeout=0, target=None)Rados.pg_command(self, pgid, cmd, inbuf, timeout=0) 就目前而言，我在抓取IO等指标时，用的比较多的接口是mon_command和mgr_command，使用这几个接口能进行的操作，都有提供cli和rest接口。我主要是在使用cli熟悉接口之后，会去代码中的MonCommands.h和MgrCommands.h文件中去找相近的prefix，然后参照着使用。 但是偶尔也是会遇到像ceph osd pool stats和ceph pg ls-by-pools这类没怎么能找到相关prefix的情况。这个时候可以充分利用起ceph这个cli入口其实是个python文本的功能了。 python -m pgd /bin/ceph osd pool stats执行，在new_style_command函数内的json_command处打断点，进入后，打印cmddict就可以看到cli发送出去的prefix拼接出来是什么样子的了，然后再拿着这个去代码里搜就好了。 开发者模式[^2] make vstart async模式 mon_command_async 好像RadosClient.cc里有这个异步下发任务, 但是似乎并没有对外提供成librados的接口. 之后有空应该是可以利用这个封装出来使用的应该. radosstripper理解 rados连接过程 似乎有加载client name. parse_config_files似乎还有指定不读取任何配置文件的时候, 即便是默认配置文件 global_pre_init里调用的似乎就是这个. \"cdef class Rados(object):\"-&gt;\"name = 'client.admin'\" 默认name client.admin context 是什么? rados_create2 rados_create_cct() librados::RadosClient::connect理解 monclient.init() 源码 RadosClient IoctxImpl AioCompletionImpl osdc 超时参数 client_mount_timeout client rados_osd_op_timeout 连接上osd后, osd断开的时间 rados_mon_op_timeout 连接上mon后,mon响应的超时时间 key/nspace/hash key相当于替换object_name的一个映射名 nspace是在crush计算时, 拼接的前缀名 hash可以直接指定pg, 但是这个好像没有封装提供对外接口 get_object_pg_hash_position\u0000 只有查询函数 12345678910111213141516171819202122232425262728293031323334// mappingint OSDMap::map_to_pg( int64_t poolid, const string&amp; name, const string&amp; key, const string&amp; nspace, pg_t *pg) const&#123; // calculate ps (placement seed) const pg_pool_t *pool = get_pg_pool(poolid); if (!pool) return -ENOENT; ps_t ps; if (!key.empty()) ps = pool-&gt;hash_key(key, nspace); else ps = pool-&gt;hash_key(name, nspace); *pg = pg_t(ps, poolid); return 0;&#125;int OSDMap::object_locator_to_pg( const object_t&amp; oid, const object_locator_t&amp; loc, pg_t &amp;pg) const&#123; if (loc.hash &gt;= 0) &#123; if (!get_pg_pool(loc.get_pool())) &#123; return -ENOENT; &#125; pg = pg_t(loc.hash, loc.get_pool()); return 0; &#125; return map_to_pg(loc.get_pool(), oid.name, loc.key, loc.nspace, &amp;pg);&#125;\u0000 pacafic版本, 实际超时退出时间为client_mount_timeout的10倍 3c2b30e这次提交, get_monmap_and_config中重构成10次retry, 而这个函数之前就是在oneshot monmap fdde016中引入的monclient过程中get_monmap_and_config以及设置10倍的interval, 之前12版本不存在该项, 所以不会10倍超时. 这个提交13版本就开始有了. 这条commit关联的pr中有144条commit, 该条commit也说了只是解决了问题, 所以设计初衷并不算很清晰 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485int MonClient::get_monmap_and_config()&#123; ldout(cct, 10) &lt;&lt; __func__ &lt;&lt; dendl; ceph_assert(!messenger); int tries = 10; cct-&gt;init_crypto(); auto shutdown_crypto = make_scope_guard([this] &#123; cct-&gt;shutdown_crypto(); &#125;); int r = build_initial_monmap(); if (r &lt; 0) &#123; lderr(cct) &lt;&lt; __func__ &lt;&lt; &quot; cannot identify monitors to contact&quot; &lt;&lt; dendl; return r; &#125; messenger = Messenger::create_client_messenger( cct, &quot;temp_mon_client&quot;); ceph_assert(messenger); messenger-&gt;add_dispatcher_head(this); messenger-&gt;start(); auto shutdown_msgr = make_scope_guard([this] &#123; messenger-&gt;shutdown(); messenger-&gt;wait(); delete messenger; messenger = nullptr; if (!monmap.fsid.is_zero()) &#123; cct-&gt;_conf.set_val(&quot;fsid&quot;, stringify(monmap.fsid)); &#125; &#125;); want_bootstrap_config = true; auto shutdown_config = make_scope_guard([this] &#123; std::unique_lock l(monc_lock); want_bootstrap_config = false; bootstrap_config.reset(); &#125;); ceph::ref_t&lt;MConfig&gt; config; while (tries-- &gt; 0) &#123; r = init(); if (r &lt; 0) &#123; return r; &#125; r = authenticate(cct-&gt;_conf-&gt;client_mount_timeout); if (r == -ETIMEDOUT) &#123; shutdown(); continue; &#125; if (r &lt; 0) &#123; break; &#125; &#123; std::unique_lock l(monc_lock); if (monmap.get_epoch() &amp;&amp; !monmap.persistent_features.contains_all( ceph::features::mon::FEATURE_MIMIC)) &#123; ldout(cct,10) &lt;&lt; __func__ &lt;&lt; &quot; pre-mimic monitor, no config to fetch&quot; &lt;&lt; dendl; r = 0; break; &#125; while ((!bootstrap_config || monmap.get_epoch() == 0) &amp;&amp; r == 0) &#123; ldout(cct,20) &lt;&lt; __func__ &lt;&lt; &quot; waiting for monmap|config&quot; &lt;&lt; dendl; auto status = map_cond.wait_for(l, ceph::make_timespan( cct-&gt;_conf-&gt;mon_client_hunt_interval)); if (status == std::cv_status::timeout) &#123; r = -ETIMEDOUT; &#125; &#125; if (bootstrap_config) &#123; ldout(cct,10) &lt;&lt; __func__ &lt;&lt; &quot; success&quot; &lt;&lt; dendl; config = std::move(bootstrap_config); r = 0; break; &#125; &#125; lderr(cct) &lt;&lt; __func__ &lt;&lt; &quot; failed to get config&quot; &lt;&lt; dendl; shutdown(); continue; &#125;\u0000 rados lock samba/ctdb_mutex_ceph_rados_helper.c at master · samba-team/samba Reference Librados (Python) — Ceph Documentation 深入理解ceph crush(2)—-手动编译ceph集群并使用librados读写文件 · Dovefi never stop Ceph学习——Librados与Osdc实现源码解析_SEU_PAN的博客-CSDN博客","categories":[{"name":"专业","slug":"pro","permalink":"https://sean10.github.io/categories/pro/"}],"tags":[{"name":"ceph","slug":"ceph","permalink":"https://sean10.github.io/tags/ceph/"},{"name":"存储","slug":"存储","permalink":"https://sean10.github.io/tags/%E5%AD%98%E5%82%A8/"},{"name":"rados","slug":"rados","permalink":"https://sean10.github.io/tags/rados/"}]},{"title":"正则表达式BRE/ERE/PRE","slug":"正则表达式BRE-ERE-PRE","date":"2020-05-16T15:53:18.000Z","updated":"2023-03-18T15:11:14.865Z","comments":true,"path":"2020/05/16/正则表达式BRE-ERE-PRE/","link":"","permalink":"https://sean10.github.io/2020/05/16/%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8FBRE-ERE-PRE/","excerpt":"概述 在开发过程中，经验遇到使用不同语言不同工具时，正则表达式无法直接复用的问题。主要原因在于不同语言使用的正则表达式的标准也是不一样的。","text":"概述 在开发过程中，经验遇到使用不同语言不同工具时，正则表达式无法直接复用的问题。主要原因在于不同语言使用的正则表达式的标准也是不一样的。 Basic Regular Expression Extended Regular Expression Perl Regular Expression 主要区别[^1] 流派 说明 BRE () {} + ? |都必须转义使用 ERE 元字符不必转义, + ? ( ) { } |可以直接使用 PRE 除了ERE支持的之外，还支持 BRE、ERE可以使用POSIX字符集来操作 使用支持 grep 支持BRE，通过参数控制，默认BRE, -P开启PRE, -E开启ERE sed 支持BRE，默认BRE，-r开启ERE awk 支持ERE，默认ERE。 C c语言的regex根据man 3 regex看到的内容来看，支持BRE和ERE. 另外由于C语言字符串处理的性质，一般使用元字符时，需要额外的转义符，如\\s Python python使用的是PRE，所以处理起来要相对C要简单不少 疑问 为什么search和findall同时存在呢? findall输出的内容里, 匹配输出过的字符串位置不会再作为输入被读取了呢? 当我需要严格的全部匹配结果的时候...应该怎么做呢? 常用 不包含指定字符串所在行, 即过滤,取反能力 不包含kuebelet的行 1^((?!kubelet).)*$ 零宽断言 在aaa后面的字符串, 不捕获aaa. 1(?&lt;=aaa).* Reference 正则表达式基础知识|Jerkwin","categories":[{"name":"专业","slug":"pro","permalink":"https://sean10.github.io/categories/pro/"}],"tags":[{"name":"linux","slug":"linux","permalink":"https://sean10.github.io/tags/linux/"},{"name":"re","slug":"re","permalink":"https://sean10.github.io/tags/re/"},{"name":"正则表达式","slug":"正则表达式","permalink":"https://sean10.github.io/tags/%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F/"}]},{"title":"C可变参数","slug":"C可变参数","date":"2020-04-28T17:29:14.000Z","updated":"2023-03-18T15:11:14.901Z","comments":true,"path":"2020/04/29/C可变参数/","link":"","permalink":"https://sean10.github.io/2020/04/29/C%E5%8F%AF%E5%8F%98%E5%8F%82%E6%95%B0/","excerpt":"旧笔记整理后发布","text":"旧笔记整理后发布 C99编译器允许可变参数宏(variadic macros), GCC默认使用的标准是GNU89/90标准，这个标准在C89的基础上增加了一些C99的功能（就比如这个Variadic macro）[^3]。 123456man gcc... gnu90 gnu89 GNU dialect of ISO C90 (including some C99 features). This is the default for C code. 查看gcc版本 1gcc -E -dM - &lt;/dev/null | grep &quot;STDC_VERSION&quot; 1234567891011#include &lt;stdio.h&gt;int main(void) &#123;#ifdef __STDC__ printf(&quot;%s\\n&quot;, &quot;stardard c&quot;);#endif#ifdef __STDC_VERSION__ printf(&quot;%d\\n&quot;, __STDC_VERSION__);#endif return 0;&#125; 在这个版本中增加的宏__VA_ARGS__前增加##可以完成对逗号的处理，在没有传入额外参数时，gcc对代码进行预处理时，识别到##会将逗号给去除。如果不加入这个，那在不传入额外参数时，就会编译错误。[^4] example 1234567891011121314151617181920212223242526#include &lt;syslog.h&gt;#include &lt;stdarg.h&gt;#include &lt;stdio.h&gt;#define BUFF_LEN_O 1024#define LOGGER(priority, format, ...) logger(priority, format, __FUNCTION__, __LINE__, ##__VA_ARGS__)static void logger(int priority, const char *format, ...)&#123; openlog(&quot;test_log&quot;, LOG_PID | LOG_NDELAY, LOG_LOCAL0); va_list ap; char buff[BUFF_LEN_O] = &#123;0&#125;; char placeholder[] = &quot;function&#123;%s&#125;,line&#123;%d&#125;&quot;; va_start(ap, format); snprintf(buff, sizeof(buff) - 1, &quot;%s %s&quot;, placeholder, format); vsyslog(priority, buff, ap); va_end(ap);&#125;int main()&#123; printf(&quot;%s %d\\n&quot;, __FUNCTION__, __LINE__); LOGGER(LOG_INFO, &quot;hello world %s&quot;, &quot;123&quot;); LOGGER(LOG_ERR, &quot;new&quot;); logger(LOG_INFO, &quot;hello world %s&quot;, __FUNCTION__, __LINE__, &quot;123&quot;); return 0;&#125; Reference C99 open-std.org/JTC1/SC22/WG14/www/docs/n897.pdf C11 ISO/IEC 9899:201x C Extensions - Using the GNU Compiler Collection (GCC) Variadic Macros - Using the GNU Compiler Collection (GCC)","categories":[{"name":"专业","slug":"pro","permalink":"https://sean10.github.io/categories/pro/"}],"tags":[{"name":"C","slug":"C","permalink":"https://sean10.github.io/tags/C/"},{"name":"linux","slug":"linux","permalink":"https://sean10.github.io/tags/linux/"},{"name":"gcc","slug":"gcc","permalink":"https://sean10.github.io/tags/gcc/"}]},{"title":"C++远程开发&&跨平台Sourcetrail","slug":"C-远程开发-跨平台Sourcetrail","date":"2020-04-24T02:28:13.000Z","updated":"2023-03-18T15:11:14.840Z","comments":true,"path":"2020/04/24/C-远程开发-跨平台Sourcetrail/","link":"","permalink":"https://sean10.github.io/2020/04/24/C-%E8%BF%9C%E7%A8%8B%E5%BC%80%E5%8F%91-%E8%B7%A8%E5%B9%B3%E5%8F%B0Sourcetrail/","excerpt":"Clion配置 Clion支持基于cmake的远程开发，最近用来在windows上开发linux程序时的高亮、提示、补全。相对以前开发时很多unix特定的头文件无法提示出来，现在要好得多了。 基本配置方式就是在perference-&gt;Build\\Execution\\Deployment-&gt;toolchains里添加remote debug环境，也可以配置gdb server做远程调试。 如果新引入了动态库，需要重新让clion去下载一下依赖的库建立索引的时候，点击Tools-&gt;Resync with Remote Hosts重新同步就可以了。","text":"Clion配置 Clion支持基于cmake的远程开发，最近用来在windows上开发linux程序时的高亮、提示、补全。相对以前开发时很多unix特定的头文件无法提示出来，现在要好得多了。 基本配置方式就是在perference-&gt;Build\\Execution\\Deployment-&gt;toolchains里添加remote debug环境，也可以配置gdb server做远程调试。 如果新引入了动态库，需要重新让clion去下载一下依赖的库建立索引的时候，点击Tools-&gt;Resync with Remote Hosts重新同步就可以了。 Sourcetrail阅读代码 另外，配合去年开源的Sourcetrail来看代码感觉也不错，调用图索引的也还可以。而且sourcetrail在建立C/C++的索引的时候，也可以使用cmake导出的一个cdb成果物。 1cmake -DCMAKE_EXPORT_COMPILE_COMMANDS .. 编译时增加上述选项就可以导出compile_commands.json这个文件，包含代码src路径和include路径、编译选项等等，用这种方式建立索引的时候就不会报错了。但是好像大部分时候看代码时也不是那么需要某些头文件的提示，缺失也影响不大。 跨平台sourcetrail建立索引[^2] 但是在开发的时候大部分代码其实主要还是linux环境偏多，并不兼容MinGW的时候，就容易出现错误文件数量过多，影响阅读的时候。针对这种情况，issue里也给出了一个方法，suorcetrail提供了command line功能，可以在编译环境中， 完成索引，然后再把生成的数据库文件拖回本机打开工程，就能直接看到代码了。 可以用图形界面直接创建一个sourcetrail工程(得到.srctrlprj文件)，然后将在编译环境中的源码路径或者是上面提到过的compile_commands.json的路径给填上。 把这个srctrlprj文件放到编译环境中，在编译环境中执行Sourcetrail index &lt;path/to/your/project.srctrlprj&gt; 把生成的srctrldb文件拖回本地srctrlprj文件所在目录，用Sourcetrail打开即可。 还是太卡了 OpenGrok + Universal CTags understand Reference Support CMake files for project setup · Issue #35 · CoatiSoftware/Sourcetrail Remote indexing · Issue #134 · CoatiSoftware/Sourcetrail","categories":[{"name":"专业","slug":"pro","permalink":"https://sean10.github.io/categories/pro/"}],"tags":[{"name":"C++","slug":"C","permalink":"https://sean10.github.io/tags/C/"},{"name":"Clion","slug":"Clion","permalink":"https://sean10.github.io/tags/Clion/"},{"name":"Sourcetrail","slug":"Sourcetrail","permalink":"https://sean10.github.io/tags/Sourcetrail/"},{"name":"Index","slug":"Index","permalink":"https://sean10.github.io/tags/Index/"}]},{"title":"小黑的故事梳理","slug":"小黑的故事梳理","date":"2019-10-05T14:24:48.000Z","updated":"2023-03-18T15:11:14.857Z","comments":true,"path":"2019/10/05/小黑的故事梳理/","link":"","permalink":"https://sean10.github.io/2019/10/05/%E5%B0%8F%E9%BB%91%E7%9A%84%E6%95%85%E4%BA%8B%E6%A2%B3%E7%90%86/","excerpt":"剧透预警","text":"剧透预警 故事发展 与小黑相关的主要人物线 罗小黑战记剧场版-c369f14a-ac8d-4fd8-9ab2-629b6b257034 小黑 小黑虽然是本片的主角，故事围绕着他发展，是本片营造的矛盾的中心，但主要出于一个提供矛盾点的作用。 在片中，在风息和无限两个阵营中处于一个阵营切换的地位。他在片中的成长点主要在于对于好坏的认知，逐步从狭义到广义，再到是相对的概念。 * 谁对我好，谁是好人（风息的第一次接触、无限的陪伴过程） * 好人的概念是不是广义绝对的？（无限回答为何抓风息，风息在整体上做了什么） * 好人是有立场的（最后决战完，风息失败了，从他理解风息的角度，风息还是个好人） 风息 风息的理念主要是人妖平等，指的是妖与人的互不侵犯的平等，根据本片来看，风息的目的主要是实现妖不用再流浪。 风息曾提到人与妖的过去曾经是人不知道妖的存在、人将妖看作为神、到如今人已不知晓妖，妖的生存空间（自然）在逐渐被开发。可以看到，从风息的立场来说，妖是处于受害者的位置的。 然后，从本片开场风息控制人类、无限来抓风息来看，风息应该是仇视人类，甚至是有伤害人类的行为的。开场时，风息就已经不像会馆里人认知的那样，是为了妖的整体考虑的了，已经是为了自己、为了大部分的妖了，从这时，风息已经为了实现妖有自己不变的家园，可以接受自己承担路上伤害无辜者的罪孽这点了。后面所做的，小黑等等，已经不在他心中不可伤害了。 无限 无限的立场是会馆中的人类，是处于人妖均衡的立场的。从我们的认知来看，会馆当前维持的局面是，大众不知晓妖的存在，从而实现的和谐相处下的均衡关系（当前应该是高层可以知晓的）。从未来发展的角度猜测，会馆应该是有在向可以让大众知晓的情况下，人与妖还能和谐发展的均衡关系发展的。 所以无限开场，试图捕获风息，让风息去会馆冷静一下这点没有任何问题。至于抓错了小黑，在找不到风息时，将小黑顺便送回会馆是一个顺便的事情。在带回去的过程中，和小黑培养感情（这个的节奏就有些缓慢，也有TV版治愈的感觉了）。在带回去的过程中，小黑被抓走，甚至被抢走领域而生命垂危，这就是无限个人情感上不可接受的点了，无限冲入被风息控制的灵质空间也就有原因了。 最终，制止了风息，小黑救回来，然后抵达神秘的会馆。小黑因与无限的羁绊确立师徒关系算是一个圆满。 作为电影 就像上面列的3个角色的发展那样，故事的发展应该主要围绕着双方立场和行为矛盾点展开。其外的内容比例一般应该是有所控制。但是电影中有一点虽然作为粉丝看着很开心，作为非观众的话，可能觉得节奏有问题的一部分，无限带小黑回会馆的这部分日常的故事这段，占用篇幅过长。因为从推进故事的角度来看，应该是没有那么重要。可以用于扩充其他角色的角度来阐述更多的背景或是矛盾点，可能会显得更好。不过这样小黑的出场可能就少了些许。","categories":[{"name":"随想","slug":"thinking","permalink":"https://sean10.github.io/categories/thinking/"}],"tags":[{"name":"动漫","slug":"动漫","permalink":"https://sean10.github.io/tags/%E5%8A%A8%E6%BC%AB/"},{"name":"罗小黑战记","slug":"罗小黑战记","permalink":"https://sean10.github.io/tags/%E7%BD%97%E5%B0%8F%E9%BB%91%E6%88%98%E8%AE%B0/"}]},{"title":"hexo主题自定义--修改indigo tag显示","slug":"hexo主题自定义","date":"2019-01-17T12:57:48.000Z","updated":"2021-01-16T13:57:48.000Z","comments":true,"path":"2019/01/17/hexo主题自定义/","link":"","permalink":"https://sean10.github.io/2019/01/17/hexo%E4%B8%BB%E9%A2%98%E8%87%AA%E5%AE%9A%E4%B9%89/","excerpt":"","text":"更换hexo-theme-indigo的时候，发现作者也是个简约主义啊，功能足够就行了，不需要更新，hhh。 增加引用 首先，将next主题中一直用的addthis统计与分享功能引入。 官网上很简单，就是一行html和js，不过似乎在我使用时，可能排版上与js中携带的addthis模块排版冲突了，导致没能显示出来 修改tag显示 主要的问题在于, 当写的Tag总计多了时, 观察不到哪些tag的文章比较多 当时初步想的是hexo-tag-cloud或者是雷达图效果. 不过想了下, 这方面如果更换, 可能css也得换, 修改较多. 试试看能不能直接在tag名字后面加一个统计数字. 这个API里理论上应该有提供 翻了下代码, 感觉layout/tags.ejs有点像显示的代码, 翻到个函数is_tag, 全局没搜到, 那应该代表着这里的一些信息是从hexo或者hexo的插件里获取到的. 的确,根据Helpers | Hexo, 在这里找到了这个函数. 对, 和页面上的id, class比对了下, 的确这里是正文中的tag和post显示的位置. 123456789101112131415161718192021222324252627&lt;% if(is_tag()) &#123; %&gt; &lt;div class=&quot;waterfall&quot;&gt; &lt;% page.posts.each(function(post)&#123; %&gt; &lt;%- partial(&#x27;_partial/archive&#x27;, &#123;post: post, date_format: config.date_format&#125;) %&gt; &lt;% &#125;) %&gt; &lt;/div&gt; &lt;% &#125; else &#123; site.tags.each(function(tag)&#123; if(tag.length)&#123; %&gt; &lt;h3 class=&quot;archive-separator&quot; id=&quot;tag-&lt;%=tag.name %&gt;&quot;&gt;&lt;%=tag.name %&gt;&lt;/h3&gt; &lt;div class=&quot;waterfall&quot;&gt; &lt;% tag.posts.each(function(post)&#123; %&gt; &lt;%- partial(&#x27;_partial/archive&#x27;, &#123;post: post, date_format: config.date_format&#125;) %&gt; &lt;% &#125;) %&gt; &lt;/div&gt; &lt;% &#125; &#125;) &#125; %&gt; 开启debug模式, hexo s --debug 实验了下, 还是header处增加统计数字更明显一些. tags-bar.ejs文件 增加tag统计角标 1&lt;a href=&quot;&lt;%- url_for(tag.path) %&gt;&quot; style=&quot;-webkit-order:&lt;%= order%&gt;;order:&lt;%= order%&gt;&quot; class=&quot;tags-list-item waves-effect waves-button waves-light&lt;% if(is_current(tag.path))&#123;%&gt; active&lt;%&#125;%&gt;&quot;&gt;&lt;%-tag.name%&gt;&lt;/a&gt; 增加了sup选项, 加了个角标,看起来还可以 1&lt;a href=&quot;&lt;%- url_for(tag.path) %&gt;&quot; style=&quot;-webkit-order:&lt;%= order%&gt;;order:&lt;%= order%&gt;&quot; class=&quot;tags-list-item waves-effect waves-button waves-light&lt;% if(is_current(tag.path))&#123;%&gt; active&lt;%&#125;%&gt;&quot;&gt;&lt;%-tag.name%&gt;&lt;sup&gt;&lt;%-tag.length%&gt;&lt;/sup&gt;&lt;/a&gt; 增加排序(未完成) 相对来说, 还是不太直观. 看下面这段代码, 看起来是在指定Tag在这个顺序中的位置. 123456789101112131415161718192021222324252627var options = []; (type === &#x27;tags&#x27; ? site.tags : site.categories).each(function(o) &#123; if(o.posts.length) &#123; options.push(o) &#125; &#125;) var index = _.findIndex(options, function(o) &#123; return is_current(o.path) &#125;) var len = options.length var order = 0 options.forEach(function(tag, i)&#123; if(index &lt;= 1) &#123; order = i &#125; else &#123; if( i &lt; index - 1) &#123; order = len - (index - 1) + i &#125; else &#123; order = i - (index - 1) &#125; &#125; %&gt; webkit-order的作用是什么呢... 理解错了, 这个其实还是为了布局用的. 问题 hexo渲染时, Markdown文本中如果出现\\&#123;\\&#123;\\&#125;\\&#125;, 又没有被转义, 是会转义失败, 报下面的错误的. 1Template render error: (unknown path) [Line 208, Column 5]","categories":[{"name":"专业","slug":"pro","permalink":"https://sean10.github.io/categories/pro/"}],"tags":[{"name":"hexo","slug":"hexo","permalink":"https://sean10.github.io/tags/hexo/"},{"name":"js","slug":"js","permalink":"https://sean10.github.io/tags/js/"}]},{"title":"Python脚本常用模块记录","slug":"Python分享","date":"2018-11-19T14:41:31.000Z","updated":"2023-03-18T15:11:14.887Z","comments":true,"path":"2018/11/19/Python分享/","link":"","permalink":"https://sean10.github.io/2018/11/19/Python%E5%88%86%E4%BA%AB/","excerpt":"","text":"最近老是写脚本，感觉主要用Python的动力就在于Python存在大量造好的轮子，开箱即用，性能和全面性又能比自己现造的轮子要好。 计数 首先就拿Counter类个例子 1234567891011121314151617181920a = [10, 8, 6, 7, 2, 8, 4, 10, 3, 7, 8, 4, 5, 7, 2, 2, 3, 8, 8, 9, 6, 2, 2, 7, 8, 7, 4, 8, 5, 2] e = dict() for item in a: if item in e: e[item] += 1 else: e[item] = 1 b = [] for item in set(a): b.append((item, a.count(item))) c = defaultdict(int) for i in a: c[i] += 1 d = Counter(a) 有4种方式，逐渐演变出来，内建函数就支持了计数功能 性能优化 123456789101112131415161718192021222324252627282930313233343536373839import cProfileimport timeitfrom collections import Counter, defaultdicta = [10, 8, 6, 7, 2, 8, 4, 10, 3, 7, 8, 4, 5, 7, 2, 2, 3, 8, 8, 9, 6, 2, 2, 7, 8, 7, 4, 8, 5, 2]def count1(): e = dict() for item in a: if item in e: e[item] += 1 else: e[item] = 1def count2(): b = &#123;item: a.count(item) for item in set(a)&#125;def count3(): c = defaultdict(int) for i in a: c[i] += 1def count4(): d = Counter(a)def main(): count1() count2() count3() count4()if __name__ == &#x27;__main__&#x27;: cProfile.run(&quot;main()&quot;) # timeit.timeit(&quot;main()&quot;, number=1) 像这样就不需要再像下面这样手动写了 123456start = time.time()....stop = time.time()total = stop - start ## 内存监控 memory_profiler 12345678910from memory_profiler import profile@profiledef main(): xxxif __name__ == &#x27;__main__&#x27;: main() 解析配置文件 12345678910111213141516171819202122import configparsercf = configparser.ConfigParser()cf.read(&#x27;conf.ini&#x27;)secs = cf.sections()print(&#x27;sections:&#x27;, secs, type(secs))opts = cf.options(&#x27;baseconf&#x27;)print(&quot;opts&quot;, opts, type(opts))host = cf.get(&#x27;baseconf&#x27;, &#x27;host&#x27;)print(host)for sec in cf.sections(): for opt in cf.options(sec): print(cf.get(sec, opt))cf.set(&#x27;baseconf&#x27;, &#x27;host&#x27;, &#x27;0.0.0.0&#x27;)cf.write(open(&#x27;temp.conf&#x27;, &#x27;w&#x27;)) 读取无section名的常用linux conf文件 1234567891011import configparserwith open(&#x27;temp.conf&#x27;, &#x27;r&#x27;) as f: config_string = &#x27;[dummy_section]\\n&#x27; + f.read()cf = configparser.ConfigParser()cf.read_string(config_string)for sec in cf.sections(): for opt in cf.options(sec): print(cf.get(sec, opt)) 读写xml 123456789101112with open(&#x27;temp.xml&#x27;, &#x27;r&#x27;) as f: doc = xmltodict.parse(f.read())import jsonprint(json.dumps(doc, indent=4))print(doc[&#x27;domain&#x27;])print(doc[&#x27;domain&#x27;][&#x27;cpu&#x27;][&#x27;@mode&#x27;])doc[&#x27;domain&#x27;][&#x27;cpu&#x27;][&#x27;@mode&#x27;] = 123print(doc[&#x27;domain&#x27;][&#x27;memory&#x27;][&#x27;#text&#x27;])doc[&#x27;domain&#x27;][&#x27;memory&#x27;][&#x27;#text&#x27;] = &quot;1111111&quot;with open(&#x27;out.xml&#x27;, &#x27;w&#x27;) as f: f.write(xmltodict.unparse(doc, pretty=True)) 读写json 12345678import jsonwith open(&#x27;temp.json&#x27;, &#x27;r&#x27;) as f: content = f.read() jsonData = json.loads(content)print(jsonData)print(json.dumps(jsonData, indent=2)) 起一个简单的http接口服务 1234567891011from flask import Flaskapp = Flask(__name__)@app.route(&#x27;/&#x27;)def index(): return &quot;hello world&quot;if __name__ == &#x27;__main__&#x27;: app.run(host=&quot;0.0.0.0&quot;, port=80) RPC接口 相比http性能更好 Pipe管道 Python默认是前缀语法，是下面这么多个括号嵌套 1sum(select(where(take_while(fib(), lambda x: x &lt; 1000000) lambda x: x % 2), lambda x: x * x)) 这种的，而不是下面这样的中缀语法，类似这样链式调用 1234567from pipe import *fib() | take_while(lambda x: x &lt; 1000000) \\ | where(lambda x: x % 2) \\ | select(lambda x: x * x) \\ | sum()","categories":[{"name":"专业","slug":"pro","permalink":"https://sean10.github.io/categories/pro/"}],"tags":[{"name":"Python","slug":"Python","permalink":"https://sean10.github.io/tags/Python/"},{"name":"script","slug":"script","permalink":"https://sean10.github.io/tags/script/"}]},{"title":"「译」sqlite为什么autoincrement不推荐使用","slug":"为什么autoincrement不推荐使用","date":"2018-09-15T14:51:18.000Z","updated":"2023-03-18T15:11:14.855Z","comments":true,"path":"2018/09/15/为什么autoincrement不推荐使用/","link":"","permalink":"https://sean10.github.io/2018/09/15/%E4%B8%BA%E4%BB%80%E4%B9%88autoincrement%E4%B8%8D%E6%8E%A8%E8%8D%90%E4%BD%BF%E7%94%A8/","excerpt":"在使用sqlite3写一个建议订单系统的时候，没设置主键，默认将第一个条属性设置成了主键，而这条属性并不具有唯一性，导致经常出现插入失败的问题。 在这个背景下，我考虑设置一个数据库里的自增主键，之后这部分就可以自动生成了。 但是在我使用的ORM_LITE中没有提供这样的属性，那么是不是这个属性不推荐使用呢？ 找到了下面这篇文章SQLite AUTOINCREMENT : Why You Should Avoid Using It","text":"在使用sqlite3写一个建议订单系统的时候，没设置主键，默认将第一个条属性设置成了主键，而这条属性并不具有唯一性，导致经常出现插入失败的问题。 在这个背景下，我考虑设置一个数据库里的自增主键，之后这部分就可以自动生成了。 但是在我使用的ORM_LITE中没有提供这样的属性，那么是不是这个属性不推荐使用呢？ 找到了下面这篇文章SQLite AUTOINCREMENT : Why You Should Avoid Using It 下文是这篇的翻译。 SQLite ROWID表简介 无论何时，创建表时不指定WITHOUT ROWID选项，都会得到一个名为rowid的隐式自动增量列。 rowid列存储64位有符号整型，用于唯一标识表中的行。 我们来看下面的例子。 首先，创建一个包含两列first_name, last_name的新表people: 1234CREATE TABLE people ( first_name text NOT NULL, last_name text NOT NULL); Try it 其次，用以下INSERT语句插入people一行: 123INSERT INTO people (first_name, last_name)VALUES (&#x27;John&#x27;, &#x27;Doe&#x27;); Try it 第三，用以下SELECT语句从people中查询数据 123456SELECT rowid, first_name, last_nameFROM people; Try it 所以，SQLite会自动创建一个名为rowid的隐式列，并 在您插入新行时自动分配一个整数值。 可以通过rowid的两个别名_rowid_和oid来使用它 如果创建具有INTEGER PRIMARY KEY列的表，则该列指向rowid列。 以下语句删除people表并重新创建它，不过这一次，我们添加另一列带有INTEGER PRIMARY KEY属性的名为person_id的列。 1234567DROP TABLE people; CREATE TABLE people ( person_id INTEGER PRIMARY KEY, first_name text NOT NULL, last_name text NOT NULL); Try it 现在person_id列实际上就是rowid列。 那么，Sqlite如何分配一个整型值给rowid列呢？ 如果插入一个新行时，你没有指定一个rowid值或者使用NULL值， Sqlite会分配一个比表中最大的rowid大1的整型。 当还没有插入任何行时， rowid是1。 首先，插入带有最大值的一行插入people表。 1234567891011INSERT INTO people ( person_id, first_name, last_name)VALUES ( 9223372036854775807, &#x27;Johnathan&#x27;, &#x27;Smith&#x27; ); Try it 第二，插入不指定person_id的另一行 123456789 INSERT INTO people ( first_name, last_name)VALUES ( &#x27;William&#x27;, &#x27;Gate&#x27; ); Try it SQLite AUTOINCREMENT 属性 SQLite 推荐你不应该使用AUTOCREMENT属性，因为: The AUTOINCREMENT keyword imposes extra CPU, memory, disk space, and disk I/O overhead and should be avoided if not strictly needed. It is usually not needed. \bAUTOINCREMENT关键字会产生额外的CPU,内存,磁盘空间和磁盘I/O开销，如果不是严格需求，应该避免使用。通常不是必须的。 此外，SQLite为AUTOCREMENT列分配值的方式与rowid列的使用方式略有不同。 请参阅以下示例。 首先，再次删除并重新创建人员表。这次，我们使用AUTOINCREMENT属性。 1234567DROP TABLE people; CREATE TABLE people ( person_id INTEGER PRIMARY KEY AUTOINCREMENT, first_name text NOT NULL, last_name text NOT NULL); Try it 其次，将具有最大行id值的行添加到people表中。 1234567891011INSERT INTO people ( person_id, first_name, last_name)VALUES ( 9223372036854775807, &#x27;Johnathan&#x27;, &#x27;Smith&#x27; ); Try it 第三，在people表中插入另一行 123456789INSERT INTO people ( first_name, last_name)VALUES ( &#x27;John&#x27;, &#x27;Smith&#x27; ); Try it 这次，SQLite发出了一条错误消息： 1[Err] 13 - database or disk is full 因为它不会重新使用未被使用数字。 AUTOCREMENT这个属性的主要目的是防止SQLite复用还未使用的值或者使用先前删除的行 如果还没有任何像这样的需求，那么你就不应该在主键中使用SQLite AUTOINCREMENT属性。 在这篇教程中，你已经学习到AUTOINCREMENT属性如何运作的，以及它如何影响SQLite分配值给主键的方式。 # Reference 1. SQLite AUTOINCREMENT : Why You Should Avoid Using It","categories":[{"name":"专业","slug":"pro","permalink":"https://sean10.github.io/categories/pro/"}],"tags":[{"name":"C++","slug":"C","permalink":"https://sean10.github.io/tags/C/"},{"name":"Qt","slug":"Qt","permalink":"https://sean10.github.io/tags/Qt/"},{"name":"sqlite3","slug":"sqlite3","permalink":"https://sean10.github.io/tags/sqlite3/"}]},{"title":"高层火灾应对方式","slug":"高层火灾应对方式","date":"2018-08-25T16:53:55.000Z","updated":"2023-03-18T15:11:14.901Z","comments":true,"path":"2018/08/26/高层火灾应对方式/","link":"","permalink":"https://sean10.github.io/2018/08/26/%E9%AB%98%E5%B1%82%E7%81%AB%E7%81%BE%E5%BA%94%E5%AF%B9%E6%96%B9%E5%BC%8F/","excerpt":"今天学姐提起了这个话题，现在住在高层19层，我们遇到火灾时，应该有哪些逃生方式。","text":"今天学姐提起了这个话题，现在住在高层19层，我们遇到火灾时，应该有哪些逃生方式。 众所周知，小学的时候都有讲过湿毛巾捂笔过滤有毒气体。还有一些摸墙跑，下层走不了就上楼之类的各种常识。不过具体问起发生火灾时，我们应该怎么判断，自己该怎么行动，这个流程倒是没有那么清晰了。 下面来捋捋这个流程。 根据知乎大佬们所说，理论上，我们能做到的自救方式，就是冷静，并能向下冲就冲，一旦被困，就只有祈祷高层防火措施完善，自动喷淋装置等能够加快消防员们灭火的措施齐全。一旦公寓防火有不完善的操作，被困就很难人力突破了。 我们实地考察了以下，大约以下几点 * 屋外走廊是否有自动喷淋装置 * 屋外走廊是否有灭火器等防火措施 * 每层的防火通道是否有2个，并且是否独立不连通 所幸这几点这个屋子都是具备的，让我心里踏实了不少。 Reference 发生火灾后，住在高层有哪些可行的逃生措施？","categories":[{"name":"随想","slug":"thinking","permalink":"https://sean10.github.io/categories/thinking/"}],"tags":[{"name":"火灾","slug":"火灾","permalink":"https://sean10.github.io/tags/%E7%81%AB%E7%81%BE/"},{"name":"高层","slug":"高层","permalink":"https://sean10.github.io/tags/%E9%AB%98%E5%B1%82/"}]},{"title":"KVM宿主机与虚拟机交互","slug":"KVM宿主机与虚拟机交互","date":"2018-08-16T12:08:01.000Z","updated":"2023-03-18T15:11:14.810Z","comments":true,"path":"2018/08/16/KVM宿主机与虚拟机交互/","link":"","permalink":"https://sean10.github.io/2018/08/16/KVM%E5%AE%BF%E4%B8%BB%E6%9C%BA%E4%B8%8E%E8%99%9A%E6%8B%9F%E6%9C%BA%E4%BA%A4%E4%BA%92/","excerpt":"环境背景 使用libvirt管理kvm， 需要在不知道虚拟机ip的情况下，与虚拟机进行交互。 翻了翻，qemu有提供一个qemu-guest-agent的工具，在虚拟机内安装后就可以让宿主机获取虚拟机内的信息了。","text":"环境背景 使用libvirt管理kvm， 需要在不知道虚拟机ip的情况下，与虚拟机进行交互。 翻了翻，qemu有提供一个qemu-guest-agent的工具，在虚拟机内安装后就可以让宿主机获取虚拟机内的信息了。 操作引导 根据redhat的指导[1], 在rhel7的系统的虚拟机xml里插入以下内容 123&lt;channel type=&#x27;unix&#x27;&gt; &lt;target type=&#x27;virtio&#x27; name=&#x27;org.qemu.guest_agent.0&#x27;/&gt;&lt;/channel&gt; 原理上，上面这部分为虚拟机添加了一个叫做org.qemu.guest_agent.0的串口，而在宿主机上则是在路径/var/lib/libvirt/qemu/channel/target/&lt;domain-6-kvm01&gt;/org.qemu.guest_agent.0创建了一个unix socket。 不过为什么要在虚拟机内建立的是串口呢？而不是和宿主机一样的unix socket呢？ 虚拟机内安装这个包之后，启动这个服务就可以了。 123yum install qemu-guest-agentsystemctl start qemu-guest-agentsystemctl enable qemu-guest-agent 这里需要注意，默认安装的qga的service文件中的串口名都是默认的guest_agent.0，如果在指定时修改了这个，手动指定了bind socket路径和target，那么虚拟机内的服务文件就需要替换这些默认名。并且，宿主机就监听不到我们所使用的端口了，需要手动使用下面的socat命令监听了。 然后宿主机，有3种 1. 执行socat /var/lib/libvirt/qemu/channel/target/&lt;domain-6-kvm01&gt;/org.qemu.guest_agent.0 readline，在这里交互式输入json格式的命令可以得到结果 2. virsh qemu-agent-command kvm_instance '{\"execute\":\"guest-network-get-interfaces\"}' 3. 也可以通过qemu-guest-agent提供的api执行命令，不过似乎要添加他的so包，没尝试 常用命令 123456789101112&#123;&quot;execute&quot;: &quot;guest-info&quot;&#125;通过下述3个命令在虚拟机内写信息到文件内&#123;&quot;execute&quot;:&quot;guest-file-open&quot;, &quot;arguments&quot;:&#123;&quot;path&quot;:&quot;/home/testqga&quot;,&quot;mode&quot;:&quot;w+&quot;&#125;&#125;&#123;&quot;execute&quot;:&quot;guest-file-write&quot;,&quot;arguments&quot;:&#123;&quot;handle&quot;:0,&quot;buf-b64&quot;:&quot;aGVsbG8gd29ybGQhCg==&quot;&#125;&#125;# 注意这个handle是返回的句柄&#123;&quot;execute&quot;:&quot;guest-file-close&quot;, &quot;arguments&quot;:&#123;&quot;handle&quot;:0&#125;&#125;# 获取虚拟机网络信息ip&#123;&quot;execute&quot;:&quot;guest-network-get-interfaces&quot;&#125; 接口扩展 如果想要在虚拟机内执行没有默认提供的命令，就需要编辑qga源码，自己添加了。当时还以为是提供的一个类似配置文件的方式进行扩展，然后实际上是自己修改源码，扩展。 去github上svn checkout https://github.com/qemu/qemu/trunk/qga拉下这个文件夹，参考[4]操作编译就好了。 在虚拟机内执行命令 如果只是需要执行shell脚本的话，参照[3],似乎可以通过上面的方法写入到fsfreeze-hook.d中，然后fsfreeze-hook来执行。 12virsh qemu-agent-command instance &#x27;&#123;&quot;execute&quot;:&quot;guest-fsfreeze-freeze&quot;&#125;&#x27;virsh qemu-agent-command instance &#x27;&#123;&quot;execute&quot;:&quot;guest-fsfreeze-thaw&quot;&#125;&#x27; 不过也可以通过上面的network interface得到ip之后通过socket或者rpc等等自己定制接口来执行就是了。 Reference How to enable QEMU guest agent in KVM qemu-guest-agent api openstack通过qemu-guest-agent在物理机上操作虚拟机","categories":[{"name":"专业","slug":"pro","permalink":"https://sean10.github.io/categories/pro/"}],"tags":[{"name":"KVM","slug":"KVM","permalink":"https://sean10.github.io/tags/KVM/"},{"name":"虚拟化","slug":"虚拟化","permalink":"https://sean10.github.io/tags/%E8%99%9A%E6%8B%9F%E5%8C%96/"}]},{"title":"frp远程桌面尝试","slug":"frp远程桌面尝试","date":"2018-08-09T15:11:43.000Z","updated":"2023-03-18T15:11:14.891Z","comments":true,"path":"2018/08/09/frp远程桌面尝试/","link":"","permalink":"https://sean10.github.io/2018/08/09/frp%E8%BF%9C%E7%A8%8B%E6%A1%8C%E9%9D%A2%E5%B0%9D%E8%AF%95/","excerpt":"迫于公司访问外网使用的机器性能以及对外网访问的各种路由、权限限制，尝试远程到家里的电脑来进行访问。","text":"迫于公司访问外网使用的机器性能以及对外网访问的各种路由、权限限制，尝试远程到家里的电脑来进行访问。 历程 偶然间看到带我的导师用的anydesk连的家里的电脑，推动了我马上开始捣鼓远程桌面。 在学校内网时，主要直接使用RDP来访问，现在都被NAT过了，那么就只有一些通过服务器来中转的软件可以使用了，第一反应就是teamviewer,不过经过这个月的摸索，公司对http请求都会ban掉，对于一些存在过风险的软件恐怕更加会ban了，果不其然，teamviewer的请求都是被拒绝了的。 简单了解，anydesk基本功能等同teamviewer，简单安装尝试，效果很棒，第一天从第一次连接到晚上下班，连接一直都没有断开。 只是第二天就是噩梦的来临，anydesk连接的持续时间不足5分钟就会断开，当时曾以为是公司网络的限制，回到家后同样如此，那么猜测可能是个人License的区别了，官网看了下，个人使用版本年费79刀，才能保证session。唉，只好选择其他方式了。 那么，就回归看上去最费事的frp穿透了。 frp穿透+rdp远程桌面 配置说简单也简单，但是在像公司网络限制的地方，就难以确定可能出现的问题原因究竟是配置问题还是网络问题了。 123wget https://github.com/fatedier/frp/releases/download/v0.20.0/frp_0.20.0_linux_amd64.tar.gztar -zxvf frp_0.20.0_linux_amd64.tar.gzcd frp_0.20.0_linux_amd64/ 服务端基本可以不改配置，直接启动./frps -c ./frps.ini也行 123# frps.ini[common]bind_port = 7000 客户端，按照需求从full.ini中选取需要的就可以了，比如rdp,启动方式同上 12345678910# frpc.ini[common]server_addr = X.X.X.Xserver_port = 7000[RDP]type = tcplocal_ip = 0.0.0.0local_port = 3389remote_port = 6000 两个都连上以后就可以看到start proxy success的成功信息。 不过成功连上以后，性能却不甚理想……远比anydesk使用时卡顿的多，看来还需要探索其他方式。 如果不是使用rdp，只需要ssh，可能还是非常不错的。 需要后台的话，使用systemd管理的方式的，在/lib/systemd/system/里添加一个service文件 123456789[Unit]Description=frps daemon[Service]ExecStart=/root/frp_0.20.0_linux_amd64/frps -c /root/frp_0.20.0_linux_amd64/frps.iniRestart=always[Install]WantedBy=multi-user.target 上面这样基本就可以了，注意执行命令必须都是绝对路径 systemd的基本控制命令如下 123systemctl daemon-reloadsystemctl restart frps systemctl enable frps # 将frps作为开机启动项","categories":[{"name":"专业","slug":"pro","permalink":"https://sean10.github.io/categories/pro/"}],"tags":[{"name":"frp","slug":"frp","permalink":"https://sean10.github.io/tags/frp/"},{"name":"rdp","slug":"rdp","permalink":"https://sean10.github.io/tags/rdp/"}]},{"title":"rsyslog & journald日志系统结构","slug":"rsyslog-journald日志系统结构","date":"2018-08-01T17:45:01.000Z","updated":"2023-03-18T15:11:14.875Z","comments":true,"path":"2018/08/02/rsyslog-journald日志系统结构/","link":"","permalink":"https://sean10.github.io/2018/08/02/rsyslog-journald%E6%97%A5%E5%BF%97%E7%B3%BB%E7%BB%9F%E7%BB%93%E6%9E%84/","excerpt":"之前在公司服务器上验证了好多次流程图，结果是被改过代码了可能，运行结果与原生CentOS镜像结果不同。被迫混淆了好久。","text":"之前在公司服务器上验证了好多次流程图，结果是被改过代码了可能，运行结果与原生CentOS镜像结果不同。被迫混淆了好久。 基本背景 实验环境 Centos 7.4 rsyslog 8.24 systemd环境 rsyslog与systemd-journald日志流向 目前来看，lsof只能查看该进程监听的socket,不显示它发送的socket。通过strace追踪，RecMsg会显示发送方的进程pid，从那里可以看到是哪个进程发送到自己监听的socket的信息。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051# rsyslog[root@localhost ~]# strace -T -ttt -f -p 35341strace: Process 35341 attached with 3 threads[pid 35343] 1532962871.699907 futex(0x559329e6e2ac, FUTEX_WAIT_PRIVATE, 23, NULL &lt;unfinished ...&gt;[pid 35342] 1532962871.699926 select(4, [3], NULL, NULL, NULL &lt;unfinished ...&gt;[pid 35341] 1532962871.699940 select(1, NULL, NULL, NULL, &#123;367, 871364&#125; &lt;unfinished ...&gt;[pid 35342] 1532962894.732966 &lt;... select resumed&gt; ) = 1 (in [3]) &lt;23.033022&gt;[pid 35342] 1532962894.733015 recvmsg(3, &#123;msg_name(0)=NULL, msg_iov(1)=[&#123;&quot;&lt;13&gt;Jul 30 11:01:34 root: newer&quot;, 8096&#125;], msg_controllen=64, [&#123;cmsg_len=32, cmsg_level=SOL_SOCKET, cmsg_type=0x1d /* SCM_??? */&#125;, &#123;cmsg_len=28, cmsg_level=SOL_SOCKET, cmsg_type=SCM_CREDENTIALS, &#123;pid=10247, uid=0, gid=0&#125;&#125;], msg_flags=0&#125;, MSG_DONTWAIT) = 31 &lt;0.000008&gt;[pid 35342] 1532962894.733070 futex(0x559329e6e2ac, FUTEX_WAKE_OP_PRIVATE, 1, 1, 0x559329e6e2a8, &#123;FUTEX_OP_SET, 0, FUTEX_OP_CMP_GT, 1&#125; &lt;unfinished ...&gt;[pid 35343] 1532962894.733094 &lt;... futex resumed&gt; ) = 0 &lt;23.033169&gt;[pid 35342] 1532962894.733098 &lt;... futex resumed&gt; ) = 1 &lt;0.000018&gt;[pid 35343] 1532962894.733110 futex(0x559329e6e0b0, FUTEX_WAIT_PRIVATE, 2, NULL &lt;unfinished ...&gt;[pid 35342] 1532962894.733116 futex(0x559329e6e0b0, FUTEX_WAKE_PRIVATE, 1 &lt;unfinished ...&gt;[pid 35343] 1532962894.733128 &lt;... futex resumed&gt; ) = -1 EAGAIN (Resource temporarily unavailable) &lt;0.000012&gt;[pid 35342] 1532962894.733140 &lt;... futex resumed&gt; ) = 0 &lt;0.000021&gt;[pid 35343] 1532962894.733154 futex(0x559329e6e0b0, FUTEX_WAKE_PRIVATE, 1 &lt;unfinished ...&gt;[pid 35342] 1532962894.733160 select(4, [3], NULL, NULL, NULL &lt;unfinished ...&gt;[pid 35343] 1532962894.733175 &lt;... futex resumed&gt; ) = 0 &lt;0.000016&gt;[pid 35343] 1532962894.733194 write(5, &quot;Jul 30 11:01:34 localhost root: &quot;..., 38) = 38 &lt;0.000020&gt;[pid 35343] 1532962894.733234 futex(0x559329e6e2ac, FUTEX_WAIT_PRIVATE, 25, NULL# systemd-journald[root@localhost ~]# strace -ttt -f -p 10247strace: Process 10247 attached1532962887.731909 epoll_wait(7, [&#123;EPOLLIN, &#123;u32=3876856720, u64=94080840508304&#125;&#125;], 10, -1) = 11532962894.732687 clock_gettime(CLOCK_BOOTTIME, &#123;246287, 470494988&#125;) = 01532962894.732723 ioctl(5, FIONREAD, [31]) = 01532962894.732755 recvmsg(5, &#123;msg_name(0)=0x7ffc9785fab0, msg_iov(1)=[&#123;&quot;&lt;13&gt;Jul 30 11:01:34 root: newer&quot;, 24575&#125;], msg_controllen=136, [&#123;cmsg_len=32, cmsg_level=SOL_SOCKET, cmsg_type=0x1d /* SCM_??? */&#125;, &#123;cmsg_len=28, cmsg_level=SOL_SOCKET, cmsg_type=SCM_CREDENTIALS, &#123;pid=35455, uid=0, gid=0&#125;&#125;, &#123;cmsg_len=70, cmsg_level=SOL_SOCKET, cmsg_type=SCM_SECURITY, &quot;unconfined_u:unconfined_r:unconfined_t:s0-s0:c0.c1023\\0&quot;&#125;], msg_flags=MSG_CMSG_CLOEXEC&#125;, MSG_DONTWAIT|MSG_CMSG_CLOEXEC) = 311532962894.732825 sendmsg(5, &#123;msg_name(29)=&#123;sa_family=AF_LOCAL, sun_path=&quot;/run/systemd/journal/syslog&quot;&#125;, msg_iov(1)=[&#123;&quot;&lt;13&gt;Jul 30 11:01:34 root: newer&quot;, 31&#125;], msg_controllen=28, [&#123;cmsg_len=28, cmsg_level=SOL_SOCKET, cmsg_type=SCM_CREDENTIALS, &#123;pid=35455, uid=0, gid=0&#125;&#125;], msg_flags=0&#125;, MSG_NOSIGNAL) = -1 ESRCH (No such process)1532962894.732870 sendmsg(5, &#123;msg_name(29)=&#123;sa_family=AF_LOCAL, sun_path=&quot;/run/systemd/journal/syslog&quot;&#125;, msg_iov(1)=[&#123;&quot;&lt;13&gt;Jul 30 11:01:34 root: newer&quot;, 31&#125;], msg_controllen=28, [&#123;cmsg_len=28, cmsg_level=SOL_SOCKET, cmsg_type=SCM_CREDENTIALS, &#123;pid=10247, uid=0, gid=0&#125;&#125;], msg_flags=0&#125;, MSG_NOSIGNAL) = 311532962894.733261 open(&quot;/proc/35455/cgroup&quot;, O_RDONLY|O_CLOEXEC) = -1 ENOENT (No such file or directory)1532962894.733307 open(&quot;/proc/35455/comm&quot;, O_RDONLY|O_CLOEXEC) = -1 ENOENT (No such file or directory)1532962894.733331 readlinkat(AT_FDCWD, &quot;/proc/35455/exe&quot;, 0x5590e71435b0, 99) = -1 ENOENT (No such file or directory)1532962894.733872 open(&quot;/proc/35455/cmdline&quot;, O_RDONLY|O_CLOEXEC) = -1 ENOENT (No such file or directory)1532962894.733923 open(&quot;/proc/35455/status&quot;, O_RDONLY|O_CLOEXEC) = -1 ENOENT (No such file or directory)1532962894.733946 open(&quot;/proc/35455/sessionid&quot;, O_RDONLY|O_CLOEXEC) = -1 ENOENT (No such file or directory)1532962894.733988 open(&quot;/proc/35455/loginuid&quot;, O_RDONLY|O_CLOEXEC) = -1 ENOENT (No such file or directory)1532962894.734014 open(&quot;/proc/35455/cgroup&quot;, O_RDONLY|O_CLOEXEC) = -1 ENOENT (No such file or directory)1532962894.734050 fstat(14, &#123;st_mode=S_IFREG|0640, st_size=8388608, ...&#125;) = 01532962894.734146 ftruncate(14, 8388608) = 0这里可以看到，35455是logger发送时建立的进程pid[root@localhost ~]# journalctl | grep 35455Jul 30 10:31:18 localhost.localdomain root[35455]: 123Jul 30 10:32:35 localhost.localdomain root[35455]: 123Jul 30 10:34:03 localhost.localdomain root[35455]: 123Jul 30 10:35:30 localhost.localdomain root[35455]: 123Jul 30 11:01:34 localhost.localdomain root[35455]: newer 常见问题 日志重复 见上图，可知默认rsyslog.conf中启动了imuxsock与imjournal两个模块，分别会通过不同的渠道获得syslog日志，因此会导致重复。配置方法详见下章配置信息对应项。 日志丢失 由于日志频次丢失 rsyslog的imjournal模块读取数据库有一个频率上限设置，而systemd-journald也有一个数据库读取频率上限设置。满足rsyslog频率上限，messages中就会drop日志；满足systemd-journald上限，journald就会miss日志。配置方法详见下章配置信息对应项。 1234rsyslogd: imjournal: 84667 messages lost due to rate-limitingsystemd-journal[1770]: Missed 1427 kernel messages journal正常，rsyslog停止记录日志 当前测试似乎是在/var/log/messages被移动或者被删除或者被轮转了导致的这个问题 在logrotate那里执行了达到100M就轮转的功能，会删除.1文件然后备份 但是这边的现象还是有点怪，在我关闭那个特别高频的日志写入之后，就会更新最新的了，但这是为什么呢？ 这里的messages是在/b_iscsi/log/messages里的，这块的设置倒是和我没太大关系，不过原因还是得测试一下，在自己的53.31的/var/log/messages里测试是没什么问题的。 通过lsof，并且从logrotate那里删除自动备份的操作，结果发现，rsyslog还是会出现被删除的情况，但是没找到哪里触发的， logrotate会在100M时删除 sys_space这个进程会在messages达到110M时删除 Aug 29 17:02:28 localhost syslog: [do_record_log_t:1013] get log info error 目前更换回/var/log/messages，没有出现被删的情况，但是每满130M会出现一次rsyslog不再读取journal的问题,需要移除那个快速写入的程序才能接着更新 看了下卡死的那个时候，rsyslog的lsof显示并不是像我之前想的那样，读取的全都是Deleted文件，反而有些是正常的文件。 刚才试了一下，top里可以看到rsyslog卡死之后读取了30M缓存。 欸，但是命名rsyslog是直接读取systemd-journald数据库啊，哪里有缓存的位置 测试journald数据库性能上限 数据库文件大小上限设置为2T,在尚未抵达文件大小上限时，出现了间歇的丢失日志 12345678910111213141516171819202122232425262728293031Aug 7 15:53:23 localhost journal: Missed 68 kernel messagesAug 7 15:53:23 localhost journal: Missed 770 kernel messagesAug 7 15:53:23 localhost journal: Missed 16 kernel messagesAug 7 15:53:23 localhost journal: Missed 95 kernel messagesAug 7 15:53:23 localhost journal: Missed 77 kernel messagesAug 7 15:53:23 localhost journal: Missed 65 kernel messagesAug 7 15:53:23 localhost journal: Missed 71 kernel messagesAug 7 15:53:23 localhost journal: Missed 92 kernel messagesAug 7 15:53:23 localhost journal: Missed 110 kernel messagesAug 7 15:53:23 localhost journal: Missed 89 kernel messagesAug 7 15:53:23 localhost journal: Missed 206 kernel messagesAug 7 15:53:23 localhost journal: Missed 5 kernel messagesAug 7 15:53:23 localhost journal: Missed 485 kernel messagesAug 7 15:53:23 localhost journal: Missed 243 kernel messagesAug 7 15:53:23 localhost journal: Missed 105 kernel messagesAug 7 15:53:23 localhost journal: Missed 893 kernel messagesAug 7 15:53:23 localhost journal: Missed 947 kernel messagesAug 7 15:53:23 localhost journal: Missed 837 kernel messagesAug 7 15:53:23 localhost journal: Missed 890 kernel messagesAug 7 15:53:23 localhost journal: Missed 892 kernel messagesAug 7 15:53:23 localhost journal: Missed 914 kernel messagesAug 7 15:53:23 localhost journal: Missed 894 kernel messagesAug 7 15:53:23 localhost journal: Missed 896 kernel messagesAug 7 15:53:23 localhost journal: Missed 888 kernel messagesAug 7 15:53:23 localhost journal: Missed 901 kernel messagesAug 7 15:53:23 localhost journal: Missed 928 kernel messagesAug 7 15:53:23 localhost journal: Missed 887 kernel messagesAug 7 15:53:23 localhost journal: Missed 884 kernel messagesAug 7 15:53:23 localhost journal: Missed 905 kernel messages: 测试再persistent与volatile状态下，数据库停止记录条件 目前在设置了日志上限的情况下，并没有出现数据库卡死，都是在覆写之前的日志。 在公司镜像上测试，发现，在volatile状态下的日志，和在persistent状态下，同样会自动覆写之前的日志。 仅当journald日志大小达到该分区上限时，目前测试为当RunMaxUse大于分区可用空间时，会导致日志卡死。 imjournald journal reloaded问题 这个问题在[7]中被提到，主要时由于systemd-journald正在轮转数据库文件，因此导致数据库文件变动，所以会出现这个reload日志。 根据[8]中添加的这个日志信息，可以看到是为了在journald切换文件位置时，为了不用重启rsyslog而添加的自动切换。 经过测试，journal日志每被切割一次，都会产生一个reloaded信息（日志level是info，不是Error，所以可以忽视） /dev/log 丢失 参照[11]，这个socket似乎在systemd设备上，是由systemd-journald.socket提供， 如果是单独的rsyslog的日志管理下，则是由imuxsock插件创建， Normally, with rsyslogd, the imuxsock module will create the /dev/log socket on its own, unlinking the previous entry before creating it. When rsyslogd is stopped (possibly because restart which fails because of faulty configuration), rsyslogd removes /dev/log. However, the rsyslog supplied with RHEL7 is expected to be used in conjunction with systemd, and the imuxsock module will actually open and remove /run/systemd/journal/syslog socket. Meanwhile, the /dev/log device is created by the system service-file systemd-journald.socket which triggers journald. 在systemd-journald.socket这个服务的Unit文件里是这么写的 123456789101112131415161718192021222324252627[root@localhost ~]# less /lib/systemd/system/systemd-journald.socket # This file is part of systemd.## systemd is free software; you can redistribute it and/or modify it# under the terms of the GNU Lesser General Public License as published by# the Free Software Foundation; either version 2.1 of the License, or# (at your option) any later version.[Unit]Description=Journal SocketDocumentation=man:systemd-journald.service(8) man:journald.conf(5)DefaultDependencies=noBefore=sockets.target# Mount and swap units need this. If this socket unit is removed by an# isolate request the mount and swap units would be removed too,# hence let&#x27;s exclude this from isolate requests.IgnoreOnIsolate=yes[Socket]ListenStream=/run/systemd/journal/stdoutListenDatagram=/run/systemd/journal/socketListenDatagram=/dev/logSocketMode=0666PassCredentials=yesPassSecurity=yesReceiveBuffer=8M 这里可以看到监听的/dev/log端口创建是由这个服务管理的。 /var/log/messages 时间存在跳变，乱序 暂时无法复现 journal input/output Error 理论上来说，应该是journald连接写入到数据库被阻断了，数据库无法访问导致的问题。 不过应该仅针对journalctl读取时的问题 将/var/log/journal目录做了软链接后，指向路径是被挂载的盘，在系统启动尚未挂载上时，会导致日志不合并，会丢失 欸，我试下了，挂载上后，新的日志就看不到了，而卸载掉后，这次启动的日志文件还是在的。 在测试中，新挂载的盘中与systemd-journal并没有建立连接，在lsof中看到的该路径下的文件是现在已经被隐藏了的目录，通过stat查看了文件inode，的确如此。 12345678910111213141516171819202122systemd-j 432 root 17u REG 8,1 8388608 531238 /root/log/journal/abf6c3e0a96f452ab2efd6c2d1a9c1e0/system.journal[root@thor ~]# stat /root/log/journal/abf6c3e0a96f452ab2efd6c2d1a9c1e0/system.journal File: 鈥root/log/journal/abf6c3e0a96f452ab2efd6c2d1a9c1e0/system.journal鈥 Size: 8388608 Blocks: 16384 IO Block: 4096 regular fileDevice: 811h/2065d Inode: 42729475 Links: 1Access: (0640/-rw-r-----) Uid: ( 0/ root) Gid: ( 0/ root)Access: 2018-08-22 14:31:18.865335001 +0800Modify: 2018-08-22 14:27:43.244195482 +0800Change: 2018-08-22 14:27:43.244195482 +0800 Birth: -[root@thor ~]# umount /dev/sdc1[root@thor ~]# stat /root/log/journal/abf6c3e0a96f452ab2efd6c2d1a9c1e0/system.journal File: 鈥root/log/journal/abf6c3e0a96f452ab2efd6c2d1a9c1e0/system.journal鈥 Size: 8388608 Blocks: 16408 IO Block: 4096 regular fileDevice: 801h/2049d Inode: 531238 Links: 1Access: (0640/-rw-r-----) Uid: ( 0/ root) Gid: ( 0/ root)Access: 2018-08-22 14:34:01.246346582 +0800Modify: 2018-08-22 14:39:01.133367970 +0800Change: 2018-08-22 14:39:01.133367970 +0800 Birth: - 配置信息 /etc/rsyslog.conf $ModLoad imuxsock 该模块导入监听本机syslog socket的功能，从syslog中接收日志,该配置项依赖systemd-journald.conf中的ForwardToSyslog=Yes $OmitLocalLogging 与 $SystemLogSocketName 该配置信息测试结果与官网有所区别，测试中指定socketName为/dev/log(可修改)，系统默认指向socket为/run/systemd/journal/syslog。使用详见下表。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970# 显式关闭 OmitLocalLog,未指定socketName || 非显式关闭，未指定socketName[root@localhost ~]# lsof -c rsyslogCOMMAND PID USER FD TYPE DEVICE SIZE/OFF NODE NAMErsyslogd 1713 root cwd DIR 253,0 224 64 /rsyslogd 1713 root rtd DIR 253,0 224 64 /rsyslogd 1713 root txt REG 253,0 663960 961 /usr/sbin/rsyslogdrsyslogd 1713 root mem REG 253,0 38128 9671 /usr/lib64/rsyslog/imuxsock.sorsyslogd 1713 root mem REG 253,0 24520 9672 /usr/lib64/rsyslog/lmnet.sorsyslogd 1713 root mem REG 253,0 2127336 61000 /usr/lib64/libc-2.17.sorsyslogd 1713 root mem REG 253,0 88720 84 /usr/lib64/libgcc_s-4.8.5-20150702.so.1rsyslogd 1713 root mem REG 253,0 20040 87327 /usr/lib64/libuuid.so.1.3.0rsyslogd 1713 root mem REG 253,0 40824 322855 /usr/lib64/libfastjson.so.4.0.0rsyslogd 1713 root mem REG 253,0 15424 322847 /usr/lib64/libestr.so.0.0.0rsyslogd 1713 root mem REG 253,0 44448 72710 /usr/lib64/librt-2.17.sorsyslogd 1713 root mem REG 253,0 19776 61006 /usr/lib64/libdl-2.17.sorsyslogd 1713 root mem REG 253,0 144792 72706 /usr/lib64/libpthread-2.17.sorsyslogd 1713 root mem REG 253,0 90664 87310 /usr/lib64/libz.so.1.2.7rsyslogd 1713 root mem REG 253,0 164264 60993 /usr/lib64/ld-2.17.sorsyslogd 1713 root 0r CHR 1,3 0t0 5423 /dev/nullrsyslogd 1713 root 1w CHR 1,3 0t0 5423 /dev/nullrsyslogd 1713 root 2w CHR 1,3 0t0 5423 /dev/nullrsyslogd 1713 root 3u unix 0xffff880037064800 0t0 29648 /run/systemd/journal/syslog# 显式打开OmitLocalLog 并 指定socketName || 并不指定socketName[root@localhost ~]# lsof -c rsyslogCOMMAND PID USER FD TYPE DEVICE SIZE/OFF NODE NAMErsyslogd 1765 root cwd DIR 253,0 224 64 /rsyslogd 1765 root rtd DIR 253,0 224 64 /rsyslogd 1765 root txt REG 253,0 663960 961 /usr/sbin/rsyslogdrsyslogd 1765 root mem REG 253,0 38128 9671 /usr/lib64/rsyslog/imuxsock.sorsyslogd 1765 root mem REG 253,0 24520 9672 /usr/lib64/rsyslog/lmnet.sorsyslogd 1765 root mem REG 253,0 2127336 61000 /usr/lib64/libc-2.17.sorsyslogd 1765 root mem REG 253,0 88720 84 /usr/lib64/libgcc_s-4.8.5-20150702.so.1rsyslogd 1765 root mem REG 253,0 20040 87327 /usr/lib64/libuuid.so.1.3.0rsyslogd 1765 root mem REG 253,0 40824 322855 /usr/lib64/libfastjson.so.4.0.0rsyslogd 1765 root mem REG 253,0 15424 322847 /usr/lib64/libestr.so.0.0.0rsyslogd 1765 root mem REG 253,0 44448 72710 /usr/lib64/librt-2.17.sorsyslogd 1765 root mem REG 253,0 19776 61006 /usr/lib64/libdl-2.17.sorsyslogd 1765 root mem REG 253,0 144792 72706 /usr/lib64/libpthread-2.17.sorsyslogd 1765 root mem REG 253,0 90664 87310 /usr/lib64/libz.so.1.2.7rsyslogd 1765 root mem REG 253,0 164264 60993 /usr/lib64/ld-2.17.sorsyslogd 1765 root 0r CHR 1,3 0t0 5423 /dev/nullrsyslogd 1765 root 1w CHR 1,3 0t0 5423 /dev/nullrsyslogd 1765 root 2w CHR 1,3 0t0 5423 /dev/null# 非显式开启OmitLocalLog ，指定socketName || 显式关闭OmitLocalLog, 并指定SocketName[root@localhost ~]# lsof -c rsyslogCOMMAND PID USER FD TYPE DEVICE SIZE/OFF NODE NAMErsyslogd 1779 root cwd DIR 253,0 224 64 /rsyslogd 1779 root rtd DIR 253,0 224 64 /rsyslogd 1779 root txt REG 253,0 663960 961 /usr/sbin/rsyslogdrsyslogd 1779 root mem REG 253,0 38128 9671 /usr/lib64/rsyslog/imuxsock.sorsyslogd 1779 root mem REG 253,0 24520 9672 /usr/lib64/rsyslog/lmnet.sorsyslogd 1779 root mem REG 253,0 2127336 61000 /usr/lib64/libc-2.17.sorsyslogd 1779 root mem REG 253,0 88720 84 /usr/lib64/libgcc_s-4.8.5-20150702.so.1rsyslogd 1779 root mem REG 253,0 20040 87327 /usr/lib64/libuuid.so.1.3.0rsyslogd 1779 root mem REG 253,0 40824 322855 /usr/lib64/libfastjson.so.4.0.0rsyslogd 1779 root mem REG 253,0 15424 322847 /usr/lib64/libestr.so.0.0.0rsyslogd 1779 root mem REG 253,0 44448 72710 /usr/lib64/librt-2.17.sorsyslogd 1779 root mem REG 253,0 19776 61006 /usr/lib64/libdl-2.17.sorsyslogd 1779 root mem REG 253,0 144792 72706 /usr/lib64/libpthread-2.17.sorsyslogd 1779 root mem REG 253,0 90664 87310 /usr/lib64/libz.so.1.2.7rsyslogd 1779 root mem REG 253,0 164264 60993 /usr/lib64/ld-2.17.sorsyslogd 1779 root 0r CHR 1,3 0t0 5423 /dev/nullrsyslogd 1779 root 1w CHR 1,3 0t0 5423 /dev/nullrsyslogd 1779 root 2w CHR 1,3 0t0 5423 /dev/nullrsyslogd 1779 root 3u unix 0xffff88003b564800 0t0 30441 /dev/logrsyslogd 1779 root 4u unix 0xffff88003b560800 0t0 30443 socketrsyslogd 1779 root 5w REG 253,0 754001 17131680 /var/log/messagesrsyslogd 1779 root 6w REG 253,0 24654 17131681 /var/log/secure 由上述可知，在不同情况下，rsyslog实际监听的socket如下 x 显式开启 显式关闭 非显式开启 指定socket null /dev/log /dev/log 不指定socket null /run/systemd/journal/syslog /run/systemd/journal/syslog $ModLoad imjournal 该模块导入直接读取systemd-journald数据库的功能，可直接从journald数据库中读取syslog日志、内核日志以及服务stdout。 imjournal在lsof中可以看到，直接读取的数据库 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889[root@localhost ~]# lsof /run/log/journal/a288ec3729494d3dad642453d0b272b7/system.journalCOMMAND PID USER FD TYPE DEVICE SIZE/OFF NODE NAMEsystemd-j 10247 root mem REG 0,19 25165824 7373149 /run/log/journal/a288ec3729494d3dad642453d0b272b7/system.journalsystemd-j 10247 root 12u REG 0,19 25165824 7373149 /run/log/journal/a288ec3729494d3dad642453d0b272b7/system.journalrsyslogd 10255 root mem REG 0,19 25165824 7373149 /run/log/journal/a288ec3729494d3dad642453d0b272b7/system.journalrsyslogd 10255 root 5r REG 0,19 25165824 7373149 /run/log/journal/a288ec3729494d3dad642453d0b272b7/system.journal[root@localhost ~]# lsof -c systemd-journalCOMMAND PID USER FD TYPE DEVICE SIZE/OFF NODE NAMEsystemd-j 10247 root cwd DIR 253,0 224 64 /systemd-j 10247 root rtd DIR 253,0 224 64 /systemd-j 10247 root txt REG 253,0 274752 16874824 /usr/lib/systemd/systemd-journaldsystemd-j 10247 root mem REG 0,19 25165824 7373149 /run/log/journal/a288ec3729494d3dad642453d0b272b7/system.journalsystemd-j 10247 root mem REG 253,0 19888 87389 /usr/lib64/libattr.so.1.1.0systemd-j 10247 root mem REG 253,0 402384 87259 /usr/lib64/libpcre.so.1.2.0systemd-j 10247 root mem REG 253,0 19776 61006 /usr/lib64/libdl-2.17.sosystemd-j 10247 root mem REG 253,0 19384 87371 /usr/lib64/libgpg-error.so.0.10.0systemd-j 10247 root mem REG 253,0 2127336 61000 /usr/lib64/libc-2.17.sosystemd-j 10247 root mem REG 253,0 144792 72706 /usr/lib64/libpthread-2.17.sosystemd-j 10247 root mem REG 253,0 88720 84 /usr/lib64/libgcc_s-4.8.5-20150702.so.1systemd-j 10247 root mem REG 253,0 44448 72710 /usr/lib64/librt-2.17.sosystemd-j 10247 root mem REG 253,0 37056 87391 /usr/lib64/libacl.so.1.1.0systemd-j 10247 root mem REG 253,0 155744 87307 /usr/lib64/libselinux.so.1systemd-j 10247 root mem REG 253,0 535064 87381 /usr/lib64/libgcrypt.so.11.8.2systemd-j 10247 root mem REG 253,0 157424 87316 /usr/lib64/liblzma.so.5.2.2systemd-j 10247 root mem REG 253,0 164264 60993 /usr/lib64/ld-2.17.sosystemd-j 10247 root mem REG 0,19 8 7972 /run/systemd/journal/kernel-seqnumsystemd-j 10247 root 0r CHR 1,3 0t0 5423 /dev/nullsystemd-j 10247 root 1w CHR 1,3 0t0 5423 /dev/nullsystemd-j 10247 root 2w CHR 1,3 0t0 5423 /dev/nullsystemd-j 10247 root 3u unix 0xffff880037e83000 0t0 42542 /run/systemd/journal/stdoutsystemd-j 10247 root 4u unix 0xffff880037e81400 0t0 42544 /run/systemd/journal/socketsystemd-j 10247 root 5u unix 0xffff880037e80800 0t0 42546 /dev/logsystemd-j 10247 root 6w CHR 1,11 0t0 5429 /dev/kmsgsystemd-j 10247 root 7u a_inode 0,9 0 5419 [eventpoll]systemd-j 10247 root 8u a_inode 0,9 0 5419 [timerfd]systemd-j 10247 root 9u CHR 1,11 0t0 5429 /dev/kmsgsystemd-j 10247 root 10r REG 0,3 0 7973 /proc/sys/kernel/hostnamesystemd-j 10247 root 11u a_inode 0,9 0 5419 [signalfd]systemd-j 10247 root 12u REG 0,19 25165824 7373149 /run/log/journal/a288ec3729494d3dad642453d0b272b7/system.journalsystemd-j 10247 root 13u a_inode 0,9 0 5419 [timerfd][root@localhost ~]# lsof -c rsyslogCOMMAND PID USER FD TYPE DEVICE SIZE/OFF NODE NAMErsyslogd 10255 root cwd DIR 253,0 224 64 /rsyslogd 10255 root rtd DIR 253,0 224 64 /rsyslogd 10255 root txt REG 253,0 663960 961 /usr/sbin/rsyslogdrsyslogd 10255 root mem REG 0,19 25165824 307917 /run/log/journal/a288ec3729494d3dad642453d0b272b7/system@cea802f344b94cb6b1e2b867690eca83-0000000000000f6d-0005722d8a52e79b.journalrsyslogd 10255 root mem REG 0,19 25165824 2282729 /run/log/journal/a288ec3729494d3dad642453d0b272b7/system@cea802f344b94cb6b1e2b867690eca83-00000000000074f5-0005722d9bdab060.journalrsyslogd 10255 root mem REG 0,19 25165824 4612418 /run/log/journal/a288ec3729494d3dad642453d0b272b7/system@cea802f344b94cb6b1e2b867690eca83-000000000000dcd4-0005722db4fed7dd.journalrsyslogd 10255 root mem REG 0,19 25165824 7373149 /run/log/journal/a288ec3729494d3dad642453d0b272b7/system.journalrsyslogd 10255 root mem REG 0,19 6455296 7976 /run/log/journal/a288ec3729494d3dad642453d0b272b7/system@cea802f344b94cb6b1e2b867690eca83-0000000000000001-000571ff63cd3044.journalrsyslogd 10255 root mem REG 253,0 68192 87353 /usr/lib64/libbz2.so.1.0.6rsyslogd 10255 root mem REG 253,0 99944 87368 /usr/lib64/libelf-0.168.sorsyslogd 10255 root mem REG 253,0 402384 87259 /usr/lib64/libpcre.so.1.2.0rsyslogd 10255 root mem REG 253,0 19888 87389 /usr/lib64/libattr.so.1.1.0rsyslogd 10255 root mem REG 253,0 297328 115274 /usr/lib64/libdw-0.168.sorsyslogd 10255 root mem REG 253,0 111080 72708 /usr/lib64/libresolv-2.17.sorsyslogd 10255 root mem REG 253,0 19384 87371 /usr/lib64/libgpg-error.so.0.10.0rsyslogd 10255 root mem REG 253,0 535064 87381 /usr/lib64/libgcrypt.so.11.8.2rsyslogd 10255 root mem REG 253,0 157424 87316 /usr/lib64/liblzma.so.5.2.2rsyslogd 10255 root mem REG 253,0 155744 87307 /usr/lib64/libselinux.so.1rsyslogd 10255 root mem REG 253,0 1139680 61008 /usr/lib64/libm-2.17.sorsyslogd 10255 root mem REG 253,0 20032 87393 /usr/lib64/libcap.so.2.22rsyslogd 10255 root mem REG 253,0 25072 9665 /usr/lib64/rsyslog/imjournal.sorsyslogd 10255 root mem REG 253,0 24520 9672 /usr/lib64/rsyslog/lmnet.sorsyslogd 10255 root mem REG 253,0 2127336 61000 /usr/lib64/libc-2.17.sorsyslogd 10255 root mem REG 253,0 88720 84 /usr/lib64/libgcc_s-4.8.5-20150702.so.1rsyslogd 10255 root mem REG 253,0 20040 87327 /usr/lib64/libuuid.so.1.3.0rsyslogd 10255 root mem REG 253,0 40824 322855 /usr/lib64/libfastjson.so.4.0.0rsyslogd 10255 root mem REG 253,0 15424 322847 /usr/lib64/libestr.so.0.0.0rsyslogd 10255 root mem REG 253,0 44448 72710 /usr/lib64/librt-2.17.sorsyslogd 10255 root mem REG 253,0 19776 61006 /usr/lib64/libdl-2.17.sorsyslogd 10255 root mem REG 253,0 144792 72706 /usr/lib64/libpthread-2.17.sorsyslogd 10255 root mem REG 253,0 90664 87310 /usr/lib64/libz.so.1.2.7rsyslogd 10255 root mem REG 253,0 164264 60993 /usr/lib64/ld-2.17.sorsyslogd 10255 root mem REG 253,0 162560 237027 /usr/lib64/libsystemd.so.0.6.0rsyslogd 10255 root 0r CHR 1,3 0t0 5423 /dev/nullrsyslogd 10255 root 1w CHR 1,3 0t0 5423 /dev/nullrsyslogd 10255 root 2w CHR 1,3 0t0 5423 /dev/nullrsyslogd 10255 root 3r a_inode 0,9 0 5419 inotifyrsyslogd 10255 root 4u unix 0xffff880037338800 0t0 9404081 socketrsyslogd 10255 root 5r REG 0,19 25165824 7373149 /run/log/journal/a288ec3729494d3dad642453d0b272b7/system.journalrsyslogd 10255 root 6r REG 0,19 25165824 4612418 /run/log/journal/a288ec3729494d3dad642453d0b272b7/system@cea802f344b94cb6b1e2b867690eca83-000000000000dcd4-0005722db4fed7dd.journalrsyslogd 10255 root 7r REG 0,19 25165824 2282729 /run/log/journal/a288ec3729494d3dad642453d0b272b7/system@cea802f344b94cb6b1e2b867690eca83-00000000000074f5-0005722d9bdab060.journalrsyslogd 10255 root 8r REG 0,19 25165824 307917 /run/log/journal/a288ec3729494d3dad642453d0b272b7/system@cea802f344b94cb6b1e2b867690eca83-0000000000000f6d-0005722d8a52e79b.journalrsyslogd 10255 root 9r REG 0,19 6455296 7976 /run/log/journal/a288ec3729494d3dad642453d0b272b7/system@cea802f344b94cb6b1e2b867690eca83-0000000000000001-000571ff63cd3044.journalrsyslogd 10255 root 10w REG 253,0 49250519 17152683 /var/log/messagesrsyslogd 10255 root 11w REG 253,0 4634 17152684 /var/log/secure $imjournalRatelimitInterval 0 该属性设置为5s,代表以5s为一个间隙统计日志频次，达到下一条配置设置的频次，即放弃读取journald数据库信息(待验证是读取前放弃，还是读取后丢弃)。 $imjournalRatelimitBurst 0 该属性设置为上一条设置的间隙期间读取日志条数上限，如5s内读取1000条，达到该频次即停止。与上一条同时设置为0，即关闭该上限 Note that it is not recommended to turn of ratelimiting, except that you know for sure journal database entries will never be corrupted. Without ratelimiting, a corrupted systemd journal database may cause a kind of denial of service (we are stressing this point as multiple users have reported us such problems with the journal database - information current as of June 2013). 但是官方并不建议关闭该上限，可能会导致数据库阻塞等问题导致其他服务出现异常。 $ModLoad imklog 该模块导入直接从平台内核中读取内核日志的功能，可以避过journald数据库读写性能瓶颈。 $ModLoad imkmsg 该模块通过/dev/kmsg设备，获取结构化日志 $ModLoad imudp 导入该模块，并打开防火墙放行，可远程访问该主机获取日志信息 $ModLoad imtcp 导入该模块，并打开防火墙放行，可远程访问该主机获取日志信息 转发规则 rhel7系统中，一般log默认保存在下述目录，/var/log 目录保管由rsyslog维护的各种特定于系统和服务的日志文件。 /var/log/messages大多数系统日志消息记录在此。例外是与身份验证，电子邮件处理相关的定期运行作业的消息以及纯粹与调试相关的信息。 /var/log/secure安全和身份验证相关的消息和错误的日志文件。 /var/log/maillog与邮件服务器相关的日志文件。 /var/log/cron crond计划任务的日志 /var/log/boot.log与系统启动相关的消息记录在此。 建议不直接修改rsyslog.conf的规则，在这个目录$IncludeConfig /etc/rsyslog.d/*.conf下存放自定义的转发规则 123456789101112131415161718192021222324252627282930313233343536:msg, contains, &quot;of user root&quot; ~ &amp; ~:msg, contains, &quot;Removed session&quot; ~ &amp; ~:msg, contains, &quot;please try to use systemctl&quot; ~&amp; ~ # Log all kernel messages to the console.# Logging much else clutters up the screen.#kern.* /dev/console# Log anything (except mail) of level info or higher.# Don&#x27;t log private authentication messages!*.info;mail.none;authpriv.none;cron.none /var/log/messages# The authpriv file has restricted access.authpriv.* /var/log/secure# Log all the mail messages in one place.mail.* -/var/log/maillog# Log cron stuffcron.* /var/log/cron# Everybody gets emergency messages*.emerg :omusrmsg:*# Save news errors of level crit and higher in a special file.uucp,news.crit /var/log/spooler# Save boot messages also to boot.loglocal7.* /var/log/boot.log 转发过滤规则，见文档 begin forwarding rule 暂未使用的远程访问日志配置信息，语法见Legacy Action-Specific Configuration Statements /etc/systemd/journald.conf systemd-journald主要获得以下信息 * Kernel log messages, via kmsg * Simple system log messages, via the libc syslog(3) call * Structured system log messages via the native Journal API, see sd_journal_print(4) * Standard output and standard error of service units. For further details see below. * Audit records, originating from the kernel audit subsystem RateLimitInterval=30s 频率间隙为30s RateLimitBurst=1000 每个间隙频次上限为1000，直到下个间隙不会接收日志 Storage=auto 该配置选项控制journald日志的存储位置，以下4个选项\"volatile\", \"persistent\", \"auto\" and \"none\"，对应/run/log/journal,/var/log/journal,根据/var/log/journal目录建立与否判断，收到即drop,但转发forward还是生效的(如imjournal等读取数据库文件等方式无效)。 RuntimeMaxUse= 设置内存中journald文件上限，一旦达到该上限，journald数据库就会阻塞住。 RuntimeKeepFree= RuntimeKeepFree表示需要保留的内存空间，剩余空间不足其设置，journald数据库同样会阻塞住。 SystemMaxUse= 与 RuntimeMaxUse= 的默认值是10%空间与4G空间两者中的较小者； SystemKeepFree= 与 RuntimeKeepFree= 的默认值是15%空间与4G空间两者中的较大者； 如果在 systemd-journald 启动时， 文件系统即将被填满并且已经超越了 SystemKeepFree= 或 RuntimeKeepFree= 的限制，那么日志记录将被暂停。 也就是说，如果在创建日志文件时，文件系统有充足的空闲空间， 但是后来文件系统被其他非日志文件过多占用， 那么 systemd-journald 只会立即暂停日志记录， 但不会删除已经存在的日志文件。 RuntimeMaxFileSize= SystemMaxFileSize= 与 RuntimeMaxFileSize= 限制单个日志文件的最大体积， 到达此限制后日志文件将会自动滚动。 默认值是对应的 SystemMaxUse= 与 RuntimeMaxUse= 值的1/8 ， 这也意味着日志滚动默认保留7个历史文件。 日志大小的值可以使用以1024为基数的 K, M, G, T, P, E 后缀， 分别对应于 1024, 1024², … 字节。 ForwardToSyslog=yes 转发syslog日志到syslog socket，从而使rsyslog调用imuxsock从该socket接收日志 该选项可被内核引导选项覆盖systemd.journald.forward_to_syslog=, systemd.journald.forward_to_kmsg=, systemd.journald.forward_to_console=, systemd.journald.forward_to_wall=，允许/禁止将收集到的日志： 转发到传统的 syslog 守护进程, 转发到内核日志缓冲区, 转发到系统控制台, 作为wall警告信息转发给所有已登录的用户 MaxLevelStore=debug MaxLevelSyslog=debug MaxLevelKMsg=notice MaxLevelConsole=info MaxLevelWall=emerg 以上配置控制在数据库上存储以及转发的最大日志等级。 日志等级一共分为\"emerg\", \"alert\", \"crit\", \"err\", \"warning\", \"notice\",\"info\", \"debug\" /lib/systemd/system/systemd-journald.service StandardOutput=null 设置进程的标准输出(STDOUT)。 可设为 inherit, null, tty, journal, syslog, kmsg, journal+console, syslog+console, kmsg+console, socket, fd 之一。 inherit 表示使用 StandardInput= 设置的值。 null 表示 /dev/null ， 也就是所有写入都会被丢弃。 tty 表示 TTY(由 TTYPath= 设置)， 如果仅用于输出， 那么进程将无需取得终端的控制权， 亦无需等待其他进程释放终端控制权。 journal 表示 systemd 日志服务(通过 journalctl(1) 访问)。 注意，所有发到 syslog 或 kmsg 的日志都会 隐含的复制一份到 journal 中。 syslog 表示 syslog(3) 日志服务。 注意，此时所有日志都会隐含的复制一份到 journal 中。 kmsg 表示内核日志缓冲区(通过 dmesg(1) 访问)。 注意，此时所有日志都会隐含的复制一份到 journal 中。 journal+console, syslog+console, kmsg+console 与上面三个值类似， 不同之处在于所有日志都会再复制一份到系统的控制台上。 socket 的解释与 StandardInput= 中的解释完全相同。 fd 表示将标准输出(STDOUT)连接到一个由 socket 单元提供的文件描述符。 可以通过 \"fd:foobar\" 格式 明确指定文件描述符的名称。 描述符名称的默认值为 \"stdout\" ，也就是 \"fd\" 等价于 \"fd:stdout\" 。 必须明确使用 Sockets= 选项 提供至少一个定义了文件描述符名称的 socket 单元。 注意，文件描述符的名称不一定和定义它的 socket 单元的名称一致。 如果出现了多个匹配，那么以第一个为准， 详见 systemd.socket(5) 手册对 FileDescriptorName= 选项的讲解。 如果单元的标准输出(StandardOutput=)或标准错误(StandardError=)中含有 journal, syslog, kmsg 之一， 那么该单元将会自动隐含的获得 After=systemd-journald.socket 依赖(见上文)。 /etc/logrotate.conf 仅对持久化后的/var/log/journal有效 journald持久化 持久化保存journal的日志，默认保存一个月的日志 直接修改journald.conf中的storage为persistent就切换到var路径下了，切换到volatile就自动回/run/log了。 12systemctl restart systemd-journald.servicesystemctl restart systemd-journald.socket 如果出现了切换到persistent状态下，日志已经存到了/var/log/journal，但是/run/log/journal路径依旧存在的状况的话，可能是自动切换有些不同。就手动将volatile修改成auto,手动mkdir /var/log/journal，这样再重启比较适合防丢日志。 在切换前，为了防止journal数据库文件大小刚好超过设置的上限，然后由于重启了服务，没能及时自动清理掉超过的部分，从而导致数据库假死，建议使用journalctl --vacuumm-size=250M，可以清除日志直到满足这个大小限制。不过这个要求sytemd版本318及以上才支持这个选项。 如果版本不支持的话，那就还是rm -rf掉这些日志或者手动删掉一些数据库文件吧，升级systemd的版本似乎带来的风险相比这些日志的价值要大得多。[12] 调试方法 检验rsyslog配置信息 1234# 可以让rsyslogd 进入 Debug模式[root@localhost ~]# rsyslogd -N6rsyslogd: version 8.24.0, config validation run (level 6), master config /etc/rsyslog.confrsyslogd: invalid or yet-unknown config file command &#x27;IMJournalStateFile&#x27; - have you forgotten to load a module? [v8.24.0 try http://www.rsyslog.com/e/3003 ] strace -p pid追踪进程 参考资料 imjournal: Systemd Journal Input Module rsyslog-logger-message-duplicated systemd service 单元语法 Filter Conditions imuxsock: Unix Socket Input Module man journald.conf rsyslog daemon have unkown log entries \"rsyslogd:imjournal: journal reloaded\" from time to time switching to persistent journal possible without rsyslog restart Journal is reloaded and duplicate messages are output into log file 关于Rsyslogd 的一些配置 (高性能、高可用 rsyslogd) How do I restore /dev/log in systemd+rsyslog host? How would I upgrade systemd? Is systemd-journald a syslog implementation?","categories":[{"name":"专业","slug":"pro","permalink":"https://sean10.github.io/categories/pro/"}],"tags":[{"name":"linux","slug":"linux","permalink":"https://sean10.github.io/tags/linux/"},{"name":"systemd","slug":"systemd","permalink":"https://sean10.github.io/tags/systemd/"},{"name":"rsyslog","slug":"rsyslog","permalink":"https://sean10.github.io/tags/rsyslog/"}]},{"title":"RMBP_me865换屏小记","slug":"RMBP-me865换屏小记","date":"2018-07-28T03:08:55.000Z","updated":"2023-03-18T15:11:14.883Z","comments":true,"path":"2018/07/28/RMBP-me865换屏小记/","link":"","permalink":"https://sean10.github.io/2018/07/28/RMBP-me865%E6%8D%A2%E5%B1%8F%E5%B0%8F%E8%AE%B0/","excerpt":"这个屏幕在去年冬天坏的，大概1月份左右，当时考虑长期就在学校肝毕设，加上屏幕当时只黑了右侧总计1/4，还能用，所以就买了块比较便宜的显示器，1080p 21.5寸，在宿舍床上用着，还是挺不错的。","text":"这个屏幕在去年冬天坏的，大概1月份左右，当时考虑长期就在学校肝毕设，加上屏幕当时只黑了右侧总计1/4，还能用，所以就买了块比较便宜的显示器，1080p 21.5寸，在宿舍床上用着，还是挺不错的。 它挺过了我搬家的时候，没料到在偶然一天，合盖的时候可能被后侧的数据线卡到的，外屏裂痕扩大，内屏也多黑了1/4，这下，真没办法使用了。 首先，考虑到维修水深，转眼可能就会偷换零件，或者修坏什么，因此首选是有淘宝店的实体维修店。然而，结果很可惜，在上海的时候看到的评论比较真实的好评店铺，定位在北京以后，搜到的几近所有好评店铺，报价在1800以下的，咨询后给出的地址都是中关村…… 既然这样，那就咨询以下v站大佬，看看有没有什么好消息。在apple分区发了2天，只有一个大佬回复了，经搜索得到的结果有些可惜，报价2200up，其他几家越是名声好的，都报价在2000+。 最后，只好进行第3个选择，自己买材料，更换。由于事前有搜到过有大佬自己更换过屏幕总成，这种不仅是内屏损坏的只有一条路，直接更换总成，这样的技术要求反而更低，很适合个人自己操作。 这条选择一波三折，公司前辈说有工具，然后都没有5角梅花的螺丝头，哎，迫于快速修理的急切心情，下楼找了个修理店借了波工具，结果螺丝刀头磨损太严重，特别费事。花了2个半小时，换完总成，结果老板下班了收走了合盖用的螺丝刀。走的时候一手手机，一手换下来的屏幕，恰恰忘了还没装上的小螺丝。 用胶带撑到了第二天小米的如风达螺丝刀抵达，一大早顶着被楼下8点的炮竹惊醒的困顿，去店里取回螺丝，成功装好。 总的来说，1400二手屏幕+100小米螺丝刀+2个半小时，还是挺不错的。 使用上，颜色稍稍感觉和以前有些差异，在外接屏幕时，似乎被系统也识别成外接的了，不能像原来那样单独修改一个屏幕的分辨率了。","categories":[{"name":"随想","slug":"thinking","permalink":"https://sean10.github.io/categories/thinking/"}],"tags":[{"name":"硬件","slug":"硬件","permalink":"https://sean10.github.io/tags/%E7%A1%AC%E4%BB%B6/"},{"name":"mac","slug":"mac","permalink":"https://sean10.github.io/tags/mac/"}]},{"title":"KVM虚拟机镜像压缩","slug":"KVM虚拟机镜像压缩","date":"2018-07-09T13:39:49.000Z","updated":"2023-03-18T15:11:14.812Z","comments":true,"path":"2018/07/09/KVM虚拟机镜像压缩/","link":"","permalink":"https://sean10.github.io/2018/07/09/KVM%E8%99%9A%E6%8B%9F%E6%9C%BA%E9%95%9C%E5%83%8F%E5%8E%8B%E7%BC%A9/","excerpt":"最近刚入职，做的还比较简单，熟悉libvirt，把KVM镜像给压缩一下。","text":"最近刚入职，做的还比较简单，熟悉libvirt，把KVM镜像给压缩一下。 KVM主要硬盘镜像有qcow2和raw两种类型。 qcow2格式是copy on write的，使用时才占用硬盘空间，而raw则是创建时即分配了。 使用ll -h和du -h可以看到实际分配的和磁盘占用的大小。 1qemu-img convert -f qcow2 -c -O qcow2 xx.qcow2 xx_compressed.qcow2 通过上述命令可以实现qcow2格式的压缩，但是无法更改硬盘初始创建时上限的大小。只有raw格式可以减小上限，一开始以为只有上限压缩了以后，才能把这样的镜像放到较小的硬盘分区里。 首先尝试了 123qemu-img convert -f qcow2 -O raw xxx.qcow2 xxx.rawqemu-img resize -f raw xxx.raw -10Gqemu-img convert -f raw -O qcow2 xxx.raw xxx.qcow2 但，的确就和其他博客里说的一样，这样会由于raw内部分区并不是顺序，而不是稀疏的，会导致破坏文件系统，如windows启动时就会导致蓝屏。 如果要这样做，就需要首先让系统分区进行压缩，如使用win7的磁盘管理进行压缩卷操作，亦或是使用gparted、libguestfs进行处理。 这里有个问题，qcow2格式用qemu-img info看到的大小是3.7G，用raw格式也仅有7.8G左右，而在win7内部磁盘管理看到的空间占用却是11.2G。这里的不对称是因为文件系统格式的原因吗？ 一开始一直在尝试安装libguestfs，因为似乎virt-resize可以做到压缩上限，但是很可惜，内网环境yum安装依赖实在是太艰难了，在将CentOS安装包的iso镜像挂载上作本地源之后，还是存在一些依赖问题。折腾了快有2天时间，在supermin5上还是没能搞定。 最后，在看qcow2压缩的博客时，发现没有人提到过要修改这个上限的问题，qcow2本身就是写时分配空间，，那么其实，是不是无关紧要呢？我分配了一个4G的硬盘，将3.7G压缩后的镜像移动到这块硬盘再启动，windows启动一点没有问题，在系统内部的文件分区显示依旧是11.2G左右。 哎，尝试了好多，最后还是回到了原点。","categories":[{"name":"专业","slug":"pro","permalink":"https://sean10.github.io/categories/pro/"}],"tags":[{"name":"KVM","slug":"KVM","permalink":"https://sean10.github.io/tags/KVM/"},{"name":"libvirt","slug":"libvirt","permalink":"https://sean10.github.io/tags/libvirt/"}]},{"title":"第一次下厨","slug":"第一次下厨","date":"2018-06-19T05:30:45.000Z","updated":"2023-03-18T15:11:14.866Z","comments":true,"path":"2018/06/19/第一次下厨/","link":"","permalink":"https://sean10.github.io/2018/06/19/%E7%AC%AC%E4%B8%80%E6%AC%A1%E4%B8%8B%E5%8E%A8/","excerpt":"","text":"西红柿炒蛋 按照食谱来做，没想到还是有很多细节上没有提到的东西，想当然了，导致最终的成品出现了大大的错误。 番茄是切块，而不是切片 由于新手手速慢，油烧热以后将火调小，再倒入菜 黄瓜炒蒜肠 没有红肠，只好先买个蒜肠，还好最后味道也还能吃。 黄瓜没能入味，虽然菜谱上说一起放进去炒，但是由于需要入味，但是单独先给黄瓜加点盐炒为好。 Reference 下厨房 番茄炒蛋 下厨房 黄瓜炒火腿 感谢豆豆儿大大的指点。","categories":[{"name":"随想","slug":"thinking","permalink":"https://sean10.github.io/categories/thinking/"}],"tags":[{"name":"下厨","slug":"下厨","permalink":"https://sean10.github.io/tags/%E4%B8%8B%E5%8E%A8/"}]},{"title":"租房布置搭配","slug":"租房布置搭配","date":"2018-06-02T11:48:01.000Z","updated":"2023-03-18T15:11:14.890Z","comments":true,"path":"2018/06/02/租房布置搭配/","link":"","permalink":"https://sean10.github.io/2018/06/02/%E7%A7%9F%E6%88%BF%E5%B8%83%E7%BD%AE%E6%90%AD%E9%85%8D/","excerpt":"","text":"终于确定了租房问题，房间虽然有点小，不过目前看大小，2.53的大小，放一个单人床之外，还是可以放的下一个稍大的桌子的。计划是最少要买个1.50.8*0.75左右的书桌，这样桌子就可以放的下显示器，又能做做笔记什么的了。不过暂时等入住以后再详细调整。 细节记录 墙壁 看情况吧？墙壁如果没问题那就没事了，要是有点脏那到时候再咨询房东能不能贴了。 桌子 简约的似乎直接用淘宝的就行，不用在意非要实木，毕竟我并不是有多个显示器外接的大佬。预算可以不用达到600了，300以内应该可以。 椅子 目前来看，不太喜欢那种椅子带滚轮的，价格低的情况下，办公椅似乎由于零部件太多容易出问题，宜家几十块的椅子带椅背就可以了 床上三件套 网购或是实体店，到时候逛逛 灯光 我台灯从高一用到大四，7年时间，关节处已经撑不住了。 宜家，爆款落地灯79，mark。 垃圾桶 必选 置物架(可选) 宜家优先，不过我不确定我有哪些需要用这个 Reference 四次租房经验，告诉你如何提高出租房的格调","categories":[{"name":"随想","slug":"thinking","permalink":"https://sean10.github.io/categories/thinking/"}],"tags":[{"name":"租房","slug":"租房","permalink":"https://sean10.github.io/tags/%E7%A7%9F%E6%88%BF/"}]},{"title":"部署Moin_wiki记录","slug":"部署beibq-wiki","date":"2018-05-30T15:16:46.000Z","updated":"2023-03-18T15:11:14.831Z","comments":true,"path":"2018/05/30/部署beibq-wiki/","link":"","permalink":"https://sean10.github.io/2018/05/30/%E9%83%A8%E7%BD%B2beibq-wiki/","excerpt":"之前一直想写一个论坛或者wiki，不过最近感觉想先部署着，以后慢慢改了。","text":"之前一直想写一个论坛或者wiki，不过最近感觉想先部署着，以后慢慢改了。 安装Moinmoin 12345678curl http://static.moinmo.in/files/moin-1.9.9.tar.gz -o moin-1.9.9.tar.gzpython2.7 wikiserver.py# 开放端口iptables -A INPUT -p tcp --dport 18082 -j ACCEPT/etc/rc.d/init.d/iptables save/etc/init.d/iptables restart 安装Mysql(虽然最后这个框架没用到) 1234567891011121314151617181920212223wget https://dev.mysql.com/get/mysql80-community-release-el6-1.noarch.rpmyum localinstall mysql80-community-release-el6-1.noarch.rpmyum repolist enabled | grep &quot;mysql.*-community.*&quot;sudo yum install mysql-community-serverservice mysqld startsudo grep &#x27;temporary password&#x27; /var/log/mysqld.log# passwd: 5!iozIn&amp;t;Vwmysql -uroot -pALTER USER &#x27;root&#x27;@&#x27;localhost&#x27; IDENTIFIED BY &#x27;fighton&#x27;;# executingpip3.6 install -r requirements.txt# 缺少mysql_configyum install mysql-develpython3 manage.py runserver -h 0.0.0.0 reference Installing MySQL on Linux Using the MySQL Yum Repository","categories":[{"name":"专业","slug":"pro","permalink":"https://sean10.github.io/categories/pro/"}],"tags":[{"name":"wiki","slug":"wiki","permalink":"https://sean10.github.io/tags/wiki/"},{"name":"centos","slug":"centos","permalink":"https://sean10.github.io/tags/centos/"}]},{"title":"zotero使用记录","slug":"zotero使用记录","date":"2018-05-16T06:52:06.000Z","updated":"2024-05-03T10:22:35.513Z","comments":true,"path":"2018/05/16/zotero使用记录/","link":"","permalink":"https://sean10.github.io/2018/05/16/zotero%E4%BD%BF%E7%94%A8%E8%AE%B0%E5%BD%95/","excerpt":"为了管理论文文献，方便引用导出等等，要用zotero,但是单纯这个导出的bibtex又无法直接给xelatex使用，就试着使用一下jabref这个工具","text":"为了管理论文文献，方便引用导出等等，要用zotero,但是单纯这个导出的bibtex又无法直接给xelatex使用，就试着使用一下jabref这个工具 问题集锦 xelatex导出bib参考文献，格式不正确，输出有些混乱[2] 使用zotero导出的bib中，文献类型同样是学位论文，但是bib中是phdThesis,而我本科的模板上是MasterThesis,暂时没找到如何让zotero修改这个的方法，倒是找到了在JabRef上修正这个的方法，看来暂时只能用JabRef了. 不过在LaTex的bst格式文件中也找到了phdthesis的输出样式，所以错误原因究竟是什么呢？ 经过一个个与模板bib文件比照，发现是由于缺少了language=&#123;Chinese&#125;这行设置，补充后即可输出了，搞定。 由于JabRef的无法正常运行，又去了解了下zotero的强大，经过检索，发现还是zotero也是可以自己配置一些可选field之后导出bib的，在language位置设置为chinese，搞定。 Zotero中文文献作者只显示姓[1] 根据知乎上作者所说，是在抓取网页解析的语法出现了问题，所以按照知乎所说修改解析方法，全部防止到姓中即可 &gt;1. 首选项-高级-文件和文件夹-打开数据文件夹。 &gt;找到translators文件夹，找到里面的CNKI.js，打开 &gt;2. 注释掉189和190两行，在后面加上一行 creator.firstName = \"\"; &gt;3. 刷新文献所在页面，重新获取条目，创建者即为作者全名。 &gt;4. 文件重命名规则可使用%a JabRef 在打开finder时，经常进入 not responding状态 按照issue里说的换成4.3 beta版本就可以正常使用了,唔，在新建entry的时候还是和issue一样Freeze了。 使用Zotfile进行pdf提取到独立目录 根据[^4]这篇文章操作了下, 现在在一个独立目录里有所有的pdf了, 至少可以跨平台阅读了. 但是这样就出现了一个新的问题, 删除文献时, 是无法把已经被rename出去的pdf也给删掉的. 不过这个倒是挺适合我的暂时, 我倒是不怎么有删文献的需求. 使用共享盘里设置软链 根据[^3]的说法? 设置软链也是个方案? 其实我一开始就是这么用的, 为了避免300MB官方空间用完, 但是这样不就回到最初的状态了, 我就是因为用ipad访问同步盘的时候, zotero的storage目录结构不好找, 根本找不到想看的文献, 所以才引入zotfile的方案的呀? 使用scite-zotero-plugin进行分析文献 使用sci-hub自动下载 按照更新版｜Zotero搭配Sci-Hub，真香！这篇文章中的配置, 找一个当前sci-hub最新的域名即可. webdav对接 用于zotero 6.0的ipad版本.(20230227从zotfile迁移到坚果云) 坚果云 使用Zotero进行从未有过的畅快学术体验 - Eddy's World 阿里云盘 自己部署webdav dropbox 自己部署webdav 解决方案集锦 zotero阅读pdf zotero结合ipad 结合思维导图 结合markdown检索. Reference Zotero 作者按西文的方式显示，如何调整为中式？ 参考文献管理工具zotero的使用经验分享 ZotFile + 同步盘，实现Zotero文献跨平台同步！ 在 iPad 上优雅地看文献：Zotero + ZotFile + 坚果云 使用Zotero进行从未有过的畅快学术体验 - Eddy's World","categories":[{"name":"专业","slug":"pro","permalink":"https://sean10.github.io/categories/pro/"}],"tags":[{"name":"zotero","slug":"zotero","permalink":"https://sean10.github.io/tags/zotero/"},{"name":"jabref","slug":"jabref","permalink":"https://sean10.github.io/tags/jabref/"}]},{"title":"档案迁移问题","slug":"档案迁移问题","date":"2018-05-16T06:38:01.000Z","updated":"2023-03-18T15:11:14.884Z","comments":true,"path":"2018/05/16/档案迁移问题/","link":"","permalink":"https://sean10.github.io/2018/05/16/%E6%A1%A3%E6%A1%88%E8%BF%81%E7%A7%BB%E9%97%AE%E9%A2%98/","excerpt":"现在毕业了，关于走流程方面有了很多问题，档案迁移需要提交什么样的表格，等等","text":"现在毕业了，关于走流程方面有了很多问题，档案迁移需要提交什么样的表格，等等 据现在知道的信息要遵守户档不分离的原则，那么户口和档案就都是回到上海，现在学校发了一张二分材料。 网上查到的上海的派遣地址存在3种可能性（上海人力资源和社会保障局、上海市各区县就业促进中心、上海市各区县人才服务中心），但是实际上现在2018年只有就业促进中心负责接收上海生源地毕业生档案，这个部分折腾了我很久，去找了些上海的大学的派遣方案里，发现写的很清楚，上海生源派遣回户口所在区县的就业促进中心就行。 确定了派遣地址： * 上海市浦东新区就业促进中心 * 上海市浦东新区浦东南路3995号309室 * 200126 * 58740409 不过又了解了一下，户档不分离的主要出处是北京毕业生集体户口迁出，既然如此，没有迁户口进入学校的情况似乎是可以不遵循户档不分离原则，是可以将档案迁移到单位所在地的。不过据别人论坛经验之谈，各省市政策不同。所以就姑且按照上面那样做吧。 派遣证信息要确保准确，就业去向为就业，签订三方协议的，需将三方协议由用人单位盖章后返回至学校，在就业信息网登记就业信息，并加盖就业指导中心公章，就业指导中心将根据毕业生在就业信息网上登记的就业信息进行派遣，其中单位名称为解决户口和档案的准确的单位名称（不能是简称），也有部分没有独立人事权的单位，需将单位名称写为放置户档的人才机构名称，一定要与用人单位确认后再上报！单位地址为解决户口的地址，（一般落实到市、区一级，如：北京市海淀区，陕西省西安市）。 Reference 毕业生就业手续办理流程","categories":[{"name":"随想","slug":"thinking","permalink":"https://sean10.github.io/categories/thinking/"}],"tags":[{"name":"档案","slug":"档案","permalink":"https://sean10.github.io/tags/%E6%A1%A3%E6%A1%88/"}]},{"title":"租房记录","slug":"第一次租房记录","date":"2018-05-12T06:32:18.000Z","updated":"2021-12-10T11:37:00.000Z","comments":true,"path":"2018/05/12/第一次租房记录/","link":"","permalink":"https://sean10.github.io/2018/05/12/%E7%AC%AC%E4%B8%80%E6%AC%A1%E7%A7%9F%E6%88%BF%E8%AE%B0%E5%BD%95/","excerpt":"终于把大一遗留下来的课给清考掉了，不用担心会被留级了。是时候准备租房了。 最后选了学长转租的那个，小区物业什么的似乎稍好一些，房间也够放个大桌子，那就行了。 搜房工具 用的几个工具是有人做好的 http://bj.yurixu.com/manage/beijing.php https://woyaozufang.live 这个是开源的 https://house-map.cn/#/ (换域名成下面这个了) 地图搜租房：多平台房源检索引擎 微信小程序暖房直租，app wellcee","text":"终于把大一遗留下来的课给清考掉了，不用担心会被留级了。是时候准备租房了。 最后选了学长转租的那个，小区物业什么的似乎稍好一些，房间也够放个大桌子，那就行了。 搜房工具 用的几个工具是有人做好的 http://bj.yurixu.com/manage/beijing.php https://woyaozufang.live 这个是开源的 https://house-map.cn/#/ (换域名成下面这个了) 地图搜租房：多平台房源检索引擎 微信小程序暖房直租，app wellcee 20250805 需求 上海, 虹桥机场附近租房 预算尽量控制在3000以下, 毕竟一周的周末是可能回家的 只要正常吵就行, 因为第一周住了附近的酒店, 其实戴耳罩的情况下, 有些还是可以接受的. 不要隔断 结果 乐贤居没有3000以下的房子了, 报了个3600的. 也就没有去实地看房了. 最后去了虹桥人才公寓线下看了下, 有2814的 小一居, 有小桌子可以用电脑, 看着比较符合我需求. 而且飞机噪音好像还行. 准备直接定了. 信息来源 xhs 公司论坛 选择 乐贤居 虹桥人才中心 (3000以下的只有早期的, 同价格没上面的大) 新泾N村(4000+) 爱博N村(4000+) 广顺小区 20230820 这次搬去武汉, 并没有做太多筛选, 价位范围在国采中心附近能接受的, 步行跑步能在2公里内的, 只有朗诗里程, 其他的都是较大的房子, 导致整租下不来. 只不过在我搬走的时候, 附近开了不少新的公寓, 比如联投新青年之类的, 可能还行. 20220529更新 需求 短租到8月初或底左右 预算尽量控制在最终搬走时低于8000?(算上假设租3个月的, 浪费一个月) 经验记录 中介平台转租的基本上都很贵 短租的民宿等, 也在150一天以上, 可能可以联系下月租能否减低? 但是反正没有合租的好 公寓也是长租的多, 除了酒店和民宿没有短租的. 这附近正常价格每天在250以上, 导致长租我觉得也降不到100出头 还是直接搜转租, 这样的好像比较合适 最好还是融泽 考虑到目前处于疫情期间, 搬家公司没办法进小区, 所以找同小区的估计自己用小推车搬家方便点 短租, 这种筛选小区的, 还是找中介? 目前筛选的我爱我家的? 看了下合同是6/16结束, 那看起来得提前搬了. 选择 已租出 回龙观新村中区 转租！13号线西二旗回龙观新村朝南超舒适落地窗小阳台心动卧室近快手百度小米 2700/月 回龙观主卧带独卫转租 龙锦苑东二区 3000/月 西二旗附近-昌平区回龙观蓝天嘉园北卧转租 2900 3人共用卫生间 到8.31 【出租】西二旗附近回龙观新村中区出租 6/15开始 2700 长租 【转租】回龙观新村主卧转租 2700/月 到8月中 融泽嘉园2号院转租、出国急转、免费送各种家具（带不走了）、可直接入住、短租7天700块 2750/月 到8.15 西二旗龙泽融泽嘉园主卧转租 2610/月 2改4 【暑期实习好房，8月底到期】 2600/月 8月底到底, 应该是在回龙观那边? 融泽嘉园西六号院18层【一居室整租】转 融泽嘉园西六号院18层【一居室整租】6400转 6400/月 融泽嘉园西六号院18层 一居 融泽嘉园二号院次卧出租个人 2500/月 次卧 转租融泽嘉园西六号院次卧 2700/月 长租 融泽嘉园 西六号院主卧 6.29到期 13号线 🆘急出二人居主卧2800 融泽嘉园2号院 可惜仅限女生 到8.15 2800/月 华府9号? 202112更新 需求 10平以上, 能额外放下140*80桌子和瑜伽垫 能点外卖送上楼 回龙观新村不行 尽量三室一厅及以下, 避免卫生间问题. 注意点 一个企业, 多加几个中介. 确保知道服务态度. 合同很重要, 转租/退租部分. ## 中介担心的风险 押金. 退租时出现不必要的费用 传统中介 我爱我家 链家 适合整租 收服务费 自如 合租推荐. 相寓 我爱我家旗下 收管理费 公寓 一天两块钱那种 资源 融泽嘉园小组 http://bj.yurixu.com/manage/beijing.php 小程序 暖房直租 微免租房 我爱我家 有个南卧, 也是比较大的阳台的. 不过似乎得1月份才能租.算了 贝壳找房 似乎会有一些小中介 闲鱼 安居客 似乎由于上面小中介可能较多, 存在不靠谱可能. 西二旗转租闲置社区 租房牛 公众号 (校友) 步行可达的 【网暖物业全包】融泽嘉园1号院精装两室次卧出租【可分担换租违约金】 3200, 必须租整年 怕后续不好转租. 麻烦 【房东直租】龙泽 开间 精装 慧华苑 有点远, 不过一室一厨一卫 3200 融泽嘉园 一号院 南卧 挺大的 有个2450/月, 然后服务费2450的.5个月的话, 等于每月3000. 感觉还可以接受. 不过怕小中介有坑 融泽嘉园 西6号院 转租到22年6月 3100, 豆瓣的, 房间应该20平了, 定了~ 搬家 滴滴搬家 原定是这个, 不过似乎箱子有点多, 考虑要不要寄走一些, 还是怎么搞. 货拉拉 自如搬家 蓝犀牛 吉米搬家 以下为18年的记录 公司附近辐射 步行 金域华府 据说是商品房 有学长出租2500 [https://bbs.byr.cn/#!article/Home/110715] 2000(由于太小，砍到1900了) 8平米https://bbs.byr.cn/#!article/Home/111715 融泽嘉园 据说是回迁房 学长出租2700 (无）1900 10平米 [https://www.douban.com/group/topic/117535918/] （客厅有隔断，唉）1850 [https://www.douban.com/group/topic/117830495/] 蓝天嘉园 1700 中介 [https://www.douban.com/group/topic/117714288/] (无)2150 [https://www.douban.com/group/topic/116591899/] 回龙观新村中区 拆迁？(路过看着也很好，可惜没联系上) 1800 [https://www.douban.com/group/topic/117733687/] 2100 [https://www.douban.com/group/topic/117347155/] 回龙观村西区 1700 有隔断 [https://www.douban.com/group/topic/117699317/] 2050 [https://www.douban.com/group/topic/117511027/] 北京人家，2KM 2000, 学长[https://bbs.byr.cn/#!article/Home/111694] 2000 [https://www.douban.com/group/topic/117073185/] 龙兴园-西区 自行车 5km范围 北店嘉园 2000 [https://www.douban.com/group/topic/117734045/] 龙锦苑东二区 2200 [https://www.douban.com/group/topic/117699317/] 风雅园三区 2000 [风雅园三区] 地铁13号线或8号线 租房要点: 下述这些最后都没用上……因为学长很省事，连押金都没要…… 看房要点 周围环境、物业安保、交通状况、配套设施等是否适宜。 看房东或者合租者是否好相处。 租房房源信息核实 所租房屋的产权证书、房东的身份证明等，确定出租房有权利出租该房屋。 看清房屋细节 *看清房屋角角落落。 主要的项目有房租、水电费、煤气费、电话费、有线电视费、垃圾清理费是否缴清 房屋内设备的数量、成新度等情况； 在租房前要仔细检查水电、马桶等日常设施是否良好；把家电都试用一遍以检查插头是否漏电，煤气是否泄漏等。一定要当面和房东把房内的设施、家具家电等核实清楚，该添置的一定要事先跟他讲明，如有问题，价格上还有商议的余地，确认无误后再决定是否签订合同。 只租过自如的房子，说下关于租自如的经验： 1. 不要租新装修的，特别是那种“首次出租” 2. 中途转租需要扣至少50%的押金，就是半个月房租，如果是退租的话需要扣80%+好像 如果公司和自如有合作的话，服务费可以打88折，并且一年有一次免费换租的机会（可以趁12月淡季的时候换一个便宜点性价比高点的） 3. 合租最好租3居室，自如的房子都是原有的n居室+1个隔断，4居往上公共空间会很挤（厕所厨房冰箱啥的，水电费还容易超阶梯），2居室一般都没有客厅，只有一个窄窄的过道 4. 最好是租13层左右的，一般都是30+的高楼，10几层正好在中间，光照好不怕遮挡并且夏天不会太热冬天不会太冷 5. 看房子的时候问下正在租的租户，水电费每个月大概是多少钱，是不是商用水电（超过阶梯价格用起来会很可怕，一个月水电费可能要150） 6. 检查下卫生间有没有返味，房间的隔音如何 7. 避免租房东打算卖房的，虽然到时候会赔你一个月房租，但经常会带人来看房子，而且到时候还得费事去找新房子 8. 尽量租在公司附近，减少不必要的通勤时间，走路就可以上班就最好啦，当然如果和对象一起租还是商量一下吧 9. 实在不行也要尽量离地铁站近一些，小区周边的配套设施也很影响生活质量（超市、小饭店、早餐店、水果店等等） 10. 第一次签约大概要准备5个月的租金（1个月押金+3个月季付+1个月服务费），要准备好预算 11. 总的来说我觉得租自如就是省事一点吧，找起房源来没那么麻烦，但也相对没那么划算，建议最好找同学或者同事一起合租一个 以上~（两年搬了四次家的感想。。[1] 租房的地点离单位近一点，要是可以步行上下班最好了，特别是如果单位有食堂管早晚餐的话，简直幸福感爆棚； 有精力尽量找个人房源，在58或者赶集上找找，这样优点是省去了和中介或者二房东讨价还价的精力和时间，缺点是不容易找到合适的，需要不停的打电话联系看房； 签合同之前要看房东的房产证和身份证，物业、水电、燃气、取暖谁交，物品损坏谁掏钱维修要讲清楚，如果提前中止合同的话，押金和房租能不能退、退多少都要在合同里写明白，能想到的就是这些。 沙发说的很棒，补充一些吧 无论价格多低都不要租隔断，隔音什么的都在其次，住了一半被赶出去的经历估计谁都不想有 如果是合租，重点考虑朝向、隔音效果、是否带独立阳台和独立卫生间，如果是整租，还要考虑是否南北通透，如非迫不得已，不要租不向阳的房子（东南西南这种斜向的勉强可以接受） 楼层低的话要注意暖气是否够热，在室内还冻手冻脚的感觉还是挺闹心的，有条件的话尽量在冬天租房子 考虑是否有小区围墙，是否有门卫，楼道是否有门禁等，那种全开放式的楼房体验是很恐怖的，楼道和电梯里全部都是小广告，平时贴小广告的、送外卖的串来串去，安全隐患很大 离公司距离越近越好，步行上下班能极大的提升幸福感，不要想着省钱住远一点，每天坐地铁公交时间长了会把意志力都磨没的 租房需要搞清楚哪些事情？ 1.交通、生活便利性。计算一下通勤的距离和费时，一共多少站，换乘几次，走到地铁站公交站要多久？附近共享单车好不好找？超市菜市场医院饭馆离得远不远？自己开车的话，早晚高峰附近的路堵不堵？ 2.物业费、取暖费。怎么交？谁来交？物业费和集中供暖的房子取暖费一般都是房东交，自采暖的房子通常是租户自己交，这些租房的时候都要问清楚。 3.水、电、燃气、网络、有线电视费。水、电、燃气都有计数表，搬进去的时候抄一下底数，拍照留存，等搬出的时候一对比就知道你用了多少，要问清楚是水电燃气的费率是民用标准还是商用标准，两者差别还是很大的。网络要问清楚小区通了哪些运营商的网络，如果你之前办过包年的网络还没用完，新的住处也有同样的运营商的话，可以联系运营商办理迁移，如果是房东提供的网络，要问清楚还剩多少时长，有没有流量限制，剩下的时长是需要交费还是赠送。有线电视费同网费。 4.周边有无污染源噪音源。周边如有长期污染源和噪音源，看房的时候短时间内很难察觉，一定要问清楚，必要的时候可以跟小区的保安或大叔大妈打听一下，比如我有朋友之前住过的小区后面有一个混凝土厂，导致小区那个水质比较差，水垢很多，之前不知道，住进去以后就感觉被坑了。（原文来自微信公众号：我在北京租租房子） 5.小区安全性。小区门禁是否严格？保安是否24小时值守？摄像头有没有覆盖？晚间有无巡逻？小租前不久电动车停在楼下就被撬了，心累。除了保障财产安全，还有人身安全，所以必要的小区安保是必须的。如果觉得问房东和中介得不到实话，可以问问小区的大爷大妈或者住过该小区的朋友。 6.家具家电是否齐全？损耗情况如何？损坏赔偿等说明。住进去之前仔细检查家具家电是否完好，如果有损坏的，签合同的时候就要说明，可以拍照留记录，避免还房的时候因为一些损耗损毁归责不明起争执，还有约定好如果东西坏了怎么赔偿，哪些东西价格比较高，使用的时候需要尤其注意。ps女生很容易弄脏床垫，有的房东床很贵，最好自己平常注意垫上垫子，淘宝上卖的姨妈垫几十块一个并不贵，一旦弄脏了，不管是赔偿还是请人专门清洗床垫都不便宜，就不太划算啦。 7.朝向、采光、楼层和冬暖夏凉情况。一般来说朝东和朝南的房子采光好一些，东向的房子是早上的阳光，在我们北半球南向的房子一整天光线都比较充足，也不会太晒，朝西的房子夕晒，下午光线强烈，夏天会很热，朝北的房子跟朝南的相反， 一整天光线都一般，冬天会偏冷，其他不是正中朝向的房子，自己推断一下就知道啦。除了朝向，附近建筑物遮挡也会影响采光，都需要提前观察好。小租还去看过一个全是平房的公寓，屋顶虽说放了遮阳板，但是夏天阳光直射还是非常晒，感觉夏天不会很愉快。楼层高的房子通常都比楼层低的采光好，但是也会增加一些不便，比如一旦电梯坏了就很崩溃了，一楼通常会潮一些，而且私密性相对差，要么整天拉着窗帘，要么路过的人都能看到屋里在干吗，这些都要自己权衡。 8.能否养宠物。很多房东都不让养宠物，主要是怕挠坏真皮家具或者让屋里有异味，如果有宠物要跟房东协商好，双方接收并且约定好规则即可。 9.隔音情况。有的房子隔音效果不好，住起来也会有困扰，一般来说正常的小区房子之间的外墙隔音还不错，内墙稍次，隔断就基本不要指望隔音了。有的公寓用料不好不实，外墙隔音也有问题，高档的装修甚至会把墙壁刷成墙面凹凸的，有吸音的效果，这里面差别就很大了。 10.房租押几付几。通常情况下都是押一付三，现在有的公寓和芝麻信用合作可以免押金，也蛮不错的，有的房东如果屋内家具家电贵重也会要求押二付三，这些就看大家自己衡量啦。（原文来自微信公众号：我在北京租租房子） 11.停车位。如果有车，要问清楚房子带不带停车位？小区有没有长租停车位？管理是否安全？费用怎么交？ 12.仔细看合同条款，有无其他限制，如合租人数，是否允许转租，退租是否提前说明等。有的房东会明确限制长住人数不超过几人，或者不允许转租，退租需要提前多久说明等等，合同一定要仔细看！合同一定要仔细看！合同一定要仔细看！否则签了什么霸王条款，到时候吃亏哭都没地方哭。小租被无赖二房东扣押金那次，最后找警察叔叔来一条条对合同，我没有任何违反合同条款的地方，无赖二房东也不得不退了我大半的押金，所以说，不管什么时候发生了纠纷，合同都是你最后一道保护伞，一定要看清楚记清楚。 搬家篇 现在搬家公司也很多啦，自如搬家、蓝犀牛、58、货拉拉、或者豆瓣租房小组直接找搬家师傅等等，多看看评价，比比价，选一个合适的即可。注意有的搬家会自带箱子，能省去部分自己打包的困扰，这些都要了解清楚。还有的搬家会看有无电梯，无电梯的房子会加收楼层费，都需要注意。（原文来自微信公众号：我在北京租租房子） 入住篇 租好了房子以后，一般建议换个门锁，以免中介或者房东留了钥匙，仍然可以随时出入你的家门，就很尴尬了。另外出门多熟悉熟悉周边环境，地铁站公交站、超市菜市场、物业位置和电话、附近医院药店、派出所、邮局、快递等等都去踩踩点，必要的时候不会两眼一抹黑。还有，记得修改网购、外卖默认地址！我就干过不止一次搬走了东西寄到原来住的地方的蠢事儿，还得回去取，肥肠麻烦的说。 最好将地址告知家人和朋友也留存一下，万一有什么事儿他们能及时找到你。容易丢钥匙或忘带钥匙的人，可以在靠谱亲友那里放一把钥匙，这样不会把自己关外面死活进不去。（原文来自微信公众号：我在北京租租房子） 防止被坑 一个在北京从事租房领域创业项目多年创业者，积累的防黑中介坑骗的重要经验与建议： 我是宋增建，根据我之前在北京进行的一个租房领域创业项目大量真实经验与数据，分享给大家，减少大家租房时，被黑中介坑骗的概率。 其实，通过网上的58、赶集等租房平台，完全可以找到大量的房东，而且其中中介公司的出租房源中，很大比例的房东，也都在58、赶集上个人登出来了，你完全可以找到他们。真正的风险，是租房过程中，被冒充房东的黑中介所坑骗，造成很大损失。这里将我之前做这方面创业时，通过大量实战，探索积累的很多经验、技巧与心得，和大家交流分享一下：1、在网上找房源，看到贴子里面的文字介绍，只有空格，而没有逗号、句号等标点时，要小心一些，这种贴子，大多是中介发的。2、主要的网上找房东个人房源的平台，就是58、赶集两个网站，其次是搜房网，别的就量很少了。在这些网站上，注意在房源中选择个人房源，但要注意，这些网站上登的个人房源，里面也有一定的比例是中介，甚至是黑中介，现有的手段，并不能完全保证对方真伪，还需要租房者自已去亲身验证。 现在一般58、赶集，都引导大家通过手机app，才可以看到房东的手机号，就可以和这套网上房源的房东联系了。3、打过去电话，可以先停顿一下不说话，静静地听对方的背景音，有时你可以听到中介公司那种很多人在打电话谈租房的交流声，这就可以判断是中介公司了。 同时，一般的房东，会主动先出声和你交流，你可以听其声音，判断其年龄、修养、气质等情况，再去聊。而如果打通后，对方很久不出声，想听你的声音，是中介的可能性较大。4、要把判断对方是否是中介作为最首要的一件事情。 在没有判断清楚时，避免说出过多个人信息，以及租房需求等。要等判断清楚了，比较自信了，再说更多个人情况。 很多中介公司会有一个系统，第一个和你通话的中介，会把你的手机号、个人信息和租房需求等录入进系统，这样其它人帮你租成了拿佣金，录入者也有业绩与分成。所以如果对方是中介，录入系统，全北京这家中介的各个分店都可以看到，并主动打电话给你，会比较烦，但作为租户，被电话骚扰的数量不会太多。你明确向对方说不用中介后，给你打电话的中介，也会把你的这个回复，录入系统中，其它中介会看到。5、在打电话前，详细记清租房贴子中的一些照片、房子情况等细节，比如地板什么样，电视什么样，楼层是多高，面积有多大，房东姓什么，租金，等等。最好打电话之前，提前记在电脑或纸上，列出这些问题与细节清单。 然后打电话时，用这些细节去验证，看房东是不是会记错与出现矛盾之处。 在刚打通电话时，注意不要自已主动说出你看到的小区的名字、几室几厅、多少租金等信息，而是先问一句：“您有房子出租吗？”，然后装作记不清小区、租金、甚至是对方姓氏等，主动去套对方的话，比如“不好意思，刚才网上看了几套，给您打电话时，手机上看不到相关信息了，想详细问您一下，我是个人租房者，想多了解了解。” 然后，将很多刚才记下的细节，一一去问，注意有时要故意用误导式提问，比如：明明照片上看到是木地板，却问其地面磁砖的颜色；或明明看到是绿色的沙发，问其蓝色的沙发是否干净等等。如果对方能及时纠正你故意说错之处，说明对方对房子情况非常了解，更可能是个人房东。而中介，有时登出很多套假的房源，是记不清这么多细节的，让你问多了，就会矛盾与错误百出，明显与网上登的细节不符。6、电话里，大量、详细地问很多东西、交流很多东西。 一般真实的房东，也会怕遇到黑中介冒充个人来租房，最后租下打隔断出租毁了房子，所以，你这样问的特别详细，真正的房东，也会对你更加信任，而中介，往往就会不耐烦。所以，就大量细节去问房东，可以偶尔加一点解释，就是强调自已是个人，所以也想找真实的个人房东，多问一点请别介意。真实的房东，也愿意多了解求租者个人信息，一般都愿意和你多交流，而中介往往受不了这么麻烦的问来问去。这是很重要的区别，两种人的出发点与目的不同。7、除了问房子情况之外，很重要的一点，是多聊聊房东是做什么工作的，最好还可以问出是哪一家公司或单位。 可以结合房东说自已的工作领域，聊一些你所知道的这个行业的一些人、事、公司等等，一方面，房东可以加深对你的赞叹与信任，另一方面，你也可以通过这些话题去验证对方真伪。 而且这里面，还可以故意说一些“陷阱性的问题”，去试探对方。比如明明你知道一个这个行业的事情，你说一个假的，或是相反的，或说一个你乱编的这行业公司的名字，看对方的反应，如果对方说是对的，顺着你说，没有纠正错误，而不是说不知道，或是对方对这个行业与领域根本说不上什么来，表现得很不耐烦或粗鲁，往往就暴露对方是中介。 如果你问对方工作，如果是中介，一般他们会说自已是做行政工作、市场营销等人们最常见的，但不会说具体的行业，中介很难说得出很具体的一些行业以及工作细节，这个就太难为他们了。所以具体到这个行业哪一家公司，或是深聊一些这个行业的一些东西，中介假冒房东，往往就会暴露。这样，你就不用白跑一趟了。8、注意对方的电话开头号段： 一般139的，或是186开头的，可信度比较高。当然这不是绝对的，而一些如155、156、131、132、133、185等开头的，是中介可能性相对较高。但这些只是相对的，不是绝对的。 现在实名制了，但中介仍然有办法找一些临时的号去发贴子，冒充房东，而139这种号的成本很高，而且这种号，往往不能多次在网上发贴，否则会被标记为经纪人，而且，过多用此号，也会被标注为经纪人，因为中介往往需要不断换号。9、在搜索引擎，去搜索看到的房东手机号，看是否被多人标注为经纪人： 安卓手机有一个功能，就是很多人标注上一个手机号是中介后，你打去时就可以看到。所以，可以找一个安装有腾迅手机管家、360手机管家等这类安卓手机打过去，这可以显示被多少人标注为中介。 还有一种方法，就是在百度、搜狗、360这三个搜索引擎中，搜索你看到的房东的手机号，这些网站与BAT出的手机安全类app是绑定的，在手机上被这些app标注的，也会在这些搜索引擎中展示出来此号被多少人标注为中介。 PC或手机浏览器上的搜索引擎，百度对应的是“百度手机卫士”app,搜狗对应的是“腾迅手机管家”app，360搜索对应的是“360手机卫士”app，这样在浏览器里用这些搜索引擎去搜索房东手机号，效果是一样的，看其标注情况，我说过，中介会经常大量换新号，这种方法只是一种辅助手段。10、看贴子、以及配的文字，感受房东是一个怎样的人。 如果是黑中介，只是希望把你骗来。所以看房子的介绍，感觉就比较粗糙，或是别处抄来的文字，就是黑中介。而如果是真正的房东，往往在照片、写的东西上面，会很用心，尤其是你一打电话，对方会对你的身份、工作、几个人住、什么关系等，希望多了解你，而这些情况，中介一般是没有兴趣过多问细节的。 通过声音，去感受到对方的气质、学识、修养、心理等很多细节，这需要你用心去感受，多注意自已的直觉，综合判断是不是黑中介，毕竟在黑中介里，有文化与修养、气质的人，还是比例很少的。 不过，很多时候，有些房东也只发布那种几乎就一句话说明的租房贴，特别简单，也没有图片，而中介有时也经常发布这种贴子，从这种很简单无图的贴子中，就很难判断。11、听电话或微信语音中的口音，判断对方身份与地域： 我管这种电话里的语气，叫“菜音”，就是听上去比较粗俗、浅薄、没多少文化、有时带有一种粗鲁，或是刻意装出来的一种有文化与文雅的感觉。 我个人，对各个地方的人，没有偏见，但整体上说，北京黑中介里面，东北口音偏多一些，还有中原地带也有少量，但南方口音，或是北京口音，并不一定就不是黑中介，只是概率小很多。 同时，从事黑中介的，绝大多数是20岁到30岁左右的年轻人，年龄大的要少很多，听年龄，也可以做出一定判断，如果对方听着50多岁，温文尔雅很有文化，那是黑中介的可能性就会很低，而毕竟，大多真实的个人房东，年龄并不轻了。 有时中介会找一些人来共同演戏，骗租房者上当。但这里面，有文化修养与高雅气质，就是大家在好的写字楼、好的公司，经常遇到的那种受到良好教育、有好的工作积淀与修养，这种气质的人，在黑中介中，比例还是很少的，但在个人房东中，就比例大多了。12、加对方微信，尽量与对方进行视频： 加上对方微信，可以看房东的朋友圈，了解这个人的情况，如果是中介，在很多方面，往往还是有差异的。同时，通过与对方微信视频，可以更清楚地看清房东的样貌、修养，而且还可以手机同步录音，截屏等，这些都是保留的一些制约假房东的证据，如果是黑中介，这些未来可以可以有法律作用，至少把录音、照片放在网上，或是提交给管理黑中介的住建委，或诉讼时交给法院，还是很有震撼作用的。 最关键不是事后，而是租房之前，在去看房前，如果通过微信视频，看到对方的气质、言谈、衣着等，如果修养、品味、气质、常识很不错的人，是中介的可能性就会很低，毕竟，这样的人往往工作不错、事业有前途，不会去做黑中介的。 当然，一切都不是绝对的，保有警惕之心很重要。13、搜索贴子中图片去判断，同时注意图片质量： 租房贴子里面的图片，用百度、搜狗、360的图片搜索功能，去拖进去，看看网上哪里，还有这样的图片，就可以判断一些房源的真伪。 中介往往从别处扒房子的图用，在这些搜索引擎的图片搜索功能中，往往会显其原形，但很多时候，也有房子的图，是中介们自已拍的，或之前多拍备用的。 另外，发在58、赶集上面的租房贴的图片质量，个人房东，有房子的人，相对收入往往较高，都是用苹果等高端手机，拍的图片质量很好，但那些黑中介发的，往往是来自于低劣的手机拍的，或是从别处扒的假房源图片粗糙处理以逃避58等网站的图片比较功能，所以，低劣质量的房源图片，看上去模糊的，是黑中介可能性较大，甚至很大。14、现场看房环节的骗局（尤其注意）： 如果现场看房，遇到了黑中介，也有几种情况列给大家如下。1）、对方穿着中介常穿的深蓝色西装，年轻，而且直接告诉你他就是中介，并且说现在网上根本找不到真实的房东的房子，来打击你让你租他们的房子。其实你自已完全可以在网上找到真实个人房东的。2）、对方冒充房东，然后说这套房子代理给他们了，或是和房东是朋友，这套房子和他签就行了，可以给你看复印的房产证，以及租给他的合同等等，反正就是各种让你要特别相信他们，他们一定不会骗你等等。这种人，是黑中介的可能性很大。3）、对方是北京人，年龄较大，同时有时旁边还有年轻人，这个年龄大的，往往是黑中介找来的托儿，冒充房东看着更可信。而年轻的，是黑中介本人，来看看租客的情况。很多时候，假房东就是一个人出现。 上面情况中，如果他们说自已是房东本人，看其身份证、房产证，尤其再去物业核实其真假，往往就会露馅。但他们想办法会说服你，说和房东关系好，是亲戚或朋友，这套房子他来管，你和他签没有任何问题等，如果你没有能力去判断真伪，建议一定要找真实的个人房东本人出面，可以大大降低被骗概率。相信我，不要过度迷信自已高学历，或是工作经验丰富，在黑中介这里，骗的很多人，都高学历高工作背景的。15、租房合同的猫腻，以及如何选择合适的合同文本： 在现场，黑中介往往用各种身份，骗你签一份“代理合同”，注意，看到这种“代理”合同，要特别小心，这就是黑中介们通过他们的律师，帮助他们精心设计的条款，对租客非常不利，合同名称是某某出租代理合同，最后签的是一个中介公司的名字。但其实，黑中介往往都是蛮不讲理，有时就算签了非常正常的合同，也会坑得你损失很大。 因此，最关键的，是别太相信合同，而是以预防避免上当为主。否则上了当，你很难有大量精力与时间，去与这些像黑社会一样的黑中介去纠缠到底的。目前走法律诉讼的很少，而且在执行中，也难度极大。 所以，最好签自已提前打印的合同带去，尽量用自已的合同，在北京市住建委官方网站上的《北京市房屋租赁合同（自行成交版）》可下载，网站见下图： 作者：宋增建 链接：https://www.zhihu.com/question/54461291/answer/139471473 来源：知乎 著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。 同时，想补充一点，签合同时，最好自已提前带着印泥，彼此都在名字上按上手印，并且双方把手印，像骑缝章一样，同进按在每一页边侧，证明合同的完整性。16、现场看房产证，以及去物业实地核实： 这是现场验证对方真假的重要途径。 对方是不是真实的房东，最安全的，还是直接和房东本人签合同，仔细看房产证，并且去物业验证这个人就是真实的房东，小区的物业是有责任帮助租房者验证房东真伪的。 房产证真件，印刷的很精致，很少有伪造的，但也要小心，而再加上去物业核实真假这一条，基本上是假房东的可能性就很小了。17、签合同现场，同时录下照片或视频： 最好签合同后，现场录下照片与视频，并且是一段连续视频，里面要出现合同，说出来时间、地点、这套房子的小区、楼、牌号等，并且房东要保证对方是房东等信息，这些法律证据非常有用。而且，未来如果是黑中介，这段视频用在网上，或交给政府相关部门的震撼作用非常大。18、可先交定金，租金支付时间上适当后置，但别太晚。 看房时，最好就提前如上面15条所讲，随着带着自已的合同两三份（至少双方一人一份，一份还可以打草稿）。看好房，验证好房东身份，可以现场马上打定金。最好可以网银转帐，或是用支付宝，这样保留下证据。而且尽量少一些，比如500，或是1000元，但也别太少。 同时，尽量让房东给你留出一定搬家的时间，比如一周后起算等，到时交全款。但根据我的经验，有时如果真是很看好房子，并且房子很抢手，还是签合同，尽量把押一付三，或是约定租金尽快交全为好，这样，房东就不能毁约再租给别人了。如果没有定金的约束，房东就算嘴上说得好，给你留着，但如果中介带人来，或别人看好给更多租金，房东也往往会和你毁约。至少定金，是一定的约束，如果合同里写出条款，让房东如果毁约支付一个月的违约金。但现实中，还是双方协商为主，真正打官司的很少。因此，当你确定对方是真实房东，房子也满意，就要尽快交清全款，才是真正的“定下来”，否则，后面的变化真得很多。 支付房租方式，可以在合同上写清楚，向房东的某某银行帐户打入的款项，就视作是支付的定金与租房款，这样，只要向此帐户打款，就视同交了租金。 尽量避免现金交接，这样，银行转帐记录本身也是法律证据。19、了解黑中介会怎么骗你： 黑中介，最后会不退押金，而且合同里各种陷阱，更恶劣的，是让你住在中途，就用各种手段说你违约为由，采用野蛮暴力的手段，把租户提前强行赶出去清房，他们行儿话，叫“做违约”，而且会把你提前多交的一两个月房租，以及押金等都找理由扣着不给。 还有在租房后，提出的各种另收的卫生费、服务费等等，先让你上钩，再收各种不合理费用。 黑中介不是每一个都这样恶劣，给你造成的损失也都不一样大，但如果租了黑中介的房子，有一定比例，会让你中途就被赶走，以北京的租金水平，你可能会被黑掉上万元。 还有的，是黑中介与房东签的合同，快到期了，却收入了你一年的钱，到时候，房东来收房，黑中介拿钱不管了，让你们双方去协商，麻烦很大。 你在交涉中，黑中介往往还会暴力化，而且无赖化，并且一家有事，周边各家黑中介一起帮忙对付你，各种手段，让你非常郁闷难受，所以尽量直接租真实个人房东的房子为好。20、如果着急找房，要找中介，尽量找大的、市场主流的中介公司，在北京市场，主要是链家、我爱我家、中原地产、麦田房产等。 基本上主流的就是这几家，尤其是以链家、我爱我家为主，他们要收一个月的中介费。注意，大中介的一些店有时也会有黑人的现象，但比黑中介还要好很多，各种什么看房费等，是不用交的，在北京看房，不用提前交任何费用。 重点小心中小型中介，有相当比例会存在一定的黑中介化。当然，规模大的一些中介，也有黑中介化的现象。所以，如果非要找中介，最好是找链家、我爱我家这两家。21、特别小心，那种所谓黑中介“代理”的房子，更是他们常用的方式。 很多黑中介，用的手段，就是“代理”，从房东那里把房子代理下来，再转租给租客。这种“代理”的房子，是黑中介的主要手段，他们相对做居间，就是让你和房东双方见面，最后只收入中介费的较少，主要利润，还是来源于这种“代理”。你和他们签这种“代理”的房子，最后就会造成很多的麻烦，上面我讲过了。22、如果合租，可以选择链家的“自如”，或是58同城租房版块下的“品牌公寓”，找一些在网上搜搜，可以看到一些风投融资等相关信息的公寓品牌。 当然，这些公寓，也不是都很令人满意，但是相对于黑中介那种合租，还是相对好一些。黑中介的合租，从房租价格上，表面上看很低，但最后算上坑你的钱，还有其它的一些乱收的钱，其实不比品牌公寓便宜。 如果你有有经验的朋友，他整租下来一套个人房源，你与他合租，是性价比相对更高的。23、租房遇到黑中介时，一定不能单纯只看租金，黑中介往往报的租金很低，这后面的坑就更大了。 你想，他们从房东那里代理来每月要6000元，而租给你5000元，甚至4000，怎么可能呢？租金明显低于市场价的，相当大的可能，会对你“做违约”，就是想办法很快让你违约，把你多交的房租，以及押金，都扣光，并赶你走。再一个个用此“代理”的房子，去陆续坑人。 因此，如果你和黑中介谈租金，他们很低都可以租给你，但最后损失的，一定是你自已。他们有太多手段对付你，你租不久就会知道的。24、找个对在北京个人租房非常有经验的朋友，甚至是认识两个黑中介，在租房过程中咨询他们： 我和黑中介打交道时间很长了，对这个行业的理解也很深。我特别想告诉大家，北京的租房黑中介行业，能够形成，是有很多方面非常复杂的因素综合造成的。这些黑中介，不能说他们每个人都是坏人，只是这个行业的商业模式，不断演化到这个样子，他们只能按照这套模式去坑你。但不能因此就简单地认为，这些黑中介个人都是坏人。在整个行业的大潮中，个人的力量与选择，往往是非常狭小的，明白了这一点，你就会更了解这些黑中介，也就更能避免被他们狠狠地坑你。 建议在你租房时，提前找找在北京个人租房非常有经验，了解如何避免上黑中介当的朋友，在你租房时，可以向他咨询和寻求帮助，最好陪你一起去。甚至你也可以认识一两个干黑中介这行的人，花几十块、上百块钱请他们吃顿饭，当你租房时，咨询一下他们，毕竟同行是最了解同行手段的，如果他们拿你当朋友，就会告诉你如何避免上当。25、最后，告诉大家一个经过实践中得来的一个重要的金律： 当你在租房时，感觉对方可能是黑中介，或是感觉这个房东不太对劲，就尽可能别租！ 因为你要相信自已的直觉，你的直觉已经感受到一些地方不太对劲，这是潜意识在对你发了警告。而你没有听从这种来自感觉的警告，租了房子，往往后患与麻烦无穷。 所以，当你租房时，上面这一条条我写的，你都处理好了，理性也认为还可以，但就是直觉不断告诉你，不太对劲，你特别要相信这种直觉，通过我过去做租房领域创业项目大量的亲身体验，这种直觉，往往会在后期被验证。 记着，北京市场上，总同时有大量的房子在出租，从来不存在房源没有的情况，而且新的房子也会大量的不断空出来，只要还有可能，尽量避免避免麻烦，而不是后期真遇到黑中介，过高估计了自已处理麻烦的能力，经济损失、心情与尊严上的损失，都会让你久久不能忘怀。 reference 2017北京租房全攻略（租房必看） 马上毕业了，租房有哪些要注意的呢？ 租房要点，适用于北上广深杭，欢迎补充","categories":[{"name":"随想","slug":"thinking","permalink":"https://sean10.github.io/categories/thinking/"}],"tags":[{"name":"租房","slug":"租房","permalink":"https://sean10.github.io/tags/%E7%A7%9F%E6%88%BF/"}]},{"title":"白帽子讲Web安全Note","slug":"白帽子讲Web安全","date":"2018-05-10T11:58:53.000Z","updated":"2023-03-18T15:11:14.834Z","comments":true,"path":"2018/05/10/白帽子讲Web安全/","link":"","permalink":"https://sean10.github.io/2018/05/10/%E7%99%BD%E5%B8%BD%E5%AD%90%E8%AE%B2Web%E5%AE%89%E5%85%A8/","excerpt":"计划看好久了，一直没看，现在终于简单过了一遍。","text":"计划看好久了，一直没看，现在终于简单过了一遍。 我的安全世界观 威胁分析 STRIDE模型 威胁 定义 对应的安全属性 Spoofing(伪装) 冒充他人身份 认证 Tampering(篡改) 修改数据或代码 完整性 Repudiation(抵赖) 否认做过的事情 不可抵赖性 InformationDisclosure(信息泄露) 机密信息泄露 机密性 Denial of Service(拒绝服务) 拒绝服务 可用性 Elevation of Privilege(提升权限) 未经授权获得许可 授权 风险分析 DREAD模型 windows Vista的UAC功能，询问用户是否允许该行为，这里说如果用户能分辨什么样的行为是安全的，那么还要安全软件做什么。这里说的很对，不过也是存在一种解释，这里的提醒只是一种用户个人对行为承担责任的方式吧，已经予以提醒，之后的操作的安全保障已经不是操作系统层面的安全性能够提供了。 客户端安全 &lt;img&gt;&lt;iframe&gt;&lt;link&gt;等标签都可以跨域加载资源，不同于XMLHttpRequest，通过Src属性加载的资源，JS权限被浏览器限制了，不能读写返回的内容，XMLHttpRequest可以读写同源，访问跨域需要遵循标准，通过目标域返回的HTTP头来授权 EVSSL相比普通的SSL,在浏览器里会有绿色高亮 跨站脚本攻击(XSS) 反射型XSS 存储型XSS Dom Based XSS 除了User Agent以外，还可以通过一些浏览器限定的操作来判断实际浏览器 XSS也是有一些攻击框架，如Attack API、BeEF等等 XSS Worm 蠕虫属于终极XSS 可以通过location.hash来发送XSS payload base标签 window.name Anehta回旋镖 XSS攻击主要发生在MVC的View层，模板引擎支持htmlEncode来对抗XSS Anti-Samy 最好的XSS filter CSRF 这个问题在之前写前后端分离部署的时候倒是遇到过……然后为了能跑起来，似乎对安全性完全没有考虑过 P3P头和Firefox等浏览器是支持发送第三方Cookie的 Anti CSRF Token ClickJacking 唔，很多盗版内容网站通过这个来获取广告点击 XSIO图片覆盖攻击 fram busting 防止跨域iframe攻击 X-Frame-Options HTML5安全 sandbox 注入攻击 使用类似xp_cmdshell等存储过程获取webshell 文件上传漏洞 避免方法: 1. 文件上传的目录设置为不可执行 2. 判断文件类型 3. 使用随机数改写文件名和文件路径 4. 单独设置文件服务器的域名 认证与会话管理 访问控制 垂直权限管理(RBAC) 水平权限管理 OAuth 加密算法与随机数 ECB(Electronic Codebook)模式 伪随机数问题 如果伪随机数的空间太小，可能被预测到，那的确很危险 小结 不要使用ECB模式 不要使用流密码(比如RC4) 使用HMAC-SHA1代替MD5(甚至是代替SHA1) 不要使用相同的key做不同的事情 salts与IV需要随机产生 不要自己实现加密算法，尽量使用安全专家已经实现好的库 不要依赖系统的保密性 当你不知道该如何选择时 1. 使用CBC模式的AES256用于加密 2. 使用HMAC-SHA512用于完整性检查 3. 使用带salt的SHA-256或SHA-512用于Hashing Web框架安全 利用好如django自身提供的安全解决方案，也仔细想想框架自身是否存在漏洞。 应用层拒绝服务攻击 即对消耗较大的应用页面不断发起正常的请求，如select * from xxx这种数据库查询操作阻塞数据库，或者占用服务端的最大连接数，亦或是通过https申明一个较大的content-length,小字节包慢慢发，占用资源。 业务前进行一个判断访问频次异常 验证码 Yahoo设计的算法(Detecting system abuse) 根据IP地址和cookie，计算客户端的请求频率并进行拦截(好眼熟，好像吴军老师的《浪潮之巅》里也提到过这个样例) WebServer配置安全 互联网业务安全 安全开发流程（SDL) Reference [《白帽子讲Web安全》] URL的井号","categories":[{"name":"专业","slug":"pro","permalink":"https://sean10.github.io/categories/pro/"}],"tags":[{"name":"信息安全","slug":"信息安全","permalink":"https://sean10.github.io/tags/%E4%BF%A1%E6%81%AF%E5%AE%89%E5%85%A8/"}]},{"title":"mac OS memory与常规memory、swap","slug":"Mac-Memory与常规memory、swap","date":"2018-05-08T15:45:18.000Z","updated":"2023-03-18T15:11:14.906Z","comments":true,"path":"2018/05/08/Mac-Memory与常规memory、swap/","link":"","permalink":"https://sean10.github.io/2018/05/08/Mac-Memory%E4%B8%8E%E5%B8%B8%E8%A7%84memory%E3%80%81swap/","excerpt":"在跑Tensorflow的时候，在Mac上没有出现的内存耗尽导致的dead问题，出现在了ubuntu上，本以为会和mac一样用硬盘来进行交换内存，而不只是使用默认设置的swap空间，结果并没有如想象的那样。","text":"在跑Tensorflow的时候，在Mac上没有出现的内存耗尽导致的dead问题，出现在了ubuntu上，本以为会和mac一样用硬盘来进行交换内存，而不只是使用默认设置的swap空间，结果并没有如想象的那样。 mac OS的activity monitor中的Memory提供了好多名词 简要 Physical Memory: 实际RAM使用的 Memory Used: App Memory: APP使用的内存量，包含其虚拟内存和物理内存 Wired Memory: 系统核心占用的，此内存中的信息无法移动到硬盘，因此必须保留在 RAM 中。联动内存的大小取决于当前使用的应用程序 Compressed: RAM中被压缩的部分,从而让出一些RAM的空间给其他进程， Cached Files: 最近使用的内存被临时存储，在使用其他应用前再次打开会直接从这里访问，加快访问速度 Swap Used: 硬盘中用来交换RAM中无用内容的大小 内存详细 Real Memory Size: 被进程使用的实际内存 Virtual Memory Size: 进程空间大小，64bit内存地址空间，所以会很大，不重要 Shared Memory Size: 表示已经被加载到物理内存中的进程私有数据所对应的虚拟内存地址空间大小。 Private Memory Size: 表示已经被加载到物理内存中的进程私有数据所对应的虚拟内存地址空间大小。 比较 在操作系统书中讲述的内存管理，其实mac OS并没有与他有太大差别，现在理解来看大致思想还是相近的。 看下mac OS是在哪个部分能够出现30G占用这种情况，是swap空间没有设置上限吗？ 看下面的swap大小与上面的virtual memory size的确对上了，的确是swap空间够大的原因……而检测过程中，占用大量内存的问题所在是tensorboard,暂时只好手动导出数据用matplot画了。 Reference Apple Activity Monitor Instrument Mac 的 memory 和 real size memory 有什么区别 Mac OS 内存管理知识 Memory terminology in Mavericks Activity Monitory How to use Activity Monitor on your Mac","categories":[{"name":"专业","slug":"pro","permalink":"https://sean10.github.io/categories/pro/"}],"tags":[{"name":"Memory","slug":"Memory","permalink":"https://sean10.github.io/tags/Memory/"},{"name":"OS","slug":"OS","permalink":"https://sean10.github.io/tags/OS/"}]},{"title":"VMWare远程控制tensorflow踩坑","slug":"VMWare远程控制踩坑","date":"2018-05-07T10:14:08.000Z","updated":"2023-03-18T15:11:14.869Z","comments":true,"path":"2018/05/07/VMWare远程控制踩坑/","link":"","permalink":"https://sean10.github.io/2018/05/07/VMWare%E8%BF%9C%E7%A8%8B%E6%8E%A7%E5%88%B6%E8%B8%A9%E5%9D%91/","excerpt":"最近做毕设跑tensorflow占用资源挺大的，就想用旧电脑来跑，本来计划的是用旧电脑双系统里装好的ubuntu来跑，不过最近发现跑完保存模型和tensorboard，甚至在跑的时候就用了很多虚拟内存，至少mac上就达到了30G。这样的话，只给分配了20个G的ubuntu就相当不够用了。只好在windows上开虚拟机再配置一下远程了。","text":"最近做毕设跑tensorflow占用资源挺大的，就想用旧电脑来跑，本来计划的是用旧电脑双系统里装好的ubuntu来跑，不过最近发现跑完保存模型和tensorboard，甚至在跑的时候就用了很多虚拟内存，至少mac上就达到了30G。这样的话，只给分配了20个G的ubuntu就相当不够用了。只好在windows上开虚拟机再配置一下远程了。 安装完ubuntu，为了能让远程直接ssh到虚拟机里，需要对NAT进行设置，在虚拟网络设置中，比如我就把将主机的10086端口映射到虚拟机IP的22端口，这样就可以直接远程ssh了。 首先修改一下apt源到清华，不过为什么感觉反而这次更慢了呢？ 不过在使用VMWare共享文件夹给ubuntu的时候倒是遭遇了一些问题。 1. legacy install 一开始为了减少桌面环境的资源占用，修改了grub的选项，默认启动命令行界面了。理论上这个部分对我之后安装vmware-tools是没有什么影响的，照常挂载cdrom,mount -t auto /dev/cdrom /mnt/cdrom，然后解压到根目录执行就好。 vmware据说是安装了vmware tools以后就可以访问共享文件夹，但是在ubuntu里安装失败多次，成功一次以后依旧没能发现那个文件夹。 sudo ./vmware-install.pl -d之后是完全不够的 需要按照2对tools打一个补丁， 然后使用更新的vmfuse替换mount，``之后就能访问共享文件夹了。 2. open-vm-tools install 1234sudo apt-get install gitgit clone https://github.com/rasa/vmware-tools-patches.gitcd vmware-tools-patchessudo ./patched-open-vm-tools.sh Python环境重建 好久没在ubuntu下重新配置环境了 123456sudo add-apt-repository ppa:deadsnakes/ppasudo apt-get updatesudo apt-get install python3.6curl https://bootstrap.pypa.io/get-pip.py -o get-pip.pypython3.6 get-pip.py 然后把pip源改到清华，OK。 终于可以跑起来了，之后再装好jupyter打开对外访问,win10防火墙开放一下修改的映射端口，就OK啦~ Jupyter远程跑的时候，频频会弹出窗口提示 Notebook has changed since we opened it. Overwrite the changed file? 一开始搜了下，最高票都提示说是bug，是自动modify_checkpoint间隙太短，在5.5版本里添加了修改这个时间的配置文件。但我之前单机使用是没有问题的，新装的版本和单机用的notebook版本是相同的，所以变量是控制了的，之后发现有人多次提到主要出现原因是因为同时多个窗口在访问这个页面，那么，细想一下，在启动notebook时默认会自动打开一个网页，text启动的ubuntu是不是也存在了这个情况(目前猜想是由于毕竟是desktop版本的ubuntu，所以还是存在自动打开网页进程的能力)，那么就去修改一下配置文件，默认不打开网页，解决了一个小问题。 但是依旧会定时弹出这个网页……暂时先集中到内容上，之后在处理吧 jupyter kernel重建 在另一台电脑上重新安装jupyter，发现由于系统内存在多个python3版本，执行的python3内核并不是我所要的。 首先修改ipython 解决方式: 12which ipythonwhich python3 将ipython文件中启动方式里的python路径改为你要用的那个版本的python即可，像我就是修改为python3。 再使用jupyter kernelspec list得到所需要修改kernel.json路径，将其中的python路径改为自己所要用的即可。 不过这里显然存在一个问题，这里我list出来的是我在virtualenvwrapper里配置的环境里装的jupyter的kernel的路径，虽然这里改了以后能够运作了，但这应该是存在问题的。 看[6]中提到的，ipython kernel install可以按自己想要的安装内核，但是我安装后还是没能出现在上面的list中，稍后再看吧。 Reference vmhgfs-fuse替换mount vmware-tools-patches pip install doc tsinghua pypi Anaconda &amp; ipython路径问题 &amp; jupyter notebook 启动核心问题（使用方法&amp;不常见的问题） jupyter与python的内核","categories":[{"name":"专业","slug":"pro","permalink":"https://sean10.github.io/categories/pro/"}],"tags":[{"name":"VMWare","slug":"VMWare","permalink":"https://sean10.github.io/tags/VMWare/"},{"name":"jupyter","slug":"jupyter","permalink":"https://sean10.github.io/tags/jupyter/"}]},{"title":"LaTex学习记录","slug":"LaTex学习记录","date":"2018-05-04T12:30:59.000Z","updated":"2023-03-18T15:11:14.826Z","comments":true,"path":"2018/05/04/LaTex学习记录/","link":"","permalink":"https://sean10.github.io/2018/05/04/LaTex%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/","excerpt":"","text":"编译过程 12345xelatex main.texbibtex main.auxxelatex main.texxelatex main.texopen -a preview main.pdf 将tex转成word 1pandoc -s main.tex -o main.docx 12345# 调用方法 ：# 单个文件texcount your-file-name.tex# 多个文件texcount file-name1.tex file-name2.tex 出现问题 ---they aren't the same literal types for entry shenyaoZhongGuoDianYingZaiXianPiaoWuFaZhanYanJiu2016 while executing---line 2571 of file buptbachelor.bst 0 is an integer literal, not a function, for entry shenyaoZhongGuoDianYingZaiXianPiaoWuFaZhanYanJiu2016 while executing---line 2571 of file buptbachelor.bst You can't pop an empty literal stack for entry shenyaoZhongGuoDianYingZaiXianPiaoWuFaZhanYanJiu2016 while executing---line 2571 of file buptbachelor.bst 根据检索，按照4次编译过程来[4]，就可以得到文献结果，只不过出现中文编码错误 英文参考文献中出现中文字符 对language域进行判断的话，需要改bst文件，针对一些特殊的域进行判断，比较麻烦。 现成的GBT7714的那个，只要language域不是空的，就按中文输出。[5] Reference Latex中bib参考文献的编译 bib格式 使用 BibTeX 生成参考文献列表 Latex下使用IEEEtran模板编译bib失败报错的解决方法 对于中英文参考文献，如何区别输出？","categories":[{"name":"专业","slug":"pro","permalink":"https://sean10.github.io/categories/pro/"}],"tags":[{"name":"LaTex","slug":"LaTex","permalink":"https://sean10.github.io/tags/LaTex/"}]},{"title":"使用github二级域名部署服务","slug":"使用github二级域名部署服务","date":"2018-04-13T13:42:36.000Z","updated":"2023-03-18T15:11:14.893Z","comments":true,"path":"2018/04/13/使用github二级域名部署服务/","link":"","permalink":"https://sean10.github.io/2018/04/13/%E4%BD%BF%E7%94%A8github%E4%BA%8C%E7%BA%A7%E5%9F%9F%E5%90%8D%E9%83%A8%E7%BD%B2%E6%9C%8D%E5%8A%A1/","excerpt":"以前比较偏向买个域名，然后理论上用服务商提供的dns解析根据不同的sub domain指向不同ip就能部署服务了。其中，将github page CNAME到自己的域名上。 如果是使用提供的二级域名作为主域名呢？域名指向权限不在自己手中的情况下，github如何提供的解决方法呢？","text":"以前比较偏向买个域名，然后理论上用服务商提供的dns解析根据不同的sub domain指向不同ip就能部署服务了。其中，将github page CNAME到自己的域名上。 如果是使用提供的二级域名作为主域名呢？域名指向权限不在自己手中的情况下，github如何提供的解决方法呢？ github支持gh-pages分支生成项目页&lt;username&gt;.github.io/&lt;project&gt;，但还是不能利用自己的服务器部署服务。 在参考1中提出了一个利用gh-pages+HTML 302的方法进行跳转的方法。 再仔细找了找，除了自定义域名和这个302的方法，Github官方没有开放这个域名指向其他服务器的权限，仔细想想这样也是有道理的。否则岂不是github的域名也无法保证这个网页的安全性了。 Reference 把 Github 用作 DNS 设置二级域名跳转","categories":[{"name":"专业","slug":"pro","permalink":"https://sean10.github.io/categories/pro/"}],"tags":[{"name":"github","slug":"github","permalink":"https://sean10.github.io/tags/github/"},{"name":"DNS","slug":"DNS","permalink":"https://sean10.github.io/tags/DNS/"}]},{"title":"广告系统初探","slug":"广告系统初探","date":"2018-04-11T13:53:18.000Z","updated":"2023-03-18T15:11:14.880Z","comments":true,"path":"2018/04/11/广告系统初探/","link":"","permalink":"https://sean10.github.io/2018/04/11/%E5%B9%BF%E5%91%8A%E7%B3%BB%E7%BB%9F%E5%88%9D%E6%8E%A2/","excerpt":"有一家公司给出了广告系统方向的offer，虽然最后没有选择，但还是了解了一下广告业务。","text":"有一家公司给出了广告系统方向的offer，虽然最后没有选择，但还是了解了一下广告业务。 引言 传统视角的广告给人的主观感觉是破坏体验，而现在如游戏联运、团购、返利等广告的新后向变现传播方式，给用户带来的体验是不差的。 互联网广告的关键不再是创意、策略等人工服务，而是以数据支撑的流量规模化交易为典型特点。 规模化的重点是让流量更加有效、高质量，构建更清晰的用户画像，精准掌握用户的个性化需求。 《计算广告》 《计算广告》主线： * 商业逻辑驱动的在线广告产品和技术的升级 * 数据的加工、利用与交易 传统媒体时代，供给方与需求方在市场地位上有相当的距离，不论你运营的是电视台、机场或杂志，都与大多数广告主需要的转化行为之间有相当大的差距。因此这一阶段广告的目的是希望借助媒体的力量来快速接触大量用户，以达到宣传品牌形象、提升中长期购买率与利润空间的目的。这种目的的广告被称为品牌广告（brand awareness)。当然，也有许多广告商 希望能利用广告手段马上带来大量的购买或其他 转化行为，这种目的的广告称为直接效果广告 （direct response），有时也简称为效果广告。 计算广告的核心问题，是为一系列用户与环境的组合找到最合适的广告投放策略以优化整体广告活动的利润。 竞价策略主要研究处于纳什均衡状态下的收益和其他特性。 关键技术 Lucene全文检索引擎 信息检索(Information Retrieval, IR) 倒排索引 向量空间模型 最优化(Optimization) \b 这方面这本书写的很详细，不过好细，还是实践的时候再细看吧。 Reference 《计算广告》 大型广告系统架构概述 一分钟读懂互联网广告竞价策略GFP+GSP+VCG 互联网广告中，品牌广告和效果广告如何对比分析？","categories":[{"name":"专业","slug":"pro","permalink":"https://sean10.github.io/categories/pro/"}],"tags":[{"name":"算法","slug":"算法","permalink":"https://sean10.github.io/tags/%E7%AE%97%E6%B3%95/"},{"name":"广告","slug":"广告","permalink":"https://sean10.github.io/tags/%E5%B9%BF%E5%91%8A/"}]},{"title":"Pycharm快捷键记录","slug":"Pycharm快捷键记录","date":"2018-03-24T15:11:40.000Z","updated":"2023-03-18T15:11:14.840Z","comments":true,"path":"2018/03/24/Pycharm快捷键记录/","link":"","permalink":"https://sean10.github.io/2018/03/24/Pycharm%E5%BF%AB%E6%8D%B7%E9%94%AE%E8%AE%B0%E5%BD%95/","excerpt":"Pycharm 键位图","text":"Pycharm 键位图 Command+B 函数跳转 Command+alt+left 返回上一页 Reference 麻瓜编程","categories":[{"name":"专业","slug":"pro","permalink":"https://sean10.github.io/categories/pro/"}],"tags":[{"name":"Pycharm","slug":"Pycharm","permalink":"https://sean10.github.io/tags/Pycharm/"},{"name":"快捷键","slug":"快捷键","permalink":"https://sean10.github.io/tags/%E5%BF%AB%E6%8D%B7%E9%94%AE/"}]},{"title":"virtualwrapper管理环境","slug":"virtualwrapper管理环境","date":"2018-03-23T14:12:05.000Z","updated":"2023-03-18T15:11:14.824Z","comments":true,"path":"2018/03/23/virtualwrapper管理环境/","link":"","permalink":"https://sean10.github.io/2018/03/23/virtualwrapper%E7%AE%A1%E7%90%86%E7%8E%AF%E5%A2%83/","excerpt":"","text":"在看工程源码时，要配置python2.7环境，这个时候发现一直用的virtualenvwrapper建立环境后就无法切换到2.7来安装环境了。 一开始找了好久，以为需要比如pyenv+virtualenv之类的多个工具才能管理python版本和环境。 结果找啊找发现，virtualenvwrapper就支持这个要求。 1mkvirtualenv --python python2.7 envname 不过在官方doc里倒是没能搜索到这个功能，只有mkvirtualenv --help才能看到这个功能…… 为什么把这里的help里的文字放到官方搜索里都搜不到………… 常用功能 12345mkvirtualenv test --python=python3lsvirtualenvworkon testdeactivatermvirtualenv test pycharm自带venv使用 Reference 使用virtualenv搭建独立的python环境","categories":[{"name":"专业","slug":"pro","permalink":"https://sean10.github.io/categories/pro/"}],"tags":[{"name":"python","slug":"python","permalink":"https://sean10.github.io/tags/python/"},{"name":"virtualenv","slug":"virtualenv","permalink":"https://sean10.github.io/tags/virtualenv/"}]},{"title":"kcp协议理解","slug":"kcp协议理解","date":"2018-03-23T06:24:38.000Z","updated":"2023-03-18T15:11:14.875Z","comments":true,"path":"2018/03/23/kcp协议理解/","link":"","permalink":"https://sean10.github.io/2018/03/23/kcp%E5%8D%8F%E8%AE%AE%E7%90%86%E8%A7%A3/","excerpt":"TCP Qos 问题 TCP的流量控制仅针对单条TCP连接，而在网络中UDP、ICMP等包并不遵循这个规则，TCP迫于流量控制，检测到端到端阻塞就会减小自己的窗口，然后被UDP等占据闲置出的带宽，导致饿死。 由于这个TCP在阻塞情况下迫于大环境无法保证传输质量，就有大批转而使用UDP协议加速的方式。","text":"TCP Qos 问题 TCP的流量控制仅针对单条TCP连接，而在网络中UDP、ICMP等包并不遵循这个规则，TCP迫于流量控制，检测到端到端阻塞就会减小自己的窗口，然后被UDP等占据闲置出的带宽，导致饿死。 由于这个TCP在阻塞情况下迫于大环境无法保证传输质量，就有大批转而使用UDP协议加速的方式。 UDP 加速 kcp的设计是为了解决在网络拥堵情况下tcp协议的网络速度慢的问题。(包括BBR等，还有很多)一般使用udp作为下层传输协议。 KCP对TCP的一些细节进行了改良[1] RTO翻倍VS不翻倍 全部重传VS选择性重传 快速重传 非延迟ACK VS 延迟ACK ACK+UNA VS UNA 非退让流控 KCP正常模式同TCP一样使用公平退让法则，即发送窗口大小由：发送缓存大小、接收 端剩余接收缓存大小、丢包退让及慢启动这四要素决定。但传送及时性要求很高的小 数据时，可选择通过配置跳过后两步，仅用前两项来控制发送频率。以牺牲部分公平 性及带宽利用率之代价，换取了开着BT都能流畅传输的效果。 RTT(round trip time) &amp;&amp; RTO(Retransmission timeout) RTT: 数据包往返时间 RTO: 超时重传时间 RTO重传间隔是指数增加的。丢包一次后，下一次重传RTO会从1，2，4，8……。叫做指数回避策略。(RTO下限200ms,写在协议里的，无法修改) 数据链路层ARQ与传输层ARQ区别 数据链路层的ARQ只能保证点到点之间传输的可靠性。 如A-B-C，数据链路层只能保证A-B不丢包，但是B会不会由于传输窗口满而丢弃包就无法保证，A-C之间传输的可靠就需要上层传输层协议来确认，这就叫做端到端的可靠性。 Reference kcp 详解 RTO 对TCP超时的影响 TCP RTO 计算方法及Go实现验证","categories":[{"name":"专业","slug":"pro","permalink":"https://sean10.github.io/categories/pro/"}],"tags":[{"name":"kcp","slug":"kcp","permalink":"https://sean10.github.io/tags/kcp/"},{"name":"tcp","slug":"tcp","permalink":"https://sean10.github.io/tags/tcp/"},{"name":"网络","slug":"网络","permalink":"https://sean10.github.io/tags/%E7%BD%91%E7%BB%9C/"}]},{"title":"travis CI 部署","slug":"travis-CI-部署","date":"2018-03-19T14:39:02.000Z","updated":"2023-03-18T15:11:14.906Z","comments":true,"path":"2018/03/19/travis-CI-部署/","link":"","permalink":"https://sean10.github.io/2018/03/19/travis-CI-%E9%83%A8%E7%BD%B2/","excerpt":"","text":"根据参考1部署了一下自动化travis， 然后自动化部署依旧报错，终于意识到了next主题无法正常运作的原因，是配置文件过时了的原因，没跟上next版本迭代的速度，所以其中有些配置信息的导入造成了错误。 重新修改之后，终于可以在travis CI正常运作了。 在更改为pandoc解析引擎时，忘记了hexo-renderer-pandoc是依赖于pandoc来执行的，按照[2]在travis.yml里添加了安装pandoc环境后就可以正常运行了。 参考: 用 Travis CI 自动部署 hexo segmentfault travis CI pandoc","categories":[{"name":"专业","slug":"pro","permalink":"https://sean10.github.io/categories/pro/"}],"tags":[{"name":"automate","slug":"automate","permalink":"https://sean10.github.io/tags/automate/"},{"name":"travis","slug":"travis","permalink":"https://sean10.github.io/tags/travis/"}]},{"title":"dockerfile学习","slug":"dockerfile学习","date":"2018-03-17T12:06:44.000Z","updated":"2023-03-18T15:11:14.891Z","comments":true,"path":"2018/03/17/dockerfile学习/","link":"","permalink":"https://sean10.github.io/2018/03/17/dockerfile%E5%AD%A6%E4%B9%A0/","excerpt":"现在装的环境有点多了，一不留神就会改动了其他工具使用的环境，这种环境下学下docker可以保障运行环境的一致性。","text":"现在装的环境有点多了，一不留神就会改动了其他工具使用的环境，这种环境下学下docker可以保障运行环境的一致性。 试着先给毕设用的环境写个dockerfile, 顺便提了个PR，希望能被合并吧。 在找错的过程中，看到好多人用docker run来后台执行命令，感觉好微妙，每次从镜像新建一个容器来执行命令，那旧的容器是继续保留吗？还是说生产环境的确就是这样做的。 可能因为我这算是学习环境，所以对Docker的变动都是在内部修改，并不完全是从dockerfile来的吧。 1docker build -t sean10:tensorflow . 在docker run时，最后的命令行参数是会和dockerfile中的RUN, CMD, ENTRYPOINT相关的。 RUN是在Build时运行的，先于CMD和ENTRYPOINT。Build完成了，RUN也运行完成后，再运行CMD或者ENTRYPOINT。 比如这个，最后的bash会覆盖CMD指定的命令 1docker run -p 7777:8888 -v /Users/sean10/Code/LSTM-Sentiment-Analysis:/LSTM-Sentiment-Analysis -it tensorflow/tensorflow:1.1.0-py3 bash todo docker如何使用相对路径的文件内? .dockerignore 在docker命令行界面中发送上下文到docker的守护进程之前，它会检查上下文目录根路径下名为.dockerignore的文件，如果这个文件存在，命令行界面会修改上下文，排除那些被.dockerignore中的模式匹配到的文件和目录。 docker stage 如何显示之前下载过的stage用的image ? 显示已下载的image的dockerfile systemd的docker内启动 docker run -tid --name test_1 --privileged=true centos:latest /usr/sbin/init docker exec -it test_1 /bin/bash 多重from image 精简Docker镜像的几个方法 - 那少年和狗 - 博客园 参考 Dockerfile里指定执行命令用ENTRYPOING和用CMD有何不同？ 跟我一起学Docker——RUN、ENTRYPOINT与CMD Docker容器怎样更改容器内应用程序的配置文件？","categories":[{"name":"专业","slug":"pro","permalink":"https://sean10.github.io/categories/pro/"}],"tags":[{"name":"Docker","slug":"Docker","permalink":"https://sean10.github.io/tags/Docker/"}]},{"title":"iTerm & zsh加载缓慢","slug":"iTerm-zsh加载缓慢","date":"2018-03-16T12:31:12.000Z","updated":"2023-03-18T15:11:14.831Z","comments":true,"path":"2018/03/16/iTerm-zsh加载缓慢/","link":"","permalink":"https://sean10.github.io/2018/03/16/iTerm-zsh%E5%8A%A0%E8%BD%BD%E7%BC%93%E6%85%A2/","excerpt":"","text":"最近iTerm每开一个tab都要等4、5秒的时间，按照ssd的加载速度来说这是本不应该发生的事情。 顶部栏是从python-&gt;ruby等等的变化，最后才到菜单栏。 猜想应该是导入的配置文件中导入了过多。 找了一下其他人遇到的问题，发现果然主要都是nvm造成的影响，把nvm的导入注释掉，就恢复到了1、2s加载速度。 不过，除此之外，iTerm默认是从系统的/usr/bin/login启动，启动时需要读取apple 系统日志(apple system log)，所以这里有两种解决方案。 清除日志 1sudo rm /private/var/log/asl/*.asl 更换启动shell 在Iterm Perferences&gt;Profile&gt;General&gt;Command 设置为/bin/zsh 参考资料 iTerm 2、Terminal 启动加速","categories":[{"name":"专业","slug":"pro","permalink":"https://sean10.github.io/categories/pro/"}],"tags":[{"name":"mac","slug":"mac","permalink":"https://sean10.github.io/tags/mac/"},{"name":"iTerm","slug":"iTerm","permalink":"https://sean10.github.io/tags/iTerm/"}]},{"title":"刘慈欣谈科幻","slug":"刘慈欣谈科幻","date":"2018-03-15T12:08:27.000Z","updated":"2023-03-18T15:11:14.884Z","comments":true,"path":"2018/03/15/刘慈欣谈科幻/","link":"","permalink":"https://sean10.github.io/2018/03/15/%E5%88%98%E6%85%88%E6%AC%A3%E8%B0%88%E7%A7%91%E5%B9%BB/","excerpt":"在这本书中，大刘对于科幻在国内的地位以及趋势的理解认识逐渐展现，让人又一次为他所折服。","text":"在这本书中，大刘对于科幻在国内的地位以及趋势的理解认识逐渐展现，让人又一次为他所折服。 悲观主义 外国科幻对国内科幻创作产生较强影响力的时期，处于中国科幻史的两端，是在清末民初和20世纪90年代至今这两个阶段。 在清末民初，世界科幻文学也还在起步阶段，依旧与文学相关，并未成立一个独立的体裁。导致国内对科学的技术幻想都只是为文学服务的。 自20世纪90年代中期至今，这一时期的科幻是一种文学型科幻，不再是阿西莫夫科普型科幻那样凸显科学和技术的地位，而是通过晦涩的象征展现幻想。 在这个时期，书中提到共有三种科幻。 科普型科幻 文学型科幻 赛博朋克科幻（这个倒是没看到过） 在20世纪90年代以前那段时间内，国内的科幻受西方悲观影响，对科学未来持一种悲观的态度，刘慈欣对于这点是觉得相当需要改变的，国内的科幻对科学的推崇尚且还没达到盛极转衰，就在文中不断对科学的前景唱衰，这对于大众读者的影响来说并不是一件好事。 大刘觉得，最美的科幻还是需要偏乐观主义一些。 再仔细看看共产主义的定义，请注意这定义中以前最不为我们注意的一句话：劳动是人们的第一需要。 天哪，这句话就反转我对共产主义的认识了。 科幻硬伤 哇，大刘居然也上过龙空(lkong.cn) 疏忽硬伤 知识硬伤 背景硬伤 灵魂硬伤","categories":[{"name":"随想","slug":"thinking","permalink":"https://sean10.github.io/categories/thinking/"}],"tags":[{"name":"科幻","slug":"科幻","permalink":"https://sean10.github.io/tags/%E7%A7%91%E5%B9%BB/"},{"name":"刘慈欣","slug":"刘慈欣","permalink":"https://sean10.github.io/tags/%E5%88%98%E6%85%88%E6%AC%A3/"},{"name":"评论","slug":"评论","permalink":"https://sean10.github.io/tags/%E8%AF%84%E8%AE%BA/"}]},{"title":"重读《失控》","slug":"重读《失控》","date":"2018-03-12T13:56:47.000Z","updated":"2023-03-18T15:11:14.904Z","comments":true,"path":"2018/03/12/重读《失控》/","link":"","permalink":"https://sean10.github.io/2018/03/12/%E9%87%8D%E8%AF%BB%E3%80%8A%E5%A4%B1%E6%8E%A7%E3%80%8B/","excerpt":"第一章 人造与天生 仿生学产物很有可能存在失控的可能性","text":"第一章 人造与天生 仿生学产物很有可能存在失控的可能性 第二章 蜂群思维 分布式的管理最后还是需要部分人的一致性来引导的吧？虽然会有一个大方向上的默认行为。 去年reddit的place游戏在最后脚本的协作中才实现稳定。 后文中提到，稀疏内存模拟的分布式记忆可以还原的能力，这点倒是有点难以理解了。 第三章 有心智的机器 机械自洽，这个也是蛮有意思的。如果过于不控制，机械之间无冲突就见不到美感了。","categories":[{"name":"随想","slug":"thinking","permalink":"https://sean10.github.io/categories/thinking/"}],"tags":[{"name":"技术","slug":"技术","permalink":"https://sean10.github.io/tags/%E6%8A%80%E6%9C%AF/"},{"name":"凯文","slug":"凯文","permalink":"https://sean10.github.io/tags/%E5%87%AF%E6%96%87/"},{"name":"失控","slug":"失控","permalink":"https://sean10.github.io/tags/%E5%A4%B1%E6%8E%A7/"}]},{"title":"读《韩松——宇宙墓碑》","slug":"读《韩松——宇宙墓碑》","date":"2018-03-11T07:15:53.000Z","updated":"2023-03-18T15:11:14.904Z","comments":true,"path":"2018/03/11/读《韩松——宇宙墓碑》/","link":"","permalink":"https://sean10.github.io/2018/03/11/%E8%AF%BB%E3%80%8A%E9%9F%A9%E6%9D%BE%E2%80%94%E2%80%94%E5%AE%87%E5%AE%99%E5%A2%93%E7%A2%91%E3%80%8B/","excerpt":"导读中说到，韩松主要风格是参考现实文学，要营造出一种反思的内涵。 总的来说这本上个世纪的作品集锦中，现在姑且只有宇宙墓碑和灿烂文化的背景设定还不错了。","text":"导读中说到，韩松主要风格是参考现实文学，要营造出一种反思的内涵。 总的来说这本上个世纪的作品集锦中，现在姑且只有宇宙墓碑和灿烂文化的背景设定还不错了。 宇宙墓碑 相比大刘的作品，这部作品读起来文字简洁，但却让人有些难以理解。 上篇中，是从现代的角度来叙述，讲述未来人从太空人的墓碑中莫名获得的迷恋感，甚至到了掘墓的程度。 下篇，造墓人的信中提出了太空女性带来的异常，以及宇宙也是个墓的想法。以及第三处曾经造过的墓的莫名消失。 下篇中的一个个线索的出现让人摸不着头绪。 灿烂文化 这篇文章从来自地球的业余考古者降落到大荒星来寻找灿烂文化开始，以大荒星时空场的变动结束，这些考古者成为灿烂文化的开拓者后又引领自己的飞船的降落，形成了一个莫比乌斯环. 没有答案的航程 飞船，一个孤立空间中，失去记忆的2人之间的人心的揣测，最终依旧没有确定的答案。 劫 又是一个时空场交错的故事，不过这次以外星人佛陀和特工诗人为主角。","categories":[{"name":"随想","slug":"thinking","permalink":"https://sean10.github.io/categories/thinking/"}],"tags":[{"name":"科幻","slug":"科幻","permalink":"https://sean10.github.io/tags/%E7%A7%91%E5%B9%BB/"},{"name":"韩松","slug":"韩松","permalink":"https://sean10.github.io/tags/%E9%9F%A9%E6%9D%BE/"}]},{"title":"豆瓣爬虫细节","slug":"豆瓣爬虫细节","date":"2018-03-09T12:54:27.000Z","updated":"2023-03-18T15:11:14.894Z","comments":true,"path":"2018/03/09/豆瓣爬虫细节/","link":"","permalink":"https://sean10.github.io/2018/03/09/%E8%B1%86%E7%93%A3%E7%88%AC%E8%99%AB%E7%BB%86%E8%8A%82/","excerpt":"","text":"1https://movie.douban.com/j/new_search_subjects?sort=T&amp;range=0,10&amp;tags=%E5%89%A7%E6%83%85&amp;start=10 像这种json获取的链接，倒是没有cookie的要求，即便多线程爬取几百页也没有被ban. 之前直接使用了rq任务队列，导致不知道该怎么写多线程了。 暂时先重新用自带的queue写写看多线程。 目前20个线程爬取10页约200个评论，耗时8.98秒,不过这里固定一个ip测试立马就被ban了。 只是添加了bid的cookie 和 随机UA似乎并不足够. 稍稍追加了一下header,然后用多进程跑起来了……真的伤心，用的其他的再复杂的框架反而失败了，协程也遭遇各式各样的难题，暂时还是用多进程拿下数据吧。 明明使用了可用的代理，但是被ban的却还有我的真实ip，经过测试，和代码无关，是代理问题。透明代理相比高匿代理是否会导致真实ip被ban还没有测试过。 在aiohttp中试图使用https代理时，才意识到https代理像贡献者说的那样没有必要，在V站讨论中，可以看到HTTPS代理仅仅是起到在客户端到代理端之间进行SSL认证的功能，与访问https还是http网站完全没有关系。 在没有用redis持久化时，想到 布隆过滤器似乎也需要持久化，查了一些，似乎基于redis或者pickle序列化持久化都是可选的，但是在找官方文档的时候看到这么一句。 Since this package natively uses mmap files, no serialization is needed. Therefore, if you have to do a lot of moving between disks etc, this module is an obvious win. mmap是什么文件 在用charles测试抓包的过程中遭遇了SSLError(SSLError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:777)'),))问题,似乎与python requests对charles ssl认证有关。 从charles保存根证书导入python requests即可。 参考资料 (requests charles SSL)[https://www.charlesproxy.com/documentation/using-charles/ssl-certificates/] Python requests请求https遇到问题 HTTP代理和HTTPS代理的区别 通过一台 HTTPS proxy 上网，这台 proxy 能获得我访问的网址吗?","categories":[{"name":"专业","slug":"pro","permalink":"https://sean10.github.io/categories/pro/"}],"tags":[{"name":"Python","slug":"Python","permalink":"https://sean10.github.io/tags/Python/"},{"name":"爬虫","slug":"爬虫","permalink":"https://sean10.github.io/tags/%E7%88%AC%E8%99%AB/"},{"name":"Spider","slug":"Spider","permalink":"https://sean10.github.io/tags/Spider/"}]},{"title":"《最好的告别》note","slug":"《最好的告别》note","date":"2018-03-08T14:00:39.000Z","updated":"2023-03-18T15:11:14.854Z","comments":true,"path":"2018/03/08/《最好的告别》note/","link":"","permalink":"https://sean10.github.io/2018/03/08/%E3%80%8A%E6%9C%80%E5%A5%BD%E7%9A%84%E5%91%8A%E5%88%AB%E3%80%8Bnote/","excerpt":"这本其实是豆瓣送礼券了，看着比较顺眼找的一本。 这本书整体还是以故事性更多，对于不了解这些思想的人可能有收获，对于已知的人就有些鸡肋了。 自序中，作者说他对一位彻底无救的病患实施了安乐死。这位患者进行了医生所知道的技术上的手术，虽然无法满足他康复的需求，结果在成功的手术后痛苦而去。 作者对病患接受无效手术的这个选择觉得有些不太恰当。这位作者的观点我还是很赞同的，不过不知道书中内容还会有哪些突破。","text":"这本其实是豆瓣送礼券了，看着比较顺眼找的一本。 这本书整体还是以故事性更多，对于不了解这些思想的人可能有收获，对于已知的人就有些鸡肋了。 自序中，作者说他对一位彻底无救的病患实施了安乐死。这位患者进行了医生所知道的技术上的手术，虽然无法满足他康复的需求，结果在成功的手术后痛苦而去。 作者对病患接受无效手术的这个选择觉得有些不太恰当。这位作者的观点我还是很赞同的，不过不知道书中内容还会有哪些突破。 在这篇序言的最后，作者提到下文: 其实，恰恰是因为我们的文化拒绝接受生命周期的限定性，以及衰老与死亡的不可避免性，我们的末期病人和老人才会成为无效治疗和精神照顾缺失的牺牲品。 这里指的是美国的文化吗？中国似乎并不存在生命周期的限定性这点。 01 独立 美国文化中，似乎老人即便不满足一些独立生活的指标，但还是会独立生活，而不是被送去疗养院（虽然疗养院才是更符合实际的做法）。 现代化并没有降低老年人的地位，而只是降低了家庭的地位。 这句话倒是表达的相当直接，老年人在家庭中的话语权随着现代化带来的选择多样化而逐渐变得不那么重要了。 这里提到一个退休社区，似乎国外还是形成了一个比较大的规模的。 对于老年痴呆，这里说到医生没有办法让老人恢复独立生活的能力，只有让家人或疗养院几个选择。据了解，这也的确是现实。 02 崩溃 老了以后，身体就像机器一样持续磨损直到一下子崩溃，如果每个细节都能持续关注维护，还是很有效果的。 03 依赖 在疗养区，因为护理人员的不理解，只是被当做病人而不是一个正常人对待，精神上并不能得到痛快。但家人也往往还没有进入老年生活，往往没有足够的时间来照料，需要花费高额工资可能也不一定能雇到能令人放心的护工。 50多年前，社会学家欧文 戈夫曼在他的著作《收容所》(Asylums)里写到监狱和疗养院之间的相同之处。疗养院和军事训练营、孤儿院及精神病院一样，是“纯粹的机构”——在很大程度上是跟社会隔绝的地方。 而绝大多数人还是需要一个隔离的空间了，老了而在这种集体空间内还是令人非常恐惧的。 04 帮助 这篇中的威尔逊提出了一个辅助生活中心、独立公寓，将机构的权力所属归还了老人们，护理人员们会意识到所有所有权归属在于老人，老人不愿意的事情便不去处理。 这个单看他给出的结果是很棒的，不过还是有很多借用这个名词却依旧只提供集中床铺的疗养院。 05 更好的生活 杰奎依 卡尔森 山伯恩之地，另一种辅助生活机构，为居民考虑更多，只需要为老人收拾他们带来的副结果。 06 放手 保险公司会提供善终服务 临终时，需要从医生那里得到的不是病人想要什么，而是需要通过谈话接受个人的必死性、清楚了解医学的局限性和可能性，这是个过程，而不是顿悟 花钱决定化疗之前，更有必要花钱与医生讨论做与不做哪个选择更明智。 07 艰难的谈话 08 勇气","categories":[{"name":"随想","slug":"thinking","permalink":"https://sean10.github.io/categories/thinking/"}],"tags":[{"name":"死亡","slug":"死亡","permalink":"https://sean10.github.io/tags/%E6%AD%BB%E4%BA%A1/"},{"name":"衰老","slug":"衰老","permalink":"https://sean10.github.io/tags/%E8%A1%B0%E8%80%81/"}]},{"title":"公众号开发笔记","slug":"公众号开发笔记","date":"2018-03-06T07:49:46.000Z","updated":"2023-03-18T15:11:14.863Z","comments":true,"path":"2018/03/06/公众号开发笔记/","link":"","permalink":"https://sean10.github.io/2018/03/06/%E5%85%AC%E4%BC%97%E5%8F%B7%E5%BC%80%E5%8F%91%E7%AC%94%E8%AE%B0/","excerpt":"试着用微信公众号来做一些bot的任务，这里稍稍记些笔记吧。","text":"试着用微信公众号来做一些bot的任务，这里稍稍记些笔记吧。 首先，id/secret/token设置需要记录下。测试接口似乎可以使用ngrok这样工具。 未认证的订阅号的被动回复权限理论上是满足我的需求了的。 遇到问题: 在用搬瓦工服务器处理消息时，似乎那边收不到我的消息，但是认证token那个收发包过程还是通过了的，暂时怀疑是服务器端口冲突了。但是iptables并没有查到冲突问题，用nginx映射时倒是才提示端口已占用。 在centos6安装python时，出现了 ModuleNotFoundError: No module named '_sqlite3',在SF，似乎是python3.6移除了3.5中的_sqlite3.so，不过按照最高票的cp python2的module过去再altinstall会引发新的ImportError: dynamic module does not define module export function (PyInit__sqlite3) 最后，只是configure时(添加个动态库选项)[http://blog.csdn.net/jaket5219999/article/details/53512071]就可以了。 12./configure --enable-loadable-sqlite-extensionsmake &amp;&amp; make install 参考资料: https://stackoverflow.com/questions/1210664/no-module-named-sqlite3 https://stackoverflow.com/questions/16018463/difference-in-details-between-make-install-and-make-altinstall http://blog.csdn.net/jaket5219999/article/details/53512071","categories":[{"name":"专业","slug":"pro","permalink":"https://sean10.github.io/categories/pro/"}],"tags":[{"name":"微信","slug":"微信","permalink":"https://sean10.github.io/tags/%E5%BE%AE%E4%BF%A1/"}]},{"title":"锯齿数独_推理数独 解法","slug":"锯齿数独-推理数独-理解","date":"2018-02-26T13:25:45.000Z","updated":"2018-02-26T17:25:45.000Z","comments":true,"path":"2018/02/26/锯齿数独-推理数独-理解/","link":"","permalink":"https://sean10.github.io/2018/02/26/%E9%94%AF%E9%BD%BF%E6%95%B0%E7%8B%AC-%E6%8E%A8%E7%90%86%E6%95%B0%E7%8B%AC-%E7%90%86%E8%A7%A3/","excerpt":"推理数独： 将1～9填入空格内，使格内数字满足右侧对应关系：每个圆圈连接的其它数字的和等于右侧对应关系中圆圈内的数字对应的数字。 如右侧为1：30则表示数字1对应线连接的格子中数字的和为30. Neighbourhood:Enter numbers from 1 to 9 once each, into the nine circles. For each number, the sum of all numbers connected to it is given.","text":"推理数独： 将1～9填入空格内，使格内数字满足右侧对应关系：每个圆圈连接的其它数字的和等于右侧对应关系中圆圈内的数字对应的数字。 如右侧为1：30则表示数字1对应线连接的格子中数字的和为30. Neighbourhood:Enter numbers from 1 to 9 once each, into the nine circles. For each number, the sum of all numbers connected to it is given. Example: 这个问题乍一眼看上去很眼熟，第一感觉可以用拓扑排序来解决。实际上目前也的确用拓扑排序成功解决了几道题。 首先观察这个图的特征，假定所有都是出路，可以观察到 2出路: 4个 3出路: 4个 4出路: 1个 将4出路标记为1，按逆时针递增标记 算法大致是下面这样，只是脑海里按照下面这个思路迭代了几次就能实验出结果了。 12340. 将图中数字降序排列1. for 取最大数置于4出路处（即1号位）2. \b for 取最小数，置于与4出路直连的2个2出路处（即2与7号位）3. 迭代求解 答案: 独 数之道的这类题是直接生成了图片再发到浏览器的，看来不能直接读包然后发回结果了。需要进行一下识图了。 参考资料 独 数之道 锯齿数独-&gt;推理数独(需注册登录才能访问)","categories":[{"name":"算法","slug":"algorithm","permalink":"https://sean10.github.io/categories/algorithm/"}],"tags":[{"name":"数独","slug":"数独","permalink":"https://sean10.github.io/tags/%E6%95%B0%E7%8B%AC/"},{"name":"sudoku","slug":"sudoku","permalink":"https://sean10.github.io/tags/sudoku/"}]},{"title":"数独note","slug":"数独note","date":"2018-02-24T11:40:46.000Z","updated":"2018-02-27T09:00:00.000Z","comments":true,"path":"2018/02/24/数独note/","link":"","permalink":"https://sean10.github.io/2018/02/24/%E6%95%B0%E7%8B%ACnote/","excerpt":"unique rectangle type 1~4没什么疑问，不过hidden unique rectangle 的删除有些疑惑，如何确定哪个是候选数a，哪个是候选数b的呢","text":"unique rectangle type 1~4没什么疑问，不过hidden unique rectangle 的删除有些疑惑，如何确定哪个是候选数a，哪个是候选数b的呢 有些技巧似乎国内的那个论坛上也并没有提到，国外那位大神总结的真是全。 Generalising X-Wing X-Wing is not restricted to rows and columns. We can also extend the idea to boxes as well. If we generalise the rule above we get: When there are * only 2 candidates for a value, in each of 2 different units of the same kind, * and these candidates lie also on 2 other units of the same kind, then all other candidates for that value can be eliminated from the latter two units. Now we have 6 combinations: Starting from 2 rows and eliminating in 2 columns -&gt; Classic X-Wing Starting from 2 columns and eliminating in 2 rows -&gt; Classic X-Wing Starting from 2 boxes and eliminating in 2 rows -&gt; Same effect as line/box reduction Starting from 2 boxes and eliminating in 2 columns -&gt; Same effect as line/box reduction Starting from 2 rows and eliminating in 2 boxes -&gt; Same effect as pointing pairs Starting from 2 columns and eliminating in 2 boxes -&gt; Same effect as pointing pairs 参考资料： SudokuWiki","categories":[{"name":"专业","slug":"pro","permalink":"https://sean10.github.io/categories/pro/"}],"tags":[{"name":"数独","slug":"数独","permalink":"https://sean10.github.io/tags/%E6%95%B0%E7%8B%AC/"}]},{"title":"Docker TensorFlow运行笔记","slug":"TensorFlow运行笔记","date":"2018-02-24T05:24:58.000Z","updated":"2018-03-01T17:00:00.000Z","comments":true,"path":"2018/02/24/TensorFlow运行笔记/","link":"","permalink":"https://sean10.github.io/2018/02/24/TensorFlow%E8%BF%90%E8%A1%8C%E7%AC%94%E8%AE%B0/","excerpt":"为了防止环境问题，所以使用了docker配置的TensorFlow环境，","text":"为了防止环境问题，所以使用了docker配置的TensorFlow环境， 为了防止万一被收录，论文查重问题，这篇之前一直没发布。 部署 12345docker pull tensorflow/tensorflowdocker run -it tensorflow/tensorflow bash发现这个仓库只能在1.1版本下跑，重新下载了个docker pull tensorflow/tensorflow:1.1.0-py3 Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA 一开始在使用tf.Session()时就报了这个错误。暂时没理会。 但是对docker 不那么熟悉，不知道代码和数据应该存在哪个位置，在那还是决定代码通过volume挂载到docker内。 1234567891011121314151617docker run -p 7777:8888 --name=tensorflow_sean10 -v /Users/sean10/Code/LSTM-Sentiment-Analysis:/LSTM-Sentiment-Analysis -it tensorflow/tensorflow bash这个版本tensorflow支持python3docker run -p 7777:8888 --name=tensorflow_sean10_py3 -v /Users/sean10/Code/LSTM-Sentiment-Analysis:/LSTM-Sentiment-Analysis -it tensorflow/tensorflow:latest-py3 bashdocker ps -a -ldocker rm $container_iddocker rmi $image_iddocker stop tensorflow_sean10_1.1.0_py3docker start -i tensorflow_sean10_1.1.0_py3docker attach tensorflow_sean10_1.1.0_py3docker exec -t -i tensorflow_sean10_1.1.0_py3 bashdocker run -p 7777:8888 -v /Users/sean10/Code/LSTM-Sentiment-Analysis:/LSTM-Sentiment-Analysis -it tensorflow/tensorflow:1.1.0-py3 bash 对运行中的docker进行网络映射 1234docker port tensorflow_sean10_1.1.0_py3docker inspect tensorflow_sean10_1.1.0_py3 | grep IPAddresspfctl 然后又接触到了jupyter,才逐渐明白这个做的不是ide的任务，有更多其他有意思的功能。 12345jupyter notebook --no-browser --ip=0.0.0.0 --allow-root想要再次获取docker exec -it &lt;docker_container_name&gt;jupyter notebook list 然后在主机浏览器内访问http://localhost:7777?token=xxxxxf 然后运行代码时，显示已经使用了python3的内核，但实际运行弹出的错误来源始终是python2.7，查到的说是默认的tensorflow image只有python2.7安装了tensorflow包，需要pull python3-latest版本才行。的确更换后就可以了…… jupyter默认没有配置自动wrap, 创建~/.jupyter/nbconfig/notebook.json配置文件，追加这一段 12345678910111213&#123; &quot;MarkdownCell&quot;: &#123; &quot;cm_config&quot;: &#123; &quot;lineWrapping&quot;: true &#125; &#125;, &quot;CodeCell&quot;: &#123; &quot;cm_config&quot;: &#123; &quot;lineWrapping&quot;: true &#125; &#125;&#125; No module named ipykernel jupyter install 后 无法找到ipykernel_launcher 解决方法： 12pip3 install pykernelpython -m ipykernel install --user Tensorflow错误记录 输入维度错误 ValueError: Input 0 of layer basic_lstm_cell_1 is incompatible with the layer: expected ndim=2, found ndim=1. Full shape received: [400] 输入数据占位符的维度错误了 basicRNNCell ValueError: Shape must be rank 2 but is rank 1 for 'MatMul' (op: 'MatMul') with input shapes: [64], [64,32]. 将BasicLSTMCell更换成BasicRNNCell时，始终出现错误。唉，在占位符embiding时没注意到传错数了，导致很久都没debug出来…… dynamic_rnn Dynamic_Rnn与Static_rnn主要区别在于输入数据的结构上。 static_rnn 输入的list的大小[序列长度,batch_size,embed大小]，所以一一般在经过embed层后，使用x = tf.unstack(embed, seq_len, 1)变换为[序列长度,batch_size,embed大小]，然后输入到static_rnn，输出也是list，大小形状为[seq_len,batch_size,hidden_size],所以我们取最后一个的输出就直接为static_rnn_out[-1],但是我们的dynamic_rnn不是这样，它的输入是[batch,seq_len,input],所以一般经过embeding层后不需要变化直接输入dynamic_rnn里面，然后输出结果为dynamic_rnn_out，他的shape为[batch,seq_len,hidden_size] ,这样我们要取到最后一个的输出，需要多维度进行一个转化：tf.transpose(dynamic_rnn_out, [1, 0, 2])，然后才可以去计算loss和accuracy等。[5] tensorflow 的dynamic_rnn方法，我们用一个小例子来说明其用法，假设你的RNN的输入input是[2,20,128]，其中2是batch_size,20是文本最大长度，128是embedding_size，可以看出，有两个example，我们假设第二个文本长度只有13，剩下的7个是使用0-padding方法填充的。dynamic返回的是两个参数：outputs,last_states，其中outputs是[2,20,128]，也就是每一个迭代隐状态的输出,last_states是由(c,h)组成的tuple，均为[batch,128]。 到这里并没有什么不同，但是dynamic有个参数：sequence_length，这个参数用来指定每个example的长度，比如上面的例子中，我们令 sequence_length为[20,13]，表示第一个example有效长度为20，第二个example有效长度为13，当我们传入这个参数的时候，对于第二个example，TensorFlow对于13以后的padding就不计算了，其last_states将重复第13步的last_states直至第20步，而outputs中超过13步的结果将会被置零。[6] 如果由于batch一次读入过大，可以使用API中的eval_in_batches(https://github.com/petewarden/tensorflow_makefile/blob/master/tensorflow/models/image/mnist/convolutional.py#L255) graph的权值偏置值复用[7] 如果不复用，训练的和测试的图就一点关系都没有了，就很有可能导致下面的那样输出结果完全无关 1tf.get_variable_scope().reuse_variables() lstm 准确率过低 输出的训练集上的loss还算正常，但是acc连50%都没有 根据知乎大神所说，二分类问题50%的准确率就等同于没有学习到，没有进行优化。 12345678910111213141516171819202122lSTMloss:5.716831 batch_Acc: 0.5 acc:0.525loss:0.16445649 batch_Acc: 0.9583333 acc:0.2225loss:0.21239458 batch_Acc: 0.9583333 acc:0.2075loss:0.07486567 batch_Acc: 1.0 acc:0.23loss:0.015121219 batch_Acc: 1.0 acc:0.275loss:0.10024478 batch_Acc: 0.9583333 acc:0.2475loss:0.056348186 batch_Acc: 0.9583333 acc:0.25loss:0.018785348 batch_Acc: 1.0 acc:0.255loss:0.017489845 batch_Acc: 1.0 acc:0.255loss:0.0008791888 batch_Acc: 1.0 acc:0.275loss:0.0012423135 batch_Acc: 1.0 acc:0.27loss:0.010488756 batch_Acc: 1.0 acc:0.2525loss:0.008405162 batch_Acc: 1.0 acc:0.245loss:0.0038538638 batch_Acc: 1.0 acc:0.2125loss:0.00075430545 batch_Acc: 1.0 acc:0.2375loss:0.0011128571 batch_Acc: 1.0 acc:0.2275loss:0.014299699 batch_Acc: 1.0 acc:0.325loss:0.00064932863 batch_Acc: 1.0 acc:0.3775loss:0.0039427895 batch_Acc: 1.0 acc:0.425loss:0.0043920926 batch_Acc: 1.0 acc:0.4025loss:0.0037787214 batch_Acc: 1.0 acc:0.41 1234567891011121314151617181920212223传统RNNloss:4.7681885 acc:0.51loss:1.3538479 acc:0.48loss:1.7510027 acc:0.4825loss:1.2965189 acc:0.5175loss:0.8639291 acc:0.4725loss:0.7651406 acc:0.48loss:0.5035551 acc:0.4725loss:0.7856639 acc:0.5125loss:0.41615644 acc:0.535loss:0.63352686 acc:0.515loss:0.8058832 acc:0.5125loss:0.715534 acc:0.5225loss:0.58976775 acc:0.49loss:0.6922045 acc:0.4875loss:0.6963689 acc:0.5225loss:0.6474119 acc:0.48loss:0.6436865 acc:0.4725loss:0.79238504 acc:0.4925loss:0.63156253 acc:0.535loss:0.6858673 acc:0.51loss:0.65090233 acc:0.52answer 模型暂时和原本的初版差别不大，训练集也还是原本的随机出的，测试集顺序理论上应该没有影响才对 就是上面那个weight和bias复用的问题……我定义在def model里了，导致reuse根本没有可以存下来 tf.truncated_normal() 这个函数产生正太分布，均值和标准差自己设定。这是一个截断的产生正太分布的函数，就是说产生正太分布的值如果与均值的差值大于两倍的标准差，那就重新生成。 bi-lstm实现 参考了[8][9][重点10] weight初始化导致无法梯度下降 使用Xavier initialization[11] basicRNNCell使用上需要在LSTMCell基础上修改一些地方 参考[13]的代码修改的，原来在rnncell的时候就直接取当前state计算就可以ile 使用MultiRNNCell的时候 InvalidArgumentError: Dimensions must be equal, but are 128 and 464 for 'rnn/while/rnn/multi_rnn_cell/cell_0/basic_rnn_cell/MatMul_1' (op: 'MatMul') with input shapes: [24,128], [464,64]. 要用python迭代器生成list，而不能直接用乘法，并且需要从函数来获取多个cell,不能直接对一个cell进行迭代 tf.metric.recall使用前需要initilizer 1sess.run(tf.local_variables_initializer()) 使用完 发现 这个值依旧是不能用的，因为这个统计的是整个session周期内的 梯度消失和梯度爆炸，如何从指标上判断出来 梯度消失似乎主要指的是多层效果反而没有浅层的好 关于recall,f1等指标计算 按照[16]条执行，成功跑出来了。 使用IndRNN 报错，似乎和while_loop有关 ValueError: Cannot use 'rnn/while/rnn/multi_rnn_cell/cell_0/ind_rnn_cell/Mul_1' as input to 'rnn/while/rnn/multi_rnn_cell/cell_0/ind_rnn_cell/clip_by_value' because they are in different while loops. See info log for more details. 看了下源码，出现了clip_by_value位置的只有设置了recurrent_abs_max的时候，所以把这个参数先取消看看，成功跑起来了~hhh 性能和普通的lstm差不多，之后再和官方的lstmcell比较一下源码，看看怎么改能够跑起来 发现问题，由于最初对tensorflow认识不足，导致训练集和测试集虽然复用了weight和bias，但是实际是运行在不同的网络中的，而IndRNN可能由于没能针对Tensorflow处理好这些问题，因此无法应用。在修改后的代码中，复用同一个网络后，这个参数添加后就没有报错了。 参考资料 本地访问远程服务器的Docker容器的Jupyter Notebook 关于Docker目录挂载的总结 wrap jupyter config No module named ipykernel tensorflow中dynamic_rnn与static_rnn区别 tensorflow高阶教程:tf.dynamic_rnn # Reference Tensorflow 变量的共享 tensorflow bilstm官方示例 TensorFlow实战12：Bidirectional LSTM Classifier tensorflow学习笔记(三十九) : 双向rnn (BiRNN) 谷歌工程师：聊一聊深度学习的weight initialization ensorFlow教程：利用TensorFlow处理自己的数据 RNN入门：利用TF的API（二） A bug in tensorflow r1.4 when applying MultiRNNCell Add precision and recall summaries tensorflow中precision,recall和F1","categories":[{"name":"专业","slug":"pro","permalink":"https://sean10.github.io/categories/pro/"}],"tags":[{"name":"TensorFlow","slug":"TensorFlow","permalink":"https://sean10.github.io/tags/TensorFlow/"},{"name":"docker","slug":"docker","permalink":"https://sean10.github.io/tags/docker/"}]},{"title":"update hexo node9 and theme next","slug":"update-hexo-node-and-next","date":"2018-02-16T18:14:16.000Z","updated":"2018-02-24T08:00:00.000Z","comments":true,"path":"2018/02/17/update-hexo-node-and-next/","link":"","permalink":"https://sean10.github.io/2018/02/17/update-hexo-node-and-next/","excerpt":"之前没有用nvm管理node版本，导致node升级到9.5以后，hexo里的依赖都不能正常运作了，单独一个个升级依赖没能成功解决bug.","text":"之前没有用nvm管理node版本，导致node升级到9.5以后，hexo里的依赖都不能正常运作了，单独一个个升级依赖没能成功解决bug. 在hexo里已经支持了update时间，在模板里添加updated即可，在next 主题配置里，修改post_meta为true即可 参考 front-matter 1234Error: write EPIPEat _errnoException (util.js)at WriteWrap.afterWrite [as oncomplete] (net.js) 遇到这个错误，重装好久，也没解决，在#2913里找到，更新了hexo-renderer-pandoc就no error了。 中途，在一个个卸载plugin判断错误来源，发现卸载了hexo-renderer-stylus之后，就无法生成css样式了。 遭遇白屏问题，似乎字号颜色渲染问题？只有下方的copyright可见，内容虽然可以点击，但是不可见，全选也看不到文字颜色反转（所以其实也不算字体颜色问题？） 似乎这是一个next久远的bug. 在network看到是fancybox.js的加载404，在console里看到的是config is not defined, next is not defined，导致后续无法识别. 根据这条issue关闭了motion就可以正常显示了。 No layout问题。 为了升级next，发现_config.yml是一个非常影响的文件，官方说hexo3支持了data file功能，可以将站点和主题config都放到到_data/next.yml中，在翻译的文档中都没有提到一点，原始的站点配置不能删除 Then, in main site's hexo/_config.yml need to define theme: next option (and if needed, source_dir: source). 来源 弄了好久……，恢复站点配置文件之后，data-file就生效了 关于pandoc解析mathjax，目前还是存在错误，view状态也存在错误 需要在每篇需要的md Frontter开启mathjax: true 首页不显示最新的，以及分类页面缓存了之前的错误","categories":[{"name":"专业","slug":"pro","permalink":"https://sean10.github.io/categories/pro/"}],"tags":[{"name":"hexo","slug":"hexo","permalink":"https://sean10.github.io/tags/hexo/"},{"name":"node","slug":"node","permalink":"https://sean10.github.io/tags/node/"}]},{"title":"《深度探索C++对象模型》Note","slug":"《深度探索C++对象模型》","date":"2018-02-08T06:00:07.000Z","updated":"2023-03-18T15:11:14.905Z","comments":true,"path":"2018/02/08/《深度探索C++对象模型》/","link":"","permalink":"https://sean10.github.io/2018/02/08/%E3%80%8A%E6%B7%B1%E5%BA%A6%E6%8E%A2%E7%B4%A2C++%E5%AF%B9%E8%B1%A1%E6%A8%A1%E5%9E%8B%E3%80%8B/","excerpt":"static initialization保证了在main函数执行以前已经实例化类。 不过实际依赖于开发环境。","text":"static initialization保证了在main函数执行以前已经实例化类。 不过实际依赖于开发环境。 译者推荐阅读一、三、四章 似乎&lt;&lt;不推荐作为类的成员函数，会由于左操作数是该实例而导致ostream只能是第二个参数，不过这本书中屡屡都是作为成员函数使用的，而且依旧是正常使用，这个疑问保留。（或许inline具有使其为非成员函数的功能？） 1234Sales_item item;item &lt;&lt; cout;似乎会变成这样，但是书里还是正常的。 泛型 就是 参数化吗？ 不定长参数如何参数化？书上那个看不太懂 简单对象模型 members 不放在object中的意思是什么？不是member本就是实例化后存储在其他位置，内部成员函数才在编译后就被分配了一个空间吗 噢噢，一开始被分配的空间只是一个指向成员的指针空间，实际成员空间在外面分配 表格驱动对象模型 数据成员表，成员函数表 对象内存储指向这两个表的指针 c++对象模型 非静态数据成员存储在对象中，静态存储在堆区。 主要优点是空间和时间存取的速度，不过实际上性能优点如何知晓？只是通过指针来访问，效率的影响有多少呢？ 似乎上面那个表格驱动模型，因只存储了指针地址，所以修改了成员函数代码时，无需重新编译其他的应用程序代码，不过付出了时间和效率上的代价 虚继承有些忘记了 编译器会在派生类B的实例中保存一个A的实例，然后在B中加入一个变量，这个变量是A的实例在实际B实例中的偏移量，实际上B中并不直接保存offset的值，而是保存的一个指针，这个指针指向一个表vbtable，vbtable表中保存着所有虚继承的基类在实例中的offset值，多个B的实例共享这个表，每个实例有个单独的指针指向这个表，这样就很好理解为什么多了4个字节了。用代码表示就像下面这样。 这个offset的作用是什么不太理解，有个指针地址不就已经能访问这个对象了吗？ 向前预览(lookahead)？ 编译器应该是能够做到经过unparser工具处理后，可以还原原本使用的关键词的。（来自cfront 中遭遇过的bug) 123struct mumble &#123; char pc[1];&#125; 这种通过malloc来分配的可变数组为什么违背了c++的规范呢，成为c++的陷阱？ \b指定多个access section，内含数据 这是什么意思? 就是访问权限区域。 private和public 在内存布局中的位置并不一定始终维持一个前后关系。 通过malloc来维持可变长数组的struct在转化为class时不可知属于哪个access section，容易出现问题 要组合C和C++，比较适合使用组合的方法，继承在当前的编译器中才存在被添加一些额外的Data members的可能性。 C++分为3个程序模型 * procedural model(过程型) * abstract data type model(抽象数据类型) * object-oriented model(面向对象模型) 只有通过pointer或reference的间接处理，才支持OO程序设计所需的多态性质。 cast 其实是一种编译器指令，大部分情况下它并不改变一个指针所含的真正地址，它只影响“被指出之内存的大小和其内容”的解释方式 一个pointer或一个reference之所以支持多态，是因为它们并不引发内存中任何”与类型有关的内存委托操作(type-dependent commitment)， 会受到改变的只是它们所指向的内存的“大小和内容解释方式”而已 构造函数语意学 Conversion运算符的引入 如果没有implicit conversion的支持, String函数库必须将每一个拥有字符串参数的C runtime library函数都复制一份。 有趣的是，标准的C++ library string class并不提供一个implicit conversion运算子, 它提供的是一个具体实名(named instance),使用者必须明确调用。 上面这个具体实名是什么情况呢？好像没见过的样子。 Schwarz Error memberwise initialization named return value optimization(NRV)身上 带有default constructor 的member class object inline是什么设计 未完待续","categories":[{"name":"专业","slug":"pro","permalink":"https://sean10.github.io/categories/pro/"}],"tags":[{"name":"C++","slug":"C","permalink":"https://sean10.github.io/tags/C/"}]},{"title":"pdf解密脚本","slug":"pdf解密脚本","date":"2018-01-11T02:36:16.000Z","updated":"2023-03-18T15:11:14.834Z","comments":true,"path":"2018/01/11/pdf解密脚本/","link":"","permalink":"https://sean10.github.io/2018/01/11/pdf%E8%A7%A3%E5%AF%86%E8%84%9A%E6%9C%AC/","excerpt":"这两天要打印pdf,结果发现老师的pdf被加密了，需要解密一下，就心血来潮想解决一下。","text":"这两天要打印pdf,结果发现老师的pdf被加密了，需要解密一下，就心血来潮想解决一下。 一开始想到的方法是，pdf可以通过浏览器打开，那么其实也就完全可以通过浏览器截图，自动下拉继续截图生成新的pdf，这算是一种解决方法嘛。似乎是可以通过浏览器打印保存pdf也能实现解密，不过莫名的pdf expert直接就能编辑被加密过的pdf。所以没想到怎么判断是否被加密。 总之，回来之后发现用linux下的ghostscript工具，可以先通过pdf2ps2pdf转换一下，转换回来之后就是无加密状态的pdf了。 但是看了看，需要转换十来个，每个需要转换的时间还挺长的，索性就看看能不能从python调用程序吧。 就有了这样一个版本的代码(github repo)[https://github.com/Sean10/Algorithm_code/tree/master/script/pdf_decrypt]。 python有2个模块可以做到调用外部程序需求，os.popen与基于前者之后升级后的subprocess.popen。 单线程执行虽然基本可以完成需求，但是多线程应该能快一些吧，如果这个模块是fork出一个子进程调用其他进行操作的话，而不是在python内部执行的话（GIL锁）。 现在每个语言基本都有了concurrent模块，对multithread和multiprocess进行了新的封装实现。 基本使用还是比较简单的，pool = subprocess.threadPoolExecutor 之后将函数添加进入就可以执行了,pool.submit(func,para)，就能实现出基本的调用操作。 不过，还遇到了一些问题，如，使用call而不是popen时，ghostscript打开文件总会报一些错误,换回popen就一切正常。 还有，subprocess和线程池进程池同时使用，效率并没有多大的提升，猜想哪个部分可能出现了阻塞？ 之后，考虑到暂时不太能区分出差别的情况，决定用shell试试。 其中主要遇到的问题就是文件名如果存在空格，就会因满足IFS（the Internal Field Separator），导致文件名被分割，最终的解决方法是在获取文件名前修改IFS,运行结束时再恢复。 多线程部分因时间问题暂时没再写，不过可以参考该博客，（linux_shell如何实现多线程)[https://www.cnblogs.com/signjing/p/7074778.html].","categories":[{"name":"专业","slug":"pro","permalink":"https://sean10.github.io/categories/pro/"}],"tags":[{"name":"script","slug":"script","permalink":"https://sean10.github.io/tags/script/"},{"name":"python","slug":"python","permalink":"https://sean10.github.io/tags/python/"},{"name":"shell","slug":"shell","permalink":"https://sean10.github.io/tags/shell/"}]},{"title":"银翼杀手2049","slug":"银翼杀手2049","date":"2018-01-02T03:53:13.000Z","updated":"2023-03-18T15:11:14.902Z","comments":true,"path":"2018/01/02/银翼杀手2049/","link":"","permalink":"https://sean10.github.io/2018/01/02/%E9%93%B6%E7%BF%BC%E6%9D%80%E6%89%8B2049/","excerpt":"这部作品，一开始并没有注意到是银翼杀手的续集，剧情前半段将背景等等交代的非常清楚，让作品对没有看过银翼杀手的新观众也能有一个比较良好的体验。","text":"这部作品，一开始并没有注意到是银翼杀手的续集，剧情前半段将背景等等交代的非常清楚，让作品对没有看过银翼杀手的新观众也能有一个比较良好的体验。 电影中，究竟谁是复制人是一个非常好的引人思考的主线。 前半段中，每一个登场的人都会被猜测身后的背景，我曾以为是华莱士公司的那个助理，但没想到直到最后，她的设定也只是作为华莱士的助理，只为他服务，在电影中丝毫没有展现其除了美甲以外的个人欲望，可能这才是华莱士所说的最美的天使的存在应有的。 到了后期，男主究竟是婴儿的本尊还是复制人让人感到扑朔迷离，上一部的男主说出他教伪装复制人修改数据时，我也依旧没有意识到男主会是这样的作品。因为电子数据中的女婴已死既诱导了男主偏离方向，同样也诱导了我们。 Joi和男主的感情线作为一个剧情的辅佐，也是相当具有卖点的，虽然机器人与人的恋爱、复制人与人的恋爱的概念已经许久了，但是真实呈现出的人工智能投影与人的恋爱还是第一次。还有！安娜 阿玛斯好漂亮。 最后男主失去了一切人生希望，Joi的消失、自身溯源的失败，他最后的拯救行为可能是为他这个溯源的过程找到的一个合适的结束，作为他个人价值的体现吧。之后，可能不是离去就是颓废了吧。 真正的婴儿的谜底揭晓时，真的是没想到，这么简单的谜底居然没能想到。病体，对于这个婴儿来说是非常现实的，同样，又是作品中少有的剧情牵扯较少的女性，完全存在其是主线剧情中心的可能性。 总的来说，以我的眼光，这部的剧情将原著还是修改的非常棒的。","categories":[{"name":"随想","slug":"thinking","permalink":"https://sean10.github.io/categories/thinking/"}],"tags":[{"name":"影评","slug":"影评","permalink":"https://sean10.github.io/tags/%E5%BD%B1%E8%AF%84/"},{"name":"科幻","slug":"科幻","permalink":"https://sean10.github.io/tags/%E7%A7%91%E5%B9%BB/"}]},{"title":"《尼采在世纪的转折点上》尼采初识","slug":"《尼采在世纪的转折点上》尼采初识","date":"2017-12-07T16:12:57.000Z","updated":"2023-03-18T15:11:14.865Z","comments":true,"path":"2017/12/08/《尼采在世纪的转折点上》尼采初识/","link":"","permalink":"https://sean10.github.io/2017/12/08/%E3%80%8A%E5%B0%BC%E9%87%87%E5%9C%A8%E4%B8%96%E7%BA%AA%E7%9A%84%E8%BD%AC%E6%8A%98%E7%82%B9%E4%B8%8A%E3%80%8B%E5%B0%BC%E9%87%87%E5%88%9D%E8%AF%86/","excerpt":"之前虽然向往周国平老师的作品，但是一直没来翻阅过其关于尼采的作品，对尼采占据哲学重要地位的上帝之死抱有相当的疑惑，直到这部作品，终于化解了心中的一部分好奇。","text":"之前虽然向往周国平老师的作品，但是一直没来翻阅过其关于尼采的作品，对尼采占据哲学重要地位的上帝之死抱有相当的疑惑，直到这部作品，终于化解了心中的一部分好奇。 上帝之死，单只从这部书中来看，指的是当时科学发展起来，引发的基督教等大众信仰的崩塌，之后在社会上发生的一系列思想等等的变革。之后的哲学家们之中诸如海德格尔、萨特似乎都带有了这一部分色彩。不过，上帝之死也并不单单是这么简单的，需要更深入的看些方能知道了。 尼采对道德的一些判断单从书中这些内容，有些不好理解，需要看看他的原作。 尼采的自我、无意识等等，在弗洛伊德那里得到了发展，当然，现在弗洛伊德的理论也已经算不上最完善的了。个人来看，荣格的理论相对弗洛伊德更贴合现在这个时代。 尼采的超人理论，似乎并不只是指自我超越，所以周国平老师才说超人理论存在缺陷。在这个基础上的，尼采的等级制度，弱者接受强者的领导，完全可以理解，平等的概念本就只有在机会上平等才是公正的，强者利用自己的能力抓住机会，弱者无力抓住机会，这本就是人的主动选择的结果，并不算得上是达尔文主义。不过，我的这个解读应该也是一种对原作的误解吧，毕竟理论是具有时代性的。 另外，尼采对学者、教育的认知已经与当下对不上了，当时的教育工厂现在都已经经过了变革，主打促进创新了。这是时代变化后的价值重估，尼采的那些论点在当时还是非常有价值的。","categories":[{"name":"随想","slug":"thinking","permalink":"https://sean10.github.io/categories/thinking/"}],"tags":[{"name":"尼采","slug":"尼采","permalink":"https://sean10.github.io/tags/%E5%B0%BC%E9%87%87/"},{"name":"周国平","slug":"周国平","permalink":"https://sean10.github.io/tags/%E5%91%A8%E5%9B%BD%E5%B9%B3/"},{"name":"读后感","slug":"读后感","permalink":"https://sean10.github.io/tags/%E8%AF%BB%E5%90%8E%E6%84%9F/"},{"name":"哲学","slug":"哲学","permalink":"https://sean10.github.io/tags/%E5%93%B2%E5%AD%A6/"}]},{"title":"《尼采在世纪的转折点上》笔记","slug":"《尼采在世纪的转折点上》笔记","date":"2017-12-07T16:10:55.000Z","updated":"2023-03-18T15:11:14.878Z","comments":true,"path":"2017/12/08/《尼采在世纪的转折点上》笔记/","link":"","permalink":"https://sean10.github.io/2017/12/08/%E3%80%8A%E5%B0%BC%E9%87%87%E5%9C%A8%E4%B8%96%E7%BA%AA%E7%9A%84%E8%BD%AC%E6%8A%98%E7%82%B9%E4%B8%8A%E3%80%8B%E7%AC%94%E8%AE%B0/","excerpt":"开创了由生命哲学到存在主义的道路","text":"开创了由生命哲学到存在主义的道路 人生的三个阶段 * 效仿 * 否定 * 肯定 二次世界大战后，科学发展，基督教信仰瓦解，流行价值真空和信仰危机，所以存在主义发展起来了 尼采将哲学家与学者相区分，认为学者不具有创造性 悲观主义是直面现实，叔本华的悲观、虚无 而基督教是逃到所谓的现实背后的真实的世界之中，属于逃离现实 酒神精神 强力意志消极的一面，拥有强力意志的人是少数，从中衍生出强者理应支配弱者和统治弱者的结论，站到了反民主的角度上去了。 永恒轮回 起源于赫拉克利特 尼采是为了抵制无意义的人生即人生来是偶然事件的这个恐惧而提出的永恒轮回，但这样的无限轮回其实也是一个二律背反。 现代西方哲学的许多流派，包括现代西方马克思主义哲学，对于人性的看法有一个重要特点， 就是强调人性的未完成性、开放性和无限可能性， 在哲学史上，断然主张绝对决定论的哲学家有之，断然主张绝对自由论的哲学家为数微乎其 微，而两者都有着明显的偏颇性。我们发现，许多哲学家动摇于两者之间（如斯宾诺莎、伏 尔泰由意志自由论转向决定论），或者试图在两者之间寻求某种折衷和结合（如康德、费希 特把人分为两部分，现象界的人受因果律支配，本体界的人有意志自由）。有趣的是，号称 唯意志论哲学家的叔本华和尼采也都并不主张意志的绝对自由，相反是反对意志自由论的。 重要的不是\"从 何而自由\"，而是\"为何而自由\"。《尼采全集》第 6 卷，第 92 页。许多人并无创造的意愿， 把自由理解为摆脱一切责任，结果所谓的\"自由\"一旦到手，精神倍感空虚。现代西方社会中 不是已经响起\"逃避自由\"的呼喊了吗? 力量是自由的前提，评价和创造是自由的真义。要把握尼采的人性观和自由观，关键是弄清 他对评价和创造的看法。 。尼采是不承认客观真理的。他认为，人与周围世界的关系只是一种价值关系，真理 只是一种价值判断，认识只是评价。 尼采认为，真实的\"自我\"往往是隐藏在无意识之中的， 而通常的认识方式，借助于语言，求之于思维，不但不能达到\"自我\"，反而歪曲了\"自我\"。 我们用来概括我们心理状态的语词，多半是为某些极端状态所取的名称，并不能指示出我们 大部分时间内所具有的不可名状的非极端状态，然而正是这些状态织成了我们的性格和命运 之网。 在尼采那里，真实的\"自我\"有两层含义。在较低的层次上，它是指隐藏在潜意识之中的个人 的生命本能，种种无意识的欲望、情绪、情感和体验。在较高的层次上，便是精神性的\"自 我\"，它是个人自我创造的产物。不过，对于尼采来说，这两层含义并不矛盾，因为他一向 把生命本能看作创造的动力和基础。 真正的个人主义追 求的既非财产，亦非浮名，而是真实的\"自我\"。 不过，王尔德因此而赞成公有 制意义上的社会主义，尼采却始终反对作为一种政治运动的社会主义，这又是他们的不同之 处。 自私就是恶，无私就是善，这种道德观念早已体现在基督教的邻人爱的原则中了。功利主义 的思想家们用合理的利己主义来反对基督教的抹杀个人的道德观念，为经济上的自由竞争制 造理论根据。可是，在资产者的实践中，事实上却是两种道德并存，一方面是最无耻最露骨 地追逐物质私利，另一方面是嫉恨和反对个人精神上的优异。 健康的\"自私\"是健康的 生命本能，是高尚的自我保护的力量。反对这样的\"自私\"，赞扬\"无我\"和牺牲，实际上是奖 劣惩优，压抑生命力旺盛、热爱生活的人，却鼓励那样的人。这种人\"不把他的全部力量和 才智用在他的保存、发展、超越、前进、强力之扩展上，而是对自己卑谦、无头脑或许竟淡漠或冷嘲地生活着\"。 可谓激进，但是在如何振兴人类的具体途径问题上，他所设计的方案却又极为保守，总是脱 不开贵族政体的陈旧观念。他不满于资产者社会的现状，但在社会学说上他提不出更进步的 社会理想，反而一再缅怀和主张早已过时的带有浓厚奴隶制色彩的等级社会。这是尼采思想 中最触目的矛盾。 尼采并非要抹煞科学本身的价值，相反，对于卢梭否定科 学文化而提出\"回到自然\"的倒退主张，他是坚决反对的。问题在于，要恰如其分地看待科学 的价值，它只具有工具价值。如果把科学当作目的本身，漫无止境地追求对物的支配，结果 只能丧失人生本真的意义，使人成为物的奴隶。 哲学始终与本体论 结下不解之缘，这种本体论以构造\"真正的世界\"为唯一使命。 。他反对的是按照人类自身的理性本性 去构造一个合乎理性的世界模式，然后又用这样的世界模式来规束人的现实生活。这样，理 性在世界上所看到的不过是它自身，逻辑把自己的界限当作世界的界限，人类认识活动的工 具被抬高到至高无上的地位，冒充为形而上学的真理，进而冒充为最高的价值标准。于是， 生命被贬值，本能受压制，法则统治一切，人生失去了生命的活力和乐趣。 对于尼采来说，审美状态是一种不可分割的肉体精神状态的整体，是\"活着 的情绪存在，是留在情绪中的肉体存在，是交织在肉体存在中的情绪 一种受压抑的冲动为了在 假想中得到满足，往往会歪曲记忆，故意遗忘。\"我的记忆说：\"我做过这事。\"我的骄傲说， 并且顽强地坚持：\"我不可能做这事。\"最后，记忆让步了。\" 遗忘成了满足愿望的手段。我们不禁想起了弗洛伊德对于日常生活中种 种过失的心理分析。 重估一切价 值\"就是要把被颠倒的评价重新颠倒过来，否定一切被肯定者，肯定一切被否定者。这也就 是\"价值的翻转\"。 。他却 不但否定了基督教伦理的根本原则，对善恶作了全新的评价，并且在一定意义上还否定了伦 理本身，把数千年来视为明白无疑的东西带入问题的领域，把道德从至高无上的地位拉下来， 确定了它对别的更高价值的从属关系。所以，他自称：\"我是第一个非伦理主义者。\" 尼采对于道德的否认，据他自己说，有两层意思：第一，否认某人的行为是出于所谓道德的 动机，也就是说，动机本身就不真实，真实的动机却是不道德的，经过自我欺骗作用而化妆 成了道德的；第二，动机是真实的，然而这动机却是一种根本错误的道德观念。 那么，尼采要否认的是道德的什么大前提呢?如果我们没有理解错尼采的意思的话，这个大 前提我们不妨称之为\"道德本体论\"，也就是把道德实体化的倾向。 。道德判断与宗教 判断有一共同点： 相信不存在的实在。道德仅是对一定现象的解释，确切地说是一种误释。 透彻地说，这是把道德现象归结为生物现象。或者说，只有生物现象，没有道德现象，人们 把生物现象曲解为道德现象了。尼采似乎就是这么说的。他用讽刺的口吻谈到，上流社会中 的所谓道德行为，如小心谨慎地避免着可笑的事、露头角的事和争端，隐匿着自己的才能和 欲求，与环境同化，从俗，自卑，这一切与动物中的保护色作用、肖形作用、装死等现象是 一回事，无非是避开仇敌和保存自己的手段，所以，仍是一种动物性现象。 基督教假定，人不知道也不可能知道，对他来说，何为善，何为恶：他信仰唯一 知道这一切的上帝。基督教道德是一个命令，它的起源是超验的；它是超越一切批评的。\" 。可是， 作为一种社会意识形态，道德自有它的现实的社会根源和必不可少的社会功能。尼采自己比 任何人都重视评价的意义，现在他又全盘否定作为最重要的价值形态之一的道德，岂非自相 矛盾? 尼采懂得，习俗和舆论的力量是巨大的。\"天天听着关于我们的批评，甚至忖度人家心中对我们的想法，--这会毁灭掉最坚强的人。 。以同情为道德的心理基础和基本原则，在 伦理学史上是一重要传统，尤为英国经验主义者和功利主义者所主张。叔本华也持这一见解。 其次，同情与尊重是两种相反的感情，在同情中蕴含着对他人 的不尊重。譬如说，我们对某人非常尊敬，羡慕，甚至崇拜，后来突然发现他有痛苦，并且 需要我们的同情，这时我们就会欣然同情他，同时也削弱了我们对他的尊敬。同情一个人， 意味着把他看成一个弱者，谁会去尊敬一个弱者呢? 那些爱表 同情的人，内心深处是在寻求一种作为施恩者的满足。最明显的证据是，倘若他们的同情遭 到拒绝，他们就会感到失望，甚至觉得受了侮辱，由同情一变而为愤怒。 更有些人所谓 的同情，不过是拿别人的痛苦当消遣。尼采讽刺地写道：\"他居于不幸中了，\"同情者\"于是 走来，将他的不幸描画一遍，--于是他们满足而且飘然走开了：他们哀不幸者的痛苦，犹如 哀自己的痛苦，很好地消磨了一下午。 尼采并非反对向痛苦者伸出帮助之手。问题是，第一，最大的帮助是唤起痛苦者的自尊自强 之心；第二，帮助必须真诚，而真诚的标准仍是不伤害痛苦者的自尊自强之心。你不要让人 感到你是一个施恩者，而你也确实不以施恩者自居。 怎样才算真诚?仅举二例。其一：\"假如我们不把别人的名誉在私下一如在人前保持，我们便 不是好人。 尼采从希腊出发，走向超人，他寄希望于一种新的人的类型的产生。在这一 点上，以存在主义为代表的现代流派不那么理想主义，也不那么贵族气，他们更多地把超越 的使命赋予每个人自己，让每个人自己通过对真实存在的体验来摆脱文明的祸害。 尼采也是反对社会达尔文主义的。在他看来，进化不利于杰出个体，反而有利于\"末人\"的生 存和繁衍。如要用生物学术语来表达，毋宁说超人的产生要靠人工选择而非自然选择，也就是要靠人类有意识地创造条件。 诚然，尼采所主张的等级制度主要地不是依据血统，而是依据精神，但这仍然是一种地道的 等级制度。他感到遗憾的是：\"自然为何对人这么吝啬，不让人按照内心的光源发光，使一 个人辉耀，另一个人黯淡?为何伟大人物的升降不像太阳那样明丽?\" (极度赞同) 。促使尼采主张等级制度 的原因有二。一是他蔑视群众，对大多数人失去信心，认为他们一旦占据支配地位，就会对 少数优秀人物施行暴政。二是他认为在事关创造文化的时候，幸福如何分配的问题无关紧要， 多数人应当为少数能够创造高级文化价值的人做出牺牲。 我们的二十世纪，已经很少有人相信超人说了，可是谈论人的自我超越 性的却越来越多。也许，这就是\"超人\"寓言的收获。（超人说难道不是指自我超越吗？） 世上有哪部哲学著作如今真的被谱成了交响乐呢?只有《查拉图斯特拉如是说》。 德国的浪漫化哲学，从席勒、费 希特、谢林、诺瓦里斯、施莱尔马赫、叔本华发展到尼采，算是达到了炉火纯青的地步，又 启示了狄尔泰、海德格尔、马尔库塞在这条路上进一步探索。求人生的诗化，进而求本体的 诗化，进而求哲学思考方式本身的诗化，是这种浪漫化哲学的主旨。 本体的艺术化与艺术的本体化是同一件事情的两个方面。既然世界本体原是一种艺术活动， 那就只有艺术活动才能体现世界本体。尼采始终强调艺术的本体论意义：\"艺术是生命的最 高使命和生命本来的形而上活动。 如果我们追循尼采的思想逻辑，我们就会发现，他之所以要把本体艺术化，又把艺术本体化， 仍然是为了给人生提供一种意义。艺术的形而上学意义实来自人生需要形而上学意义。\"我 们的最高尊严在艺术活动的价值之中，因为只有作为审美现象，人生和世界才永远有充足理 由。 世界本身并无意义，它不断产生和毁灭个体生命的活动本身也并无意义，如果你要 用真理或道德的眼光去探究它的意义，你只会失望，会对生命本身失去信心。可是，一旦用 艺术的眼光去看世界，无意义的生成变化过程突然有了一种意义，那就是审美的意义。在尼 采看来，舍此别无肯定存在的途径。\"艺术的本质方面始终在于它使存在完成，它产生完美 和充实，艺术本质上是肯定，是祝福，是存在的神化。 尼采提出的主要问题是：在传统价值全面崩溃的时代，人如何重新确立生活的意义?我们可 以把他的答案归结为：一、解除理性和道德对于生命本能的压抑，使生命本能健康发展；二、 发扬人的超越性，做精神文化价值的创造者；三、以审美的人生态度取代科学和伦理的人生 态度。 当我们分别从这三个方面向前探寻时，我们在第一条路上发现了生命哲学家和弗洛伊德主义 者，在第二条路上看见了存在哲学家的活跃的身影，在第三条路上遇到了高举艺术革命旗帜 的浪漫主义骑士马尔库塞。 总的来说，在人的自由和超越性问题上，存在主义的主要进展在于，通过对人的存 在结构的分析，从本体论上建立了人的自由和超越性命题，它也就是存在主义的基本命题： \"存在先于本质\"。 。到了存在主义，情绪更加明确地获得了本体论意义。 海德格尔就直截了当地认为情绪是基本的存在状态。当他分析人的存在结构时，\"畏\"、\"烦\" 的情绪在此结构中起了关键的作用。萨特的\"恶心\"，雅斯贝尔斯的\"临界状态\"、\"沟通\"，也 无不起了这样的作用。在存在主义者那里，人生的意义实际上被归结为内心的某种情绪体验， 情绪成了实现自由和超越的唯一阵地。对比之下，尼采至少还重视创造高级文化这一可见形 式的超越，似不如此偏颇。","categories":[{"name":"随想","slug":"thinking","permalink":"https://sean10.github.io/categories/thinking/"}],"tags":[{"name":"尼采","slug":"尼采","permalink":"https://sean10.github.io/tags/%E5%B0%BC%E9%87%87/"},{"name":"周国平","slug":"周国平","permalink":"https://sean10.github.io/tags/%E5%91%A8%E5%9B%BD%E5%B9%B3/"},{"name":"哲学","slug":"哲学","permalink":"https://sean10.github.io/tags/%E5%93%B2%E5%AD%A6/"},{"name":"读书笔记","slug":"读书笔记","permalink":"https://sean10.github.io/tags/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/"}]},{"title":"《Effective_C++》note","slug":"《Effective-C-》note","date":"2017-11-28T14:47:56.000Z","updated":"2023-03-18T15:11:14.869Z","comments":true,"path":"2017/11/28/《Effective-C-》note/","link":"","permalink":"https://sean10.github.io/2017/11/28/%E3%80%8AEffective-C-%E3%80%8Bnote/","excerpt":"in-class 初值设定 只支持整型常量","text":"in-class 初值设定 只支持整型常量 class static专属变量可以不定义，直接声明并使用 如果要取地址，就在定义文件里再定义const ，不要初始化，因为值在声明时已经默认了。 这不知道是哪个C++的版本加入的功能，旧编译器不支持初值 不支持in class时，可以用enum&#123;NumTurns = 5&#125;替代 这叫做enum hack补偿做法 这是template metaprogramming的基本技术 bitwise constness(physical constness) and logical constness 二进制常量性 和 逻辑常量性 利用Mutable解决掉non-static的const摆动场，释放bitwise constness 新式转型 static_const转型操作 const_cast去除const操作 core dump错误 基类使用派生类函数 1. 使用virtual从继承向上移动 2. 使用安全容器 绝对拒绝cascading dynamip_cast，理由不理解 尽可能使用C++ style新式转型 无参数构造函数，为什么也需要用到初始化操作？ （噢，可能是为了不忘记哪个参数不需要初值） 不同编译单元内定义之non-local static对象，编译器对初始化顺序并没有设定 **多个编译单元内的non-local static对象经由“模板隐式具现化 implicit template instantiations\"”形成 将non-local 移到专属函数中，调用一个函数返回一个reference指向所含的对象， 这是Singleton模式的一个常见实现手法 但是在多线程环境下存在不确定性 做法：在程序的单线程启动阶段手工调用所有reference-returning函数，可消除与初始化有关的”竞速形式(race conditions) 编译器拒绝生成拷贝构造函数和操作符的几种情况 将成员函数声明为private并不去实现，就可以阻止编译器生成public拷贝构造函数等等 声明一个uncopyable基类，继承他就可以直接阻止编译器 c++的异常绝对不要放在析构函数里 连锁赋值 返回*this，这个是返回引用 自我赋值，释放，陷阱 传统做法，添加identity test 异常安全性是什么？ 工厂函数factory function RAII，资源取得时机便是初始化时机(Resource Acquisition is Initialization) 智能指针 或者 referenced counting smart pointer resource handler shared_ptr存在删除器，可以指定调用函数作为释放这种行为 std::tr1::shard_ptr&lt;Investor&gt; ptr ptr(m1, Unlock) 有时APIs直接接触原始资源，无法通过资源管理类来接触 对原始资源的访问最好是通过显式转换，但是对客户来说，隐式转换 可能更加方便 隐式转换也是可以在自定义类中重载的吗？ 以独立语句将newed对象存储于智能指针内。如果不这样做，一旦异常被抛出，有可能导致难以察觉的资源泄露 优良接口 许多客户端错误可以因为导入新类型而获得预防 以函数替换对象，表现某个特定月份 和non-local static对象的初始化次序有什么关系？ 嗯，想起来了，构造函数的赋值和初始化次序可能不定，还是直接调用函数效果更确定 tr1::shared_ptr支持定制型删除器，可防范DLL问题，可被用来自动解除互斥锁。 这条不太理解，不知道DLL可能发生什么错误 设计class犹如设计type 函数内的static local对象何时释放？ global slinton 在一个命名空间内添加多个头文件也是一种做法 特化版本是什么，好像没见过 条款25，特化swap，感觉不理解，特别复杂 避免返回handles（包括references、迭代器）指向对象内部 异常安全性 不泄露任何资源 不允许数据败坏 异常安全码 copy and swap一般化策略 pimpl idiom function template和头文件是啥关系，似乎没啥关系 条款31 将文件件的编译依存关系降至最低 我们可以这样做，将person分割为两个classes，一个只提供接口，另一个负责实现该接口。 这样可以实现接口与实现相分离 std头文件依旧引用，除此之外。接口使用前置声明。 关键:用“声明的依存性”替换“定义的依存性” Pass By Value就需要用到定义，而如果传递指针或引用，就不需要定义，只要声明 为声明式和定义式上提供不同的头文件 就像 这个被称为Handle classes. 2种: * 接口与实现相分离 * 抽象基类，叫interface class 类似Java的Interface 继承这个抽象基类的叫做具象类(concrete classes)，调用基类的创建函数，在创建函数中调用具象类对象动态分配，并返回static，然后通过基类中提供的接口对返回的对象进行操作。哇，这也是一种接口与实现相分离 handle classes 和Interface classes解除了接口和实现之间的耦合关系，从而降低了文件间的编译依存性(compilation dependencies) virtual意味着接口必须被继承，non-virtual意味着接口和实现必须被继承 转角函数 forwarding function 函数接口继承和函数实现继承 virtual和inline究竟有什么关系？ 接口和缺省实现应该分开 可以在纯虚函数的定义中进行缺省实现 简朴的(非纯)impure vritual函数具体制定接口继承及缺省实现继承。 缺省实现继承不还是pure virtual函数实现的吗？ 难道这个简朴的，指的不是virtual函数？ non-virtual interface(NVI手法)，外覆器(wrapper) Template Method设计模式 虚函数private，还能被继承吗？ 不能的话，那有什么意义？ strategy设计模式 传递函数指针 tr1::function可以实现stategy设计模式 任何兼容的可调用物(callable entity) 与给定之目标签名式(target signature)兼容 上面2条什么意思？ 非虚函数，Base类指针指向派生类，执行的函数式Base类中的，而不是派生类中的。 如果是虚函数，那么就都执行派生类中的。 静态绑定，动态绑定 dynamically bound,stataically bound 不能调用继承Private的virtual函数，那么允许重新定义这个虚函数的价值是什么呢？ 如果继承的private是非虚函数，也是可以重新定义的吧？ 难道这个不行 Java和C#自带 组织derived class 重新定义virtual 函数 空白基类最优化 多重继承 virtual inheritance 泛型编程 衍生出模板元编程 显式接口，运行期多态 template中指涉一个嵌套丛书类型名称，就必须在紧邻它的前一个位置放上关键字typename 模板 特化 全特化模板的调用很有可能编译器不会去查询，也就无法调用，存在一些问题 共性与变性分析 模板化基类 被覆盖 working set 因非类型模板参数造成的代码膨胀，可以用class来替换template，但是完全理解不了 Traits是一门技术，获取类型信息的，无论是内置还是自动类型 TMP元编程技术越来越牛了 可以定制new和delete，set_new_handler","categories":[{"name":"专业","slug":"pro","permalink":"https://sean10.github.io/categories/pro/"}],"tags":[{"name":"C++","slug":"C","permalink":"https://sean10.github.io/tags/C/"}]},{"title":"东野圭吾作品的别致","slug":"东野圭吾作品的别致","date":"2017-10-31T12:57:52.000Z","updated":"2023-03-18T15:11:14.866Z","comments":true,"path":"2017/10/31/东野圭吾作品的别致/","link":"","permalink":"https://sean10.github.io/2017/10/31/%E4%B8%9C%E9%87%8E%E5%9C%AD%E5%90%BE%E4%BD%9C%E5%93%81%E7%9A%84%E5%88%AB%E8%87%B4/","excerpt":"这应该是我看的东野圭吾的第二部作品，第一部看的是《白夜行》。","text":"这应该是我看的东野圭吾的第二部作品，第一部看的是《白夜行》。 感觉上，在印象里，东野圭吾的风格和我曾经看过的其他悬疑推理作品完全不同，其他作品诸如柯南道尔的《福尔摩斯》会给出细微的描写的线索，然后将凶手隐藏起来，需要切切实实的仔细推理，存在多个凶手的可能性。 而东野圭吾的作品却是一开始便只提供了唯一的凶手选项，然后带领读者逐渐获取线索，寻找真相。在这个过程中，让读者对凶手的性格有所成形，并逐渐理解凶手的杀人动机。如果简单地说句和其他人的作品的不同，恐怕就是东野圭吾的作品都是挂着推理外壳的情感小说吧，而其他人的则是挂着情感线索外壳的推理悬疑小说，不过这部《拉普拉斯的魔女》藏在推理外壳内的应该算是一个科幻小说吧，主要试图讲述的人类大脑建模计划的成果?。 另外，在这部小说中，每个角色的戏份似乎是相近的，都构造出了一个真实的人的模样。说来，其他推理作品，我看的都是探案集，只有主角是长久的，其他的配角都只需要为主角提供助力，营造一个模糊性格就足够了，而东野圭吾的作品中没有冗余的角色，可能在他眼中，真实的社会中每个人都是主角，具有好奇心的人都会发展出各自的故事？ 这样的故事读完，倒是别有一番风味，没有推理完的烧脑感，但能有一股引人思考的回味感。","categories":[{"name":"随想","slug":"thinking","permalink":"https://sean10.github.io/categories/thinking/"}],"tags":[{"name":"读后感","slug":"读后感","permalink":"https://sean10.github.io/tags/%E8%AF%BB%E5%90%8E%E6%84%9F/"},{"name":"东野圭吾","slug":"东野圭吾","permalink":"https://sean10.github.io/tags/%E4%B8%9C%E9%87%8E%E5%9C%AD%E5%90%BE/"},{"name":"推理","slug":"推理","permalink":"https://sean10.github.io/tags/%E6%8E%A8%E7%90%86/"},{"name":"小说","slug":"小说","permalink":"https://sean10.github.io/tags/%E5%B0%8F%E8%AF%B4/"}]},{"title":"仿佛天元突破","slug":"仿佛天元突破","date":"2017-10-07T14:25:18.000Z","updated":"2023-03-18T15:11:14.903Z","comments":true,"path":"2017/10/07/仿佛天元突破/","link":"","permalink":"https://sean10.github.io/2017/10/07/%E4%BB%BF%E4%BD%9B%E5%A4%A9%E5%85%83%E7%AA%81%E7%A0%B4/","excerpt":"这部作品是这两天我补番过程中，唯一能被称之为杰作的作品了把。","text":"这部作品是这两天我补番过程中，唯一能被称之为杰作的作品了把。 而这部来自深渊，一开始我认为是相对比较简单的，可是在接触了解这个世界观越来越深以后，愈发有种可能与《天元突破》那部老番拥有神似的感觉了。虽然故事并不相同，但是将主角身世等等的秘密逐渐揭露，逐渐发现隐藏的更深的秘密，这种引动好奇心的叙事能力，令人欲罢不能。同样是奇幻类型，同样围绕着一个限定的职业展开之后的故事。 这部作品也是近年来少有的用吉卜力风格的作品，并不使用当下流行的九头身的GAL画风，而是用了3头身，将着重点放在整个冒险故事本身。这种做法，不盲随大流，展现给观众的表现力着实不错。 仔细想来，这种设定下，如果用偶像风格，那可能这个故事就会因为主次区分度不足，而导致观众无法理解故事本身了吧。说来，前段时间的那部《ReWrite》，我就完全没能看懂。听说只有玩了原著游戏才能稍稍有所了解。","categories":[{"name":"随想","slug":"thinking","permalink":"https://sean10.github.io/categories/thinking/"}],"tags":[{"name":"动漫","slug":"动漫","permalink":"https://sean10.github.io/tags/%E5%8A%A8%E6%BC%AB/"},{"name":"来自深渊","slug":"来自深渊","permalink":"https://sean10.github.io/tags/%E6%9D%A5%E8%87%AA%E6%B7%B1%E6%B8%8A/"},{"name":"吉卜力","slug":"吉卜力","permalink":"https://sean10.github.io/tags/%E5%90%89%E5%8D%9C%E5%8A%9B/"},{"name":"奇幻","slug":"奇幻","permalink":"https://sean10.github.io/tags/%E5%A5%87%E5%B9%BB/"}]},{"title":"系列首作，所以只是引观众进行哲思","slug":"系列首作，所以只是引观众进行哲思","date":"2017-10-07T14:23:15.000Z","updated":"2023-03-18T15:11:14.841Z","comments":true,"path":"2017/10/07/系列首作，所以只是引观众进行哲思/","link":"","permalink":"https://sean10.github.io/2017/10/07/%E7%B3%BB%E5%88%97%E9%A6%96%E4%BD%9C%EF%BC%8C%E6%89%80%E4%BB%A5%E5%8F%AA%E6%98%AF%E5%BC%95%E8%A7%82%E4%BC%97%E8%BF%9B%E8%A1%8C%E5%93%B2%E6%80%9D/","excerpt":"《全部成为F》，这可以说是比较棒的一部作品，不过也是有局限性的。","text":"《全部成为F》，这可以说是比较棒的一部作品，不过也是有局限性的。 《全部成为F》应该说是推理、悬疑类的标准作品，在动漫中的排名不低，但是在整个悬疑类动漫里，可能就并不能显得非常出色了，唯有他的系列设定中所占不小的试图表现的哲学+数学内涵可以拉动一些他的分数。相比其他的纯推理作，这部作品在当下这个年代，二进制普及的年代，F的谜题不算难想到了（在当年推出的那个背景是算是非常了不起的了，不愧是工科博士/教授)。所以，作为S&amp;M系列的正式首作，终究只是给系列作品起了个开幕式。动画并不能算完整。 这部里，我感觉到的内涵，就是天才认为活着有种病态感了。 天才的真贺田博士，在认知上已经超出了常人的范畴，对一切的理解似乎是已经超出了读者的想象。而犀川教授，虽然在常人的范畴，也可以称之为天才，但是他与真贺田博士终究还是不同的，他与女主西之园萌绘互相支撑，互相度过了最艰难的时间，终究没有选择走向自由、死亡的那一步，而真贺田博士最终是落实了自由的那一步，放弃了作为普通人类所拥有的道德观与人生观，杀死了父母，女儿自杀而摆脱了阻碍，进入了社会。 这个动画，我剪了所有的哲思对话(B站15155955)，发现动画里回答的还是比较简单的，没有用理论主义的演绎法，也没有用经验主义的归纳法，只是在阐述与寻找共鸣，就感觉有点让观众不那么好理解了。(个人感觉只能算是给观众提了问题，动画里的回答只是设定里的回答，并不能让观众信服) 恐怕，也是存了毕竟只是一个系列的开幕，所以不需要在这一部里讲的太多，反而讲不清案件了吧。","categories":[{"name":"随想","slug":"thinking","permalink":"https://sean10.github.io/categories/thinking/"}],"tags":[{"name":"动漫","slug":"动漫","permalink":"https://sean10.github.io/tags/%E5%8A%A8%E6%BC%AB/"},{"name":"全部成为F","slug":"全部成为F","permalink":"https://sean10.github.io/tags/%E5%85%A8%E9%83%A8%E6%88%90%E4%B8%BAF/"},{"name":"真贺田四季","slug":"真贺田四季","permalink":"https://sean10.github.io/tags/%E7%9C%9F%E8%B4%BA%E7%94%B0%E5%9B%9B%E5%AD%A3/"}]},{"title":"「序列之争」最后30分钟太可惜","slug":"「序列之争」最后30分钟太可惜","date":"2017-10-02T08:46:28.000Z","updated":"2023-03-18T15:11:14.894Z","comments":true,"path":"2017/10/02/「序列之争」最后30分钟太可惜/","link":"","permalink":"https://sean10.github.io/2017/10/02/%E3%80%8C%E5%BA%8F%E5%88%97%E4%B9%8B%E4%BA%89%E3%80%8D%E6%9C%80%E5%90%8E30%E5%88%86%E9%92%9F%E5%A4%AA%E5%8F%AF%E6%83%9C/","excerpt":"前80分钟我觉得剧情完全可以，将VR与AR之间的差异与美妙讲述的相当清楚。","text":"前80分钟我觉得剧情完全可以，将VR与AR之间的差异与美妙讲述的相当清楚。 只看这部分的话，桐人在这里的展现就像是一个偏好宅VR的人被AR的现充给打倒了，然后逐渐接受，开始成长。到这里为止，剧情的设定还算是显得比较普通，虽然不算杰作，但在这个杰出的背景设定下也绝对不差。 然而，从进入演唱会阶段开始，可能是为了突出一个打倒BOSS，主角们都很棒，反派必须死的主线?就设定了一个必须要桐人出面才能拯救所有人的条件吧。 首先，桐人居然直接就打开了会场的门，从楼上直接就能跳到主会场里，就说这一点，难道后面支援的部门里的大人们就不行？他们非要把这个责任完全交给孩子？无论如何，多手准备总归是要有的吧，桐人走主流通关路线，分配几个人去会场引导大家摘下设备完全可以，留几个人直接去关闭游戏主服务器，再分配几个人去找博士呗。前面的剧情相当有脑，怎么到了这里就这么的让人想吐槽呢。 其次，就算你一时忘了吧，用枪打开门那部分，我也想说说了，既然是同样的电子锁，你这里直接打爆断电能够开门还是比较正常的，那为什么在会场那里你不直接开枪打开门呢……给桐人堆戏份的目的也太明显了…… 再三，博士明明可以慢工出细活，慢慢收集数据就是了。明知道这么直接，暴露被抓的话，显然对未来复活的尤娜来说也不是一件好事。明明可以通过长时间发布活动来收集他们的回忆，这种曾经的冒险时的记忆显然已经是处于长期记忆状态了，并不会在短时间内遗忘了，不存在迫使博士必须要短时间爆发强制扫描记忆的动机。 像茅场晶彦那样准备已久，一次爆发，之后完全安全地存活在信息世界中，才是真正符合现实的吧。博士已经有眼前的经验了，居然仍旧这么选择，就显得有些角色崩坏了吧。 当然，整部作品不考虑后面的剧情失常表现，打斗的画面还是一如既往的精致。结衣开外挂那里开的倒也挺正常，毕竟现在SAO服务器启动了，结衣权限再次生效还是可能的。 这部作品，在这个大数据热门的时代，倒是很符合潮流，很有热点。","categories":[{"name":"随想","slug":"thinking","permalink":"https://sean10.github.io/categories/thinking/"}],"tags":[{"name":"动漫","slug":"动漫","permalink":"https://sean10.github.io/tags/%E5%8A%A8%E6%BC%AB/"},{"name":"刀剑神域","slug":"刀剑神域","permalink":"https://sean10.github.io/tags/%E5%88%80%E5%89%91%E7%A5%9E%E5%9F%9F/"}]},{"title":"考研预报名脚本","slug":"考研预报名","date":"2017-09-26T14:43:40.000Z","updated":"2023-03-18T15:11:14.869Z","comments":true,"path":"2017/09/26/考研预报名/","link":"","permalink":"https://sean10.github.io/2017/09/26/%E8%80%83%E7%A0%94%E9%A2%84%E6%8A%A5%E5%90%8D/","excerpt":"","text":"本来打算自己写JS填表的，不过在github上直接搜到了一个同学的杰作，就直接使用了，链接放在这里。 之前每次手填怪慢和累的，而且还经常最后提示繁忙什么的……用脚本就没问题了。 祝各位报名顺利吧~","categories":[{"name":"专业","slug":"pro","permalink":"https://sean10.github.io/categories/pro/"}],"tags":[{"name":"考研","slug":"考研","permalink":"https://sean10.github.io/tags/%E8%80%83%E7%A0%94/"}]},{"title":"未来镜像","slug":"未来镜像","date":"2017-08-24T07:03:07.000Z","updated":"2023-03-18T15:11:14.819Z","comments":true,"path":"2017/08/24/未来镜像/","link":"","permalink":"https://sean10.github.io/2017/08/24/%E6%9C%AA%E6%9D%A5%E9%95%9C%E5%83%8F/","excerpt":"这本作品原来中外合作的意思是双语啊，看完才知道……很赞","text":"这本作品原来中外合作的意思是双语啊，看完才知道……很赞 《以太》: 一个神似《1984》的故事，不过并非通过监控而后暴力压制，而是通过监控后彻底的欺骗，这个故事完全可以存在且有效。 《开光》: 一个违反熵的算法的出现，引发了宇宙的干扰行为，最终始作俑者终将受到处置。 《格里芬太太决定于今夜去死》: 一个存在了人工智能的世界里，一个人与一个家用机器人的故事，一个男人为了妻子另外兼职试图购买一个家用机器人，刚刚攒够之际遭遇意外，妻子明白了丈夫对她的爱，却没有机会再见。妻子还是讲本该购买的机器人LW31买回了家，在自己离开之后，LW31来照顾自己的女儿格里芬。格里芬为了在废除机器人的时代保护LW31，遇到了自己的丈夫，在逃亡直到政府破灭通缉失效方才回归，而她的丈夫则因为逃亡中的伤害而早早离开。后来，她的女儿也遇到了自己心爱的人准备移民，却在星际移民过程中遭遇不测。最终，只有LW31与格里芬太太相依为命，所幸LW31依旧存在，作为最后一个爱着格里芬的人而保护着她。 《饿塔》: 人性的归原，最终舍弃了智慧的人也舍弃了得救的希望。 《安检》: 在安检的过程中通过纳米器械彻底替换物质乃至人，为了国家的安全。感觉脑洞不够大。这和人时时刻刻在新陈代谢，下一秒不再是刚才的自己一般。 《留下她的记忆》: 记忆是真实的，但部分的记忆又是虚假的，毕竟记忆是带有主观色彩与方向的，就像事实一般具有诱导性。 《祖母家的夏天》: 之前读过一遍的郝景芳大大的作品，依旧感觉是那么的赞，你永远不知道一样东西的真正用处是什么。这里用《物语》里班长的话来说就是:\"我不是什么都知道，只是刚好知道而已。\"我们知道的只是刚好知道的，而永远不会是全部。 《寒冬夜行人》: 只是一个隐藏喜欢的诗人隐私的故事，为什么算是科幻作品呢？只能算是一个文艺的短篇小说吧。 《圆圆的肥皂泡》: 童年的幻想化作未来的坚持，幻想的真正用处终究能找到。","categories":[{"name":"随想","slug":"thinking","permalink":"https://sean10.github.io/categories/thinking/"}],"tags":[{"name":"读书笔记","slug":"读书笔记","permalink":"https://sean10.github.io/tags/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/"},{"name":"科幻","slug":"科幻","permalink":"https://sean10.github.io/tags/%E7%A7%91%E5%B9%BB/"}]},{"title":"克苏鲁神话初学","slug":"克苏鲁神话","date":"2017-08-04T07:24:18.000Z","updated":"2023-03-18T15:11:14.903Z","comments":true,"path":"2017/08/04/克苏鲁神话/","link":"","permalink":"https://sean10.github.io/2017/08/04/%E5%85%8B%E8%8B%8F%E9%B2%81%E7%A5%9E%E8%AF%9D/","excerpt":"初闻，有所疏漏，请见谅。","text":"初闻，有所疏漏，请见谅。 克苏鲁神话短篇译名对照表(详见附录一): 作者 分类 原名 译名 创作时间 译者 制表：玖羽 HPL 小说 The Alchemist 炼金术士 1908 白苹果 早期 Ashes 灰烬 1923 zimmer 共作 At the Mountains of Madness 疯狂山脉 1931.02-03.23 竹子 重要 较长 Azathoth 阿撒托斯 1922.06 玖羽 残篇 较短 The Battle that Ended the Century 新世纪前夜的决战 1934.06 玖羽 恶搞 共作 较短 The Beast in the Cave 洞中兽 1905.04.21 Milk 早期 较短 Beyond the Wall of Sleep 翻越睡梦之墙 1919 竹子 早期 The Book 书 1933 玖羽 残篇 较短 The Call of Cthulhu 克苏鲁的呼唤 1926.夏 竹子 重要 The Case of Charles Dexter Ward 查尔斯·迪克斯特·瓦德事件 1927.01-05.01 竹子 重要 较长 The Cats of Ulthar 乌撒的猫 1920.06.15 玖羽 早期 幻梦境 较短 Celephaïs 塞勒菲斯 1920.11 玖羽 早期 幻梦境 较短 The Challenge from Beyond 来自彼方的挑战 1935.08 竹子 共作 Collapsing Cosmoses 崩坏的宇宙 1935.06 玖羽 恶搞 共作 残篇 较短 The Colour Out of Space 星之彩 1927.05 修白川 重要 Cool Air 寒气 1926.05 竹子 The Crawling Chaos 伏行的混沌 1920/21 竹子 早期 The Curse of Yig 伊格的诅咒 1928 竹子 共作 Dagon 达贡 1917.07 玖羽 早期 较短 Deaf, Dumb, and Blind 聋，哑，瞎 1924 竹子 共作 The Descendant 后裔 1926 yolu 残篇 较短 The Diary of Alonzo Typer 阿隆佐·泰普尔的日记 1935.10 玖羽 共作 The Disinterment 掘墓 1935.09 竹子 共作 The Doom That Came to Sarnath 降临在萨尔纳斯的灾殃 1919.12.03 玖羽 早期 幻梦境 较短 The Dream-Quest of Unknown Kadath 秘境卡达斯梦寻记 1926.秋-1927.01.22 竹子 重要 幻梦境 较长 The Dreams in the Witch House 魔女屋中之梦 1932.01-02.28 竹子 重要 较长 The Dunwich Horror 敦威治恐怖事件 1928.夏 竹子 重要 较长 The Electric Executioner 电刑器 1929 竹子 共作 The Evil Clergyman 邪恶的教士 1933.10 竹子 较短 Ex Oblivione 来自遗忘 1920/21 玖羽 早期 幻梦境 较短 Facts Concerning the Late Arthur Jermyn and His Family 关于已故亚瑟·杰尔敏及其家系的事实 1920 玖羽 早期 The Festival 魔宴 1923.10 玖羽 重要 From Beyond 自外而来 1920.11.16 竹子 早期 The Ghost-Eater 噬鬼者 1923 zimmer The Green Meadow 绿色草原 1918/19 玖羽 早期 幻梦境 The Haunter of the Dark 夜魔 1935.11 竹子 重要 He 他 1925.08.11 竹子 Herbert West – Reanimator 尸体复活者赫伯特·威斯特 1921-1922 竹子 枪稿 重要 History of the Necronomicon 《死灵之书》的历史 1927 竹子 随笔 较短 The Hoard of the Wizard-Beast 巫兽的宝藏 1933 竹子 共作 The Horror at Martin's Beach 马丁海滩的怪物 1922.06 竹子 共作 较短 The Horror at Red Hook 雷德胡克的恐怖 1925.08.01-02 竹子 The Horror in the Burying-Ground 墓园里的恐怖 1933/35 竹子 共作 较短 The Horror in the Museum 蜡像馆惊魂 1932.10 竹子 共作 The Hound 猎犬 1922.09 cimar Hypnos 休普诺斯 1922.03 玖羽 Ibid 伊比德 1928 玖羽 恶搞 In the Vault 地窖中 1925.09.18 竹子 In the Walls of Eryx 厄瑞克斯之墙 1936.01 竹子 The Last Test 最终测试 1927 竹子 The Little Glass Bottle 小玻璃瓶 1897 玖羽 幼年 较短 The Loved Dead 可爱的死者 1923 zimmer The Lurking Fear 潜伏的恐惧 1922.11 玖羽 枪稿 The Man of Stone 石像 1932 Setarium 较短 Medusa's Coil 美杜莎的卷发 1930 竹子 较长 Memory 记忆 1919 玖羽 早期 较短 The Moon-Bog 月之沼 1921.05 Setarium 早期 较短 The Mound 丘 1929-1930 竹子 重要 较长 The Music of Erich Zann 埃里奇·赞之曲 1921.12 竹子 The Mysterious Ship 神秘船 1902 竹子 幼年 较短 The Mystery of the Grave-Yard 墓园之谜 1898 竹子 幼年 较短 The Nameless City 无名都市 1921.01 竹子 The Night Ocean 夜之洋 1936.秋 annshark01 共作 Nyarlathotep 奈亚拉托提普 1920.12 玖羽 早期 较短 Old Bugs 老臭虫 1919 竹子 早期 较短 The Other Gods 蕃神 1921.08.14 玖羽 幻梦境 较短 Out of the Aeons 超越万古 1933 竹子 重要 较长 The Outsider 异乡人 1921 竹子 重要 较短 Pickman's Model 皮克曼的模特 1926 玖羽 重要 The Picture in the House 屋中画 1920.12.12 竹子 早期 Poetry and the Gods 诗与诸神 1920 玖羽 早期 随笔 共作 较短 Polaris 北极星 1918.05 玖羽 早期 幻梦境 较短 The Quest of Iranon 伊拉农的探求 1921.02.28 玖羽 幻梦境 较短 The Rats in the Walls 墙中之鼠 1923.08-09 竹子 重要 A Reminiscence of Dr. Samuel Johnson 回忆塞缪尔·约翰逊博士 1917 竹子 早期 较短 The Secret Cave or John Lees Adventure 隐秘的洞穴，或约翰·李的冒险 1898 竹子 幼年 较短 The Shadow Out of Time 超越时间之影 1934.11-1935.05 竹子 重要 较长 The Shadow Over Innsmouth 印斯茅斯之影 1931.11-12.03 竹子 重要 较长 The Shunned House 畏避之屋 1924.10.16-19 竹子 The Silver Key 银钥匙 1926 竹子 重要 The Slaying of the Monster 诛杀怪物 1933 玖羽 共作 较短 The Statement of Randolph Carter 兰道夫·卡特的供述 1919.12 竹子 早期 较短 The Strange High House in the Mist 雾中怪屋 1926.11.09 玖羽 The Street 道路 1920 玖羽 早期 随笔 较短 Sweet Ermengarde 甜美的艾门嘉德 1917 Setarium 早期 恶搞 较短 The Temple 神殿 1920 玖羽 早期 The Terrible Old Man 可怕的老人 1920.01.28 玖羽 早期 较短 The Thing in the Moonlight 月下之物 1927.11.25(托名) Setarium 共作 较短 The Thing on the Doorstep 门口的东西 1933.08.21-24 竹子 Through the Gates of the Silver Key 穿越银匙之门 1932.10-1933.04 竹子 重要 共作 较长 Till A' the Seas 直至诸海…… 1935.01.01 竹子 共作 The Tomb 坟墓 1917.06 竹子 早期 The Transition of Juan Romero 胡安·罗梅洛的变貌 1919.09.16 玖羽 早期 较短 The Trap 圈套 1931 玖羽 共作 The Tree 树 1920 玖羽 早期 较短 The Tree on the Hill 山上的树 1934.05 竹子 Two Black Bottles 两只黑瓶 1926.07-10 竹子 Under the Pyramids 金字塔下 1924.02-05 竹子 枪稿 The Unnamable 不可名状 1923.09 竹子 The Very Old Folk 远古的民族 1927.11.02 玖羽 较短 What the Moon Brings 月光下 1922.06.05 竹子 较短 The Whisperer in Darkness 暗夜呢喃 1930.02.24-09.26 竹子 重要 The White Ship 白船 1919.11 玖羽 早期 幻梦境 较短 Winged Death 有翼死神 1933 竹子 共作 文章 Notes on Writing Weird Fiction 怪奇小说创作笔记 1934.06 玖羽 Supernatural Horror in Literature 文学中的超自然恐怖 1927 Setarium 重要 较长 资料收集 海中岛屿， 死城拉莱耶，伟大的克苏鲁及其部署长眠于此。 《皮克曼的模特》： 作品中主要讲述的便是从一个欣赏者的角度发现一名画家的作品之惊悚，而在其家中参观时发现了，本以为是幻想作品的作品实际上是写实了一幅令人惊悚的照片，作品与之没有任何区别。 《印斯茅斯之影》： 印斯茅斯这个城镇中的居民在恶魔礁上与异形做出了交易，选择了与之通婚，令后代拥有永生的能力，只是会随着年龄增长，逐渐趋于异形，最终回到海中。而主角的曾祖母便是出自这个通婚后的家族的后代，主角在挖掘家族根源时发现了这个真相，在最终自己也进行变化时，选择回到起源的海中永恒生存。 《墙中之鼠》： 主角将家族的一栋悬崖边的别墅整修后，准备在这里颐养晚年。第一个夜晚，相伴的老猫发现了这栋建筑下隐藏的恐怖，惊醒了主角，主角叫上了同伴，逐渐挖掘真相。在原本的祭坛（祭祀的应该是奈亚拉托提普）下，发现了一个洞穴，在其中是祖先曾经圈养过某种怪物（老鼠？或是邪神之下的某种怪物）的痕迹，食物短缺时，这些老鼠将一切都啃尽。主角在最后受到了奈亚拉托提普的召唤，永远被困在了墙中之鼠的梦之中。 《星之彩》： 来自宇宙的陨石带来的异常，这个陨石会逐渐消失（似乎无法隔绝，暂定空间上具有扩散性质，沉浸到了附近的土地中），这个陨石令着陆周围的一切动植物受到了克苏鲁的影响，令周围的一切都变得异乎寻常，最终导致周围的那家人全部带着恐惧或精神失常而死去。 《克苏鲁的呼唤》： 在调查叔伯遗留下的记录时，发现了带有克苏鲁印象的雕塑、浮雕等等，与警长、学者找到了一个现存的依旧崇拜旧日支配者的邪教，证实了克苏鲁的真实存在，直到当下。 《夜魔》： 布莱克在好奇中进入了星之智慧教徒召唤夜魔的教堂，偶然间完成了召唤的步骤，将夜魔唤醒，逐渐与夜魔合二为一，最终似乎融合之后而离开了。 这部中布莱克在融合时还记录了其他邪神，似乎是进入了那个世界。 《敦威治恐怖事件》： 这部小说中，老沃特雷教导威尔伯通过犹格·索托斯召唤旧日支配者，然而在老沃特雷去世之后，威尔伯没能在图书馆取得所需的完整的《死者之书》，反而死在了那里，导致召唤仪式并不完整，之后，他的孪生兄弟从被关着的家中逃了出来，在山顶祭坛与村落中往返可能试图召唤其父亲旧日支配者，但最终被来自图书馆的三个阿卡姆人以破译出的咒语送回了世界之外。 《丘》： 登上土丘进行挖掘的人便会消失，可能能够带着邪神的见闻而带着不同的概念神智不健全地回来，也可能永远回不来。 洪水将老一代洗净，没有进来的，没有出去的。 伟大的图鲁——阿撒托斯——奈亚拉托提普——等待着，等待着 在传说中，那是一个可怖的存在，早在地球尚且年轻还未完全成形之时，它就已经从群星之间降临到了大地上 地下之人居住在撒托的巨大城市之中，其生物结构与人类存在两百万年之间的差距，所以他们能够永生，而外来的人类学习了也很难完全做到，另外，他们已经可以做到物质与非物质之间的转化（衍生出一种投射能力，类似于占卜？可以与目标建立联系，获得到一些信息（神秘度倾注））。 这里有一点可以看到比较好奇，记录者，对于未知动物（这里是还设定了一个显然的非自然造物），因为无知而恐惧。那现代的人会恐惧吗？还是只是会萌发好奇心呢？猜想我自己如果遇到应该是会恐惧的。 撒托古亚：蟾蜍样 图鲁: 章鱼样 伊格: 蛇样 莎布 尼古拉斯: 万物之母 这篇在开头设立了一个现象，文中从多个角度发现一个真相，而文末将开头的现象给彻底解密，悬疑类小说的通常表达方式，这种比较吸引读者，之前看的几篇综觉得有些坑并没有解释清楚，写的似懂非懂。 《屋中画》: 又是一个与阿卡姆相关的地点的故事。 仅仅只是在一个孤僻的地带遭遇了食人者的故事。 根据译者所说，这个故事中才是第一次提到阿卡姆这个背景，即洛夫克拉夫特在小说最常用的背景——那个想象中的新英格兰世界，阿卡姆以及密斯卡托尼克河。 这个背景后来也经常被人们称为“Lovecraft Country”。在此之后，直到他去世前，洛夫克拉夫特用这个背景写了一连串著名的故事。例如《敦威治恐怖事件》、《印斯茅斯的阴霾》、《魔宴》、《魔女屋中之梦》等等。然后，随着德雷斯的进一步扩充，这片充满了孤僻村落、阴森人群以及黑暗秘密的新英格兰世界终于成为了克苏鲁神话中的标志之一。 《埃里奇·赞之曲》： 这里面有一个隐晦的暗示：关于奥斯尔路的名字，在英文小说中是the Rue d’Auseil. 这是个法语词，其中Rue d’的意思是路，而Auseil其实是个短语 au seil意思是“门槛”。 这个故事中隐含的就是在一堵墙外可能就是另一个世界的意思吧。 《异乡人》: 一个尚且以为自己是人类的已然化身为其他人眼中的怪物的寻找光明却意识到自身的历程。 《门外之物》: 同样是阿卡姆与印斯茅斯的背景下的故事，来自印斯茅斯家族的亚西纳控制了爱德华的身体，通过献祭给莎布 尼古拉斯，最终将以爱德华的身体重生，而爱德华将不得不在亚西纳的身体里。 传统鬼怪故事，按照译者的意思，似乎这部作品并不受欢迎，由于缺乏了那种洛夫克拉夫特独有的宇宙观（我还不太能理解这个宇宙观）。 《达贡》：（这个还是玖羽翻译的好，克苏鲁那本书里的翻译用的词不太恰当感觉） 设定了一个海中的恐怖，之后就被所谓的海中半人半鱼之神达贡给缠身了。 《关于已故亚瑟·杰尔敏及其家系的事实》： 感觉是类似印斯茅斯的一个背景下的，设定是亚瑟的曾祖父与一个类人猿女神(体毛稀少，几近人类)结合，亚瑟返祖，与那位类人猿女神极度相似。 《奈亚拉托提普》： 噩梦的记述作。 《可怕的老人》: 强盗遭遇超常怪物就此Over的故事。 2017.08.26 买了《克苏鲁神话》那本电子书，看了下，感觉翻译没有 《黑暗中的低语》: 这个是在新出的《克苏鲁神话》这本书里收录的，引领读者逐渐去探寻克苏鲁的世界，埃克利最终还是没能逃脱，而教授在被米戈蒙骗之后成功逃脱将经历记述了下来。 《自彼界而来》: 乍一看前几段时，有一种接下来的故事可能就是在对自己摧残式地实验中偶然接触到了伟大的存在(在那个时代可能辐射就是最大的幻想诱因)，而后就将其召唤或是被附身之类了。 结果倒也相近，进入了一个可以类似称为高维的状态，见到了奇妙的物种，主角过于自信，拒绝了克劳福德，结束了这段神奇的故事，最终却发现自己还是错了。 《神殿》: 潜艇上可能因为异常导致船员心理异常(受到了伟大存在的召唤)，最终只有上尉在下沉中见到了传说中的“亚特兰蒂斯”，但潜艇里失去了光源，上尉逐渐也开始进入异常状态，似乎见到了之前死去的船员的尸体。 《猎犬》: 盗墓的故事，猜想是盗墓者在某个古墓唤醒了一个恐怖的存在？ 盗墓者拿走了一个与《死灵之书》有关的护身符，后面的结果可以想象了。最终选择逃往死之世界。 《乌撒之猫》: 乌撒的杀猫者终受到了超能者的报复的结局。 《无名之城》： 参考资料: (克苏鲁神话新手入门书单/豆瓣)[https://www.douban.com/note/581689161/]","categories":[{"name":"随想","slug":"thinking","permalink":"https://sean10.github.io/categories/thinking/"}],"tags":[{"name":"克苏鲁","slug":"克苏鲁","permalink":"https://sean10.github.io/tags/%E5%85%8B%E8%8B%8F%E9%B2%81/"},{"name":"科幻","slug":"科幻","permalink":"https://sean10.github.io/tags/%E7%A7%91%E5%B9%BB/"}]},{"title":"原计划更换markdown渲染引擎","slug":"更换markdown渲染引擎","date":"2017-07-01T09:01:14.000Z","updated":"2023-03-18T15:11:14.874Z","comments":true,"path":"2017/07/01/更换markdown渲染引擎/","link":"","permalink":"https://sean10.github.io/2017/07/01/%E6%9B%B4%E6%8D%A2markdown%E6%B8%B2%E6%9F%93%E5%BC%95%E6%93%8E/","excerpt":"","text":"前两天在写复习笔记的时候，发现渲染出的mathjax公式不像本地预览时显示的那样正常，含有_符号的都被渲染成了&lt;em&gt;标记，导致公式显示异常。网上推荐更换渲染引擎hexo-renderer-krame，虽然这个是fork出来特地解决了hexo-renderer-marked的这个问题的，但是同样，也修改了markdown的一些基本语法，在写行内公式时，就需要在$$外套上一层`符号，而我本地的预览使用的渲染引擎同样也会需要修改，这就比较麻烦了。 再进行了搜索，发现了一个据说非常强大的引擎pandoc，不过我在安装后，始终遇到以下错误。 INFO Start processing FATAL Something's wrong. Maybe you can find the solution here: http://hexo.io/docs/troubleshooting.html Error: [pandoc warning] YAML header is not an object \"source\" (line 67, column 1) at ChildProcess. (/Users/sean10/Code/sean10.github.io/node_modules/hexo-renderer-pandoc/index.js:73:20) at emitTwo (events.js:106:13) at ChildProcess.emit (events.js:191:7) at maybeClose (internal/child_process.js:877:16) at Process.ChildProcess._handle.onexit (internal/child_process.js:226:5) 经过搜查，这似乎属于pandoc解析时的错误，找到了以下类似内容。 See http://johnmacfarlane.net/pandoc/README.html#yaml-metadata-block There must be something in your document that looks like a YAML metadata block, but isn't. Such a block would start with---on a line by itself and end with---or...on a line by itself. The line numbers in the error message refer to lines inside the metadata block, not to lines of the document. By the way, you can turn off YAML metadata block parsing entirely by putting 1--from markdown-yaml_metadata_block in your pandoc command line. 不过这个解决方法并没能解决问题，我换了一个思路。 后来想了想，是否可能是在渲染文章头部YAML格式时出现错误，导致后续的markdown就无法渲染了，所以可能是在文章内容上出现了问题，但是这个error信息没能显示具体文件，又没有日志，我决定二分排查是哪篇的错误。 很快就发现了，是最近写的Unix复习那篇的错误，在第67行，没有意识到错误所在，经过测试，发现问题是在于markdown的语法上，pandoc语法要求标题#前必须插入一空行，修改后终于成功渲染了。真是不容易。 Extension: blank_before_header 始 markdown 語法在標題之前並不需要預留空白行。Pandoc 則需要（除非標題位於文件最開始的地方）。這是因為以 # 符號開頭的情況在一般文字段落中相當常見，這會導致非預期的標題。例如下面的例子： I like several of their flavors of ice cream: 1#22, for example, and #5. 参考文献 parse yaml","categories":[{"name":"随想","slug":"thinking","permalink":"https://sean10.github.io/categories/thinking/"}],"tags":[{"name":"hexo","slug":"hexo","permalink":"https://sean10.github.io/tags/hexo/"},{"name":"markdown","slug":"markdown","permalink":"https://sean10.github.io/tags/markdown/"}]},{"title":"计算机系统结构复习note","slug":"计算机系统结构复习note","date":"2017-06-28T07:58:32.000Z","updated":"2023-03-18T15:11:14.905Z","comments":true,"path":"2017/06/28/计算机系统结构复习note/","link":"","permalink":"https://sean10.github.io/2017/06/28/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%B3%BB%E7%BB%9F%E7%BB%93%E6%9E%84%E5%A4%8D%E4%B9%A0note/","excerpt":"仅供参考~ 看到了，没记住是最悲剧的……","text":"仅供参考~ 看到了，没记住是最悲剧的…… 第一章 基础知识 系统结构的相关概念 计算机系统的层次结构概念 由硬件、软件和固件（被固化在ROM中的微程序）组成的复杂系统。 按语言功能（非组成）划分成多级层次结构: 硬件层(物理机):如果问几层的话还是去除L0硬件层 第0层：硬件 第1层：微程序（固件） 由微程序控制实现，逻辑程序员用微指令集编写，微程序由固件／硬件来解释。 第2层：机器语言机器(软硬件界面) 机器语言是指令系统，程序通过中央处理机由L1级微程序或L0级硬联逻辑进行解释 虚拟机: 第3层：操作系统机器 运行在L2级的操作系统级解释程序。 包括传统的机器指令(如算术、逻辑运算)及操作系统级指令(打开、关闭文件、读/写文件等) 与L2级指令相同由微程序解释 第4层：汇编语言机器 汇编语言程序，负责将上级语言翻译成L2和L3级语言，再由机器执行。完成汇编语言翻译的程序称为汇编程序 第5层：高级语言机器 语言：如C、C++、FORTRAN等。高级语言程序一般由称为编译程序的翻译到L4或L3级上。个别高级语言程序如Python等,采用解释方法实现，即用解释程序翻译到L4或L3级。 第6层：应用语言机器 语言：为满足某种用途而专门设计的面向问题的应用语言（使用超级计算机时优化用的语言吧)，由应用程序包翻译到L5级上 广义机器、虚拟机器、透明性、编译、解释 广义机器: 执行和存储程序的算法和数据结构的集合体 虚拟机器: 由软件实现的机器 透明性: 在计算机技术中，一种本来存在的事物或属性，但从某种角度看又好像不存在的概念称为透明性。通常底层机器的属性对于高层机器程序员来说是透明的。 编译: 转换程序将高一级机器上程序转换为低一级机器上的等效程序，然后在低一级机器上运行，实现程序的功能。 解释: 把高一级机器上的每一条语句，转换为低级机器上的一段等效程序并执行。执行完后，去高一级机器再取下一条语句或指令执行，如此反复，直到解释执行完整个程序。 计算机系统结构、组织和实现 计算机系统结构: 计算机系统的软、硬件的界面 计算机组成: 计算机系统结构的逻辑实现 计算机实现: 计算机组成的物理实现 具有相同系统结构的计算机可以采用不同的物理组成。 同一种物理组成又可以采用不同的计算机实现。 计算机系统分类方法 Flynn 分类法 按指令流和数据流的组织方式分类 * 单指令流单数据流（SISD）计算机系统：传统顺序处理计算机 * 单指令流多数据流（SIMD）计算机系统：阵列处理机 * 多指令流单数据流（MISD）计算机系统：未定 * 多指令流多数据流（MIMD）计算机系统：多处理机 系统分析技术 大概率事件优先原理 优先加速使用频率高的部件 此原理适用于资源分配、减灾防灾等 Amdahl定律、加速比定义 Amdahl定律可计算因改进某些部件而获得的系统性能的加速比, 也可用来确定系统中对性能限制最大的部件 程序访存的局部性原理 程序执行时所访问的存储器地址分布不是随机的 常用经验规则: 程序执行时间的90%都是在执行程序中10%的代码 可以根据程序最近的访问情况来比较准确地预测将要访问的指令和数据。凡是涉及数据重用的地方都可能会用到它。 CPU性能公式 CPU时间 \\[ CPU_{时间} = 执行程序所需的时钟周期数 \\times 时钟周期时间 \\] 时钟周期时间t(ns)是系统时钟频率的倒数 每条指令执行的平均时钟周期数CPI \\[CPI = \\frac{执行程序所需的时钟周期数}{IC}\\] IC：所执行的指令条数 则CPU时间可以写成下式 \\[CPU时间 = IC ×CPI ×时钟周期时间 \\] 性能评价标准 性能指标（CPU时间， CPI， MIPS,MFLOPS) MIPS 每秒百万条指令数 性能比较 执行时间 吞吐率 实例 1.11 假设浮点数指令FP指令的比例为30%，其中浮点数平方根FPSQR占全部指令的比例为4%, FP操作的CPI为5，FPSQR操作的CPI为20, 其他指令的平均CPI为1.25.现有两种改进方案，第一种是把FPSQR操作的CPI减至3, 第二种是把所有的FP操作的CPI减至3, 试比较两种方案对系统性能的提高程度。 答: 改进之前，系统指令平均时钟周期CPI为 \\[CPI=\\sum{(CPI_i \\times \\frac{I_i}{I_c})}=(5 \\times 30 % )+(1.25\\times70 %) = 2.375\\] 如果采用A方案：FPSQR操作的CPI减至3，则整个系统的平均时钟周期数为: \\[CPI_A=CPI-(CPI_{FPSQR}-CPI_{FPSQR}^{&#39;}) \\times 4 %=2.375-(20-3) \\times 4 %=1.695\\] 如果采用B方案：把所有的FP操作的CPI减至3，则整个系统的平均时钟周期数为： \\[CPI_B=CPI-(CPI_{FP}-CPI_{FP}^{&#39;})\\times4 %=2.375-(5-3)\\times30 %=1.775\\] 从降低整个系统的指令平均时钟周期数的程度来看，方案A要优于B。 另外，分别计算两种方案的加速比: \\[S_A=\\frac{改进前CPU的执行时间}{A的CPU执行时间}=(I_C\\times时钟周期\\times CPI)/(I_c \\times 时钟周期\\times CPI_A)=\\frac{CPI}{CPI_A}\\] \\[S_A=\\frac{2.375}{1.695}=1.4\\] \\[S_B=\\frac{2.375}{1.775}=1.34\\] 由此也可知，方案A优于方案B。 第三章 流水线技术 流水线的概念： 静（动）态流水线 单（多）功能流水线 线性流水线 流水线的各段串行连接，没有反馈回路。数据通过流水线中的各段时，每一个段最多只流过一次 非线性流水线 流水线中除了有串行的连接外，还有反馈回路 单功能与多功能流水线 （按照流水线所完成的功能来分类） 单功能流水线：只能完成一种固定功能的流水线。 多功能流水线：流水线的各段可以进行不同的连接，以实现不同的功能。 例： 多功能流水线：加、乘流水线 流水线表示方法--时空图 、连接图 流水线特点：五段流水线（访存部件ME, 转移EX) ALU LOAD/STORE BRANCH(转移) IF 取指 ID 译码，读寄存器堆 EX 执行 计算访存有效地址 计算转移目标地址，设置条件码 MEM (空操作) 访问存储器(读或写) 若条件成立，将转移目标地址送PC WB 结果写回寄存器堆 将读写的数据写入寄存器堆 (空操作) 性能指标 ： 吞吐率、加速比、效率、 最佳段数 流水线相关与冲突及解决办法 数据相关（真数据相关）/名相关/控制相关 结构冲突、数据冲突、控制冲突： 数据冲突解决办法 控制冲突解决办法 多功能流水线时空图 吞吐率：在单位时间内流水线所完成的任务数量或输出结果的数量 瓶颈问题 加速比：完成同样一批任务，不使用流水线所用的时间与使用流水线所用的时间之比。 流水线的效率：流水线中的设备实际使用时间与整个运行时间的比值，即流水线设备的利用率( 效率) 静态处理分支指令的基本方法： * 预测成功 * 延迟分支 降低流水线分支损失的方法有哪些？ （1）在流水线中尽早判断出分支转移是否成功； （2）尽早计算出分支转移成功时的PC值（即分支的目标地址） * “冻结”或“排空”流水线的方法 * 预测分支失败 * 预测分支成功 * 延迟分支 请对延迟分支办法中的三种调度策略进行评价。 1. 从前调动：分支必须不依赖于被调度的指令，总是可以有效提高流水线性能。 2. 从目标处调度：若分支转移失败，必须保证被调度的指令对程序的执行没有影响，可能需要复制被调度指令。分支转移成功时，可提高流水线性能。但由于复制指令，可能加大程序空间。 3. 从失败处调度：若分支转移成功，必须保证被调度的指令对程序的执行无影响。分支转移失败时，可提高流水线性能。 预测分支 命中Cache似乎不考 第四章 向量处理机 向量处理方法 横向处理: N次数据相关、2N次功能相关 纵向处理: 1次数据相关、1次功能相关 当向量长度超过寄存器长度N时，可分组处理 纵横处理: 组内纵向处理, 组间横向处理 适合\"寄存器-寄存器结构\"工作的向量处理机 向量流水处理机结构 存储器-存储器结构：纵向处理 占据一般存储器的3倍带宽，一个时钟周期内读入2个操作数并写回1个结果 延迟缓冲器 寄存器-寄存器结构：纵横处理 支持流水线链接技术 不遭遇向量Vi冲突和功能部件冲突，就都能并行工作 提高向量处理机性能的方法 多个功能部件的并行操作 链接技术 WD相关 链接技术：具有先写后读相关的两条指令，在不出现功能部件冲突和Vi冲突的情况下，可以把功能部件链接起来进行流水处理，以达到加快执行的目的。 空间方面约束条件 向量寄存器使用冲突 源寄存器冲突: 同时只能提供一个 结果寄存器冲突: 同时只能写一个 功能部件冲突 时间方面约束条件 前一条指令的第一个结果分量送入寄存器的那一个时钟周期方可链接 执行时间和寄存器长度必须相同 顺序执行时，一个向量的所有操作数执行完方才进行下一个向量的处理。而链接执行，就可以在一个向量的一个操作数得到结果后立即获得，对下一个向量立即进行处理。这样就可以免去等待第一个向量所有操作数完成运算的过程。 分段开采(循环开采) 流水线启动时间 多处理机系统结构 向量处理机性能的主要参数 一条向量指令的处理时间 执行一条向量长度为n的向量指令所需的时间: \\[T_{vp} = T_{s} + T_{e} + (n-1)T_{c}\\] \\(T_s\\) : 流水线的建立时间为了使处理部件流水线能开始工作所需要的准备时间。 \\(T_e\\) : 向量流水线的通过时间第一对向量元素通过流水线并产生第一个结果所花的时间。 \\(T_c\\) : 流水线的时钟周期时间 一条指令 上式转换为时钟周期个数 \\[T_{vp} = [s + e + (n-1)]T_c\\] 令 \\(T_{start} = s + e -1\\) , 则 \\[T_{vp} = (T_{start} + n)T_c\\] \\(T_{start}\\) : 向量指令的启动时间。产生第一个结果的前一个时钟周期数。 每秒多少个浮点运算结果（MFLOP或一个浮点运算的时间） \\[MFLOPS = \\frac{I_{FN}}{T_p \\times 1000000}\\] \\(I_{FN}\\) : 程序中浮点运算总次数 \\(T_p\\) : 执行程序时间 一组向量指令的处理时间 影响因素: 向量的长度 向量操作之间是否存在流水功能部件的使用冲突以及数据的相关性 数据的相关性 编队: 能在一个时钟周期内一起开始执行的几条向量指令 流水功能部件冲突 \\(V_i\\) 冲突 数据的相关性 编队后时间计算公式 \\[T_{all} = \\sum_{i = 1}^{m}{T_{vp}^{(i)}}\\] 当一个编队是由若干条指令组成时，其执行时间就是该编队中各指令的执行时间的最大值 一组向量指令、m个编队的处理时间 \\[T_{all} = \\sum_{i = 1}^{m}{T_{vp}^{(i)}} = \\sum_{i = 1}^{m}{(T_{start}^{(i)} + n)T_c} = (\\sum_{i = 1}^{m}{T_{start}^{(i)} + mn)}T_c = (T_{start} +mn)T_c\\] \\(T_{start}^{(i)}\\): 第i编队中各指令的启动时间的最大值 表示成时钟周期个数 \\[T_{all} = T_{start} + mn\\] 分段开采时一组向量指令的总执行时间(复习课件中未作为重点) 向量流水线的最大性能 \\(R_{\\infty}\\) 例题 最大性能例题 半性能向量长度 \\(n_{\\frac{1}{2}}\\) 半性能向量长度 \\(n_{\\frac12}\\) 是指向量处理机的性能为其最大性能的一半时所需的向量长度。 \\(n_{\\frac12}\\) 小表示流水线建立的时间少。 \\(n_{\\frac12}\\) 越小， 对给定的向量处理，流水线性能越好。反映为建立流水线而导致的性能损失。 半性能长度计算 长度向量临界值 \\(n_v\\)(同样不是重点) 实例 题目补充：各功能部件的启动时间为：取数和存数部件为12个时钟周期、乘法部件为7个时钟周期，执行标量代码的开销 \\(T_{loop} = 15\\) 个时钟周期，对一个向量元素执行一次操作的时间Tg=一个时钟周期。 第五章 指令集并行 指令级并行度ILP 指令间存在的一种固有的并行性，计算机可以并行执行两条或两条以上的指令。 开发指令级并行度可以降低指令执行的平均周期数CPI 开发ILP的方法可以分为两大类 主要基于硬件的动态开发方法（动态调度） 记分牌动态调度算法 Tomasulo算法 基于软件的静态开发方法（静态调度） 记分牌(Scoreboard)算法 基本思想:记分牌硬件实现了对指令的动态调度。支持乱序执行，在没有结构冲突时尽早地执行没有数据冲突的指令，使多条指令同时处于执行阶段。 记分牌维护3张表： * 指令状态表 记录正在执行的各条指令已经到了哪一段 * 功能部件状态表 记录各个功能部件的状态。每个功能部件有一项，每一项由以下9个字段组成： * Busy：忙标志，指出功能部件是否忙。初值为“no”； * Op：该功能部件正在执行或将要执行的操作； * \\(F_i\\)：目的寄存器编号； * \\(F_j\\)，\\(F_k\\)：源寄存器编号； * \\(Q_j\\)，\\(Q_k\\)：指出向源寄存器 \\(F_j\\)、 \\(F_k\\)写数据的功能部件 ； * \\(R_j\\)，\\(R_k\\)：标志位，“yes”表示 \\(F_j\\)，\\(F_k\\) 中的操作数就绪且还未被取走。否则就被置为“no”。 结果寄存器状态表 指出哪个功能部件将把结果写入该寄存器 为了乱序执行，译码段ID分解成流出和读操作数 流出：指令译码，检查是否存在结构冲突。 读操作数：等待数据冲突消失，然后读操作数。 第3章的5段流水线局限性:只能按序流出(In-order Issue)和按序执行(In-order Execution) 每条指令的执行过程分为4段（主要考虑浮点操作） * 流出：如果当前流出指令所需的功能部件空闲，并且所有其他正在执行的指令的目的寄存器与该指令的不同，就向功能部件流出该指令，并修改记分牌内部记录表。 解决了WAW冲突 * 读操作数： 监测源操作数的可用性，如果数据可用，就从寄存器中读出源操作数并开始执行。 解决了RAW冲突，导致乱序执行。 * 执行： 取到操作数后，功能部件开始执行。当产生出结果后，就通知记分牌它已经完成执行。 在浮点流水线中，这一段要占用多个时钟周期。 * 写结果 执行前会检测是否存在WAR冲突 WAR冲突可能发生在以下情况: 1. 前面的某条指令（按顺序流出）还没有读取操作数；而且,其中某个源操作数寄存器与本指令的目的寄存器相同。 2. 在这种情况下，记分牌必须等待，直到该冲突消失。 记分牌MIPS处理器基本结构 性能受限(不考) * 程序代码中可开发的并行性，即是否存在可以并行执行的不相关的指令。 * 记分牌的容量（寄存器大小？） 记分牌的容量决定了流水线能在多大范围内寻找不相关指令。流水线中可以同时容纳的指令数量称为指令窗口 * 功能部件的数目和种类 功能部件的总数决定了结构冲突的严重程度 * 反相关和输出相关 它们引起记分牌中WAR和WAW冲突。 Tomasulo算法 基本思想: * 通过分散控制处理数据相关和乱序执行。记录和检测指令相关，将发生RAW的可能性减少到最小 * 通过寄存器换名(通过保留站和流出逻辑实现)来消除WAR冲突和WAW冲突 结构图 保留站：保存已经流出并等待到本功能部件执行的指令，在保留站通过流出逻辑来完成的寄存器换名（顺序流出，乱序执行） 公共数据总线CDB :所有功能部件计算结果都送到CDB，由它把这些结果直接送到各个需要该结果的地方（乱序完成） 具体算法（可选，暂时不看） 相关与流水线冲突 相关: 程序中指令之间的一种相互依赖关系。是程序固有的属性。 流水线冲突: 由于相关的存在，使得流水线指令流中的下一条指令不能在指定的时钟周期执行。 三种相关: * 数据相关 * 名相关 * 控制相关 三种流水线冲突: * 结构冲突 * 数据冲突 * 控制冲突 ##### 数据相关及其处理技术(其余相关都不是重点) 理想流水线的CPI加上各类停顿的时钟周期数： \\[CPI_{流水线} = CPI_{理想} + 停顿_{结构冲突} + 停顿_{数据冲突} + 停顿_{控制冲突}\\] IPC：Instructions Per Cycle(每个时钟周期完成的指令条数) \\[CPI = \\frac{1}{IPC}\\] 动态分支预测技术 分支历史表BHT 用二进制数10、11、01、00来表示转移预测状态的转换图 BHT状态转换 从图中可以看出，只有连续两次预测错误，才会改变对分支去向的预测 优点: 转移预测提前到取指阶段。预测正确，则没有延迟损失。 缺点:仅提供转移目标指令信息,未提供转移目标指令地址信息。 所以它只有在以下情况下才有用: 判定分支是否成功所需的时间大于确定分支目标地址所需的时间。在前述5段流水线中，由于判定分支是否成功和计算分支目标地址都是在ID段完成的，所以BHT方法不会给该流水线带来好处。（用BHT时，上一条指令的EX在执行，分支预测的判定和取指是同时在进行的，判定时间(上一条指令的执行时间)更长时才可以保证存在开销减少的价值，否则预测成功，也是需要多花一个周期来进行译码） 预测不正确，则清除指令预取(队列)缓冲器。会产生延迟时间损失。 BHT方法可以同 I-cache（指令cache）结合起来 对于前述5段流水线来说，BHT方法是在ID段对BHT进行访问，所以在ID段的末尾，能够获得分支目标地址(在ID段计算出)、顺序下一条指令地址以及预测的结果。如果能再提前一拍，即在IF段就知道这些信息，那么分支开销就可以减少为0.BTB能够实现这一点。 （BHT方法不像静态分支预测技术会直接加载预测的分支指令地址，所以导致即便预测成功也需要一个时钟周期来取得地址） 分支目标缓冲器BTB（有时也称为分支目标Cache） 将分支成功的分支指令的地址和它的分支目标地址都放到一个缓冲区中保存 缓冲区以分支指令的地址作为标识 得到转移目标指令地址信息 结构图 流水线各阶段进行的操作 超标量处理机 在每个时钟周期内流出多条指令， CPI＜1 在每个时钟周期流出的指令条数不固定,但有上限，依代码的具体情况而定。 设这个上限为n，就称该处理机为n-流出(发射)。 可以通过编译器进行静态调度，也可以基于Tomasulo算法进行动态调度。 超流水线处理机 将每个流水段进一步细分，这样在一个时钟周期内能够分时流出多条指令。这种处理机称为超流水线处理机。 对于一台每个时钟周期能流出n条指令的超流水线计算机来说，这n条指令不是同时流出，而是每隔1/n个时钟周期流出一条指令。 实际上该超流水线计算机的流水线周期为1/n个时钟周期。 超长指令字（VLIW)处理机 在每个时钟周期流出的指令条数是固定的，这些指令构成一条长指令或者一个指令包。 指令包中，指令之间的并行性是通过指令显式地表示出来的。 指令调度是由编译器静态完成的。 流水线时空图必考。 超标量流水线调度策略及时空图 1.按序流出按序完成；2.按序流出无序完成；3.无序流出 第1条是无调度 第2条是动态调度，考上述的记分牌算法吧 第3条可能是考多流出技术 实例 记分牌算法中，记分牌中记录的信息由哪三部分构成 答: 指令状态表、功能部件状态表、结果寄存器状态表 动态分支预测技术 5.6 给出采用分支目标缓冲器(BTB)后，在流水线三个阶段(IF段、ID段、EX段）所进行的相关操作有哪些？ 5.8 分支延迟 5.9 画超标量处理机时空图 第九章 互联网络 互连网络相关概念 分类 静态互联网络 动态互联网络 总线网络 多级互连网络 交叉开关网络 三大要素：互连结构、开关元件、控制方式 特征 拓扑结构 静态 动态 控制策略 集中式 分布式 定时方式 同步 异步 交换方法 线路交换 分组交换 互联函数 基本互联函数 恒等函数 交换函数 实现二进制地址编码中第k位互反的输入端与输出端之间的连接。 主要用于构造立方体和各种超立方体互连网络。 它共有 \\(n = log_{2}{N}\\) 种互联函数。（N为结点个数） 例子： 当N＝8时，n＝3，可得到常用的立方体互连函数: \\[Cube_{0}(x_{2}x_1x_0) = x_2x_1\\overline{x_0}\\] \\[Cube_{1}(x_{2}x_1x_0) = x_2\\overline{x_1}x_0\\] \\[Cube_{2}(x_{2}x_1x_0) = \\overline{x_2}x_1x_0\\] 均匀洗牌函数 将输入端分成数目相等的两半，前一半和后一半按序一个隔一个，从头依次与输出端相连，类似洗牌方式 \\[\\sigma(x_{n-1}x_{n-2}\\cdots x_1x_0) = x_{n-2}x_{n-3}\\cdots x_1x_0x_{n-1}\\] 逆均匀洗牌函数 将输入端的二进制编号循环右移一位而得到所连接的输出端编号。 蝶式函数 蝶式互连函数：把输入端的二进制编号的最高位与最低位互换位置，便得到了输出端的编号 \\[\\beta(x_{n-1}x_{n-2}\\cdots x_2x_1x_0) = x_0x_{n-2}\\cdots x_1x_{n-1}\\] 均匀洗牌，蝶式函数不能单独实现任意结点间互连。它们与交换函数多级组合是构成复杂多级网络的基础 反位序函数 将输入端二进制编号的位序颠倒过来求得相应输出端的编号。 \\[\\rho(x_{n-1}x_{n-2}\\cdots x_1x_0) = x_0x_1\\cdots x_{n-2}x_{n-1}\\] 移数函数 将各输入端都错开一定的位置（模N）后连到输出端。 \\[\\alpha(x) = (x\\pm k)mod N\\] \\[1\\leqslant x\\leqslant N-1, 1\\leqslant k\\leqslant N-1\\] PM2I移数函数(重点) 该函数又称为“加减 \\(2^i\\) ”函数 \\[ PM2\\_{+i}(x) = (x +2^i)mod N\\] \\[ PM2\\_{-i}(x) = (x -2^i)mod N\\] \\[ 1\\leqslant x\\leqslant N-1, 1\\leqslant i\\leqslant n-1, n=log\\_2N\\] PM2I共有2n个互联函数(怎么算出来的?) 实质为1,2,4个环型网（环形网是什么） 移数函数可构成环型网(单向环网、双向环网)、方格网、移数网 互联网络的结构参数 网络参数 : 网络规模、 结点度、 距离、直径，等分宽度（重点) 网络规模N：网络中结点的个数。 结点度d：与结点相连接的边数（通道数），包括入度和出度。 进入结点的边数叫入度。 从结点出来的边数叫出度。 结点距离：对于网络中的任意两个结点，从一个结点出发到另一个结点终止所需要跨越的边数的最小值。 网络直径D：网络中任意两个结点之间距离的最大值。 网络直径应当尽可能地小。 等分宽度b：把由N个结点构成的网络切成结点数相同（N/2）的两半，在各种切法中，沿切口边数的最小值。 线等分宽度：B＝b×w 其中：w为通道宽度（用位表示） 该参数主要反映了网络最大流量。 互联网络的性能指标 评估互连网络性能的两个基本指标：时延和带宽 * 通信时延 指从源结点到目的结点传送一条消息所需的总时间 * 软件开销：在源结点和目的结点用于收发消息的软件所需的执行时间 * 通道时延：通过通道传送消息所花的时间。 * 选路时延：消息在传送路径上所需的一系列选路决策所需的时间开销 * 竞争时延：多个消息同时在网络中传送时，会发生争用网络资源的冲突。为避免或解决争用冲突所需的时间就是竞争时延。 * 网络时延 通道时延与选路时延的和 * 端口带宽 对于互连网络中的任意一个端口来说，其端口带宽是指单位时间内从该端口传送到其他端口的最大信息量。 * 聚集带宽 网络从一半结点到另一半结点，单位时间内能够传送的最大信息量。 * 等分带宽 与等分宽度对应的切平面中，所有边合起来单位时间所能传送的最大信息量。 互联网络 典型互联网络:立方体型 和Illiac网，Omega网络（混洗函数）（重点） ##### 典型静态互联网络 * 线性阵列 * 环和带弦环 * 循环移数网络 * 树形和星形 * 胖树形 * 网格形和环网形 * Illiac网络 * 超立方体 * 带环n-立方体 * k元n立方体 动态互联网络 由交换开关构成的互联网络，可按运行程序的要求改变网络的连接状态 特点： * 网络中开关元件可以控制（有源）。 * 链路可通过设置开关的状态来重构。 * 网络边界上的开关元件可与处理机相连。 总线网络 交叉开关网络 多级互联网络的构成 MIMD和SIMD计算机都采用多级互连网络MIN（Multistage Interconnection Network） 一种通用的多级互连网络 * 由a×b开关模块和级间连接构成的通用多级互连网络结构 * 每一级都用了多个a×b开关 * 相邻各级开关之间都有固定的级间连接 各种多级互连网络的区别在于所用开关模块、控制方式和级间互连模式的不同。 * 控制方式：对各个开关模块进行控制的方式。 * 级控制：每一级的所有开关只用一个控制信号控制，只能同时处于同一种状态。 * 单元控制：每一个开关都有一个独立的控制信号，可各自处于不同的状态。 * 部分级控制：第i级的所有开关分别用i＋1个信号控制，0≤i≤n－1，n为级数。 * 常用的级间互连模式 * 均匀洗牌、蝶式、多路洗牌、纵横交叉、立方体连接等 多级立方体网络 多级立方体网络包括STARAN网络和间接二进制n方体网络等。 * 两者仅在控制方式上不同，在其他方面都是一样的。 * 都采用二功能（直送和交换）的2×2开关。 * 当第i级（ \\(0\\leqslant i\\leqslant n-1\\) ）交换开关处于交换状态时，实现的是 \\(Cube_i\\) 互连函数。 一个N输入的多级立方体网络有 \\(log_2N\\) 级，每级用 \\(\\frac N2\\) 个2×2开关模块，共需要 \\(log_2N\\times\\frac {N}{2}\\) 个开关。 一个8个入端的多级立方体网络 STARAN网络采用级控制和部分级控制。 * 采用级控制时，所实现的是交换功能； * 采用部分级控制时，则能实现移数功能。 间接二进制n方体网络则采用单元控制。 * 具有更大的灵活性。 Omega网络 一个8×8的Omega网络 * 每级由4个4功能的2×2开关构成 * 级间互连采用均匀洗牌连接方式 一个N输入的Omega网络（重点） * 有 \\(log_2N\\) 级，每级用 \\(\\frac N2\\)个2×2开关模块，共需要 \\(\\frac N2log_2{N}\\) 个开关。 * 每个开关模块均采用单元控制方式。 * 不同的开关状态组合可实现各种置换、广播或从输入到输出的其它连接。 动态互联网络的比较 消息传递机制（重点） 当源结点和目的结点之间没有直接的连接时，消息需要经过中间的结点进行传递。寻径就是用来实现这种传递的通信方法和算法。有的称之为路由 路由选择和消息传递方法式: 线路交换和包交换（存储转发，虚拟直通、虫孔方式） * 线路交换：在传递信息之前，先建立一条从源结点到目的结点的物理通路( 所需时间 Lt ×（D+1）/B)，然后再传递信息( 所需时间 L/B) 。包经中间结点时,包无需存储 * 优点：包经中间结点时,包无需存储，实际通信时间较短，使用缓冲区少. 适合于具有动态和突发性的大规模并行处理数据的传送。 * 缺点： 1. 物理通道非共享。传输过程中通道一直占用。 2. 若频繁建立源到目的结点的通路，时间开销大 * 存储转发：最简单的分组交换方式。 * 存储转发中，包是信息传递的基本单位。包从源结点经过一系列中间结点到达目的结点。 * 要求：包经过的每个中间结点都要设置一个包缓冲器。当一个包到达某个中间结点时，该结点先把这个包全部存储起来，然后在出口链路可用、而且下一个结点的包缓冲器也可用的情况下，传递给下一个结点。 * L为消息包的长度 * 存储转发中网络时延与源和目的地距离成正比. * 第一代多计算机系统常采用存储转发方式 * 缺点： 1. 包缓冲区大，不利于VLSI实现； 2. 网络时延大，与结点距离成正比。 * 虚拟直通: 为减少存储转发中 包存储的时延较大，包不必全部存入缓冲后再做路由判断，只要接收到用作寻径信息（头部），即进行路由选择。 1. 如果结点的输出链路空闲，包立即转送到下一个结点。如果整个通路都空闲，包直达目的结点，如同线路交换 2. 如果没有空闲链路时或出现寻径阻塞时，须将整个信息全部存储在寻径结点中。等同存储转发。 * 缺点： 1. 每个结点中需要有缓冲。以便没有空闲链路时，要用缓冲器存储。 2. 包缓冲区大，不利于VLSI实现； * 虫孔(wormhole)方式 为减少存储转发中包的存储时延，包可分为更小的“片” 。当一个结点把头片送到下一结点后，后面的各个片也依次送出。 * 特点：包不必全部存入缓冲后再做路由判断，只要接收到用作寻径信息（头片），即进行路由选择。 * 结点中缓冲器的容量小，各片的传送可按流水方式进行。传输延迟略大于线路交换，网络冲突较小。 * 一个结点一旦开始传送一个包中的头片后，必须等待这个包所有片都送出后，才能传送其他包。不同包的片不能混合在一起传送。 * 在新型的多计算机系统中得到了广泛的应用。 * 与虚拟直通的不同之处 当输出通路忙时，结点是把一个片存储到缓冲器中。 片的大小比包小很多，所以能有效地减少缓冲器的容量，使得它易于用VLSI实现。 存储转发与虫孔方式的时间比较 死锁与虚拟通道 流量控制策略 包冲突的解决 通过通道在两个相邻结点之间传送一个片，要同时具备3个条件： 源缓冲区已存有该片； 通道已分配好； 接收缓冲区准备接收该片。 当两个包到达同一个结点时，可能都在请求同一个接收缓冲器或者同一个输出通道，这时必须对两个问题进行仲裁。 4种解决方案 后一个包暂存(在缓冲区) 优点:不会浪费已经分配了的资源，但要求结点中有一个足够大的缓冲器来存放整个信息包。 阻塞后一个包 第一个包送入片缓冲区，用门控拒绝第二个包（阻塞）。不丢弃。 丢弃后一个包 第一个包送入片缓冲区。 有可能会造成严重的资源浪费，而且要求重新进行被丢弃包的传输与确认。 后一个包绕道 在包寻径方面有更多的灵活性，但为了到达目的结点，可能要花费 较多的通道资源，造成浪费。 确定性寻径和自适应寻径 确定性寻径：通信路径完全由源结点地址和目的地址来决定，也就是说，寻径路径是预先唯一地确定好了的，而与网络的状况无关。 自适应寻径：通信的通路每一次都要根据资源或者网络的情况来选择。 对于二维的网格网络来说，这种寻径方法被称为X-Y寻径。 先沿X维方向进行寻径，然后再沿Y维方向寻找路径。 对于超立方体来说，这种寻径方法被称为E-cube寻径。 通信模式 单播：对应于一对一的通信情况，即一个源结点发送消息到一个目的结点。 选播：对应于一到多的通信情况，即一个源结点发送同一消息到多个目的结点。 广播：对应于一到全体的通信情况，即一个源结点发送同一消息到全部结点。 会议：对应于多到多的通信情况。 通道流量和通信时延是常用的两个参数 * 通道流量用传输消息所使用的通道数来表示。 * 通信时延用包的最长传输时间来表示。 优化寻径网络以最小通道流量或通信时延为目标。 实例 混洗交换题计算方法: 在混洗交换网络中，最远的两个入、出端号 是全 \"0\" 和 全\"1\", 它们的连接需要 n 次交换 和n-1 次混洗。 所以其 最大距离为2n - 1. 在有8个处理器的混洗交换网络中，若要使第0号处理器与第7号处理器相连，需要经过2次混洗和 \\(\\underline{3}\\) 次交换 在有16个处理器的混洗交换网络中，若要使第0号处理器与第15号处理器相连，需要经过多少次混洗和交换 答：3次混洗和4次交换 设Cube为立方体互联函数， \\(\\sigma\\) 为均匀洗牌函数， \\(\\beta\\) 为蝶式函数， \\(\\rho\\) 为反位序函数，分别求 \\(Cube_{3}(0110)\\) 、 \\(\\sigma_{(3)}(0110)\\) 、 \\(\\beta(0110)\\) 、 \\(\\rho^{(2)}(0110)\\) . 答: * \\(Cube_3(0110) = 0010\\) * \\(\\sigma_{(3)}(0110) = 0101\\) * \\(\\beta(0110) = 0110\\) * \\(\\rho^{(2)}(0110) = 1010\\) 9.11 N=16的STARAN网络在级控制方式下实现分组交换置换，如果实现的分组交换置换是：首先是4组4元交换，然后是2组8元交换，最后是1组16元交换，写出网络实现的互联函数。 9.12 具有 \\(N=2^n\\) 个输入端的Omega网络，采用单元控制。 (1) N个输入总共应有多少种不同的排列？ (2) 该Omega网络通过一次可以实现的置换总共可有多少种？ (3) 若N=8, 计算一次通过能实现的置换数占全部排列的百分比。 答: (1) N个输入可有N!种不同排列。 (2) 该Omega网络通过一关可以实现的置换有 \\(2^{\\frac{N}{2}log_2N}=N^{\\frac{N}{2}}\\) 种不同。 (3) 若N=8, 通过Omega网络一次可以实现的不重复置换有 \\(8^4 = 4096\\) 种。 8个输入可实现的不重复排列有 \\(8! = 40320\\) 种。 故，一次可实现的置换数占全部排列数的10.16%. Omega网络 第十章 多处理机 多处理机概念: 由若干台独立的计算机或处理机(CU或PU)组成，每台计算机能独立执行自己程序。不同于并行处理机。 多个指令部件控制，统一操作系统，实现指令级以上(任务级、作业级）并行。MIMD结构。 多处理机通过互连网络连接，以共享某种设备（主存、输入输出或网络）方式，实现程序间数据交换和同步。 算法上，开发、挖掘和实现更多通用算法中隐含的并行性；不限于向量数组处理. 依靠软件手段解决资源分配和管理问题，特别是处理机管理和进程调度等。 MIMD计算机的特点、分类 Flynn分类法 SISD、SIMD、MISD、MIMD MIMD已成为通用多处理机系统结构的选择，原因： MIMD具有灵活性； MIMD可以充分利用商品化微处理器在性能价格比方面的优势。 计算机机群系统（cluster）是一类广泛被采用的MIMD机器。 根据存储器的组织结构 ，把现有的MIMD机器分为两类 （每一类代表了一种存储器的结构和互连策略） * 集中式共享存储器结构 * 最多由几十个处理器构成。 * 共享一个集中式的物理存储器。 * 分布式存储器多处理机（DSM) * 存储器在物理上是分布的。 * 非均匀访存模型，NUMA。 多处理机一致性问题 Cache的一致性问题和原因 允许共享数据进入Cache，就可能出现多个处理器的Cache中都有同一存储块的副本， 当某个处理器对其Cache中的数据进行修改后，会使得其Cache中的数据与其他Cache中的数据不一致。 例 由两个处理器（A和B）读写引起的Cache一致性问题 存储器的一致性 如果对某个数据项的任何读操作均可得到其最新写入的值，则认为这个存储系统是一致的。 单处理机系统中，Cache一致性问题存在于Cache与主存之间，可通过全写法（write－through，写直达，写通过）解决。 全写法：同时修改Cache和主存中值(或策略)。回写法：仅修改Cache值，不立即修改主存。 全写法只能维持一个Cache和主存之间的一致性，不能更新其他处理机中的Cache的相同副本。 解决Cache一致性问题是多处理机的重要问题。 实现一致性的基本方案 在一致的多处理机中，Cache提供迁移、复制两种功能： 共享数据的迁移：把共享数据拷贝后迁入本地Cache 减少了对远程共享数据的访问延迟，也减少了对共享存储器带宽的要求。 共享数据的复制：把共享数据多个副本拷放在多个处理器Cache 不仅减少了访问共享数据的延迟，也减少了访问共享数据所产生的冲突。 一般情况下，小规模多处理机是采用硬件的方法来实现Cache的一致性。 Cache一致性协议 在多个处理器中用来维护一致性的协议。 * 关键：跟踪记录共享数据块的状态 * 两类协议（采用不同的技术跟踪共享数据的状态） * 目录式协议（directory）： 存储器数据块的共享状态被保存在一个称为目录的地方 * 监听式协议（snooping） 处理机向局部Cache 写数据通过总线广播，其他处理机对广播的写事务进行监视，如果某Cache中有数据副本，用写作废或写更新处理. 采用两种方法来解决Cache一致性问题。 写作废协议 在处理器对某个数据项进行写入之前，作废其它的副本(保证它拥有对该数据项的唯一的访问权) 写更新协议 当一个处理器对某数据项进行写入时，通过广播使其它Cache中所有对应于该数据项的副本进行更新。 监听协议的实现 监听协议的基本实现技术 实现监听协议的关键有3个方面 处理器之间通过一个可以实现广播的互连机制相连。 通常采用的是总线。 当一个Cache响应本地CPU的访问时，如果涉及到全局操作，就在总线上发出相应的消息。 所有处理器都一直在监听总线，它们检测总线上的地址在它们的Cache中是否有副本。若有则响应，并进行相应的操作 。 Cache发送到总线上的消息主要有以下两种： RdMiss——读不命中 WtMiss——写不命中 需要通过总线找到相应数据块的最新副本，然后调入本地Cache中。 写直达Cache：因为所有写入的数据都同时被写回主存，所以从主存中总可以取到其最新值。 对于写回Cache，得到数据的最新值会困难一些，因为最新值可能在某个Cache中，也可能在主存中。 （后面的讨论中，只考虑写回法Cache） 目录协议的基本思想 监听一致性协议的可扩放性很差 主存中设置一个中央目录，存放每个数据块状态位和指针位（位向量） ，指针位对应处理机Cache 。 目录：一种集中的数据结构。对于存储器中的每一个可以调入Cache的数据块，在目录中设置一条目录项，用于记录该块的状态以及哪些Cache中有副本等相关信息。 任何一个数据块，都可以在目录表唯一的一个位置中找到相关的信息。使一致性协议避免了广播操作 状态位指示数据块状态，指针位（位向量）指向处理机Cache ，指出Cache中是否有数据块副本。 当一个处理机写入本身Cache时，根据目录表有选择地通知存有数据块的处理机的Cache。避免Cache不一致性 目录协议的三种结构 不同目录协议的主要区别主要有两个 所设置的存储器块的状态及其个数不同 目录的结构 目录协议分为3类 全映象目录、有限映象目录、链式目录 多处理机分类 按多处理机之间物理连接的紧密程度与交互作用能力强弱 紧耦合系统 松耦合系统 按处理机结构 同构型多处理机系统 异构型多处理机系统 按系统组成结构 并行向量处理机(PVP) 对称多处理机(SMP) 分布共享存储器多处理机(DSM) 大规模并行处理机(MPP) 工作站机群(COW) 五类机器特征比较 按存储器组织结构 集中式共享存储器结构(SMP) 分布式存储器结构（DSM) 第十三章 阵列处理机 阵列处理机 多处理单元(PE)按照一定互连方式，在同一控制部件(CU) 控制下，对各自数据完成同一条指令规定的操作。 * 从CU看，指令串行执行。 * 从PE 看，数据并行处理。 * 属于单指令流多数据流结构(SIMD)。细粒度并行处理机 * 应用领域：主要用于高速向量或矩阵运算。 操作模型 阵列处理机的操作模型可用五元组表示 阵列处理机＝（N，C，I，M，R） * N：机器的处理单元（PE）数。 例如：Illiac Ⅳ计算机有64个PE MP-1计算机有16384个PE * C：控制部件CU直接执行的指令集，包括标量指令和程序流控制指令。 * I：由CU广播至所有PE进行并行执行的指令集。 包括算术运算、逻辑运算、数据寻径、屏蔽以及其他由每个PE对它的数据所执行的局部操作。 * M：屏蔽方案集 每种屏蔽将所有PE划分成允许操作和禁止操作两种工作模式。 * R：数据寻径功能集 说明互连网络中PE间通信所需要的各种设置模式。 阵列处理机的结构 分布式存储器的阵列机: 含有多个相同的处理单元PE，每个PE有各自的本地存储器LM。 PE之间通过数据寻径网络以一定方式互相连接。它们在阵列控制部件的统一指挥下，实现并行操作。 指令的执行顺序基本上是串行进行的。 程序和数据是通过主机装入控制存储器。 共享存储器的阵列机: 集中设置存储器 共享的多体并行存储器SM通过对准网络与各处理单元PE相连。 存储模块的数目等于或略大于处理单元的数目。 必须减少存储器访问冲突 （将数据合理地分配到各存储器模块中 ） 在处理单元数目不太多的情况下是很理想的 所有阵列指令都必须使用长度为n的向量操作数 （n为PE的个数) 阵列处理机的特点(与流水线向量对比) * 阵列机是以单指令流多数据流方式工作的 * 阵列机是通过设置多个相同的处理单元来开发并行性的，它利用并行性中的同时性，而不是并发性。所有处理单元必须同时进行相同的操作。这与利用时间重叠的向量流水处理机是不一样的。 * 阵列机是以某一类算法为背景的专用计算机。这是因为阵列机通过都采用简单，规整的互联网络来实现处理单元间的连接操作，从而限定了它所使用的求解算法类别。 * 阵列机的研究必须与并行算法的研究密切结合，以便能充分发挥它的处理能力。 * 阵列机的控制器实质上是一台标量处理机，而为了完成I/O操作以及操作系统的管理，尚需一个前端机。因此实际的阵列机系统是由上述三部分构成的一个异构型多处理机系统。 SIMD机与并行算法的关系 以Illiac Ⅳ为例，讨论阵列处理机的算法。 解有限差分方程（需要知道大致含义） 把一个有规则的网格覆盖在整个场域上，用网格点上的变量值写出差分方程组以代替场方程来进行计算。 描述平面场的拉普拉斯方程 差分法求解的精度与网格间距有直接的关系，网格越小，精度越高，但求解所花费的时空开销越大。 Illiac Ⅳ在计算时，是把内部网格点分配给各个处理单元的。因此，上述计算过程可以并行地完成，从而大幅度地提高处理速度。 矩阵加 矩阵乘 设A、B和C为3个8×8的二维矩阵。若给定A和B，则 C＝A*B的64个分量可利用下列公式计算。 \\[c_{ij} = \\sum_{k=0}^{7}{a_{ik}b_{kj}}\\] \\[0 \\leqslant i,j \\leqslant 7\\] FORTRAN 程序 123456DO 10 I＝0，7 DO 10 J＝0，7 C（I，J）＝0 DO 10 K＝0，7 10 C(I，J) ＝C(I，J)＋A(I，K)*B(K，J) * 在SISD计算机上求解，三重循环，每重循环执行8次，共需512次乘加的时间 * 在SIMD阵列处理机上求解这个问题 执行下列FORTRAN程序： 1234DO 10 I＝0，7 C（I，J）＝0 DO 10 K＝0，7 10 C(I，J) ＝C(I，J)＋A(I，K)*B(K，J) 速度提高到原来的8倍，即每个处理单元的计算时间缩短为64次乘加时间。 递归折叠求和算法 一个将N个数的顺序相加转变为并行相加的问题。 取N＝8。即有8个数A（I）要顺序累加（0≤I≤7） 这是一个串行程序，共要进行8次加法。 在阵列处理机上采用成对递归相加的算法，则只需 \\(log_28＝3\\) 次加法 。 实例 阵列处理机操作模型可以用5元组表示:阵列处理机=(N, C, I, M, R), 简述其中N、C、I、M、R的含义。 答:N为极其的处理单元(PE)数； C为控制部件CU I为由CU广播至所有PE进行并行执行的指令集 M为屏蔽方案集，其中每种屏蔽将所有PE划分成允许操作和禁止操作两种模式 R为数据寻径功能机，说明互联网络中PE间通信所需要的各种设置模式 13.3 简述阵列处理机的特点 答： 1. 阵列机是以单指令流多数据流方式工作的。 2. 阵列机是通过设置多个相同的处理单元来开发并行性的，它利用并行性的同时性，而不是并发性 3. 阵列机是以某一类算法为背景的专用计算机 4. 阵列机的研究必须与并行算法的研究密切结合 5. 阵列机的控制器实质上是一台标量处理机 试分析与比较SIMD计算机与向量计算机的相同与不同 答: 相同点: 都能对大量数据进行向量处理 不同点: * SIMD获得高处理速度主要是采用资源重复的并行措施 * 各个处理单元并行工作 * 向量处理机依靠的是多功能流水线部件时间重叠，指高速度 * 另一区别是SIMD计算机有它的互联网络 简述SIMD计算机的分布式存储器与共享存储器的异同 答: 相同点: 都存在互联网络 不同点: * 在共享方案中，共享的多体并行存储器通过对准网络与各处理单元相连 * 在分布内存方案中，每个处理单元有自己的本地存储器，处理单元之间的数据通过数据寻径网络完成。 存储器 这道题，推算体号地址公式的知识点不在我们书上，理论上，我们应该只能一个个尝试填表。 **例1．试分别在下面两种计算机系统上用最短的时间来计算表达式s=A1B1+A2B2+…A32*B32。假设加法和乘法分别需要两个和四个单位时间，从存储器取指令、取数据、译码的时间忽略不计，所有的指令和数据已装入有关的PE。试确定下列每种情况的最小计算时间：（重点，必考） 1. 一台SISD串行计算机。 2. 一台有8个PE的SIMD计算机，8个PE用移数函数PM2I连接。每个PE用一个单位时间可以把数据直接送给它的相邻PE。操作数Ai和Bi最初存放在PEi mod 8中，其中i=1，2，…，32。每个PE可在不同时刻执行加法或乘法** 答: 1. 在SISD计算机中,需要32次乘法和31次加法。 共需要时间：T=432+231=190单位时间 在SIMD计算机上计算的算法： 假定向量中的32对元素平均地分配到8个处理器中，每个处理器分配4对，则每个处理器计算时间为 44+32 总时间 =每个处理器计算时间+递归折叠求和算法 T=44+32+1+2+1+2+1+2=31","categories":[{"name":"专业","slug":"pro","permalink":"https://sean10.github.io/categories/pro/"}],"tags":[{"name":"系统结构","slug":"系统结构","permalink":"https://sean10.github.io/tags/%E7%B3%BB%E7%BB%9F%E7%BB%93%E6%9E%84/"}]},{"title":"Unix编程环境复习笔记","slug":"Unix编程环境复习笔记","date":"2017-06-27T06:36:03.000Z","updated":"2023-03-18T15:11:14.888Z","comments":true,"path":"2017/06/27/Unix编程环境复习笔记/","link":"","permalink":"https://sean10.github.io/2017/06/27/Unix%E7%BC%96%E7%A8%8B%E7%8E%AF%E5%A2%83%E5%A4%8D%E4%B9%A0%E7%AC%94%E8%AE%B0/","excerpt":"关于shell内的圆括号的问题，圆括号不是本来就在shell中作与操作吗，为什么还要用转义符转义才能在find中用？ 难道说如果不用转义符，其优先级会更高？导致会报错误？姑且先这么记吧。 check: 括号中的命令将会新开一个子shell顺序执行，所以括号中的变量不能够被脚本余下的部分使用","text":"关于shell内的圆括号的问题，圆括号不是本来就在shell中作与操作吗，为什么还要用转义符转义才能在find中用？ 难道说如果不用转义符，其优先级会更高？导致会报错误？姑且先这么记吧。 check: 括号中的命令将会新开一个子shell顺序执行，所以括号中的变量不能够被脚本余下的部分使用 检索目录src以及其子孙目录中的所有文件名后缀为.c和.h文件，查找哪些文件中含有字符串TPDU，并列出在这文件中的行号。 答：使用find命令和grep命令。find命令可以在指定的目录树 中查找满足某个条件的文件或目录，并对查找到的满足条件的对象执行一个动作。指定查找条件为“文件名后缀为.c和.h”，动作为“查找哪些文件中含有字符串TPDU，并列出在这文件中的行号”，分别是find的-name和-exec选项。完整的命令为： 1find src –name &quot;*.[ch]&quot; –exec grep –n TPDU &#123;&#125; /dev/null \\; 这里是将grep的数据输出到/dev/null作为垃圾处理吧，但不用&gt;重定向符了？ 统计出由用户liu创建并且正在运行的进程数目。 答：使用ps命令列表出系统中所有进程，过滤后仅保留用户liu创建的进程（用grep），每个进程占一行，用wc命令统计一共有多少行即可。 ps –ef | grep liu | wc –l 这里我感觉也可以用ps -ef -u liu | wc -l来替换吧，但是跑出来结果却不同，看来是进程创建者和使用者不同概念，-u只能检索出使用者。 去掉文件list.txt中的所有空行(所谓空行指：行内不含有任何除空格之外的字符)，存为新文件list-new.txt。 答：使用grep命令可以用正则表达式对文本文件过滤，-v选项用于筛选掉能匹配指定正则表达式的行，描述一个空行的正则表达式为^ *$，即：从行首开始(^)，有零个到多个空格( *)，然后是行尾($)，命令为： grep –v ’^ *$’ list.txt &gt; list-new.txt 为什么我man grep得到的是--invert-match，显示不匹配的部分呢？，grep实际使用中不需要-v就能识别正则吧。 增量备份 cp -ur test test.bak 不过我实际操作找不到-u，google用的人也不多，都用rsync LINUX文件权限设计为简单的三级控制，用户liu对用户sun的文件data.txt要么具有全部的读权限，要么不可以读。因此，没有办法限制liu只对文件的指定部分读。 答：错误。可以利用SUID权限，用户sun将文件data.txt的读写权限设置为rw-------，由文件所有者sun自己编写程序以实现对文件的访问，程序中的访问当然可以限制只对文件的指定部分读，但是该程序文件的属性应当为rws--x--x，用户liu只有执行这个可程序程序文件才能实现对文件data.txt的访问。 查看僵尸进程 ps -ef | grep defunct | wc -l 查看进程表表项上限 MacOS下据说写在proc_internal.h中的PID上限是99999，下限是100. 而Linux下32位似乎是32768. 参考资料：http://blog.csdn.net/gatieme/article/details/51058797 Linux操作系统被设计得非常健壮，所以程序在运行过程中不会产生死锁。 答：错误。像信号量等，Linux仅给出了一组信号量操作的机制，如果应用程序设计的多个进程之间对信号量的操作处置不当，仍然可能导致死锁。操作系统没有办法检测出应用进程之间的逻辑操作不正确产生的死锁。使用管道等其他的进程之间通信的系统调用，也可能产生死锁。 Windows用户使用命令行命令ftp从Linux下载文件ftas.c，即使没有病毒破坏，成功下载结束后，下载的文件与原文件也有可能在文件大小（字节数）上不符。 答：正确。这种情况是可能存在的， FTP支持ASCII方式和BINARY方式的文件传输。前者会把数据文件理解为文本文件，会在通信的两个机器之间进行文本文件格式的转换。LINUX和Windows对文本文件的定义方式不同，Windows行间保留“换行”和“回车”两个字符，但是LINUX行间仅包括“换行”一个字符。所以在使用ASCII方式在Windows和Linux间交换文件可能会导致下载的文件与原文件在文件大小（字节数）上不符的情况。 关于文本文件处理的实用程序都有哪些？这些程序都有哪些共同的特点？为什么要这样设计这些命令？ 答：关于文本文件处理的实用程序有很多，如：head，tail，sort，grep，wc，cat，od，sed，awk，等等。 这些程序的共同特点是：每个小程序的功能设置简洁；当不指定处理对象时从标准输入获取处理数据；当指定文件名时，从指定的文件中获取处理数据，而且允许指定多于一个的文件名；处理结果在标准输出文件中输出。 这样设计这些命令的原因是：可以利用系统提供的输入、输出重定向和管道，连接和组合多个命令，提供灵活又丰富的使用功能；允许指定多于一个的文件作为处理对象可以和shell 的文件名通配符替换功能配合使用。体现了“策略和机制相分离”的设计理念。系统设计不复杂却可以提供强大的功能。 正则表达式中，一些配对的元字符使用转义时，只需要对开始的一个转义即可。 比如与开方括号 [ 对应的闭方括号 ]，与开花括号 { 对应的闭花括号 } ，这两个字符是否元字符，需要依据具体正则表达式的情况确定，我们以闭方括号]的情况为例（}的情况与此类似）：如果之前能找到与之对应的元字符开方括号[，则]作为元字符出现，否则，作为普通字符出现。 正则表达式里，使用圆括号时，为什么前面必须要加\\转义，变成\\(s+\\)这样呢？ (4) 将格式为“日-月-年”的日期数据，如：18-06-2010，替换为“年.月.日”格式，如：2010.06.18 s/\\([0-9][0-9]*\\)-\\([0-9][0-9]*\\)-\\([0-9][0-9]*\\)/\\3.\\2.\\1/ 正则表达式里，[0-9][0-9]*和[0-9]+有什么区别？ 记得有一个命令执行以后，整个终端的字符显示会全部错乱，似乎是ASCII序列被打乱了？ 好像是执行了一个重定向操作？ 并不是，是执行了一个cat命令，打印出一个二进制文件到终端，而这个二进制文件中某个字段可能刚好和某个命令相同，执行出来导致系统字符乱码。 select系统调用的主要作用是什么？ 答：使得用户进程可同时等待多个事件发生 用户进程告知内核多个事件，某一个或多个事件发生时select返回，否则，进程睡眠等待。例如：告知内核在rfds集合中的任何文件描述符“读准备好”，或在wfds集合中的任何文件描述符“写准备好”，或在efds集合中的任何文件描述符有“异常情况”发生，或者超时时间tm指定的时间间隔到。 **下列的脚本程序从键盘输入三个整数A,B,C，并且求出A*(B+C)的值。 在划线出填入适当的内容，完成整个程序。显式地标出你所添加的命令中必须有的空格和转义字符，并解释为什么必须这些空格和转义。** 123456#!/bin/shecho –n ”Input A:”; read Aecho –n ”Input B:”; read Becho –n ”Input C:”; read CV= echo ”A*(B+C)=$V” 答：expr $A \\* \\( $B + $C \\) 由于星号和圆括号属于shell的元字符，所以前面增加反斜线，阻止shell对元字符的处理，而是将这些符号直接传递给expr命令。上述命令一共需要6个空格，空格起单词分界线的作用。如果丢失了相应的空格，expr命令将无法得到正确的参数输入，导致expr无法按预期的功能工作。 写出一段完整的C语言程序，使用fork()系统调用，创建两个子进程，第一个子进程打印HELLO后立刻终止，第二个子进程打印WELCOME后立刻终止，父进程等待两个子进程都终止后，打印BYE然后终止。 答：程序如下： 12345678910111213141516main()&#123; int sv; if (fork() == 0) &#123; printf(”HELLO\\n”); return 0; &#125; if (fork() == 0) &#123; printf(”WELCOME\\n”); return 0; &#125; wait(&amp;sv); wait(&amp;sv); printf(”BYE\\n”); return 0;&#125; 这里的sv是接收fork的子进程返回的结果，作为子进程的结束。 int execlp(const char * file,const char * arg,……); execlp的第一个参数是用来在PATH或者路径中查找可执行文件，第二个参数是作为显示的进程名，我设置为aaa，则在ps -ef | grep test中可以查看到这个名字。 123456789101112131415#include &lt;unistd.h&gt;#include &lt;stdio.h&gt;int main(int argc, char *argv[])&#123; execlp(&quot;ls&quot;, &quot;test&quot;, &quot;-al&quot;,(char*)0); //最后一个0是形同NULL,表示数组的结束 // for(int i = 0;i &lt; 1;i++) // &#123; printf(&quot;argv[0]:%s\\n&quot;, argv[0]); printf(&quot;argv[1]:%s\\n&quot;, argv[1]); printf(&quot;argv[2]:%s\\n&quot;, argv[2]); // &#125; return 0;&#125; 我这样写执行结果和将第二个参数设置为ls是一样的，只是在查看进程时，名字显示为第二个 管道完整程序： 1234567891011121314151617181920212223242526272829303132#include &lt;unistd.h&gt;#include &lt;stdio.h&gt;#include &lt;fcntl.h&gt;int main(int argc, char *argv[])&#123; int fd[2], sv; pipe(fd); //fd[0] = open(&quot;out.txt&quot;,O_RDONLY); //fd[1] = open(&quot;out.txt&quot;, O_WRONLY); if(fork() == 0) &#123; dup2(fd[1],1); close(fd[1]); close(fd[0]); execlp(&quot;ls&quot;, &quot;test&quot;, &quot;-al&quot;,(char*)0); &#125;else if(fork() == 0) &#123; dup2(fd[0], 0); close(fd[1]); close(fd[0]); //execlp(&quot;ls&quot;, &quot;test2&quot;, &quot;-l&quot;, (char*)0); execlp(&quot;grep&quot;, &quot;MtGrep&quot;, &quot;javaw&quot;, (char*)0); &#125; close(fd[1]); close(fd[0]); wait(&amp;sv); wait(&amp;sv); return 0;&#125; linux 执行命令 先搜索Path，而windows先搜索当前目录 区别原因？ 考虑到安全问题，如果本地路径下自己写的程序的操作是类似rm -rf /，那就没救了 linux ./操作和. 操作区别 ./操作是fork一个子进程执行 . 操作就是用当前的进程直接执行 --- linux 如何显示出 所有的命令行参数与选项 据说是man argv，不过我执行的是man xargv","categories":[{"name":"专业","slug":"pro","permalink":"https://sean10.github.io/categories/pro/"}],"tags":[{"name":"Unix","slug":"Unix","permalink":"https://sean10.github.io/tags/Unix/"},{"name":"Linux","slug":"Linux","permalink":"https://sean10.github.io/tags/Linux/"}]},{"title":"图形学复习笔记","slug":"图形学复习笔记","date":"2017-06-26T08:35:28.000Z","updated":"2023-03-18T15:11:14.905Z","comments":true,"path":"2017/06/26/图形学复习笔记/","link":"","permalink":"https://sean10.github.io/2017/06/26/%E5%9B%BE%E5%BD%A2%E5%AD%A6%E5%A4%8D%E4%B9%A0%E7%AC%94%E8%AE%B0/","excerpt":"","text":"第一章 计算机图形学概论 1． 比较计算机图形学与图象处理技术相同点和不同点。 Computer Graphics将抽象的语义信息转化成图像(数据转换为图形)，Computer Vision从图像中提取抽象的语义信息。Image Processing（图像处理）探索的是从一个图像或者一组图像之间的互相转化和关系，与语义信息无关。 图形学输入的是对虚拟场景的描述，通常为多边形数组，而输出的则是图像，多维像素数组。 而图像处理技术输入的是图像，输出的也是图像。 2． 列举三个计算机图形的应用实例。 CAx领域 计算机辅助设计CAD; 计算机辅助制造CAM; 计算机辅助教学CAI; 等 系统模拟、虚拟现实 航空、航天、建筑、体育等模拟与训练 OA与电子出版系统 过程控制 飞船、卫星、导弹、工业生产过程等 绘制勘探、测量图 地形、地貌、矿藏、气象、GIS • 艺术、娱乐和商业 平面设计、动画、影视制作 • 医学诊断技术 CT、核磁共振等数据分析诊断病因,手术模拟 • 科学计算可视化 复杂数据的直观表示,方便观察结果 3． 简述计算机图形学发展动向。 造型技术 规则形体: 可用欧氏几何描述的形体 几何造型技术（几何描述） 特征造型技术（特征作为形状描述的单元） 基于物理的造型技术（动画） 不规则形体: 过程式模拟, 如分形、粒子系统、基于文法生成 真实图形生成技术 简单局部光照模型、全局光照模型, 基于图象绘制技术 人-机交互技术 三维人-机交互技术, 虚拟环境, 多通道技术, 非精确交互 基于网络的图形技术 网络和多媒体技术, 分布式图形, 虚拟现实建模语言VRML 第二章 计算机图形系统概述 1． 叙述计算机图形系统的基本功能。 输入、输出、计算、存储、对话 2． 输入设备可有哪几种逻辑功能？请举出各自对应的物理设备。 共有6类逻辑输入设备： * 定位(locator): 指定一个坐标点。对应的物理设备有鼠标器、键盘、数字化仪、触摸屏等。 * 笔划(stroke): 指示一个坐标点系列, 如指定一条曲线的控制点等。主要物理设备有数字化仪 * 送值(valuator): 输入一个数值。最常用的物理设备是键盘的数字键。 * 字符串(string)：输入一个字符串。最基本的物理设备是键盘的数字字母键 * 拾取(pick)：选择一个显示对象, 为应用程序处理确定目标。常用的物理设备是各种定位设备 * 选择(choice)：在一个可选动作或选项中进行选择, 如选择菜单项。典型的物理设备是鼠标器、数字化仪、键盘的功能键等。 3． 画出图形软件的层次结构及主要组成。 4． 颜色查找表的概念及实现原理。 彩色表又称为调色板, 用来定义图像的 不同颜色。 彩色表的工作原理 代号-颜色RGB值对照表 5. 光栅扫描显示器结构与工作原理。 (1)图形信息的产生有两种主要途径: 其一, 由计算机执行相应的图形应用程序, 图像生成系统接受指令将图形的矢量表示转换成像素表示, 再将像素值存入显示存储器; 其二, 图像生成系统直接把图形输入设备(摄像 机、扫描仪等)输入的图形图像直接或经过主存 储器间接地存放到显示存储器中。 (2)显示控制器生成水平和垂直同步扫描信号送到 监视器, 使CRT电子束进行水平扫描和垂直扫描形成光栅; 另一方面又根据电子束在屏幕上的 行、列位置, 不断地读出显示存储器中对应位 置的像素值。 (3)利用彩色表将读出的像素值转换成R、G、B 三原色的亮度值, 来控制CRT的R、G、B电子束, 在屏幕对应点生成需要的像素颜色。 6． 什么要制订图形软件标准？举例说明它的分类。 制定图形软件标准的目的在于使图形软件能 够在不同的计算机和图形设备之间进行移植, 以便提高图形软件的利用率, 降低开发成本, 缩短研制周期, 使图形软件向着通用、高级与 设备无关的方向发展。 目前已经制定或正在制定的一些图形标准都是接 口标准。这些标准的功能旨在使图形系统中两 部分之间的接口标准化, 可以分为两类: * 数据接口标准 * 子程序接口标准 第三章 基本图形生成算法 1． Bresenham 直线生成算法原理。它与 DDA 算法相比，有何改进？ 根据直线的斜率确定选择X或者Y方向作为计 长方向, 在此方向上每次递增一个单位步长(或 者一个像素单位), 另一个方向上是否同时产生 一个单位增量由一个计算量很小的判别式来判 断。 Bresenham算法相比DDA算法去除了费时的取整运算，效率更高了。 2． 比较几种常用画圆弧算法的原理和效率。 Bresenham算法 与Bresenham直线生成算法一样, 其基本方法 是从一个起点出发, 利用判别式选择下一个显 示点。判别式的值通过简单计算获得, 其符号 用作判断。 算法特点 Bresenham圆弧算法是最有效的算法之一, 生 成圆时利用第一象限的上八分之一圆弧对称 扩展。选择点时所用判别式是递推表达式， 仅用加、减和移位即可计算, 算法效率高。 正负法（逐点比较法） • 首先,区分不同象限的圆弧； • 然后,选定圆弧起点后,在输出圆弧的过程中, 根 据当前点的位置与理想圆弧的关系和所在象限， 决定下一步的走向, 每次只在一个方向(X 或 Y) 走步取点; • 这样一步步地逼近产生应显示的圆弧。 算法特点 计算机用正负法生成圆弧时运算只有加、减和 移位(乘2)运算, 无乘除, 因此运算效率高, 这很 适用于用硬件实现。 较之Bresenham算法, 正负法的运算更为简单, 但对于同一段圆弧而言, 由于正负法每次只是 单向走步, 因而生成的点数比Bresenham算法生 成的点数要多。 多边形逼近法 当圆的内接多边形边数足够多时, 该多边形可 以和圆接近到任意程度, 因此在允许的误差范 围内(例如圆周和多边形之间的最大距离小于半 个像素的宽度), 可用显示多边形代替显示圆。 显示多边形的边可以用Bresenham直线生成算 法来实现。 个人猜想：毕竟采用的不是描点法，因而效率会更高 3． 简述两种字符生成方法。 矢量字符 写字模：采集每一笔两个端点的值。 点阵字符 采用mask来定义字符 所谓(mask)字符掩膜,就 是包含该字符的像素信息的一小块光栅。 4． 何谓四连通和八连通？写出一种边界表示的八连通区域填充算法。 4连通区域：取区域中的任何两个像素,从一象 素出发,通过上、下、左、右4种运动,只经过 该区域的点可以达到另一像素 8连通区域：取区域中任何两个像素,从一象素 出发通过上、下、左、右、两条对角线方向共 8种运动,只经过该区域的点可达到另一像素 4连通区域和8连通区域的关系： 4连通区域是8连通区域的一种特殊情况。4连通区域的边界必定是8连通式的；（8连通区域的边界必定是4连通式的？）。 这里指的是连通（而不是边界） 5． 解释活化边表的思想，以多边形区域填充为例介绍它的应用。 6．已知多边形各个顶点的坐标为(2,2), (2,4), (8,6), (12,2), (8,1), (6,2)及 (2,2), 在用扫描线填充算法实现扫描转换时, 写出其边表(ET)和全部的活化边表(AET)的内容。 7. 设计和实现一个图形函数库，具有绘制直线段、任意圆弧、椭圆弧、 多边形区域的阴影填充和颜色填充等功能。（仅调用画点函数） 大作业第一个 见附录 第四章 图形变换与裁剪 1．什么是灭点? 任何一束不平行于投影平面的平行线的透视投 影将汇聚成一点,称为灭点。灭点可以看作是 无限远处的一点在投影面上的投影。灭点有无 限多个。 在坐标轴方向上的灭点, 称为主灭点。 透视投影根据主灭点的个数分为一点透视、二 点透视和三点透视。主灭点数是和投影平面切割坐标轴的数量相对应的。 2．试用几种不同顺序的简单几何变换,求出将平面上的任一线段P1(x1, y1), P2(x2, y2)变换成与 X 轴重合的变换阵,并说明其等效性。 3．已知 OXYZ 坐标系下平面方程是 x+y+z+d=0，试求变换距阵 T，使该平面在 O’X’Y’Z’坐标系下变成 z’=0。 4．试简述二维图形裁剪的基本原理及可选用的裁剪策略. 在显示图形之前, 组成图形的每一个基本元素都 要经过裁剪, 因此裁剪算法直接影响整个图形系 统的效率。 裁剪的基本目的是判断图形元素是否在所考虑 的区域内。如在区域内, 则进一步求出在区域内 的那一部分。因此裁剪处理包含两部分内容: 1)点在区域内外的判断; 2)计算图形元素与区域边界的交点。 可选用的裁剪策略： * 编码裁剪法(Sutherland-Cohen算法) * 中点分割裁剪法 * 多边形的裁剪 * 逐边裁剪法 * 双边裁剪法 第五章 人机交互技术 1. 基本的交互任务有哪些？它们可用什么设备执行？ 定位 定位设备 选择 选择设备 数量输入 取值设备 文本输入 键盘 三维交互 鼠标 设备有:定位设备，键盘设备，取数设备，选择设备，其他输入设备 2. 举例说明 WINDOWS 系统常用的交互方式，编程实现其中一例。 windows系统常用选择交互方式，鼠标点选选项进行操作。 3. 叙述设计人机交互的一般风格和原则。 现在计算机系统的人机界面一般具有下列风格, 即: “所见即所得”(what you see is what you get) , 直接操作(direct manipulate)及菜单和图形符号 (icon)驱动。 * “所见即所得”在交互式图形系统中一般都 能做到, 即在屏幕上所见到的设计结果和用硬 拷贝所得的输出结果是一致的。 * 直接操作是对对象、特性及关系等操作时用 户可得到一种直观及形象的表示, 以说明这个 操作是正确地被执行了。 * 图形符号驱动的目的是要用户不需要专门学 习及记忆便可借助于菜单选择来运行系统。 要做到这一点最主要的是要设计好图形符号, 使它一看便知道它代表什么操作。 第六章 曲线曲面的表示 1. Bezier 曲线具有哪些特性？试用 n 的归纳法证明其凸包性。 证明就算了，一点都看不懂…… 2. B 样条曲线的定义及其特点。 3. 比较 Bezier 曲面和Ｂ样条曲面的功能特点。 Bezier曲面和B样条曲面的特点是曲面逼近控制网 格。 Ｂ样条曲面不仅在保留了Bézier曲面的优点的同时克服了由于整体表示带来的不具有局部修正性质的特点，而且成功地解决了样条函数的局部控制问题，轻而易举地在参数连续性上解决了贝奇尔方法的连接问题。 4. Coons 曲面片构造方法及其特点。 Coons曲面特点是插值, 它构造满足给定边界条 件的曲面。 第七章 三维实体的造型 1. 体素构造表示法中两物体正则运算的公式，并举例说明它们的计算方 法。 2. 形体的拓扑信息和几何信息各包含哪些内容？举例说明它们起何作用。 几何信息－物体大小、尺寸、位置、形状等 拓扑信息－物体上所有顶点、棱边、表面间连接关系 几何信息和拓扑信息分开表示的优点: 便于具体查询物体中各元素、获取它们的信息; 容易支持对物体的各种局部操作; 对于具有相同拓扑结构而只是大小、尺寸不同 的物体,可以用统一的数据结构加以表示; 便于在数据结构上附加各种非几何信息。 3. 欧拉公式及其应用意义。 给用户提供了直接使用顶点、棱边、表面等基 本元素构造三维立体的手段。用户可以通过输入 点,再建立边, 构成面, 形成体。 任何数目顶点、棱边、表面并不能构成一个体。 它们之间须满足拓扑一致性和几何一致性。 – 几何一致性由用户输入几何信息时保证, 系统应 提供检查输入信息几何一致性功能。 4. 试写出判定空间任意位置的两个长方体是否相交的算法。 5. 试比较实体的边界表示、扫移表示、CSG 表示及八叉树表示的优缺点。 说明它们适应的应用。 边界表示法：用顶点、棱边、表面等物体的边界信息来表示物体。边界就是物体内部点与外部点的分界面。 扫描表示 CSG表示：一个复杂物体可由一些比较简单、规则的物体经过布尔运算而得到。其中叶结点为基本体素(立方体, 圆柱, 圆锥等); 中间结点为正则集合运算结点。 优点: 将复杂物体表示转换为简单物体之间运算,也可递归求出物体性质; 缺点: 方法有局限性,物体复杂时,这种表示不太适应。 空间位置枚举：使用该方法时, 先将空间分割成均匀的立方体网格, 然后根据物体所占据的网格位置来定义物体的形状和大小。 优点–适合所有形状三维物体表示, 容易实现物体的并交差及整体性质计算(对应着数组运算) 缺点–没有明确给定物体边界信息, 占据存储量大 八叉树（改进的空间位置枚举) • 物体之间集合运算在八叉树中十分简单 物体并－两物体一共占有的空间； 物体交－两物体共同占有的空间。 运算时只需同时遍历参加集合运算两物体相应的 八叉树。 • 简化了隐藏线和隐藏面的消除 核心是排序(按离观察点远近排序); 八叉树中物体元素已按空间位置排成一定顺序, 同一层的八叉树结点通过优先级表示。 • 计算物体的性质(体积、质量)更简单 对物体的各项操作＝》体元的操作。 第八章 消隐技术 1. 为何要进行隐藏面的消除？ 消除图形的二义性 2. 简述区域子分消隐算法思想和描述。 区域子分算法是针对光栅扫描式图象显示器上 填色产生图形的。它是一种所谓分而治之的算 法。 整个屏幕称为窗口, 每一次把矩形的窗口等分成 4个相等的小矩形,分成的矩形也称为窗口, 见图 8.2。 每一次子分, 均要把要显示的多边形和窗口的 关系做一次判断。这种关系有以下4种: –多边形包围了窗口(图8.3中情况1); –多边形和窗口相交(图8.3中情况2); –窗口包围了多边形(图8.3中情况3); –窗口和多边形分离(图8.3中情况4)。 窗口和每个多边形的关系确定之后, 有些窗口 内的图形便可显示了, 它们属于下列情况: (1)所有多边形都和窗口分离。这时只要把窗口 内所有的象素填上背景颜色。 (2)只有一个多边形和窗口相交,或这个多边形 包含在窗口内。这时先对窗口内每一象素填 上背景颜色, 再对窗口内多边形部分用扫描 线算法填色。 (3)只有一个多边形和窗口相交,这个多边形把 窗口整个包围在内;或虽有几个多边形和窗 口相交,但离观察者最近的一个多边形包围 了整个窗口。这时把整个窗口填上离观察者 最近的那个多边形的颜色。 对上述3种情况不成立的窗口再一分为四,见图 8.2。分得的窗口重复上述的处理。 • 重复处理后,窗口的边长越分越短, 分了若干次 后, 窗口的边长就和一个象素的宽度一样了。 这时, 这个窗口对应的象素的颜色可取成最靠 近观察者的多边形的颜色, 或和这个窗口相交 的多边形颜色的平均值。 3. 简述 Z 缓存消隐算法思想和描述。 深度缓存算法(Z-Buffer)是一种最简单的图象空间 面消隐算法, 既适应于多边形面也适用其它曲面。 • 它需要一个深度缓存数组ZB, 其大小与屏幕上象素 点的个数相同, 也与显示器的帧缓存FB的单元个数 相同, 彼此一一对应。 • 如图8.6, 在屏幕坐标系中, 过屏幕上任一象素点(i, j) 作平行于Z轴的射线R, 与物体表面上的多边形相交 于p 1 和p 2 点。 • 比较p 1 和p 2 的Z值, 将最大Z值存入深度缓存数组ZB, 最大Z值所对应点的颜色存入显示器的帧缓存FB。 算法描述 4. 比较几种主要的隐藏面的消除算法的特点。 区域子分算法是针对光栅扫描式图象显示器上 填色产生图形的。它是一种所谓分而治之的算 法 用边界盒的办法就可判定一些多边形和指定窗 口是无交的。因此, 这些多边形可从窗口多边 形序列中排除, 从而提高排序效率 深度缓存算法的优点是简单、可靠, 不需要对显示对象的 面预先进行排序; • 缺点是要很大的Z缓冲器, 显示对象的表面和象素对应的 每一个点处都要计算它的Z值, 因而工作量较大。 第九章 真实感图形技术 1. 用框图描述三维真实感图形的产生流程。 –用数学方法建立所需三维场景的几何描述, 并将它们输入计算机； –将三维几何描述转换为二维透视图； –确定场景中的所有可见图(消隐)； –计算场景中可见面的颜色。（本章重点） 2. Phong 局部光照模型及其实现算法描述。 3. 叙述 Phong 多边形明暗处理算法原理, 与 Gouraud 算法比较它的优缺 点。 Phong明暗处理技术(Phong Shading) • 思想: 对离散的法向量采样作双线性插值, 构造一个连续的法向量函数, 将这个连续的 法向量插值函数代入光亮度计算公式, 即得 到一个非线性的光亮度插值公式。 如图9.7所示, 任一点P处法向按插值方法由 各顶点处法向推出。 • 优点: 大大减少了马赫带效应;产生真实的高光效果。 缺点: 由于对每一像素光亮度计算还需使用 光照模型, 故计算量大。 Gouraud明暗处理技术(Gouraud Shading) • 思想：对离散的光亮度采样作双线性插值 以获取连续的光亮度函数。 • 过程： a.计算出多边形顶点处的光亮度值, 作为 插值采样点； b.对多边形顶点的光亮度插值计算出多边 形内任一点的光亮度。 优缺点 效果尚好, 计算量小; 不能正确模拟高光, 会产生Mach带效应(光亮度 变化率不连续的边界处呈现亮带或黑带)。 4. 何为全局光照模型，典型的模型举例。 Phong模型仅考虑光源直接照射在景物表面产生 的反射光能, 因而是一种局部光照模型。 • 局部光照模型忽略了光能在环境景物之间的传 递, 很难生成高质量真实感图形。 原因: 未能考虑环境的漫射、镜面反射和规则透 射对景物表面产生的整体照明效果。 Whitted在Phong模型中增加了环境镜面反射光 亮度Is 和环境规则透射光亮度It , 从而模拟周围环境的光透射在景物表面上产生的理想镜面反 射和规则透射现象。 5. 实现真实感绘制的光线跟踪技术的主要思想和算法描述。 光线跟踪技术是为了求解Whitted模型而提出 一种高度真实感图形绘制技术. 6. 加速光线跟踪算法的主要方法。 包围盒技术 景物空间分割技术 7. 何谓纹理映射，简述其实现原理。 纹理：物体表面所呈现的表面细节。 生成颜色纹理的方法。其过程是: 在一平面区域(纹理空间)上预先定义纹理图案; 然后建立物体表面的点与纹理空间的点之间的 对应关系(即映射)。 主要有法向扰动法、分形生成技术等。 8. 试写出将一幅图片贴到三维圆柱体表面的算法。 第十章 OPEN GL 简介 1. 试设计一个室内三维环境, 并利用 OPEN GL 展示它的三维效果。要求：(1)包含基本的实体元素：球、多面体、锥体、柱体、曲面等； (2)有全局光照效果和纹理功能； (3)程序具有交互功能。 第二次大作业。 附录","categories":[{"name":"专业","slug":"pro","permalink":"https://sean10.github.io/categories/pro/"}],"tags":[{"name":"图形学","slug":"图形学","permalink":"https://sean10.github.io/tags/%E5%9B%BE%E5%BD%A2%E5%AD%A6/"},{"name":"openGL","slug":"openGL","permalink":"https://sean10.github.io/tags/openGL/"}]},{"title":"Qt学习汇总遇到的问题","slug":"Qt学习汇总遇到的问题","date":"2017-06-15T08:42:46.000Z","updated":"2023-03-18T15:11:14.894Z","comments":true,"path":"2017/06/15/Qt学习汇总遇到的问题/","link":"","permalink":"https://sean10.github.io/2017/06/15/Qt%E5%AD%A6%E4%B9%A0%E6%B1%87%E6%80%BB%E9%81%87%E5%88%B0%E7%9A%84%E9%97%AE%E9%A2%98/","excerpt":"","text":"使用qt信号槽时，始终no such slots，原因是我没有在槽函数的类中使用Q_OBJECT MACRO 这个的原因是什么呢？ 在类声明的开始位置必须加上Q_OBJECT语句，这条语句是不可缺少的，它将告诉编译器在编译之前必须先应用 moc工具进行扩展 这个时候先执行qmake，再build 开了一个refresh信号的线程，但是一使用emit signalRefresh就爆出系统错误 &gt;:-1: error: symbol(s) not found for architecture x86_64 &gt;:-1: error: linker command failed with exit code 1 (use -v to see invocation) 这个错误经常会出现 c++跨文件或跨类传输变量参数是通过在对应文件声明类，然后调用该类获得参数的函数 但是qt里我一旦这样做，就会出现上面那个系统错误。 普通形参加不加const限定符对实参没有影响，引用形参和指针形参前面没有const限定符时，实参必须是非const的，而前面有const限定符时对实参也没有什么影响。 为什么会出现这种情况？ 原因在于实参的传递方式不同，函数中的形参是普通形参的时，函数只是操纵的实参的副本，而无法去修改实参，实参会想，你形参反正改变不了我的值，那么你有没有const还有什么意义吗？引用形参和指针形参就下不同了，函数是对实参直接操纵，没有const的形参时实参的值是可以改变的，这种情况下怎能用函数来操纵const实参呢。 ui文件似乎必须要建一个类通过setupUI才能使用 主要需要新建一个dialog来show就可以了 Qt的模态对话，setModal和dialog.exec() == box::accepted有什么区别？ QT的close没有反应，似乎要使用事件循环 setAttribute (Qt::WA_DeleteOnClose); 这个明明是解决内存泄露问题，为什么可以关闭窗口呢，而close却做不到 qVector输入之后，造成implicitly deleted because base class \"QObject\" has a deleted copy constructor Qt 资源文件，可以通过添加qrc来实现路径的操作 但是 //路径这里存在问题，为什么添加了qrc之后依旧不需要前缀就可以使用了呢？ 明明理论上说要\":/db/user.db\" 但只是\"user.db\"就可以使用了 始终不能调用数据库，原因是我没有使用query.finish，以及建表语法出现了错误。 事件似乎和信号有点相似，又有点不同。 事件是一个新的概念，与信号不一样。 又遇到了当初的link错误，没有详细信息的那种 SF的答案是这个，感觉比较靠谱，我也确实有在Compile Output里看到问题，是client.o的问题，不过这个文件我都没有引用，为什么会错呢 把databaseControl设置继承QObject就出现编译不过的问题 就是上面的link错误，不过更复杂 遇到这个错误error: member function not viable this argument has type const 但是我一时忘了怎么解决的了 call to implicitly-deleted copy constructor /Users/sean10/Qt/5.8/clang_64/lib/QtCore.framework/Headers/qlist.h:461: error: call to implicitly-deleted copy constructor of 'centralAirConditioner' current-&gt;v = new T(reinterpret_cast&lt;T&gt;(src-&gt;v)); ^ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 遇到这个错误，发现又是因为继承了基类QObject的原因 暂时设计了从multithread发送信号到databaseControl,暂时没能测试出数据是否发送成功 好像知道为什么发送了信号，但槽函数没有执行的原因了，似乎是因为信号和槽不在一个线程里 但是默认是会执行异步的啊 稍后添加对于开关机的容错措施 数据锁尚未添加 优先设置spinBox的lowtem会导致workTemperature变成这个lowTem,明明是满足他的约束的 噢，可能是因为spinBox一开始是0，没有设置，当有了约束之后，自动变成了18，满足了值变动，所以导致初始化被覆盖了。 tcp粘包问题： 怎么分也需要双方组织一个比较好的包结构，所以一般可能会在头加一个数据长度之类的包，以确保接收。 从控机修改工作模式，但没有发送给主控机的过程，这个问题有待修正 这里应该根据文档来写：从控机没有调整工作模式的机会，只能由主控机设定 connectToHost似乎是mac的问题，大大的windows执行就没有问题。 找到每次修改完工作温度，室温就顺便同步的原因了，是因为信号问题，每发送一个SignalSendRequest就执行了9次SendRequest. 但是没有找到有多次connect的函数啊。 即便是用了uniqueConnection还是执行了多次。 找到问题了，有另外一个函数不停发送了signal，定时发送 第二次从控机开机，主控机上没有再显示出那台从控机状态？ why? 还有解决粘包问题 把室温用电子时钟模式展示出来 可以使用doxygen来进行根据注释生成文档 /** * 要输出成文档的注释 */ 或者 //! qmake project 变量使用 一个pro生成多个app似乎现在不行了，只能通过subdirs来实现了？ 通过$$PWD来导入公用包 用CLion的Cmake和 命令直接clang++都没办法把sqlite3成功编译通过，但是用Qt就能过，真的是奇特。 sqlite3 使用怪怪的 select * from sqlite_master; 始终得到结果为空 然后报错 libc++abi.dylib: terminating with uncaught exception of type std::__1::system_error: SQL logic error CREATE TABLE main.table_name( column1 datatype PRIMARY KEY(one or more columns), column2 datatype, column3 datatype, ..... columnN datatype, ); 现在尝试用回俊宁大佬的库，但是连创建table都使用不了…… 找到了俊宁大佬自己的作业，从那里的实例来进行操作 Qt dialog传递参数 https://blog.csdn.net/xzh_blue/article/details/51490747 现在很奇怪，有时候能够充值上去，有时候就报这个错误，导致失败 123456[INFO] send message: &#123;&quot;define&quot;:2&#125;[INFO] receive message: &#123;&quot;define&quot;:3,&quot;username&quot;:&quot;ls1&quot;&#125;[INFO] Get user balance request comes[INFO] send message: &#123;&quot;balance&quot;:0,&quot;define&quot;:1&#125;SQL error: &#x27;UNIQUE constraint failed: OrderInfo.type&#x27; at &#x27;insert into OrderInfo(type,amount,out_account,in_account,record_time) values (4,25,&#x27;cash&#x27;,&#x27;ls1&#x27;,1536938826);&#x27;[INFO] Someone offline, now 0 conne C/S架构下， 登录过程中 密码 是否需要加密？ 出现了一个权限值为25，似乎是哪里传输的时候顺序出错了？把转账的值写入到了权限的位置？ QT 点击自定义QDialog类\"确定\"按钮 , 模态框立刻关闭 , 之后又做空值检查问题解决 - CSDN博客 mac 自带openssl 0.98，而官方最新版 1.1 (6 条消息)UUID是如何保证唯一性的？ - 知乎 现在有一个问题，我的tableView没有释放过standardItem，因此一定会出现内存泄露问题 (6 条消息)互联网中TCP Socket服务器的实现过程需要考虑哪些安全问题？ - 知乎 引用openssl库的方式 clang client.c -o client -I/usr/local/opt/openssl/include -L/usr/local/opt/openssl/lib -lcrypto -lssl 像上面这样加上最后那4条就可以正常运行了 openssl生成过程 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374mkdir misccd miscsudo cp /usr/local/etc/openssl/openssl.cnf ./cp /usr/local/etc/openssl/misc/* .///这里生成的是rsa的ca.key和 .rnd 输入密钥是fightonopenssl genrsa -out ./private/ca.key -rand ./private/.rnd -des 2048// 这里确认了密钥，然后要求输入下面那些内容openssl req -new -x509 -days 3650 -key ./private/ca.key -out ./private/ca.crt -config openssl.cnf&lt;!-- Enter pass phrase for ./private/ca.key:You are about to be asked to enter information that will be incorporatedinto your certificate request.What you are about to enter is what is called a Distinguished Name or a DN.There are quite a few fields but you can leave some blankFor some fields there will be a default value,If you enter &#x27;.&#x27;, the field will be left blank.-----Country Name (2 letter code) [AU]:ZHState or Province Name (full name) [Some-State]:BeijingLocality Name (eg, city) []:BeijingOrganization Name (eg, company) [Internet Widgits Pty Ltd]:HikvisionOrganizational Unit Name (eg, section) []:bjyfCommon Name (e.g. server FQDN or YOUR name) []:sean10Email Address []:sean10reborn@gmail.com --&gt;// 这个应该是显示一下证书openssl x509 -in ./private/ca.crt -noout -text## // 产生server证书openssl genrsa -out ./private/server.key 1024openssl req -new -key ./private/server.key -out ./newcerts/server.csr -config openssl.cnf&lt;!-- You are about to be asked to enter information that will be incorporatedinto your certificate request.What you are about to enter is what is called a Distinguished Name or a DN.There are quite a few fields but you can leave some blankFor some fields there will be a default value,If you enter &#x27;.&#x27;, the field will be left blank.-----Country Name (2 letter code) [AU]:ZHState or Province Name (full name) [Some-State]:BeijingLocality Name (eg, city) []:BeijingOrganization Name (eg, company) [Internet Widgits Pty Ltd]:bjyfOrganizational Unit Name (eg, section) []:hikCommon Name (e.g. server FQDN or YOUR name) []:sean10Email Address []:sean10reborn@gmail.comPlease enter the following &#x27;extra&#x27; attributesto be sent with your certificate requestA challenge password []:helloworldAn optional company name []:hik --&gt;touch index.txttouch serialecho 00 &gt; serialopenssl ca -in ./newcerts/server.csr -cert ./private/ca.crt -keyfile ./private/ca.key -config openssl.cnf -policy policy_anything -out ./certs/server.crtopenssl genrsa -out ./private/proxy.key 1024//这步要是产生错误，请看后面的解决方法openssl req -new -key ./private/proxy.key -out ./newcerts/proxy.csr -config openssl.cnfopenssl ca -in ./newcerts/proxy.csr -cert ./private/ca.crt -keyfile./private/ca.key -config openssl.cnf -policy policy_anything -out ./certs/proxy.crtopenssl x509 -in ./certs/proxy.crt -noout -text 基于OpenSSL自建CA和颁发SSL证书 | Sean's Notes Qt 如何 引入 openssl库 QT总结第3篇：如何在QT中添加.lib，.dll还有.h文件 - CSDN博客 现在在编译时，ui_widget.h丢失？ 奇怪了。将lssl等加到LIBS这里之后，server可以编译了，但是client又出现了上面的问题，明明这次client一行代码都没改…… 终于发现了，我在socket.h里多导入了一个curve.h这个包，这个包里的一个函数qblog和 Qt 的一个包 重名了 case中无法定义同一个变量 用if else 代替 switch 语句; 2：在case中用{}将代码括起来,这样在{}中就能定义变量了; 3：如果变量在各个case中都要用的话,就把变量定义在switch外面吧; 目前在switch case中定义的变量无法被后续的代码发现，从而使用 可能是作用域的原因？ 想要手动定义，但是无法通过typeid .name 打印出来 还需要找到办法手动定义 openSSL OpenSSL主配置文件openssl.cnf - 骏马金龙 - 博客园 基于OpenSSL自建CA和颁发SSL证书 | Sean's Notes 使用c语言实现在linux下的openssl客户端和服务器端编程 - 欢跳的心 - 博客园 openssl编程轻松入门（含完整示例）-飞月-51CTO博客 (6 条消息)用 C++ 写 HTTPS 客户端和服务器大体步骤有哪些？ - 知乎 OPENSSL编程入门学习 - 骑着蜗牛逛世界 - 博客园 用Cross Functional Vertical就可以画图了 https://www.processon.com/view/5938c757e4b036140a0ef5ef?fromnew=1 https://www.processon.com/diagrams/new#temp-system","categories":[{"name":"专业","slug":"pro","permalink":"https://sean10.github.io/categories/pro/"}],"tags":[{"name":"C++","slug":"C","permalink":"https://sean10.github.io/tags/C/"},{"name":"Qt","slug":"Qt","permalink":"https://sean10.github.io/tags/Qt/"}]},{"title":"git笔记","slug":"git笔记","date":"2017-02-20T16:12:09.000Z","updated":"2025-01-26T15:13:12.662Z","comments":true,"path":"2017/02/21/git笔记/","link":"","permalink":"https://sean10.github.io/2017/02/21/git%E7%AC%94%E8%AE%B0/","excerpt":"常用命令 切换分支 git reset --hard ## 查看操作历史，寻找之前记录的分支 git reflog ## 查找指定行的commit log git log -S \"void ss()\" /path/file 将上次commit取消, 保留本地所有修改, 重新发起commit 1git reset --soft HEAD^ 查看未提交的文件修改 1git show show not staged 1git diff 查看指定commit存在哪些分支 1git branch -r --contains xxx 查找指定commit后面的commit 1git log --oneline --reverse master..REF | head -n 10 查看merge的commit, 显示出其diff 123git show --first-parent xxxgit log -p --first-parent xxx如果不带-m, merge的commit的快照无法找到parent, 因此不输出内容 How to \"git show\" the diffs for a merge commit? - Stack Overflow 查看被删除的文件相关的commit 12git log --all -- src/mgr/PyModule.cc 查看tag之间差异的commit 1git log v12.2.12..v13.0.2 src/mgr tag功能 如何找到tag是从哪个分支的哪个commit打出? 子模块 git subtree(第三方, 独立仓库子树合并) git submodule(独立的子仓库) .gitmodules修改为mirror地址 git submodule sync git submodule init git submodule update 或者 git submodule update --init --recursive 添加git submodule 123git submodule add &lt;url&gt; &lt;path&gt;git diff --cachedgit commit -m &quot;xxx&quot; submodule的submodule 1git submodule update --init --recursive 理论上这个可以, 那我编译时还触发了git clone的应该是因为代码并不是完全用submodule维持的关系了把? 回滚. git reset --hard即可. git diff 与vscode对接 git支持通过difftool对接一些外部插件 123456789101112git config --global difftool.code.cmd &#x27;code --wait --diff $LOCAL $REMOTE&#x27;git config --global mergetool.code.cmd &#x27;code --wait $MERGED&#x27;git config --global -lgit difftool devgit difftool -t code devgit mergetool -t code dev 潜在问题: 好像在difftool这个交互进程退出前, 会在dock上弹出很多个vscode的图标 记录 git的快照流是指什么？ (参见 Git 内部原理 来了解更多关于到底 .git 文件夹中包含了哪些文件的信息。) 事实上，如果你的服务器的磁盘坏掉了，你通常可以使用任何一个克隆下来的用户端来重建服务器上的仓库（虽然可能会丢失某些服务器端的挂钩设置，但是所有版本的数据仍在，详见 在服务器上搭建 Git ）。","text":"常用命令 切换分支 git reset --hard ## 查看操作历史，寻找之前记录的分支 git reflog ## 查找指定行的commit log git log -S \"void ss()\" /path/file 将上次commit取消, 保留本地所有修改, 重新发起commit 1git reset --soft HEAD^ 查看未提交的文件修改 1git show show not staged 1git diff 查看指定commit存在哪些分支 1git branch -r --contains xxx 查找指定commit后面的commit 1git log --oneline --reverse master..REF | head -n 10 查看merge的commit, 显示出其diff 123git show --first-parent xxxgit log -p --first-parent xxx如果不带-m, merge的commit的快照无法找到parent, 因此不输出内容 How to \"git show\" the diffs for a merge commit? - Stack Overflow 查看被删除的文件相关的commit 12git log --all -- src/mgr/PyModule.cc 查看tag之间差异的commit 1git log v12.2.12..v13.0.2 src/mgr tag功能 如何找到tag是从哪个分支的哪个commit打出? 子模块 git subtree(第三方, 独立仓库子树合并) git submodule(独立的子仓库) .gitmodules修改为mirror地址 git submodule sync git submodule init git submodule update 或者 git submodule update --init --recursive 添加git submodule 123git submodule add &lt;url&gt; &lt;path&gt;git diff --cachedgit commit -m &quot;xxx&quot; submodule的submodule 1git submodule update --init --recursive 理论上这个可以, 那我编译时还触发了git clone的应该是因为代码并不是完全用submodule维持的关系了把? 回滚. git reset --hard即可. git diff 与vscode对接 git支持通过difftool对接一些外部插件 123456789101112git config --global difftool.code.cmd &#x27;code --wait --diff $LOCAL $REMOTE&#x27;git config --global mergetool.code.cmd &#x27;code --wait $MERGED&#x27;git config --global -lgit difftool devgit difftool -t code devgit mergetool -t code dev 潜在问题: 好像在difftool这个交互进程退出前, 会在dock上弹出很多个vscode的图标 记录 git的快照流是指什么？ (参见 Git 内部原理 来了解更多关于到底 .git 文件夹中包含了哪些文件的信息。) 事实上，如果你的服务器的磁盘坏掉了，你通常可以使用任何一个克隆下来的用户端来重建服务器上的仓库（虽然可能会丢失某些服务器端的挂钩设置，但是所有版本的数据仍在，详见 在服务器上搭建 Git ）。 $ git clone https://github.com/libgit2/libgit2 mylibgit 这将执行与上一个命令相同的操作，不过在本地创建的仓库名字变为 mylibgit。 Git 支持多种数据传输协议。 上面的例子使用的是 https:// 协议，不过你也可以使用 git:// 协议或者使用 SSH 传输协议，比如 user@server:path/to/repo.git 。 在服务器上搭建 Git将会介绍所有这些协议在服务器端如何配置使用，以及各种方式之间的利弊。 最后，该命令还显示了当前所在分支，并告诉你这个分支同远程服务器上对应的分支没有偏离。 现在，分支名是 “master”,这是默认的分支名。 我们在 Git 分支 会详细讨论分支和引用。 忽略文件 一般我们总会有些文件无需纳入 Git 的管理，也不希望它们总出现在未跟踪文件列表。 通常都是些自动生成的文件，比如日志文件，或者编译过程中创建的临时文件等。 在这种情况下，我们可以创建一个名为 .gitignore 的文件，列出要忽略的文件模式。 来看一个实际的例子： 123$ cat .gitignore*.[oa]*~ 第一行告诉 Git 忽略所有以 .o 或 .a 结尾的文件。一般这类对象文件和存档文件都是编译过程中出现的。 第二行告诉 Git 忽略所有以波浪符（~）结尾的文件，许多文本编辑软件（比如 Emacs）都用这样的文件名保存副本。 此外，你可能还需要忽略 log，tmp 或者 pid 目录，以及自动生成的文档等等。 要养成一开始就设置好 .gitignore 文件的习惯，以免将来误提交这类无用的文件。 文件 .gitignore 的格式规范如下： 所有空行或者以 ＃ 开头的行都会被 Git 忽略。 可以使用标准的 glob 模式匹配。 匹配模式可以以（/）开头防止递归。 匹配模式可以以（/）结尾指定目录。 要忽略指定模式以外的文件或目录，可以在模式前加上惊叹号（!）取反。 所谓的 glob 模式是指 shell 所使用的简化了的正则表达式。 星号（*）匹配零个或多个任意字符；[abc] 匹配任何一个列在方括号中的字符（这个例子要么匹配一个 a，要么匹配一个 b，要么匹配一个 c）；问号（?）只匹配一个任意字符；如果在方括号中使用短划线分隔两个字符，表示所有在这两个字符范围内的都可以匹配（比如 [0-9] 表示匹配所有 0 到 9 的数字）。 使用两个星号（*) 表示匹配任意中间目录，比如a/**/z 可以匹配 a/z, a/b/z 或 a/b/c/z等。 我们再看一个 .gitignore 文件的例子： 1234567891011121314151617# no .a files*.a# but do track lib.a, even though you&#x27;re ignoring .a files above!lib.a# only ignore the TODO file in the current directory, not subdir/TODO/TODO# ignore all files in the build/ directorybuild/# ignore doc/notes.txt, but not doc/server/arch.txtdoc/*.txt# ignore all .pdf files in the doc/ directorydoc/**/*.pdf TIP GitHub 有一个十分详细的针对数十种项目及语言的 .gitignore 文件列表，你可以在 https://github.com/github/gitignore 找到它. 查看已暂存和未暂存的修改 git .gitignore 我的powershell不能调用，待会看看 另外一种情况是，我们想把文件从 Git 仓库中删除（亦即从暂存区域移除），但仍然希望保留在当前工作目录中。 换句话说，你想让文件保留在磁盘，但是并不想让 Git 继续跟踪。 当你忘记添加 .gitignore 文件，不小心把一个很大的日志文件或一堆 .a 这样的编译生成文件添加到暂存区时，这一做法尤其有用。 为达到这一目的，使用 --cached 选项： 1234$ git rm --cached READMEgit rm 命令后面可以列出文件或者目录的名字，也可以使用 glob 模式。 比方说：$ git rm log/\\*.log 注意到星号 * 之前的反斜杠 ， 因为 Git 有它自己的文件模式扩展匹配方式，所以我们不用 shell 来帮忙展开。 此命令删除 log/ 目录下扩展名为 .log 的所有文件。 类似的比如： 1$ git rm \\*~ 该命令为删除以 ~ 结尾的所有文件。. Git 保存的不是文件的变化或者差异，而是一系列不同时刻的文件快照。 http://git-scm.com/book/zh/v2/Git-%E5%88%86%E6%94%AF-%E8%BF%9C%E7%A8%8B%E5%88%86%E6%94%AF 远程分支不太能够理解，比如远程仓库和本地仓库分支之间fetch什么的 还有origin/master怎么操作 现在，可以运行 git fetch teamone 来抓取远程仓库 teamone 有而本地没有的数据。 因为那台服务器上现有的数据是 origin 服务器上的一个子集，所以 Git 并不会抓取数据而是会设置远程跟踪分支 teamone/master 指向 teamone 的 master 分支。 这里有些工作被简化了。 Git 自动将 serverfix 分支名字展开为 refs/heads/serverfix:refs/heads/serverfix，那意味着，“推送本地的 serverfix 分支来更新远程仓库上的 serverfix 分支。” 我们将会详细学习 Git 内部原理 的 refs/heads/ 部分，但是现在可以先把它放在儿。 你也可以运行 git push origin serverfix:serverfix，它会做同样的事 - 相当于它说，“推送本地的 serverfix 分支，将其作为远程仓库的 serverfix 分支” 可以通过这种格式来推送本地分支到一个命名不相同的远程分支。 如果并不想让远程仓库上的分支叫做 serverfix，可以运行 git push origin serverfix:awesomebranch 来将本地的 serverfix 分支推送到远程仓库上的 awesomebranch 分支。 如何避免每次输入密码 如果你正在使用 HTTPS URL 来推送，Git 服务器会询问用户名与密码。 默认情况下它会在终端中提示服务器是否允许你进行推送。 如果不想在每一次推送时都输入用户名与密码，你可以设置一个 “credential cache”。 最简单的方式就是将其保存在内存中几分钟，可以简单地运行 git config --global credential.helper cache 来设置它。 想要了解更多关于不同验证缓存的可用选项，查看 凭证存储。 git branch 如何切换一个本地分支跟踪远程仓库的分支 git checkout 哑（Dumb） HTTP 协议 如果服务器没有提供智能 HTTP 协议的服务，Git 客户端会尝试使用更简单的“哑” HTTP 协议。 哑 HTTP 协议里 web 服务器仅把裸版本库当作普通文件来对待，提供文件服务。 哑 HTTP 协议的优美之处在于设置起来简单。 基本上，只需要把一个裸版本库放在 HTTP 跟目录，设置一个叫做 post-update 的挂钩就可以了（见 Git 钩子）。 此时，只要能访问 web 服务器上你的版本库，就可以克隆你的版本库。 下面是设置从 HTTP 访问版本库的方法： 12345$ cd /var/www/htdocs/$ git clone --bare /path/to/git_project gitproject.git$ cd gitproject.git$ mv hooks/post-update.sample hooks/post-update$ chmod a+x hooks/post-update 这样就可以了。 Git 自带的 post-update 挂钩会默认执行合适的命令（git update-server-info），来确保通过 HTTP 的获取和克隆操作正常工作。 这条命令会在你通过 SSH 向版本库推送之后被执行；然后别人就可以通过类似下面的命令来克隆： $ git clone https://example.com/gitproject.git 这里我们用了 Apache 里设置了常用的路径 /var/www/htdocs，不过你可以使用任何静态 web 服务器 —— 只需要把裸版本库放到正确的目录下就可以。 Git 的数据是以基本的静态文件形式提供的（详情见 Git 内部原理）。 通常的，会在可以提供读／写的智能 HTTP 服务和简单的只读的哑 HTTP 服务之间选一个。 极少会将二者混合提供服务。 git pull返回错误“You asked to pull from the remote 'origin', but did not specify a branch. Because this is not the default configured remote for your current branch, you must specify a branch on the command line.” http://stackoverflow.com/questions/3133387/confusing-error-message-from-git refusing to merge unrelated histories 强制git merge --allow-unrelated-histories yourbranch w强制回滚，用来撤销失败的调试 git reset --hard HEAD Auto packing the repository in background for optimum performance. See \"git help gc\" for manual housekeeping. error: The last gc run reported the following. Please correct the root cause and remove .git/gc.log. Automatic cleanup will not be performed until the file is removed. warning: There are too many unreachable loose objects; run 'git prune' to remove them. Git的底层并没有采用 CVS、SVN 底层所采用的那套增量式文件系统，而是采用一套自行维护的存储文件系统。当文件变动发生提交时，该文件系统存储的不是文件的差异信息，而是文件快照，即整个文件内容，并保存指向快照的索引。这种做法，提高 Git 分支的使用效率；但也容易导致代码仓库中内容重复程度过高，从而仓库体积过大。当遇到这种情况时，或者需要将仓库推送到远程主机时，就需要Git中的gc（garbage collect）功能，也就是垃圾回收功能。 大体来说，当运行 \"git gc\" 命令时，Git会收集所有松散对象并将它们存入 packfile，合并这些 packfile 进一个大的 packfile，然后将不被任何 commit 引用并且已存在一段时间 (数月) 的对象删除。 此外，Git还会将所有引用 (references) 并入一个单独文件 git prune功能，似乎是在遇到大文件的问题,有意思，这个git的垃圾回收问题以前倒是没遇到过呢 git status显示utf-8中文 1git config --global core.quotepath false gitlab/github免密 使用ssh密钥时, .ssh/config里的host和对应的IdentifyFile也要指定. 然后git config 看到的username和credential也要对应. git merge 从指定分支合入log到当前分支 git pull 和git pull --rebase git rebase 12345678➜ markless git:(dev) git push origin devTo https://github.com/sean10/markless.git ! [rejected] dev -&gt; dev (non-fast-forward)error: failed to push some refs to &#x27;https://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@github.com/sean10/markless.git&#x27;hint: Updates were rejected because the tip of your current branch is behindhint: its remote counterpart. Integrate the remote changes (e.g.hint: &#x27;git pull ...&#x27;) before pushing again.hint: See the &#x27;Note about fast-forwards&#x27; in &#x27;git push --help&#x27; for details. 可以用下述强制命令. 1git push --force-with-lease origin dev gh (github CLI) 查找关联的PR 1234567# 登录, 使用token生成gh auth login # 配置该token缺失的权限gh auth refresh -h github.com -s admin:public_keygh repo set-defaultgh pr view 18276 简单讲下怎么追溯社区提交 注意vscode装下gitlens, 下载下带git记录的版本代码, 然后看到不理解的部分, 就去翻ceph的commit提交时的PR, 看提交时是怎么说的 如果配置gitlens好了, 直接点开commit即可. 如果没配置好, 这里也有commit id. 手动拼接url也可以进去, 比如最后那个commit id, https://github.com/ceph/ceph/commit/c7ee66c 如果是手动找到的commit id, 那也可以直接git show c7ee66c 查询tracker缺陷单, 从而找到PR 在tracker.ceph.com中搜索问题关键词.\u0000 gitlens 使用 search commits 唯一遇到问题是有多个repo时, 每次都需要选择一下 手动在git的remotes界面右键关闭Repo, 下次搜索就不用手动选择了, 不会搜那个repo了. # 参考 1. git gc功能 2. Git子仓库深入浅出 - 知乎**** 快速在commit间切换 hutusi/git-paging: Treat git log as a book, exec `git next` or `git prev` to checkout the next or the previous commit. 查看上次和本次之间的diff 1git diff HEAD^ HEAD 阅读开源代码小技巧 | 胡涂说 git环境准备 12345678# 从之前的设备上把~/.ssh/config下配置好ssh代理Host github.com ProxyCommand nc -x 10.11.12.2:7890 %h %p# 从之前设备上把id_rsa默认密钥复制过来, 或者在~/.ssh/config中指定IdentifyFilegit config --global user.name sean10git config --global user.email sean10reborn@gmail.com","categories":[{"name":"专业","slug":"pro","permalink":"https://sean10.github.io/categories/pro/"}],"tags":[{"name":"git","slug":"git","permalink":"https://sean10.github.io/tags/git/"}]},{"title":"C++_Note","slug":"C-Note","date":"2017-02-10T14:49:18.000Z","updated":"2023-03-18T15:11:14.853Z","comments":true,"path":"2017/02/10/C-Note/","link":"","permalink":"https://sean10.github.io/2017/02/10/C-Note/","excerpt":"使用qt信号槽时，始终no such slots，原因是我没有在槽函数的类中使用Q_OBJECT MACRO 这个的原因是什么呢？ 在类声明的开始位置必须加上Q_OBJECT语句，这条语句是不可缺少的，它将告诉编译器在编译之前必须先应用 moc工具进行扩展 这个时候先执行qmake，再build","text":"使用qt信号槽时，始终no such slots，原因是我没有在槽函数的类中使用Q_OBJECT MACRO 这个的原因是什么呢？ 在类声明的开始位置必须加上Q_OBJECT语句，这条语句是不可缺少的，它将告诉编译器在编译之前必须先应用 moc工具进行扩展 这个时候先执行qmake，再build 开了一个refresh信号的线程，但是一使用emit signalRefresh就爆出系统错误 &gt;:-1: error: symbol(s) not found for architecture x86_64 &gt;:-1: error: linker command failed with exit code 1 (use -v to see invocation) 这个错误经常会出现 c++跨文件或跨类传输变量参数是通过在对应文件声明类，然后调用该类获得参数的函数 但是qt里我一旦这样做，就会出现上面那个系统错误。 普通形参加不加const限定符对实参没有影响，引用形参和指针形参前面没有const限定符时，实参必须是非const的，而前面有const限定符时对实参也没有什么影响。 为什么会出现这种情况？ 原因在于实参的传递方式不同，函数中的形参是普通形参的时，函数只是操纵的实参的副本，而无法去修改实参，实参会想，你形参反正改变不了我的值，那么你有没有const还有什么意义吗？引用形参和指针形参就下不同了，函数是对实参直接操纵，没有const的形参时实参的值是可以改变的，这种情况下怎能用函数来操纵const实参呢。 ui文件似乎必须要建一个类通过setupUI才能使用 主要需要新建一个dialog来show就可以了 Qt的模态对话，setModal和dialog.exec() == box::accepted有什么区别？ QT的close没有反应，似乎要使用事件循环 setAttribute (Qt::WA_DeleteOnClose); 这个明明是解决内存泄露问题，为什么可以关闭窗口呢，而close却做不到 qVector输入之后，造成implicitly deleted because base class \"QObject\" has a deleted copy constructor Qt 资源文件，可以通过添加qrc来实现路径的操作 但是 //路径这里存在问题，为什么添加了qrc之后依旧不需要前缀就可以使用了呢？ 明明理论上说要\":/db/user.db\" 但只是\"user.db\"就可以使用了 始终不能调用数据库，原因是我没有使用query.finish，以及建表语法出现了错误。 事件似乎和信号有点相似，又有点不同。 事件是一个新的概念，与信号不一样。 又遇到了当初的link错误，没有详细信息的那种 SF的答案是这个，感觉比较靠谱，我也确实有在Compile Output里看到问题，是client.o的问题，不过这个文件我都没有引用，为什么会错呢 把databaseControl设置继承QObject就出现编译不过的问题 就是上面的link错误，不过更复杂 遇到这个错误error: member function not viable this argument has type const 但是我一时忘了怎么解决的了 call to implicitly-deleted copy constructor /Users/sean10/Qt/5.8/clang_64/lib/QtCore.framework/Headers/qlist.h:461: error: call to implicitly-deleted copy constructor of 'centralAirConditioner' current-&gt;v = new T(reinterpret_cast&lt;T&gt;(src-&gt;v)); ^ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 遇到这个错误，发现又是因为继承了基类QObject的原因 暂时设计了从multithread发送信号到databaseControl,暂时没能测试出数据是否发送成功 好像知道为什么发送了信号，但槽函数没有执行的原因了，似乎是因为信号和槽不在一个线程里 但是默认是会执行异步的啊 稍后添加对于开关机的容错措施 数据锁尚未添加 优先设置spinBox的lowtem会导致workTemperature变成这个lowTem,明明是满足他的约束的 噢，可能是因为spinBox一开始是0，没有设置，当有了约束之后，自动变成了18，满足了值变动，所以导致初始化被覆盖了。 tcp粘包问题： 怎么分也需要双方组织一个比较好的包结构，所以一般可能会在头加一个数据长度之类的包，以确保接收。 从控机修改工作模式，但没有发送给主控机的过程，这个问题有待修正 这里应该根据文档来写：从控机没有调整工作模式的机会，只能由主控机设定 connectToHost似乎是mac的问题，大大的windows执行就没有问题。 找到每次修改完工作温度，室温就顺便同步的原因了，是因为信号问题，每发送一个SignalSendRequest就执行了9次SendRequest. 但是没有找到有多次connect的函数啊。 即便是用了uniqueConnection还是执行了多次。 找到问题了，有另外一个函数不停发送了signal，定时发送 第二次从控机开机，主控机上没有再显示出那台从控机状态？ why? 还有解决粘包问题 把室温用电子时钟模式展示出来 可以使用doxygen来进行根据注释生成文档 /** * 要输出成文档的注释 */ 或者 //! C++在类头文件中试图定义QVector的成员变量，提示错误，不能理解。 std::vector numList[9]; 头文件这样定义成员变量，但是在构造函数中不能对他初始化。 不管是QVector还是vector都不行。 问题的回答是这么说的： 这是定义，不是声明。良好的C++规范要求，除了类定义、inline函数定义、const常量定以外，头文件内不应该放置其他定义。 其次：猜测一下，你这是在试图定义(或声明)类的成员变量么？ 建议：补充一下C++基础。 找到原因了，成员函数内不能定义，毕竟只是一个声明. 在主函数内就可以了 用QVector需要先进行resize,就像分配内存一样？因为QVector我不能直接定义一个81个单元的Vector。 为什么重定向输入，结果读取不了呢？明明从控制台输入就可以。 使用macro宏定义时，始终没能正确替换表达式 现在虽然会了用clang编译选项，但是还是非常不对。 结果居然是因为我宏用了小写……导致了错误，我居然一直没发现。 tmp[] = {9,9}; //vector_2 = tmp; vector vector_2(tmp, tmp+1); 这样就报出了 1234567code.cpp:158:9: error: expected expression tmp[] = &#123;9,9&#125;; ^code.cpp:158:13: error: expected expression tmp[] = &#123;9,9&#125;; ^2 errors generated. 奇怪，用vector&lt;int&gt; vector_2(begin(tmp), end(tmp)); 同样也有这个问题，但是上面那个赋{1}的单项的就没有问题。 发现问题了，只能初始化的时候直接赋列表值，之后就只能一个个赋，或者再定义一个了。 发现segmentfault的原因了，传入指针时，得先定义或者new一下，不然传入赋完值，定义的指针位置什么都没变，就得不到你要的结果了。 C++11添加的raw字符串 C++允许省略C中的结构体的struct语句 C++11支持数组、字符串、结构体列表初始化 c++仅当使用可变参数时函数参数使用……，而C在函数原型中使用可以使用空格()，C++就必须至少是(……),但是更推荐句首说的规则。 有一层const关系时，可以通过非const数据的指针来修改const类型的指针指向的非const类型的数据。 函数指针中(*pf)居然与pf在使用时等价，天哪~ 这种函数引用操作的意义是什么？怎么感觉和在函数中使用没什么区别呀？ 噢，可以省去写重载几个方法的过程，直接传入参数和使用的方法就可以返回结果。 c++11的auto(auto似乎只是自动类型推断，出了错还是程序员的问题)类型转换和显式、隐式类型转换区别在哪里？ 如何传递参数给引用调用时，这个参数是个表达式时，会报错，因为这样会把引用的参数被赋值成那个为了计算表达式而自动建立的临时变量 但是用const引用即可，可以保证这个引用不会被临时变量修改，又可以创建临时变量来计算表达式。 c++11有了 右值引用，可以接受常量了，据说是用来实现移动语义，(move semantics) 返回引用的作用，传统返回，会先把返回的结构复制到一个临时位置，再复制给要赋值的变量，而引用的返回就省去临时位置了。(但是如果这个返回的是该函数中的一个临时变量，这样就会越界，程序出错了，因为该临时变量已经被释放了，却还要从这个位置调用变量) PS:返回引用的函数实际上是被引用的变量的别名。 在使用引用返回时时，如果不使用const，会导致该函数成为左值，可以被赋值，导致错误 重载运算符时省略const是个好方法，但是一般还是使用const更好。 继承有另一个特征，基类引用可以指向派生类对象，而不用进行强制类型转换。 一个基类作为形参的函数，可以输入这个基类的派生类作为实参！！！ 棒！ 默认参数 函数多态和函数重载，似乎不太一样 一个函数的多个形式，是长什么样呢？据说是同一回事，但是通常使用函数重载 在检查特征标时，编译器将引用和类型本身视为同一个特征标。 将非const变量作为实参赋给const变量是合法的。 返回类型可以不同，但是特征标也必须不同。 编译器会跟踪重载函数，进行名称修饰或者名称矫正 模板里的typename是C++98添加的，在这以前都是用class的，所以能用typename还是用typename吧 template需要声明也需要定义 模板重载 模板局限性，有些类型的操作不支持 ### 显示具体化 具体化优先于常规模板，而非模板函数优先于具体化和常规模板。 template&lt;&gt; void Swap&lt;job&gt;(job &amp;, job &amp;); 实例化和具体化 隐式实例化，就是使用模板生成函数定义 现在支持了显式实例化， template void Swap&lt;int&gt;(int, int); 显式实例化可以将原本不匹配的模板函数调用，进行了强制类型转换以后进行调用。 。 以上统称为具体化。 相同之处在于，它们表示的都是使用具体类型的函数定义，而不是通用描述。 选择最佳重载函数时 1. 完全匹配 2. 提升转换(char/short到in, float到double) 3. 标准转换(int to char,long to double) 4. 用户定义的转换，如类声明中定义的转换 术语“most specialized”并不一定意味着显示具体化，指编译器推断使用哪种类型时执行的转换最少。 这个属于C++98增加的函数模板的部分排序规则 不知道模板函数中，应该在声明中使用哪种类型，现在可以用关键字decltype 还有一种函数声明语法（C++11后置返回类型) 1234567891011double h(int x, float y);变成auto h(int x, float y) -&gt; double;使用template &lt;class T1, class T2&gt;auto gt(T1 x, T2 y) -&gt; deltype(x+y)&#123; ... return x + y;&#125; c++内存模型 存储持续性 自动存储持续性 静态存储持续性 线程存储持续性(C++11) 动态存储持续性 内部链接性和外部链接性 const默认内部链接性 可以通过extern扩展 内联函数 似乎不需要满足单定义规则 multable可以让优化 实现可以使用其他语言链接性 new失败返回，std::bad_alloc new是在堆中建立 p1 = new(buffer) int;在buffer中建立，buffer指定的是静态内存中，不能用delete 名称空间 using编译指令和using声明 C++保证函数不会修改变量， void Stock::show() const 声明为const成员变量 用枚举来创建符号常量 可以用static在类声明中定义常量 static const int Mouth = 12; ^ | 像这样 c++11提供了新枚举 123enum class egg &#123;Small, Medium, Large, Junbo&#125;;enum class t_shirt &#123;Small, Medium, Large, junbo&#125;; 不过这种不支持隐式类型转换，不能自动变成int，需要显式转换 当构造函数只接受一个参数是，下面这3个是等价的 123Swtonewt incognito = 275;Swtonewt incognito(275);Swtonewt incognito = Swtonewt(275); 不过，如果把构造函数声明成explicit，就不能用上面的第一行了，就关闭了隐式自动转换 转换函数： 把类赋给基本类型变量： 12operator int();operator double(); * 转换函数必须是类方法； * 转换函数不能指定返回类型 * 转换函数不能有参数 过程中自动应用了类型转换 出现多个转换函数，用隐式存在二义性时，编译器会error 类中的静态存储类 static声明的变量 即便有多个类副本，也只有一个这个变量，是共享的。 C++11提供了2个特殊成员函数： 移动构造函数和移动赋值运算符 c++11空指针nullptr 静态类成员函数，只能用这种方法调用 12int count = String::HowMany(); 继承 继承is-a关系：公有继承 is a kind of关系 而不是has a 关系 多态公有继承 虚方法 在派生类中重新定义基类的方法 虚函数能够根据指针/引用的对象实际是什么类型而确定选择基类的方法还是派生类的方法 可以使用一个对象的指针数组来保存他和他的派生类，实现一种多态性 虚析构函数也是有作用的，比如保证派生类的析构作用能够生效 静态联编(static binding) 使用了虚函数时，静态联编不足以做到，就需要使用到动态联编 由于效率和概念模型才使用2种联编方式 如果要在派生类中重新定义方法，才定义虚函数，否则就定义非虚函数 虚函数的工作原理 析构函数应当是虚函数， 因为基类的析构函数如果不是虚函数，就无法释放在派生类中新添加的对象的内存 友元不能是虚函数 重新定义虚函数，将隐藏基类的方法 不过如果返回类型是基类引用或指针，则可以修改为派生类的引用或指针，叫做covariance of return type 抽象基类 ABC概念 使用纯虚函数 包含纯虚函数的对象只能用作基类，无法被定义，声明结尾为0 12virtual double Area() const = 0; 继承和动态内存分配 友元类 lambda表达式 1234[](int x) &#123;return x % 3 == 0;&#125;//匿名函数[](double x)-&gt;double&#123;int y = x; return x-y;&#125;//不止一句时要用后置语法，因为只有一句返回语句组成lambda时，自动类型推断才管用。 基类动态内存分配，派生类不用，则不用显示定义析构函数、复制构造函数和复制运算符 派生类有，则需要，并且派生类的复制构造函数需要调用基类的复制构造函数（因为没有权限访问基类成员） c++11添加了可以继承的构造函数，不过默认不开 valarray类 使用公有继承，可以获得接口和实现（基类有纯虚函数只能获得接口） 使用组合，可以获得实现，但没有接口 explicit将禁止隐式类型转换 私有继承：可以直接在成员方法中使用基类的私有变量和方法了 也是has-a关系 也可以同时私有继承多个类 C++11的初始化列表是通过initializer_list il来实现的，之后可以看下 在头文件中 智能指针，auto _ptr,unique _ptr和shared _ptr，auto在C++11已经被摒弃 throw()也被摒弃，但是这个是什么东西？ unique _ptr强调对象所有权，而shared _ptr则添加引用计数，在最后的计数为0时才释放 unique可用于数组的变体，new []，而其他2个没有 在用的迭代器的时候，可以用C++11的自动推断，auto pd = score.begin()挺有意思的 for_each(),random_shuffle(),sort()都挺特别的 c++11的循环类似python中的 for(auto x: books) ShowReview(w) 正向迭代器:双向通行算法 迭代器类型只是概念性描述 \badapter，一个类或函数，可以将一些其他接口转换为STL使用的接口 看不太懂 就像这样 123#include &lt;iterator&gt;ostream_iterator&lt;int,char&gt; out_iter(cout, &quot; &quot;); vector反向打印 可以使用rbegin()的指向超尾的反向迭代器，rend()返回一个只想第一个元素的反向迭代器 插入迭代器 c++11添加的概念，可复制插入，可移动插入 移动构造函数 异常规范方面的修改，noexcept 作用域内枚举 右值引用（完全不记得了） 包装器，std::function&lt;double(char, int)&gt; ef c++11，atomic原子操作，并行编程 多个专业库 regex支持正则表达式 --- 不会写widget，所以先写console版本测试时，发现conio.h不是ANSI C标准的，在mac平台C++中 并不支持。 c++ hash函数 hash在C++11有了元编程 123hash&lt;string&gt; h;size_t n = h(url);cout &lt;&lt; n; c++ stringstream getline作为分隔符相当好用 12345while(getline(ss, temp, &#x27;,&#x27;))&#123;&#125;","categories":[{"name":"专业","slug":"pro","permalink":"https://sean10.github.io/categories/pro/"}],"tags":[{"name":"C++","slug":"C","permalink":"https://sean10.github.io/tags/C/"}]},{"title":"《星之梦》传播星空之人","slug":"《星之梦》传播星空之人","date":"2017-01-04T07:03:45.000Z","updated":"2023-03-18T15:11:14.862Z","comments":true,"path":"2017/01/04/《星之梦》传播星空之人/","link":"","permalink":"https://sean10.github.io/2017/01/04/%E3%80%8A%E6%98%9F%E4%B9%8B%E6%A2%A6%E3%80%8B%E4%BC%A0%E6%92%AD%E6%98%9F%E7%A9%BA%E4%B9%8B%E4%BA%BA/","excerpt":"","text":"《星之梦》开篇引出的AI机器人第一时间给我的反应是，这极可能又是基于阿西莫夫机器人三定律之上的人与机器人的故事。 梦美在这里的设定显然不止是常规的Robot，虽然她自称是廉价型，不过也显然不同于故事开始时攻击人类的武装机器人一般只是贯彻攻击指令，她是具有自主性的AI。姑且忽视老化、无修理能力、供电持续30年等一系列相对不现实的因素，当作满足了千万分之一的偶然性吧。这样的设定给梦美提供了一个令人不由得深思的背景，29年多的等待只为服务人类、坚守机器人的守则，这样的梦美为我们揭示的想必就是机器人之中善良的特质吧。 在这个男主时刻为机器人追杀、攻击的年代里，从未遇到善良机器人的男主为其感动，信任了梦美，也得到了梦美的回报，梦美以自己的理念贯彻保护人类。以星空作为回忆媒介，令男主回忆起作为人，不仅仅应该只为生存而生存，而是应当为梦想而追逐。 不过显然啦，假想现实如果发生这样的故事，也就只有人物设定成梦美这样萌，才有后续发展的一丝可能性了。无论如何，亲和感终究只会发生在有羁绊亦或是感官上可接受的对象之间。 在《星之人》剧场版里好像就是之后发生的故事，男主与梦美作为传播星空之人而四处游走之后的故事了，不过现在国内还没上映，估计要等段时间了吧。","categories":[{"name":"随想","slug":"thinking","permalink":"https://sean10.github.io/categories/thinking/"}],"tags":[{"name":"日本","slug":"日本","permalink":"https://sean10.github.io/tags/%E6%97%A5%E6%9C%AC/"},{"name":"动漫","slug":"动漫","permalink":"https://sean10.github.io/tags/%E5%8A%A8%E6%BC%AB/"},{"name":"影评","slug":"影评","permalink":"https://sean10.github.io/tags/%E5%BD%B1%E8%AF%84/"}]},{"title":"爬虫学习笔记","slug":"爬虫学习笔记","date":"2016-10-27T12:49:28.000Z","updated":"2018-03-09T12:49:28.000Z","comments":true,"path":"2016/10/27/爬虫学习笔记/","link":"","permalink":"https://sean10.github.io/2016/10/27/%E7%88%AC%E8%99%AB%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/","excerpt":"爬虫学习笔记 2016.10.27 在一开始按照例子写最简单的爬虫的时候居然都写错了，写成了如下的","text":"爬虫学习笔记 2016.10.27 在一开始按照例子写最简单的爬虫的时候居然都写错了，写成了如下的 1234567import urllib2req = urllib2.Request(&#x27;http://example.com&#x27;)#response = urllib2.urlopen(&#x27;http://python.org&#x27;)response = urllib2.urlopen(req)html = response.readf = open(&quot;out.txt&quot;,&quot;w&quot;)print &gt;&gt; f,html 在html = response.read()这里少加了个括号，导致赋值的内容不是爬到的内容，而是read的属性？ 1&lt;bound method _fileobject.read of &lt;socket._fileobject object at 0x7fea52107bd0&gt;&gt; 得到了这种奇怪的东西 URLError 通常，URLError在没有网络连接(没有路由到特定服务器)，或者服务器不存在的情况下产生。 这种情况下，异常同样会带有\"reason\"属性，它是一个tuple（可以理解为不可变的数组）， 包含了一个错误号和一个错误信息。 我们建一个urllib2_test06.py来感受一下异常的处理： 12345678910111213import urllib2req = urllib2.Request(&#x27;http://www.example.com&#x27;)f = open(&quot;out.txt&quot;,&quot;w&quot;)try: urllib2.urlopen(req)有些东西用js解密的方法，python实在是不会啊except urllib2.URLError, e: print &gt;&gt;f ,e.reason 按下F5，可以看到打印出来的内容是： [Errno 11001] getaddrinfo failed 也就是说，错误号是11001，内容是getaddrinfo failed i have no answer. 123456789101112import urllib2req = urllib2.Request(&#x27;http://bbs.csdn.net/callmewhy&#x27;)f = open(&quot;out.txt&quot;,&quot;w&quot;)try: urllib2.urlopen(req)except urllib2.URLError, e: print &gt;&gt;f ,e.reason #print &gt;&gt; f, e.code 2.HTTPError 服务器上每一个HTTP 应答对象response包含一个数字\"状态码\"。 有时状态码指出服务器无法完成请求。默认的处理器会为你处理一部分这种应答。 例如:假如response是一个\"重定向\"，需要客户端从别的地址获取文档，urllib2将为你处理。 其他不能处理的，urlopen会产生一个HTTPError。 典型的错误包含\"404\"(页面无法找到)，\"403\"(请求禁止)，和\"401\"(带验证请求)。 HTTP状态码表示HTTP协议所返回的响应的状态。 比如客户端向服务器发送请求，如果成功地获得请求的资源，则返回的状态码为200，表示响应成功。 如果请求的资源不存在， 则通常返回404错误。 HTTP状态码通常分为5种类型，分别以1～5五个数字开头，由3位整数组成： ------------------------------------------------------------------------------------------------ 200：请求成功 处理方式：获得响应的内容，进行处理 201：请求完成，结果是创建了新资源。新创建资源的URI可在响应的实体中得到 处理方式：爬虫中不会遇到 202：请求被接受，但处理尚未完成 处理方式：阻塞等待 204：服务器端已经实现了请求，但是没有返回新的信 息。如果客户是用户代理，则无须为此更新自身的文档视图。 处理方式：丢弃 300：该状态码不被HTTP/1.0的应用程序直接使用， 只是作为3XX类型回应的默认解释。存在多个可用的被请求资源。 处理方式：若程序中能够处理，则进行进一步处理，如果程序中不能处理，则丢弃 301：请求到的资源都会分配一个永久的URL，这样就可以在将来通过该URL来访问此资源 处理方式：重定向到分配的URL 302：请求到的资源在一个不同的URL处临时保存 处理方式：重定向到临时的URL 304 请求的资源未更新 处理方式：丢弃 400 非法请求 处理方式：丢弃 401 未授权 处理方式：丢弃 403 禁止 处理方式：丢弃 404 没有找到 处理方式：丢弃 5XX 回应代码以“5”开头的状态码表示服务器端发现自己出现错误，不能继续执行请求 处理方式：丢弃 ------------------------------------------------------------------------------------------------ HTTPError实例产生后会有一个整型'code'属性，是服务器发送的相关错误号。 Error Codes错误码 因为默认的处理器处理了重定向(300以外号码)，并且100-299范围的号码指示成功，所以你只能看到400-599的错误号码。 BaseHTTPServer.BaseHTTPRequestHandler.response是一个很有用的应答号码字典，显示了HTTP协议使用的所有的应答号。 当一个错误号产生后，服务器返回一个HTTP错误号，和一个错误页面。 你可以使用HTTPError实例作为页面返回的应答对象response。 这表示和错误属性一样，它同样包含了read,geturl,和info方法。 我们建一个urllib2_test07.py来感受一下： i have no answer 1234567891011121314151617import urllibimport urllib2url = &#x27;http://www.someserver.com/cgi-bin/register.cgi&#x27;user_agent = &#x27;Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36&#x27;values = &#123;&#x27;name&#x27;: &#x27;Michael Foord&#x27;, &#x27;location&#x27;: &#x27;Northampton&#x27;, &#x27;language&#x27;: &#x27;Python&#x27; &#125;headers = &#123;&#x27;User-Agent&#x27;: user_agent&#125;data = urllib.urlencode(values)req = urllib2.Request(url, data, headers)response = urllib2.urlopen(req)the_page = response.read()f = open(&quot;out.txt&quot;,&quot;w&quot;)print &gt;&gt; f, the_page this has been unacceptable. 2017.11.18 使用selenium+PhantomJS 编写爬虫时，如果单纯是静态网站，Nodejs的cheerio,requests以及Python的urlib、urlib2与request(BeautifulSoup)就能解决需求。如果碰上网站通过AJAX获取数据或者JS延迟获取数据时。 使用lxml解析器的原因是比较性能之后，还是lxml比较优异，基本都能解析 HTTP请求主要分为Get和Post两类： GET是从服务器上获取指定页面信息，POST是向服务器提交数据并获取页面信息。 GET请求参数都显示在URL上，服务器根据该请求所包含URL中的参数来产生响应内容。 \"Get\" 请求的参数 是URL的一部分。 POST请求参数在请求体当中，消息长度没有限制而且以隐式的方式进行发送，通常用来向HTTP服务器提交量比较大的数据（比如请求中包含许多参数或者文件上传操作等）。 \"POST\"请求的参数 不在URL中，而在请求体中。 页面的form表单一般都有method属性，默认值是\"get\"。 举个栗子，登录时提交用户名和密码： 如果用\"get\"方式，提交表单后，则用户输入的用户名和密码将在地址栏中暴露无遗； 如果设置为\"post，则提交表单后，地址栏不会有用户名和密码的显示。 所以处理登录页面的form表单时，发送的请求都是\"POST\"方式。 wsgi协议 字节协议 没找到为什么，python socket建立服务器的时候，浏览器始终接收不到数据，接收到也显示不出来，不明白为什么 chrome和safari不显示，但是firefox显示了，先用firefox,以后再想这几个之间的区别 去掉了HTTP/1.1的表头，居然还能显示出来 换行符协议 特殊字符分割协议 二进制字符长度定义协议 为什么使用301永久重定向呢？ 一个解答是为了SEO 启动和停止ssdb服务 启动：ssdb-server /usr/local/etc/ssdb.conf 守护进程启动方式 ssdb-server -d /usr/local/etc/ssdb.conf 停止： ssdb-server /usr/local/etc/ssdb.conf -s stop 重启：停止： ssdb-server /usr/local/etc/ssdb.conf -s restart 启动客户端:ssdb-cli 支持数据类型 SSDB ⽀持三种数据类型, 别分是 KV(key-value), Hashmap(map), Zset(sorted set). requests爬取中文乱码 使用str(html.content,\"utf-8\")搞定 http://www.cnblogs.com/bitpeng/p/4748872.html StringIO这个模块在python3里有点不一样了，存在了Io模块里，没办法直接用别人的资料了 保存图片在本地 12345678910111213from PIL import Imageimport ioimport requestshtml = requests.get(&quot;http://jwxt.bupt.edu.cn/validateCodeAction.do?random=&quot;)f = open(&#x27;code.jpg&#x27;,&#x27;wb&#x27;)f.write(html.content)f.close()img = Image.open(&#x27;code.jpg&#x27;)#&#x27;/Users/sean10/Desktop/code.jpg&#x27; 而在python3.x中，GIL不使用ticks计数，改为使用计时器（执行时间达到阈值后，当前线程释放GIL），这样对CPU密集型程序更加友好，但依然没有解决GIL导致的同一时间只能执行一个线程的问题，所以效率依然不尽如人意。 这些队列都实现了锁原语，能够在多线程中直接使用 python并发 从threading到multiprocess，再到concurrent.future支持 jsessionid似乎是j2ee的东西 beautifulSoup的对象，如何打印出来，他的子对象tag对象没有text方法 常见的反爬策略主要有： IP限制 UA限制 Cookie限制 资源随机化存储 动态加载技术 …… 对应的反爬处理手段主要有： IP代理池技术 用户代理池技术 Cookie保存与处理 自动触发技术 抓包分析技术+自动触发技术 有效地存储（数据库应该怎样安排） 有效地判重（这里指网页判重，咱可不想把人民日报和抄袭它的大民日报都爬一遍） 有效地信息抽取（比如怎么样抽取出网页上所有的地址抽取出来，“朝阳区奋进路中华道”），搜索引擎通常不需要存储所有的信息，比如图片我存来干嘛... 及时更新（预测这个网页多久会更新一次） BeautifulSoup找不到解析的元素的原因，似乎是因为网页编码问题，比如学校教务系统用的是GBK,不是utf-8，就不好搞了 在使用Beautifulsoup过程中，对于大多数html源码，通过指定正确的编码，或者本身是默认UTF-8编码而无需指定编码类型，其都可以正确解析html源码，得到对应的soup变量。 然后就接着去利用soup实现你所想要的功能了。 但是有时候会发现，有些html解析后，有些标签等内容丢失了，即所得到的soup不是所期望的完整的html的内容。 这时候，很可能遇到了非法的html，即其中可能包含了一些不合法的html标签等内容，导致Beautifulsoup虽然可以解析，没有报错，但是实际上得到的soup变量，内容缺失了一部分了。 比如我就遇到过不少这样的例子： 部分Blogbus的帖子的html中非html5和html5的代码混合导致Beautifulsoup解析错误 之前在为BlogsToWordPress添加Blogbus支持过程中去解析Blogbus的帖子的时候，遇到一个特殊的帖子：http://ronghuihou.blogbus.com/logs/89099700.html，其中一堆的非html5的代码中，包含了这样一段html5的代码的写法，即标签属性值不加括号的： 1234&lt;SCRIPT language=JavaScript&gt;document.oncontextmenu=new Function(&quot;event.returnValue=false;&quot;); //禁止右键功能,单击右键将无任何反应document.onselectstart=new Function( &quot;event.returnValue=false;&quot;); //禁止先择,也就是无法复制&lt;/SCRIPT language=JavaScript&gt; 结果导致Beautifulsoup解析错误，得到的soup中，找不到所需要的各种class等属性值。 对应的解决办法就是，把这部分的代码删除掉，然后再解析就可以了： 其中一堆的非html5的代码中，包含了这样一段html5的代码的写法，即标签属性值不加括号的： 123456789foundInvliadScript = re.search(&quot;&lt;SCRIPT language=JavaScript&gt;.+&lt;/SCRIPT language=JavaScript&gt;&quot;, html, re.I | re.S );logging.debug(&quot;foundInvliadScript=%s&quot;, foundInvliadScript);if(foundInvliadScript): invalidScriptStr = foundInvliadScript.group(0); logging.debug(&quot;invalidScriptStr=%s&quot;, invalidScriptStr); html = html.replace(invalidScriptStr, &quot;&quot;); logging.debug(&quot;filter out invalid script OK&quot;);soup = htmlToSoup(html); 判断浏览器版本的相关代码，导致Beautifulsoup解析不正常 之前在给BlogsToWordpress添加新浪博客的支持的过程中 遇到很多新浪博客的帖子的html中，包含很多判断浏览器版本的相关代码： &lt;!–[if lte IE 6]&gt; xxx xxx &lt;[endif]–&gt; 由此导致Beautifulsoup解析html不正常。 font标签嵌套层次太多，导致Beautifulsoup无法解析html 接上面那个解析新浪博客帖子的例子，期间又遇到另外一个问题，对于一些特殊帖子：http://blog.sina.com.cn/s/blog_5058502a01017j3j.html 其包含特殊的好几十个font标签且是一个个嵌套的代码，导致无法Beautifulsoup无法解析html，后来把对应嵌套的font标签删除掉，才可以正常解析。 相关python代码为： handle special case for http://blog.sina.com.cn/s/blog_5058502a01017j3j.html processedHtml = processedHtml.replace('', \"\"); processedHtml = processedHtml.replace(\"\", \"\"); 遇到其他类似的问题，也可以去删除或替换出错代码，即可解决问题。 不过需要说明的是，很多时候，你未必很容易就找到出错的代码。 想要找到出错的代码，更多的时候，需要你一点点调试，一点点的删除看似可疑的一些html源码，然后最终才能定位到出错的代码，然后删除掉后，才可以正常工作的。 uri资源文件如何获取，似乎有格式 似乎是jquery自带的延迟加载技术 像淘宝或者京东这样的APP页面上有很多图片,当我们滑到下一屏时下一屏的图片才会加载,这就采用了图片懒加载的方式. 图片懒加载,简单来说就是在页面渲染过程中,图片不会一次性全部加载,会在需要的时候加载,比如当滚动条滚动到某一个位置时触发事件加载图片,如下代码: 通过js将img标签的data-src属性赋值给src属性 但是如果是用base64的，在dom里属性就消失不见了 针对decode base64编码的图片比较慢的问题,我们可以选择使用canvas来加速.当向canvas发出绘画命令时,浏览器直接将指令发到图形加速器而不需要开发者更多的干预,硬件图形加速器则以难以执行的运算速度实时绘画和渲染图形.因此,我们可以使用canvas来渲染base64编码后的图片 Inlined Placeholder Image To reduce the amount of request you can use data uri images as the placeholder. 最后解析出来的base64居然不是图片，也是怪奇怪的 http://api.nicodic.jp/ 豆瓣获取url还是非常简单的，就是被403了，明天再看了吧，还有个数据库连接池多线程的问题需要试试。 python的json.dumps方法默认会输出成这种格式\"35aba26ed\",。 要输出中文需要指定ensure_ascii参数为False. 1output = json.dump(jsonData,targetFile,ensure_ascii=False,indent=4) 在输出的时候，对文件制定特定的UTF-8编码： 123import codecswith codecs.open(path,&#x27;w&#x27;,&#x27;utf-8&#x27;) as w: 框架使用 主要期望了解一下目前社区始终更常用的类似低代码的配置化实现方案. scrapy 12345678910scrapy shell &quot;https://quotes.toscrape.com/page/1/&quot;scrapy genspider itcast &quot;itcast.cn&quot;cd tutorialscrapy crawl itcast 剩下主要是item和spider之间组合的问题 使用一个parse函数的输出作为另一个函数的输入 通过对parse函数的callback嵌套触发Request Using multiple spiders at in the project in Scrapy - Stack Overflow python - Scrapy - parse a page to extract items - then follow and store item url contents - Stack Overflow 动态目录实现 关键是以下两个ImagesPipeline的函数重载 get_media_requests image_paths Scrapy框架之利用ImagesPipeline下载图片 - 简书 Downloading and processing files and images — Scrapy 2.8.0 documentation 123def file_path(self, request, response=None, info=None, *, item=None): image_guid = hashlib.sha1(to_bytes(request.url)).hexdigest() return f&quot;full/&#123;image_guid&#125;.jpg&quot; 奇怪, 如果按照ImagesPipeline的函数, 这里应该是full才对, 所以到底file_path是什么时候感知到settings里的IMAGES_STORE的呢? ## PySpider 订阅源 学习 rsshub legado 书源 订阅源 最终","categories":[{"name":"专业","slug":"pro","permalink":"https://sean10.github.io/categories/pro/"}],"tags":[{"name":"Python","slug":"Python","permalink":"https://sean10.github.io/tags/Python/"},{"name":"爬虫","slug":"爬虫","permalink":"https://sean10.github.io/tags/%E7%88%AC%E8%99%AB/"},{"name":"Spider","slug":"Spider","permalink":"https://sean10.github.io/tags/Spider/"}]},{"title":"吸血鬼起源","slug":"吸血鬼起源","date":"2016-08-26T09:25:43.000Z","updated":"2023-03-18T15:11:14.830Z","comments":true,"path":"2016/08/26/吸血鬼起源/","link":"","permalink":"https://sean10.github.io/2016/08/26/%E5%90%B8%E8%A1%80%E9%AC%BC%E8%B5%B7%E6%BA%90/","excerpt":"之所以写起这个，是因为最近开始写起宅文了，背景设定需要就来搜集一些资料。 所以本文会提到的起源只会是从神话角度和各式作品里提取的。","text":"之所以写起这个，是因为最近开始写起宅文了，背景设定需要就来搜集一些资料。 所以本文会提到的起源只会是从神话角度和各式作品里提取的。 当下流行的魅力无边的吸血鬼来自于1819年约翰·波里道利，这是19世纪早期最有影响力的吸血鬼作品。 不过，作为吸血鬼小说的精粹而被铭记，并且为现代吸血鬼传说铺路的，是布莱姆·斯托克1893年所著的《德古拉》。 在民间传说之中，虽然认为吸血鬼在夜间比较活跃，但通常它们并没有被认为对阳光敏感。 在一些文化里，吸血鬼不能在镜中倒映，也没有影子，也许这是吸血鬼没有灵魂的表现。（这点可以借鉴） 吸血鬼起源除了小说作品和民间传说之外，在《圣经》等传说、史诗中也保有可追溯的典故。 1.犹大 犹大背叛耶稣的典故众所周知，他背叛耶稣，加上他自缢身亡不符合礼数，因而死后灵魂没有办法安息，天堂与地狱都没有他的位置。因此犹大的灵魂回到原本的身体，变成了吸血鬼。 据说背叛上帝或是基督教信仰的人，一定会变成吸血鬼，因为灵魂无处可去，只好游荡人间，永世不得安息，直到获得赦免的那一天。 2.该隐(Cain) 该隐弑弟亚伯，受到上帝的诅咒，永远不能行于白天之下，只能在黑暗中与夜晚的生物共存，并靠吸食动物的血为生。与小说中的吸血鬼形象十分贴切，因而便传出了其为吸血鬼先祖的传说。 该隐之后与同被诅咒的莉莉丝相结合，诞生了13个孩子，之后传说中的吸血鬼十三氏族是他们的后代第三代吸血鬼所创立的，据说他们叛变了他们的父母。 在面临天主教捕杀危险即将灭族之际，七大幸存氏族确立了六条戒律。 第一戒律：避世(The First Tradition: The Masquerade) 不可對非氏族的人顯露自己的面目，否則其他吸血鬼會和你斷絕一切關係。 第二戒律：領權(The Second Tradition: The Domain) 在自己的領土上，你有著至高無上的權利，任何外來的吸血鬼都要尊重你。 第三戒律：後裔(The Third Tradition: The Progeny) 如果你要創造新的吸血鬼，你必須得到尊長的同意。如果你違反此戒條，你和你的後裔都會被處死。 第四戒律：責任(The Fourth Tradition: The Accounting) 你所創造的吸血鬼是你的後裔，在他們被讓渡之前，你應該在各個方面指導他們。他們的罪要當成自己的來忍耐。 第五戒律：客尊(The Fifth Tradition: Hospitality) 吸血鬼應該互相尊重領權，當你到達陌生的土地的時候，應該向當地的長老引薦自己，不得他的批准，你不能做任何事情。 第六戒律：殺親(The Sixth Tradition: Destruction) 嚴禁殺害你的同類，只有長老有獵殺的權利。 以下是动漫世界中的背景设定，可忽视 《噬血狂袭》： 魔族中的一种，不老不死，恢复力和身体能力超越一般人类，同时拥有眷兽。 吸血鬼吸血可以补充魔力，不过吸血行为多半是由于性欲引起的冲动，因为吸血冲动而把爱人吸血过度致死的事件也不少。 吸血鬼之所以被称为最强的魔族，那都是因为有压倒性战力的眷兽，其肉体能力在魔族中并不算强。 即便被夸大成不咯不死，吸血鬼也并非彻底的不死之躯。特别是控制魔力的脑以及司掌血液循环的心脏，都算致命性弱点。 这里的真祖的来源是人类被现在已逝去的神施加了诅咒，或是经由神的密咒自身变成吸血鬼，通过吞噬吸血鬼也可以把人类变成真祖，也可能被反噬，如主角晓古城。 这里的吸血鬼无法进行同族相噬，年轻世代的吸血鬼如果吞噬了高等级的吸血鬼，可能被对方从身体内侧吞噬。 《十字架与吸血鬼》： 有“力量之大妖”的称号的稀少种族。自尊心很强，能够把自身的妖气化成力量以使出各种物理攻击，而且有异常强的复原能力及妖气探知。不过，这里的吸血鬼参考了民间传说，弱点为水和十字架。他们只能使用放入特殊草药的水。另外，吸血鬼的血拥有使人复原的能力，只要肉体能够承受血液，即使在濒死边缘也可以复原。不过，接受者也有副作用，拥有吸血鬼力量就有机会像主角一样尸鬼化。 《终结的炽天使》中提取到的背景资料是这样的。 这里的吸血鬼设定是有尖耳锐牙与赤瞳，以及常年不易老化的身体，身体能力是人类的七倍以上，这部分是基本设定。 这里的吸血鬼依旧遵循了常规的怕光的设定，不过这里吸血鬼外出的服装上会装备一种叫做紫外线中和的装置，是左上臂黑色那块。 据称这个世界观下的吸血鬼发展下去最终是变成鬼。 1 2 然后，这里并没有提到始祖的的由来。 参考资料： [1] 《终结的炽天使》漫画8.5卷，http://home.gamer.com.tw/creationDetail.php?sn=2860481 [2] 维基百科——吸血鬼，https://zh.wikipedia.org/wiki/%E5%90%B8%E8%A1%80%E9%AC%BC [3] 维基百科——噬血狂袭，https://zh.wikipedia.org/wiki/%E5%99%AC%E8%A1%80%E7%8B%82%E8%A5%B2 [4] 维基百科——十字架与吸血鬼，https://zh.wikipedia.org/wiki/%E5%8D%81%E5%AD%97%E6%9E%B6%E8%88%87%E5%90%B8%E8%A1%80%E9%AC%BC [5] 吸血鬼起源的三大典故，http://darthmoon.pixnet.net/blog/post/19794082 [6] 揭秘吸血鬼种族的由来，http://www.nownews.com/n/2013/06/15/231804","categories":[{"name":"随想","slug":"thinking","permalink":"https://sean10.github.io/categories/thinking/"}],"tags":[{"name":"小说","slug":"小说","permalink":"https://sean10.github.io/tags/%E5%B0%8F%E8%AF%B4/"},{"name":"吸血鬼","slug":"吸血鬼","permalink":"https://sean10.github.io/tags/%E5%90%B8%E8%A1%80%E9%AC%BC/"}]},{"title":"小议各式主角之死","slug":"小议各式主角之死","date":"2016-08-04T23:25:34.000Z","updated":"2023-03-18T15:11:14.858Z","comments":true,"path":"2016/08/05/小议各式主角之死/","link":"","permalink":"https://sean10.github.io/2016/08/05/%E5%B0%8F%E8%AE%AE%E5%90%84%E5%BC%8F%E4%B8%BB%E8%A7%92%E4%B9%8B%E6%AD%BB/","excerpt":"","text":"在作家手中，为了推进故事发展，往往总是会有角色离开我们，主角也无例外。 在我最喜欢的《叛逆的鲁鲁修》中，lelouch在故事的最后以自己的死亡来解放全世界。Lelouch决心背负世界的罪恶，作为全世界的敌人而死，让人们珍惜来之不易的和平。而型月世界里的Gilgamish说过“王来承认，王来允许。王来背负整个世界。”各个故事中，作为王的主角，若是离去，必背负着一切。在《罪恶王冠》中，集如同Lelouch的挚友朱雀一般，背负了祈和涯托付给他的未来以及他自身的罪孽继续活着。 不过，存在王的故事往往都是基于一个宏大的世界观，具有伟大的背景，这样的故事写好了的终究还是少数。更多的还是基于现实的日常，但又脱离了现实的故事。《命运石之门》，我想就可以说是一部代表作。以世界线变动作为这个世界的基准，凤凰院凶真扰动了世界线，拯救了克里斯蒂娜的死，但有得必有失，等价交换的原则，以真由理之死为代价。故事最终找到了一个完美的世界线，作者给了一个幸福的结局。这类故事基于日常，所以主线都会围绕着人与人之间的感情而展开，最多的是爱情，友情其次。 说到爱情之死，不得不提到Key社名作《Clannad》了。在After Story中，渚身体虚弱离去了，朋也崩溃了，颓废了，直到在早苗的安排下带着汐旅行时意识到自己的父亲在同样的处境下所背负的，意识到了自己所该做的，决心照顾好汐。同样的，汐也走上了和渚小时候面临的同样的处境，坚强的汐最后还是没能挺过发烧。这个时候，这个小镇的奇迹发生了，朋也回到了渚生下汐的那一刻，这个世界里，渚活下来了。故事终于在一遍又一遍的催泪中达成了一个满意的结局。 爱情之死，都是作为剧情的推动，引发其他角色的心理的一个巨大变化。 除此之外，就是推理故事中的推理所需的案件之死了。《弹丸论破》是以角色的死亡来为主角提供线索破解故事，《名侦探柯南》则是柯南所到之地，必有人死亡。 前两种死亡，都会带来无比的催泪效果，虐心倒不觉得，毕竟作者提供的铺垫已足够强烈。 PS:《斩！赤红之瞳》里的死根据剧情明明可以避免，却偏要以悲剧来推动，并不能接受。","categories":[{"name":"随想","slug":"thinking","permalink":"https://sean10.github.io/categories/thinking/"}],"tags":[{"name":"死亡","slug":"死亡","permalink":"https://sean10.github.io/tags/%E6%AD%BB%E4%BA%A1/"}]},{"title":"论Pokemon Go","slug":"论Pokemon-Go","date":"2016-07-14T13:30:20.000Z","updated":"2023-03-18T15:11:14.838Z","comments":true,"path":"2016/07/14/论Pokemon-Go/","link":"","permalink":"https://sean10.github.io/2016/07/14/%E8%AE%BAPokemon-Go/","excerpt":"","text":"","categories":[],"tags":[]},{"title":"重读《爱的艺术》","slug":"重读《爱的艺术》","date":"2016-07-02T02:09:22.000Z","updated":"2023-03-18T15:11:14.883Z","comments":true,"path":"2016/07/02/重读《爱的艺术》/","link":"","permalink":"https://sean10.github.io/2016/07/02/%E9%87%8D%E8%AF%BB%E3%80%8A%E7%88%B1%E7%9A%84%E8%89%BA%E6%9C%AF%E3%80%8B/","excerpt":"","text":"弗洛姆在书中首先讲述了爱情其本质也是一门艺术，而非对象问题。 其次讲述了爱情的本质目的是为了补全人类的天性的缺失，弥补个人的孤独，这是人类的生存的必要条件。 第三讲述的是孩子对父母的依存，从父母身上找到仍在胎中时的温暖的感觉。而父母在这个过程中对孩子的影响则是巨大的，导向了孩子长大后对爱的艺术的掌握。， 第四正式讲述了关于爱的对象的问题，对不同对象所见所具有的不同的爱，博爱、母爱、性爱、自爱、神爱。 关于博爱，无法做到对所有需要帮助的人均爱，则无法称之为博爱。 母爱，则是对上一章的补充，补充了唯有无私并能奉献出一切，除了被爱者的幸福一无所求的母亲才真的就具有母爱。 关于性爱，则是讲到性要求的数种误解，其一是认为性要求能够解除一切的隔阂，然而这样建立的亲密关系随着时间的推进会很快消失;其二，认为有了性要求必然是已经具备了爱的结果，然而性要求是爱情之后的衍生，但性要求并非唯有具备了爱之后才会产生。另外，一种认为性爱完全是两个人之间的吸引力，是两个特殊的人之间绝无仅有的联系;另一种认为性爱只是意志的行为。以上两种观点都是正确的其实。是两者综合之后方具有的爱情。 关于自爱，这种爱是判断你是否具有爱的能力的标志。无法以爱自己般爱他人与无法以爱他人般爱自己均是不具有爱的能力的体现，仅仅是一种利己的表现。 关于神爱，神爱是另一种形式的爱。 依据悖论逻辑，人只有在现实的矛盾中才能感觉现实，人永远无法在思想上把握最终实体，把握宇宙。人们不应该把从思想上找到答案看作最终目的。思想只能使我们认识到思想不能使我们作出最终回答，思想的世界囿于悖理之中。即对神的爱既不是从思想上了解神，也不是指自己爱神的思想，而是在爱的体验中体验自己同神的一致。这里印度、中国和神秘主义的宗教中，是以此作为神爱。 而在西方主流思想中，人们相信在正确的思想中会找到最终真理，因而也会引起科学的发展。 第五，爱情在当下西方资本主义社会中的衰亡。于当下，迫于社会的高度集中的特性，现代人受到了异化，失去自我，成为一种自动机器。这样的情况下为解除孤独而但诞生的爱情和婚姻概念实际上是强调保护自己免遭不可忍受的孤独感的侵袭。两个人结成以反对全世界的同盟，却把这种两个人的自私看作是爱情和信赖。后续还稍稍提及了神经技能病态爱情的部分。 第六，爱的实践。在这一部分中，作者着重强调了任何艺术掌握的必备条件，在生活中的每一个阶段将训练纪律、集中和耐心作为实践爱的艺术的开端。之后讲述了关于作者认为的爱的艺术的必备条件——克服自恋与积极的活动。整个这一段的内容放至当下仍无不可。 大致就是以上的内容了。","categories":[{"name":"随想","slug":"thinking","permalink":"https://sean10.github.io/categories/thinking/"}],"tags":[{"name":"读书笔记","slug":"读书笔记","permalink":"https://sean10.github.io/tags/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/"},{"name":"爱的艺术","slug":"爱的艺术","permalink":"https://sean10.github.io/tags/%E7%88%B1%E7%9A%84%E8%89%BA%E6%9C%AF/"},{"name":"爱情","slug":"爱情","permalink":"https://sean10.github.io/tags/%E7%88%B1%E6%83%85/"}]},{"title":"综述日本动漫艺术","slug":"综述日本动漫艺术","date":"2016-06-12T10:32:12.000Z","updated":"2023-03-18T15:11:14.880Z","comments":true,"path":"2016/06/12/综述日本动漫艺术/","link":"","permalink":"https://sean10.github.io/2016/06/12/%E7%BB%BC%E8%BF%B0%E6%97%A5%E6%9C%AC%E5%8A%A8%E6%BC%AB%E8%89%BA%E6%9C%AF/","excerpt":"综述现代日本动漫艺术表现","text":"综述现代日本动漫艺术表现 摘要： 动画从本质上来说是属于电影艺术的一个分支，与根据现实情况拍摄、构造的电影是基本一样的。甚至而言，现实拍摄无法制作的电影，藉由一切由想象力掌控的动画，完全可以得到实现。随着时代的发展，无论是从技术上来说、还是从艺术表现的思想和手段，动画都已经成为了一个极其深刻的思想产物。而仅从现在来看，动画范围内，日本动画无论是从艺术水平来说，还是从动画产业发展的成熟性来说，无愧为世界第一。因而，对于日本动画的艺术表现进行调查十分有必要。日本动画采用分镜、分格系统来描写整个故事，掌控故事节奏。在描写角度上，主要受史诗影响，客观描写整体与细节；而从描写题材上，则以具有传奇性为特点。 关键词：日本动漫；史诗；艺术表现；绘画；特征 一、引言 动画从本质上来说是属于电影艺术的一个分支，与根据现实情况拍摄、构造的电影是基本一样的。甚至而言，现实拍摄无法制作的电影，藉由一切由想象力掌控的动画，完全可以得到实现。 虽然在过去，动画一直都是被定位为面向未成年人，并且这样的情况可能还会存在很长一段时间，不过有点必须为我们所意识到，那便是动画已不再只是简单而附肤浅的了。随着时代的发展，无论是从技术上来说、还是从艺术表现的思想和手段，动画都已经成为了一个极其深刻的思想产物。 动画终将会在艺术范畴内占据一定地位，而仅从现在来看，动画范围内，日本动画无论是从艺术水平来说，还是从动画产业发展的成熟性来说，无愧为世界第一。虽说美国是动画最早诞生之地，技术水平上在世界上处于领先地位，但单从两国的动画作品的艺术境界上来看，迪斯尼作品与日本作品尚还存在天堑之别。以宫崎骏的《千与千寻》为例，以绝对艺术实力在各大电影节中拿下了不少奖项。 因而，对于日本动画的艺术表现进行调查学习，还是存在相当的借鉴意义的。 二、日本动漫的历史[1] 十二世纪到十七世纪江户时代初期，日本漫画界一直把十二世纪的鸟羽僧正觉犹当做祖师爷。在十二世纪，绘卷戏画流行，形成日本独特的绘画形式。十七世纪江户时代初期，京都、大阪的绘师画了一些身材修长的鸟羽绘，成功的造成了时代的风格，引领下一波浮世绘的画风。 十八世纪中到十九世纪，1760年日本伟大的浮世绘师葛饰北斋诞生，一般印象中，他是[漫画]一词用在画作上的第一人。不同于早期的绘卷戏画，北斋的《北斋漫画》创作了很多笔意活泼的滑稽画谱，带动流行，甚至对欧洲绘画界造成一股震撼。 十九世纪中后期，西风东渐，西洋漫画对于日本漫画的革新有很大的贡献。1862年英国漫画家Charles Wirgrman创办《日本笨拙》漫画杂志。这本以时事漫画、风俗漫画为主要内容的创作，用木板美浓纸印刷。《日本笨拙》对日本漫画界产生很大的冲击。西洋漫画的批判式口吻、幽默感以及造型成了时尚。新生代漫画家莫不受其影响，如北泽乐天。 明治时期（1870年-1911年），漫画一直热闹非凡，杂志也多的不胜枚举。1906年，北泽乐天创办了日本第一份漫画刊物《东京小精灵》，是日本现代漫画的鼻祖。日本现代漫画的历史可追溯到明治时期。确立日本现代漫画的是在讽刺画界极为活跃的北泽乐天。 大正时期（1912年-1925年），以冈本一平为重心的十人漫画家成立了东京漫画会，举办漫画展，大正时代就在他们的主导下更为活泼了。漫画大师冈本一平赋予漫画文学的内容，是故事漫画的先驱者。 与此同时，漫画偶像也出现了，促进了儿童漫画的发展。1923年，日本的第一个漫画偶像出现，这就是桦岛胜一的《阿正的冒险》。儿童漫画也在《阿正的冒险》受欢迎后，由于画家纷纷投入创作，阵容日益增强。 同时期，另外，在讽刺漫画的基础上，反映现实题材的幽默漫画兴盛起来。1924年漫画大师麻生丰的幽默长篇漫画《满不在乎的爸爸》在《报知新闻》刊出大为轰动。这部作品鼓舞了东京大地震劫后余生的人们，获得极大的成功，从此幽默漫画大量在报端出现。 昭和十年（1926年-1936年），昭和初年少年漫画大放异彩，一些作品具有很高的水准，如田河水泡的《黑流浪汉》、岛田启三的《阿吉历险记》、横山隆一的《健少爷》、《小阿福》等。这些作品不仅吸引了全国的少年，而且受到了包括成年人在内的普遍喜爱。 这个时代也是漫画改组的时代，漫画家也纷纷成立了团体。1932年，以《漫画人》的执笔画家横山隆一等二十人为主建立了[新漫画派集团]，另外还有[日本漫画奉公会]、[三光漫画工作室]等组织。结合志同道合的人团结出击，有的还出版年鉴，办很多促销活动，漫画界呈现出百花齐放的局面。 不过不久之后，日本军国主义化，漫画界也被强制集中了。1931年田河水泡的《野狗二等兵》在《少年俱乐部》开始连载，作品采取拟人化的手法，反应了强烈地军国主义思想，迎合了当时日本发动侵略战争的需要。日本漫画创作停滞不前，直到战争结束。 战后初新漫画崛起（1945年-1955年），战后十年，新的价值观打乱了战前的传统与秩序，出现了充满生机的混乱，在这种混沌状态中登场的漫画界巨头就是手冢治虫，他在画技上、内容上和风格上都带来革新，形成日本动漫独特的风格，并且使动漫深入人心。1946年手冢治虫的《新宝岛》问世，迈出了成为现代主流映像漫画的第一步。1952年《铁臂阿童木》开始连载，1963年搬上银幕，它确立了以剧情为重点，不追求图象效果，看重角色的塑造这一独特的日式动画风格。从此，日本漫画界形成了将成功作品改编为TV动画长片的不成文惯例。手冢的漫画大大超越二战前的故事漫画，运用电影运镜手法，使漫画映像有了革命性的变革。由手冢发起的新类型漫画，以剧情发展和人物塑造为主的娱乐故事，逐渐向题材的多元化延伸。 1956年-1965年，漫画题材、类型逐渐丰富，电视动画也兴盛起来了。仿佛是为了摆脱喧闹的市井生活，漫画界涌现出很多朦胧作品。少女漫画得到发展，名列榜首的女作家有上田俊子、牧美也子、花村英子等。石森章太郎的处女作《二级天使》是一部童话喜剧，获得第一届文艺春秋漫画奖的谷内六郎的《离家的孩子》是一部反映郁郁寡欢的乡愁和童心的幻想曲。横山隆一的《阿福》和冈部冬彦的《小男孩》等以家庭生活为题材的漫画开始走红。日本从战后的混乱中开始康复，经济开始复苏，人们的生活比较安定。这一时期的漫画题材广泛，贴近人们的生活，容易被更多的人接受并喜欢。 在大阪，连环画开始萌牙，月刊《影》和1957年创刊的《街》成为连环画的基地。这时，日本漫画界又出现了一股新的潮流，即所谓的「貸本漫画」，即“租借连环画”。最早使用“连环画”这个名称的，是在《街》杂志社工作的辰已嘉裕。1959 年在大阪辰已嘉裕、斋藤隆夫、佐藤雅旦等人组织了连环画工作室。杂志方面，1959 年讲谈社的《少年杂志》等周刊杂志纷纷创刊。租借连环画的主要读者层不再是少男少女，而是那些在日本高速经济增长中，从日本各地大量涌入东京、大阪等大城市中的青年人。可以说，租借连环画唤起了成年人对漫画的需求。 动画在手冢治虫的影响下，整个60年代都处在摸索阶段，题材向多元化延伸。1959年东京电视塔建成，家庭电视机拥有台数已超过700万台。电视的普及加快了动漫的发展，扩大了动漫市场。日本第一部彩色动画电影是 1958 年东映动画制作的《白蛇传》，这部电影可以看作是日本现代动画的开端。科幻题材的动画片如《铁臂阿童木》，横山光辉的《铁人28》、平井正和的《8号人》深入人心。藤子不二雄的《怪物Q 太郎》被改编成动画片，这是科幻动画片以外类型的动画片首次获得巨大成功。随着电视突飞猛进的发展，颇受欢迎的漫画开始被搬上银幕，这些动画片的巨大成功加快了漫画电视化的步伐。从题材上看，科幻动画占了主流，向往自由和平、正义光荣的“机器朋友”是刻画的主要角色。 1965年-1975年，这十年里漫画迅速发展。新的漫画杂志应运而生，培育出一批新漫画的读者层，如《少年杂志》的主要读者是中、小学生，他们的社会人际关系很简单，一般就是家长和孩子、学生和老师、男孩和女孩。集英社1968年创办的《少年跳跃》，发掘出一批新漫画家。此时，《少年杂志》的佳作有《巨人之星》（川崎登）、《明日的乔》（千叶铁矢）等就是围绕中、小学生人际关系创作的连环漫画。这些作品描写了少男少女的成长奋斗过程。由于故事内容都来自少年读者身边，所以极受他们的欢迎。漫画开始受到了社会的瞩目。此后，日本漫画的读者也从中、小学生扩展为高中生、大学生，以及各阶层的青年。 这一时期，日本漫画家协会诞生了，它是全国性的漫画家职能团体。它的宗旨 是维护漫画家协会会员的权益，对文化作出贡献。1972 年设立了 “日本漫画家协会奖”。还有“文艺春秋漫画奖”、“小学馆漫画奖”、“讲谈社漫画奖”及“读卖国际漫画奖”等报社设立的漫画奖。还有个人设立的奖，如“手冢奖”、“藤子不二雄奖”等等。日本漫画家协会诞生以及各种奖项的设立表明在日本动漫的文化地位，认知度大大提高，对动漫进一步发展铺平了道路。 60 年代中叶到 70年代中叶，漫画为了适应迅速发展的需要，故事中的相当大的成份是由其它领域的作家来完成的。连环画的老将小岛刚夕，与小池一夫组合后发挥实力创作的《带孩子的狼》就是典型的例子。另一位专业脚本作家泷泽解的《高中流浪派》，也使人感到新鲜的时代气息。科幻作家加纳一郎、动画片作家藤种桂介等等，也分别拿出成功的作品，以漫画脚本为职业的小池一夫等人进一步扩大了市场占有率。漫画质量的提高，与他们的实力有很大关系。 这一时期，少女漫画有了更高的发展，出现了许多知名的女作家，开拓了少女漫画新的题材。较突出的有高中学生里中满智子的处女作《娜娜和丽丽》、情节剧名家细川知荣子的《帕莉子别哭》，还有擅长写爱情剧的西谷样子的《玛丽露》，还有弓月光的《第一次体验》等作品。在少年漫画肥沃的土壤上，少女漫画迅速赶超上来。这一时期连东京大学的书架上都摆着少女漫画，池田理代子的《凡代赛的玫瑰》以其严谨的历史考证和曲折的故事情节，把少女漫画推上了高峰。 1970年代中-90年代初，日本动漫逐步走向成熟。1975 年至 1985 年这一时期，女漫画家的佳作频频，少年漫画的创作仍然十分丰富，欣赏性、艺术性和娱乐性兼好的作品接二连三出现。这些作品在日本不仅家喻户晓，而且又的作 品被翻译成其它语言，为世界各地的人所熟知。细川知荣子的《尼罗河女儿》、青池保子的《伊凡的儿子们》，1977 年美内铃惠的超长篇《玻璃假面》连载十几年，盛况不衰。藤子 F 不二雄的《机器猫》、鸟山明的《阿拉蕾》、安达充的代表作《接触》、女作家高桥留美子的《福星小子》、原哲夫《北斗神拳》也大受欢迎。这些作品在日本不仅家喻户晓，而且又的作品被翻译成其它语言，为世界各地的人所熟知。如以真正的描写和故事吸引读者的作品大友克洋的《阿基拉》，显示出极高的水平，得到西方国家的认可。 进入 90 年代，日本漫画流派在画风、题材、故事情节等方面八仙过海，各显其能，漫画界出现了百花齐放的局面。如鸟山明的《七龙珠》等作品。漫画作为一种宣传媒介，越来越受到人们的重视。石森章太郎的《漫画日本经济入门》、《漫画日本历史》也在连载，这些都是以成年读者为对象的漫画。这一时期，漫画家的个性更加鲜明了，漫画已从战前的儿童伙伴历经半个世纪的成长，变成了社会的大众传播媒体。 自 1974 年松本零士的《宇宙战舰》上演至 1982 年为止，日本第一次动画热爆发，动画的题材渐渐得到了明确。在这期间日本动画在明确了题材的同时也向着商业化发展。七、八十年代，设定复杂的“商业动漫”迅速覆盖了每个频道。宇宙战舰》是日本动画史上第一部超级剧情片，在该片后，松本零士另有《银河铁道 999》，《一千年女王》等受欢迎的作品。继松本零士后，由富野由悠季原作小说改编成《机动战士高达》在 1979 年开始上演，由于剧情结构复杂而严密，受到动画迷热烈的支持。《宇宙战舰》上演，风靡了无数青少年，连续创下票房奇迹。它的空前成功首次向所有人证明了动画片完全可以不止是娱乐小孩子的消遣玩意，动画在日本的文化地位也因这部电影而被彻底改变。其中《机动战士高达》的成功不仅开创了写实机器人动画的新时代，而且也成为日本科幻动画特别是软科幻动画发展的助燃剂。 自 1982 年《超时空 要 塞 》上演至1987年为止，日本第二次动画热爆发，画技得到了突破。1983年日本动画市场上出现了世界上第一部OVA动画。OVA 为动画在电影、电视 市场外，开辟了一个新市场--录影带市场。该时期由于人们追求视觉享受成为风潮，因此动画画技力求突破。《超时空要塞》创新的视点快速移动效果，造成极佳的动感；宫崎俊的《风之谷》和《天空之城》精细写实的背景；《机动战士 Z》的强调反光，明暗对比等，皆对后来的动画贡献很大。日本动画发展至本时期结束时，剧情、内容、画技皆已达到极高的水准。动画进入了成熟期。70 年代的经济复苏使得日本的工业发展异常迅猛。经济飞跃的同时少年的精神生活需求大增，动漫画的热潮带来的庞大的消费市场。 自 1987 年到90 年代初，日本动画进入路线分化期，走向成熟。受年龄路线思路的影响，1987 年后半年以来，电视上的低龄动画逐渐增多，面向较高年龄层的动画开始转向动画电影。日本电视史上第一部以高中生以上为主要对象的文艺动画连续剧《相聚一刻》曾获得 1988 年日本动画优秀作品排行榜第二名 (该年排行第一是《圣斗士星矢》)；另外还有《天空战记》曾获得 1989 年动画排行第一名。动画进入成熟期后，也像漫画一样出现数部佳片。年龄路线思路下的转向，造成目前日本电视上佳作颇少，而动画电影几乎部部精彩的情况。 最后，20世纪90年代到现在，日本动画进入了风格创新期。在画技、制作手法、构思设计方面都日趋成熟的日本动画，开始追求风格上的创新，试图突破原有的模式，以完善的技巧，加上超越时空的构思，带给观众全新的感官冲击。押守井的电影版《攻壳机动队》以阴郁压抑冷酷的风格，冷静地思考身处高科技社会的人类对未来的不安。 95 年庵野秀明监督的《新世纪福音战士》上映，它则是现代人矛盾而孤寂的心理折射。二十世纪末，人类对自身的思考也逐渐深刻，而同时日本的动画也开始越来越关注贴近现实与心理方面的剖析，由原本普遍爱与友情的主题转为更加人性的刻画。各方面都日臻完美的日本动画并没有停止发展的脚步，仍然在不断自我完善和突破。 三、日本动漫描写特点[2] 动画与漫画虽然分属两种不同的艺术形式，但在日本文化中这两者却有着紧密的关联。日本漫画从动画中汲取了电影的许多视觉效果控制技巧，这使得日本漫画突破了原来以四格漫画为主题的漫画形式，形成了长篇的以叙事为主体的漫画。这种漫画与原来的连环画也相当不一样。它们篇幅要宏大得多，在艺术表现手法上更多运用变形、抽象等经典漫画的手法，而连环发比较倾向于写实风格。更重要的是，日本漫画常常自觉运用某些电影的镜头语言，比如特写、快慢镜头等技巧，来表现画格中的内容。由许多漫画家的图画，略加处理，基本就可用做动画电影的分镜头剧本，比如高桥留美子的作品之一《人鱼之伤》。传统连环画在这方面无疑还处于自发的状态。日本动画在漫画上汲取的营养则更多些。它的剧本大多改编自漫画，纵使是原创作品，其故事的构建方式，也差不多是属于漫画类型的。日本动画一般说比美国动画内容深，题材面广，比欧洲动画要建明动人，这和其漫画的叙事风格是分不开的。因此，在某种意义上来说，日本动画与漫画是二位一体的。[2] （一）日本漫画与动画框架特点 日本漫画（manga）根据文献查阅来看，其特点在于基本框架： 1.具有与影视分镜表类似的分镜系统. 2.具有平面构成因素和阅读顺序作用的分格(frame)系统. 3.其他画面符号系统，如拟声词、文本框等。 4.其他非画面因素的阅读系统，如翻页、连载周期等。 这四个系统在相互影响之下共同决定着日本漫画的语言。[2] 漫画为了达成对故事的长篇叙述，是参照着影视语言而发展的，不过他们之间在一些地方存在显著的区别。这也将是动画与现实影视的一些区别，也是其特点。 二者在表现手法上的时间性存在重要的差别。漫画中的一格是不具有时间性的，它单格叙事的时间性依赖于读者想象去补充。而电影中单个镜头的时间性是显然的。当前，漫画基本是采用蒙太奇的方式来模仿影视。多格可以表现事件发展的时空转换，一格就是一个单位的时间，同一事件所用的格子越多，则表明这一事件经过的时间越久。分格构图的动态节奏随着故事的推进而变化，这不仅出于时空变化演进的需要，也是出于故事叙述的节奏和视觉韵律的需要。 二者的第二个区别是漫画分格系统的独立性以及它和分镜系统的互动作用。Manga引入影视语言中的分镜思路而形成的分格系统，达成了对故事节奏的控制。 漫画绘画的间隔性，导致其世界是由读者所想象而创造出的。漫画引入分镜头语言来表现，通过对分块大小、色彩的控制，可以达成对气氛的控制。如日本漫画家多田由美善于使用大块的黑白灰的颜色，充实实体空间以对观众构筑心理空间和想象空间，引发读者的情绪。 而分镜头的远近则是表现人物情绪、营造心理氛围的有效方法。拉进的镜头，由于画面的充实，对人的视觉神经造成强烈地压迫感；而远景相对显得客观真实，有利于交代人物所处的环境和位置关系。 由于漫画的阅读顺序的自由，带来了一个电影不存在的限制，分格对此起到作用。因为电影的观赏是一个不可逆的过程，读者会被中心点快速吸引注意。而漫画是整体同时展现于读者面前，虽然可能没有意识到，但是所有的分镜都在眼中。从整个页面构成上来说，没有特殊意义的重复性只会带来厌倦。为了防止这样的重复性，不得不添加一些空镜头、全景镜头、以及进行一些视角的变化等等，但这些镜头假如是在电影中则是属于多余的部分，因而对于这些部分的分格大小控制就显得十分重要，既不冗余亦填充了页面。[3] 漫画语言与影视语言的第三点区别在于，文学在漫画中的直接介入。文字的魅力毋庸置疑，漫画因而既具备了影视的具象描述性又拥有了文学所具有的抽象描述性。不过如何控制其平衡，也是一种深刻的技术了。 第四点区别则是漫画具有翻页和连载周期的机制。电影是一次性放送的，而连载漫画是一个时间相当长的过程，对故事叙述的时间长度不同决定了它们叙述手法的不同。漫画的翻页和连载机制的本质上是一种悬念和出人意料的机制，作者需要不断地控制节奏保留高潮。上面说过，读者在翻开前就会对整页的构成有了大概印象，看到分格大小即可知道镜头的重要性，所以要达到悬念效果就必然需要在翻页后。 （二）日本动画艺术描写特点 当前日本动画从描写角度来看深受史诗文体的影响，从题材上来说均属“传离奇之事”。 史诗类作品一个至关重要的文体特征是：创作者不但重视世界情况整体概貌的介绍，且将相关的细节描写视作问题表现的一大乐趣。在这描写过程中，作者力求以客观的、陈述式的笔法赋写，不掺入个人的意见。无论写到何等古怪离奇之事物，他们亦作出客观冷静之态，令观者意味他们仅在“直言其事耳”。 不过随着时代环境的变化，现代作家终究有所不同。对于经典作家来说，无论他们描写的对象有多么离奇怪异，他们不会觉得这些东西与他们现实生存的世界有多么截然对立或扞格不入。他们以综合性的思维描写着他们认为是客观的对象。而现在人对于现实、虚构、理想、狂想、信仰不同向度所指对象本质的不同，有着明晰的洞察。因此，根据描写对象的世界观是否属于现实或想象的范畴的不同，动画家门发展出了一些更细致的关于世界情况叙述的亚类型。 而题材，无论是多么朴实的内容，经过创作家改写之后，终将会凸显其别致之处“离奇”，也唯有此方可让读者感到新鲜与好奇。 1.史诗文体影响 （1）关于未来世界的想象 “未来”者就是有可能到来而尚未到来之事，即被列入科幻分类之内容。而科幻又有“硬科幻”和“软科幻”之分。“硬科幻”，一般地说，是在对现代科技发展深入了解的基础上而展开未来想象的虚构故事。故事对未来技术的描写，从科学的逻辑上说是完全有可能实现的。而软科幻类作品对于未来科技的描写，与现代科技的现实和逻辑存在极大的知识上的断层。日本动画基本都是以“软科幻”为主。如押井守的《攻壳机动队》、手冢治虫的《铁臂阿童木》、富野由悠季的《高达》系列。高达系列中包罗万象，有宏大的战争场面，有惊心动魄的机器人格斗；有诡谲的政客政治，有非理性的暴民政治；有世俗气浓重的社会生活，有平静温馨的家庭生活；有勾心斗角的阴暗人性，有阳光少年的青春活力等等。作品很细腻，刻画了各种各样的人和各种复杂的任性，但作者并没有展现出对某种价值观的倾向，展现了坚定的史诗的客观态度。 对未来世界的描写当然不仅仅只是对恒久不变任性的客观谛视、对人类社会中权利争斗的洞察、对未来世界某一标志性的对象物进行复杂的甚至是谱系化的描写等等，不过不得不承认，日本这一类型的动画创作者均受到了深厚的影响，没能脱离这个范围。 (2)追忆过往 过往的历史留有的空白给人们同样留下了巨大的想象空间。追忆已经过去了的好时光，试图弥补已经成为既定历史现实的憾恨，将过去、现在、未来联系起来系统考察并谛视人类宿命的思想冲动等等，都构成了强大的心理情结，使得作家们不禁频频回望人类的既定历史，并以此为基础抒发个人的情怀。和月伸宏的《浪客剑心》以大剑客绯村剑心的爱恨情仇为主线，但这主线并不仅是个人浪漫经历的折射，是与19世纪末叶日本国内可歌可泣的倒幕维新运动和现代化的立国进程紧密地联系在了一起。剑心不断地与大久保利通、新撰组这些不同性质的政治力量周旋、斗争，并从中寻找个人最终价值的皈依。战争中的人性、战争中的正义与非正义、日本为什么会走上军国主义之路等沉重问题，在特定背景中一一给予了反省。 (3)凝望现实 一般地说，史诗性创作的问题特征与现代生活带给人们的感受是有所抵触的。黑格尔说过，“整个现代世界情况是受散文似的秩序支配的，和我们对史诗所要求的必不可少的条件完全背道而驰。”不过，在现实中也是可以诞生史诗品格作品的。创作者对于故事的世界设定需要是单纯的，并充满作者的理想情怀，虽展现现实，但却并非真实现实那般的复杂、残酷。如《足球小将》中的足球世界，充斥着理想与美好，并不存在真实世界的复杂交易，正是因为其不真实的美好，而令读者充分感受其中对足球的热忱向往、及其奋斗的坚毅。 (4)多元时空的混合交融 在这种作品中，世界的先验设定、展开逻辑是与现实世界存在极大不同的。日本动漫家常常假定这样的生存空间，在这个世界里，人类过去、现在、未来的各种经验、想象，甚至是一些纯粹来自于可能世界的想象，被糅合在了一起，被当做了一种客观实存的东西来加以表现，即龙与地下城之类背景风格的故事创作。这种世界观的作品，在日本动漫中一直以来占据重要地位，永井豪、石森章太郎、赤冢不二夫和横山光辉早期的创作、宫崎骏、Clamp、高桥留美子、富坚义博等均是深有影响的描绘平行时空的动漫艺术家。 2.传奇题材 （1）战争主题 虽然动漫作家中很少有人真正去考量整个民族的心灵在历史进程中必须要直面什么，承担什么的问题，但他们还是能够自觉地认识到，有关战争的问题，总是能够引起大部分人的关注。而战争吸引人的，无非是宏大场面，扭转乾坤的英雄人物以及智谋斗争这些基本元素。如《风之谷》、《银河英雄传说》、《高达》系列、《超时空要塞》系列、《EVA》等。 关于战争的描写，在自发展现之余，如手冢治虫、宫崎骏、押井守、大友克洋等人都就此话题展开过沉重的思考。 大友克洋是日本动漫家中关于战争对人性的异化、战争与人的本性关系等问题做过深入考察的一位动漫大家。最具有代表性的，便是《AKIRA》。“AKIRA”是他虚构的一种神秘能力，人如果得到了这种能力，就意味着他拥有了一种超人的支配力；同时也意味着他在人性中就不可避免地走向了暴虐，因为控制别人必然是暴虐的。这样人便往往处于一种两难之境：不如意的生活、混乱的政治体制常常促使人们去追求这股力量，但得到之后，往往快速为这股力量推向迅速灭亡的道路。整部动漫便是以此为背景展开的，在这部动漫的结束中，大友克洋以暴力美学的形式，将战争的绝对的毁灭性之以及战争与人的活动之间无奈的羁绊关系直率地表现了出来。 （2）争战性主题 有些故事，尽管未见金戈铁马的征伐，但其中包含的战斗情绪的激烈程度并不弱于两军对垒的白刃相格。如但丁的《神曲》，“这里基本冲突仍然导源于战争，即恶魔背叛上帝那场原始的斗争，由此在人世现实领域便派生出反抗上帝和崇敬上帝两种势力之间的不断内外战争”。因此，这里讲主要表现多股实力激烈对抗而突出显现其一的求胜意志的作品，统称为争战类。主要集中在角力、竞技游戏、武术技击等几个方面。 角力的代表有《七龙珠》、《圣斗士星矢》等。竞技类则以《灌篮高手》、《棒球英豪》、《游戏王》为代表，以新番而言则为《网球王子》、《黑子的篮球》、《飙速宅男》、《排球少年》为代表了。武术的想必则以《史上第一弟子》为励志典范了。 四、参考文献 [1] 冯 硕，日本动漫的特性及其对中国动漫发展的启示[D]，北京：对外经济贸易大学，2005. [2] 陈奇佳，日本动漫艺术概论[M]，上海：上海交通大学出版社，2006,223. [3] 马静雯，日本动漫特征分析[J]，剑南文学（经典教苑），2012,(3):157-158. [4] 唐立耘，日本动画分镜与漫画分镜比较研究[D]，武汉：武汉理工大学，2013","categories":[{"name":"随想","slug":"thinking","permalink":"https://sean10.github.io/categories/thinking/"}],"tags":[{"name":"动漫","slug":"动漫","permalink":"https://sean10.github.io/tags/%E5%8A%A8%E6%BC%AB/"},{"name":"综述","slug":"综述","permalink":"https://sean10.github.io/tags/%E7%BB%BC%E8%BF%B0/"}]},{"title":"一省幕间","slug":"一省幕间","date":"2016-05-16T14:48:28.000Z","updated":"2023-03-18T15:11:14.885Z","comments":true,"path":"2016/05/16/一省幕间/","link":"","permalink":"https://sean10.github.io/2016/05/16/%E4%B8%80%E7%9C%81%E5%B9%95%E9%97%B4/","excerpt":"","text":"算来已经快整3周没听课了，整日在刷小说中，试着以放纵来令自己对小说失望，不过成效些微，反倒进度缺失的确实很多。 近来，从动漫同人到电影同人，再到架空历史、竞技，再回到科幻、奇幻、玄幻，爱好的小说类型愈发的变化，曾经最喜欢看的西红柿、三少的小白文倒是无法再入口，其剧情框架已被用烂了，再无出彩的创意，始终从零打怪升级，无非依靠主角光环，不见出彩伏笔，亦不见大气世界观，不过满足了大家的YY想法。 今天看到这样一句，《将夜》中说道： &gt;你究竟喜欢的是读书这件事情，还是读完所有书这件事情呢？ 我不得不说，自己所爱好的是读完书这件事情，在小说上只是希望自己能尽快看到作者出彩的后续剧情，而在专业书上，只是想为自己在豆瓣上的成果上多一笔，自己看完了那本专业巨著呢！ 哎，真的不得不对自己说，真的是太俗了。 也因为这个，虽然收了不少CS的经典了，但看的却没几本，我的兴趣去哪了呢？ 每个人都会碰到很多难题，想要解开这些难题，就必须专心的做下去，就需要疯狂的那股痴劲儿，但这股痴却不是山一般压在你肩上的重量，而是你内心深入向往的那些喜悦。 宁缺望着美丽的书院后山，说道：以前我曾经痴过，这些天却忘了痴的本质是喜欢。不存在虚妄的希望，自然也就没有虚妄的失望，更没有什么绝望。人生如题各种痴，就是各种喜欢，喜欢做什么那便做下去。这道题目总会有答案的。 可能在看的多了之后终究会懂，但却无法持之以恒。向往，却又不够向往。 给我无尽的知识，我便以自身为支点，撬起无尽世界。 虽然没有如此宏伟，但这也可谓是一种追求吧。","categories":[{"name":"随想","slug":"thinking","permalink":"https://sean10.github.io/categories/thinking/"}],"tags":[{"name":"暮省","slug":"暮省","permalink":"https://sean10.github.io/tags/%E6%9A%AE%E7%9C%81/"}]},{"title":"一省吾身","slug":"反思","date":"2016-04-19T15:31:21.000Z","updated":"2023-03-18T15:11:14.883Z","comments":true,"path":"2016/04/19/反思/","link":"","permalink":"https://sean10.github.io/2016/04/19/%E5%8F%8D%E6%80%9D/","excerpt":"近来，明明是在时间最紧迫的时刻，作业堆积如山、学姐布置的任务ddl也在迫近，可我却始终感觉缺了点什么似的，用最近看的村上春树的书中常提到的话来说恐怕就是“留在此处的只是我的一半，另一半怕是已然随着某事离开”。","text":"近来，明明是在时间最紧迫的时刻，作业堆积如山、学姐布置的任务ddl也在迫近，可我却始终感觉缺了点什么似的，用最近看的村上春树的书中常提到的话来说恐怕就是“留在此处的只是我的一半，另一半怕是已然随着某事离开”。 话虽如此，我面临的终究是现实，将时间寄托于小说，什么都不能改变。 也许是压力带来的消极，也许只是天性懒惰，严格一点来说，不过都是对自身不满，而将一切的一切倾泄于自暴自弃。以直觉来看，恐怕现在苦恼的这些随着时间的流逝，会什么都算不上。现在明明有那么多的知识摆在面前，只差我的汲取，我却将时间牺牲在摸索自己的消极、苦恼的心理之上。不用一年，一个月后我就又会深深的后悔了吧。毕竟，我已经如此折腾去了近一年了。 我想，于生活，并没有必要去研读那些深厚的心理学专著，只要记住\"Just do it\"就已经足够了罢。哲学也好，心理学也好，于业余人士来说，若非沉下心去从地基打起，没有丰富的阅历是不足以驾驭住心理学的专著的。无力驾驭，仅仅只言片语的心理分析，理解了，然而你真的懂了吗？真的进入你的心底了吗？于我来说，心理学是一门无比实用的科学，但以我的阅历与智商，实在无法仅凭一己之力将其应用。 话是那么说，不过这也只是我恨自己不能实用心理学而言，各人各有理解。 —————————————————————————————————— 回到我的专业，计算机科学与技术。 实际上来说，我真的明白这门专业是做什么的是在进了大学之后了。虽然我高考时所有的志愿专业都是计算机相关，4个志愿学校也是从计算机排名的高校里依次选的，可惜现在想来，当时似乎只是因为父母对自己使用计算机的限制，以为计算机于自己的意义就只有游戏，而对计算机的理解太过浅薄，将计算机科学神话了之后的选择。当然，现在专业选择了计算，我一点都不后悔。 但是，我很后悔自己不能更早接触到编程。现在既想玩玩前端，也想折腾下服务器搭搭后台，但是又有更主要的DM，只恨现在自己扛不住高压的学习节奏，好几次仅仅几天身体就各种撑不住，给了自己松懈的理由。每每看到同学的快节奏的学习，就不由得对自己的集中力叹气了。再说到，睡眠之浅，对声音的敏感，这样的环境又无可改变，休息不好，时刻增加着精神上的疲惫。 虽说能做的只有适应，适应不行就只能为大流所淘汰，但自己又不具备放下正常学习课表的魄力，弄成这般学习下滑、技术始终初学者的半吊子，所以不得不恨自己呀。 恨归恨，就看我能不能把这股恨刻入心底，真的记住失去的机会的疼痛，去承受高压的学习节奏了。 虽说身体是硬件，但有足够的觉悟，也一定可以无视！","categories":[{"name":"随想","slug":"thinking","permalink":"https://sean10.github.io/categories/thinking/"}],"tags":[{"name":"暮省","slug":"暮省","permalink":"https://sean10.github.io/tags/%E6%9A%AE%E7%9C%81/"}]},{"title":"《情书》：平淡-回忆","slug":"情书","date":"2016-04-16T03:47:43.000Z","updated":"2023-03-18T15:11:14.858Z","comments":true,"path":"2016/04/16/情书/","link":"","permalink":"https://sean10.github.io/2016/04/16/%E6%83%85%E4%B9%A6/","excerpt":"为图方便，这部电影是从B站上拉标签看评论找到的。 看过了村上春树的几部小说以后，加之桥本爱的《small forest》，对日本的作品的初印象就是非常的平静，在长达1个多小时的作品中逐渐静下来，在看这部片时感觉尤为深刻。","text":"为图方便，这部电影是从B站上拉标签看评论找到的。 看过了村上春树的几部小说以后，加之桥本爱的《small forest》，对日本的作品的初印象就是非常的平静，在长达1个多小时的作品中逐渐静下来，在看这部片时感觉尤为深刻。 电影一开始，便是在令人不由得肃穆的告别辞世之人的场景下，女主博子淡淡的出场，时刻沉浸于对前未婚夫的哀思之中，因为难以抑制其思念，也许是想作为结束思念的标记，想向着已经不存在的地址发出一封寄往天国的思念。然而，在本片的诞生的关键，她所记录的地址是恋人昔日同班的同名的另一位藤井树的家。随后，便是在书信往来中，藤井树逐渐回忆起初中时分。渐渐地，藤井树对于这位藤井树的淡淡的柔情得以揭露，错过的恋爱渐渐在我们面前呈现。 论剧情，可能并不像烧脑惊悚片那样跌宕起伏、让人出乎意料，但这部电影在细节的刻画、细节的共鸣上让我触动不已。 你好吗？ 我很好。 什么样的心理下，能写下如此简单的思念？ 我不知道，不能想象。但其心情传达到了心里，感觉暖暖的。 导演岩井俊二同时也是一个作家，这部电影便是由他的小说改编而成，从刻画上来看，想必原作品的小说同样精彩。 虽然我是奔着《情书》的制作的平淡而去，但最后还是不由得对回忆有所思。 作者岩井俊二在《情书》日文版电影特刊中，接受佐藤佳访问时，认为回忆是推动自己现在的一大原动力。一般人以为过去是过去，现在是现在，两者互无关系。某个时机，回忆起过去的事情，自然会发现一些过去与现在的连带关系，反过来影响了现在的自己。 毕竟回忆存储的是我们过去的时时刻刻，过去曾是现在，正是无数个现在的想法决定了未来的无数分叉点。既然过去既定，塑造而来的现在才得以存在，又何来无关之说呢？回忆可以是对往昔的省悟，也可以是情感的重拾，什么能作为推进的源动力，我想各人各有其道吧。","categories":[{"name":"随想","slug":"thinking","permalink":"https://sean10.github.io/categories/thinking/"}],"tags":[{"name":"日本","slug":"日本","permalink":"https://sean10.github.io/tags/%E6%97%A5%E6%9C%AC/"},{"name":"影评","slug":"影评","permalink":"https://sean10.github.io/tags/%E5%BD%B1%E8%AF%84/"},{"name":"爱情","slug":"爱情","permalink":"https://sean10.github.io/tags/%E7%88%B1%E6%83%85/"},{"name":"青春","slug":"青春","permalink":"https://sean10.github.io/tags/%E9%9D%92%E6%98%A5/"}]},{"title":"《starting over重启人生》","slug":"《starting-over重启人生》","date":"2015-12-15T15:48:00.000Z","updated":"2023-03-18T15:11:14.824Z","comments":true,"path":"2015/12/15/《starting-over重启人生》/","link":"","permalink":"https://sean10.github.io/2015/12/15/%E3%80%8Astarting-over%E9%87%8D%E5%90%AF%E4%BA%BA%E7%94%9F%E3%80%8B/","excerpt":"###starting over重启人生 这是这一个月来看的第一本质量感觉不错的轻小说。 初看完，我觉得从小说的方向上来说是引起我们对自己人生的反思的，我之前看过的《我将死去，你将重生》感觉和这本类似的感觉，同样值得一看。","text":"###starting over重启人生 这是这一个月来看的第一本质量感觉不错的轻小说。 初看完，我觉得从小说的方向上来说是引起我们对自己人生的反思的，我之前看过的《我将死去，你将重生》感觉和这本类似的感觉，同样值得一看。 每个人多少应该都怀有那么些后悔，觉得「当初要是那么做就好了」。人生就是伴随着后悔，「如果人生可以重來，誰都想以第一人生的反省、教訓或是記憶，期待更加美好的第二人生。」 主角却恰恰相反，选择了看似与众不同的道路。他对第一人生的幸福已经万分满足，没有再来一次进行更加美好的人生的欲望，因而在这个「多余的事」的第二人生选择了模仿第一人生。 这个时候，主角并不知道自己其实是被掩藏了一部分记忆的，否则就会感谢这样的机会了吧。 主角认为这样的机会多余，实际并不多余。「所谓的机会，永远都是给那些不企求机会的人。」这句话其实从另一个角度已经解释了机会的出现，记得以前看到过这么一说，上帝给你机会让你凤凰涅槃，你却任凭机会逝去，只为等待上帝让你一步登天。当你不企求机会的时候，才是真正抓住了机会。 在这里，主角现在得到了重来的机会，虽然他还没有意识到其意义，这并不意味着这个机会没有意义。 「总而言之，我不管做任何事都很认真地在放水。」为了重现第一人生，主角坚持对任何事都不尽力，这样的选择会带来什么样的结局？我们都很清楚，环境的影响力是不可忽视的。不过假如我们同主角一般，带着10年的记忆回来，生活没有了一丝难度，失去了挑战的乐趣，也没有找到新的爱好，如此一直懈怠下去。假如，忽然你遭遇了意料之外的挫折，在曾经的记忆中如同呼吸一般顺理成章的发展在第二人生却改变了，你会如何呢？ 主角在第二人生懈怠了5年之后遭遇了这样的事。「举几个例子来说，对了，就是被第一人生中的好朋友欺负，被第一人生中的女朋友狠狠甩了，没考上第一人生中念的高中……这种感觉。」这里作者让主角联想到的是蝴蝶效应，似乎是这样的原因，自己的变化影响了周围的一切，让原本可能实现的第一人生的未来彻底从自己的人生中消失了。 主角因而颓废了高中3年，这样的发展很正常吧。在颓废中，他没有放弃思考对他来说最重要的第一人生的女朋友甩了他的原因，为了试图找到挽回的机会，他在最后一年找回了曾经的学习的状态，最终考上了第一人生中的那所和女友一同念的大学。这点其实还是值得参考的，拥有努力过的记忆，如果拥有年轻的身体，好好学习还是可能做到的。 来吧，故事进入了大学，也就是拥有的记忆的最后2年，出现了新的角色。出现了所谓的「分身」，拥有和主角在第一人生中同样特质的人出现了，在第二人生中取代了那个位置，身边的女生则是主角一直在追寻的被甩的「女友」。 主角这时候受到什么样的打击都无可厚非吧，但他发现那个「分身」和曾经的自己完全相同之后，试图以消灭那个人来让其他人注意到自己这个本尊的存在。当然，在最后的最后，这所谓的「分身」和「本尊」都不存在意义，因为都是现实存在的人，不存在满足主角取代想法的美好幻想。 在跟踪计划中，来到了这10年的最后几个月，主角发现了一个现实，在他身旁，从初中开始，一直互相以对方作为最后的孤独同伴的女生——柊，其实是他带着第一人生的记忆回来的女友。而与此同时，主角在最后的最后找回了在第一人生的最后的故事的记忆，第一人生的他们在圣诞之夜出了车祸。 主角在这里觉悟了，虽然心里很平静。** 「这样啊，那两个人要死了吗？」只是这样。** 「因为他们一直以来可以过着那么幸福的人生，不如说，能在幸福的顶点死去也是一种幸福吧。」 「因为我们就算再怎么等下去，亚弥也不会变成我的，常叶也不会变成你的。加上我们只要一看到那两个人，就算不情愿也会想起第一人生的事，因而落入不停执著于过去的窘境。既然如此，亚弥和常叶干脆都消失了还比较好。」 主角只是为了让自己不后悔，心里虽然那么安慰自己，但还是希望能够拯救这一人生的那一对「分身」，拉着柊冲向之后本将发生车祸的路口，在夜晚停电时维护交通状况。 10年的记忆也只到这里，主角接下来要在没有记忆的干扰的情况下，和柊一起开始新的人生。故事就此结束了。 其实，故事也没有什么特别的感悟，仅仅只是主角追寻与女主的羁绊，颓废之后发现真相，以拯救曾经的自己的行动弥补自己的无意义的10年，让自己能够无后悔的开展新的人生。 其实从一定角度，作者三秋缒老师的后记更值得一看。 三秋缒老师只为了以自己期待的方式完成自己期待的故事，以最大的努力完成了这本书。老实说我感觉我很喜欢，能够将人生道理赋予现实，我做不到，所以我很钦佩。尤其在老师的第二本书中，更是凸显无疑。当下火热的《我的青春恋爱物语果然有问题》是他的第二本书，八幡大老师的人生道理在各式弹幕站上都是十分热门的。 总的来说，好评无误。 插一张小说的图 img","categories":[{"name":"随想","slug":"thinking","permalink":"https://sean10.github.io/categories/thinking/"}],"tags":[{"name":"轻小说","slug":"轻小说","permalink":"https://sean10.github.io/tags/%E8%BD%BB%E5%B0%8F%E8%AF%B4/"},{"name":"日本","slug":"日本","permalink":"https://sean10.github.io/tags/%E6%97%A5%E6%9C%AC/"},{"name":"书评","slug":"书评","permalink":"https://sean10.github.io/tags/%E4%B9%A6%E8%AF%84/"},{"name":"治愈向","slug":"治愈向","permalink":"https://sean10.github.io/tags/%E6%B2%BB%E6%84%88%E5%90%91/"}]},{"title":"huffman编码实现压缩与解压缩","slug":"huffman编码实现压缩与解压缩","date":"2015-12-13T13:23:00.000Z","updated":"2023-03-18T15:11:14.893Z","comments":true,"path":"2015/12/13/huffman编码实现压缩与解压缩/","link":"","permalink":"https://sean10.github.io/2015/12/13/huffman%E7%BC%96%E7%A0%81%E5%AE%9E%E7%8E%B0%E5%8E%8B%E7%BC%A9%E4%B8%8E%E8%A7%A3%E5%8E%8B%E7%BC%A9/","excerpt":"","text":"题目：将任意一个指定的文件进行哈夫曼编码，并以真正的二进制位生成一个二进制文件（压缩文件）；反过来，可将一个压缩文件解码还原为原来的文件。 以下是编码过程中需要注意的地方 1.读入字符 这里需要明白fread的运用。这段代码要实现的功能是对各类型文件进行转码，所以文本输入的方式fscanf不能在这里使用，只能用fread. 读入过程中需要记录文件中总计的单字节字符数量n，后面需要写入编码的文件中用于后续解码时判断是否已经到了最后一个字符的编码处，跳过补充的0代码段的解码。 2.统计字符出现频次 这里需要统计实际的哈弗曼树的叶子节点的数量，即不同的字符数量。 3.通过2的过程已经得到了每个字符的权值，即前nReal项已经输入完毕，可以开始建树 首先通过Select函数从已经得到的字符中提取最小的2个字符的权值，然后进行循环建树。这里的过程就是常规的建立静态分配空间以后的哈夫曼树的过程。 4.建树完毕，接下来开始进行编码操作 主体编码的流程是左子树为0，右子树为1，如果该节点两个孩子节点均指向0,,则该节点编码完毕，将临时分配的cd空间内的字符存入哈夫曼树中。 5.编码完毕，接下来直接输出即可 重新按照文件的字符出现的顺序，找到该字符对应的编码，按每8位完成一个编码写入文件，当抵达最后一个字符的时候，如果不足8位，补充编码，后面解码的时候的n就是用在这里跳过补充的编码的。 注意：这里并不能直接输出 如果直接以char型写入，输出的并没有起到压缩的作用，最多只能算是转码，所以这里需要追加一个过程，使得输出的0、1为确实的单比特输出，而不是1个字节的字符型输出。 并且这里char型与unsigned char型在首位也是存在差别的，所以建议转换类型为unsigned char。 下面解码 虽然说哈弗曼编码运用了前缀编码的原理，编码不会发生无法解码的过程，但是其终究是建立在具有了哈弗曼树的前提下才可进行解码。假如没有哈夫曼树，因为文件内部的二进制码是没有间断点的，如果一个一颗成形的哈夫曼树，我们并不能判断是否已经到了这个字符的编码结束的位置。假如迭代暴力解码，间断点的可能性有(n-1)!种，相当于o(n^n)级的复杂度，不可行。 所以我们在这里在编码时就将整棵树输出到解码文件的首部，解码时通过读取此树，再根据这棵树进行解码。 1.首先，读取nReal，动态分配足够的空间给接下来建立的树，读取文件中关于树的data和权值。 2.建树完毕，读取二进制编码，根据01决定左、右子树，如果抵达叶子节点，则其左右子树均为0，存入输出字符串即可。 这里对于补充的编码长度如何写入呢？ 程序优化： 可以对哈夫曼树进行压缩 参考资料: [1].http://blog.csdn.net/u013275340/article/details/38778497?utm_source=tuicool&amp;utm_medium=referral [2].http://zzh87615.blog.163.com/blog/static/1178207282009516271866 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264#include &lt;cstdio&gt;#include &lt;cstdlib&gt;#include &lt;cstring&gt;#define MAX 99999999typedef struct node&#123; unsigned char data; int weight; int parent,lchild,rchild; //unsigned char *bit; unsigned char *bit;&#125;HuffmanNode,HuffmanTree[512];/*typedef struct bit&#123;//设立位域，用于解码进行数字比对 unsigned a:1; unsigned b:6; unsigned c:1;&#125;Bit;*/void Select(HuffmanTree HT,int k,int &amp;s1,int &amp;s2)&#123;//选取最小的两个未链入哈弗曼树中的节点 int minHuf1 = MAX,minHuf2 = MAX; s1 = 99999999,s2 = 99999999; for(int i = 1;i &lt;= k;i++)&#123; if(HT[i].weight &lt; minHuf1 &amp;&amp; HT[i].parent == 0)&#123; minHuf2 = minHuf1; s2 = s1; minHuf1 = HT[i].weight; s1 = i; &#125;else if(HT[i].weight &lt; minHuf2 &amp;&amp; HT[i].parent == 0)&#123; s2 = i; minHuf2 = HT[i].weight; &#125; &#125;&#125;void Encode(HuffmanTree HT,int nReal)&#123;//进行字符编码 unsigned char *cd; cd = (unsigned char*)malloc(nReal*sizeof(unsigned char)); cd[nReal-1] = &#x27;\\0&#x27;; for(int i = 1;i &lt;= nReal;i++)&#123; int start = nReal-1; for(int curr = i,parent = HT[i].parent;parent != 0 &amp;&amp; 0 &lt; parent &amp;&amp; parent &lt;= 2*nReal-1;curr = parent,parent = HT[parent].parent)&#123; if(curr == HT[parent].lchild) cd[--start] = &#x27;0&#x27;; else cd[--start] = &#x27;1&#x27;; &#125; HT[i].bit = (unsigned char*)malloc((nReal-start+1)*sizeof(unsigned char)); int x = 0; do&#123; HT[i].bit[x++] = cd[start++]; &#125;while(cd[start-1] != &#x27;\\0&#x27;); HT[i].bit[x] = &#x27;\\0&#x27;; //strcpy(HT[i].bit,&amp;cd[start]); &#125; free(cd); /* if(nReal == 1) HT[1].bit[0] = &#x27;0&#x27;; */&#125;void Init(FILE *fpR,HuffmanTree &amp;HT,int &amp;nReal,int &amp;n)&#123;//初始化哈夫曼树 nReal = 0; HuffmanNode *p; int i; unsigned char ch; for(p = HT,i = 1;i &lt;= 511;i++,p++) *p = &#123;&#x27;\\0&#x27;,0,0,0,0&#125;; int start = 1; while(true)&#123; fread(&amp;ch,1,1,fpR); if(feof(fpR)) return; int tag = 0; n++; for(int j = 1;j &lt;= nReal;j++)&#123; if(ch == HT[j].data)&#123; HT[j].weight++; tag = 1; break; &#125; &#125; if(tag == 0)&#123; HT[start].data = ch; HT[start++].weight++; nReal++; &#125; &#125;&#125;void BuildTree(HuffmanTree &amp;HT,int nReal)&#123;//建树 int m = 2*nReal-1; for(int i = nReal+1;i &lt;= m;i++)&#123; int s1,s2; Select(HT,i-1,s1,s2); HT[s1].parent = i; HT[s2].parent = i; HT[i].lchild = s1; HT[i].rchild = s2; HT[i].weight = HT[s1].weight + HT[s2].weight; &#125;&#125;void Decode(HuffmanTree &amp;HT,int &amp;n,int &amp;nReal,FILE *fpR,FILE *fpW)&#123;//解码 int sup; fread(&amp;sup,sizeof(int),1,fpR); fread(&amp;n,sizeof(int),1,fpR); fread(&amp;nReal,sizeof(int),1,fpR); int i; HuffmanNode *p; for(p = HT,i = 1;i &lt;= 511;i++,p++) *p = &#123;&#x27;\\0&#x27;,0,0,0,0&#125;; for(i = 1;i &lt;= 2*nReal-1;i++)&#123; fread(&amp;HT[i].data,sizeof(unsigned char),1,fpR); fread(&amp;HT[i].weight,sizeof(int),1,fpR); &#125; BuildTree(HT,nReal); unsigned char c; unsigned char str; int root = 2*nReal-1; //i = 0; int length = 0;//对字符读取数量的计数，判断是否已经结束一次字符串读取 int flagSup = 0; while(true)&#123; fread(&amp;c,1,1,fpR); if(feof(fpR)) return; //fseek(fpR,len,SEEK_CUR); for(int k = 0;k &lt; 8;k++)&#123; if(HT[root].lchild == 0 &amp;&amp; HT[root].rchild == 0)&#123;//哈弗曼树不存在度为1的节点，故用and或者or均可 //if(HT[root].data == &#x27;\\0&#x27;) // fprintf(stderr,&quot;Error str\\n&quot;); str = HT[root].data; root = 2*nReal-1; fwrite(&amp;str,1,1,fpW); length++; &#125; if(length == n) break; if((c&amp;128) == 0) root = HT[root].lchild; else if((c&amp;128) == 128)&#123; root = HT[root].rchild; &#125; c = c &lt;&lt; 1; if(length == n) flagSup++; &#125; &#125;&#125;void EncodeOutput(HuffmanTree HT,FILE *fpR, FILE *fpW,int n,int nReal)&#123;//输出编码 fseek(fpW,4,SEEK_SET); fwrite(&amp;n,sizeof(int),1,fpW); fwrite(&amp;nReal,sizeof(int),1,fpW); for(int i = 1;i &lt;= 2*nReal-1;i++)&#123; fwrite(&amp;HT[i].data,sizeof(unsigned char),1,fpW); fwrite(&amp;HT[i].weight,sizeof(int),1,fpW); &#125; int length = 0; unsigned char c = 0;//编码变量 unsigned char ch;//输入字符变量，作为文件顺序参照 int sup = 0; int start = 0; fseek(fpR,0,SEEK_SET); for(int i = 0;i &lt; n;i++)&#123;//进行逐个字符编码写入 fread(&amp;ch,1,1,fpR); for(int j = 1;j &lt;= nReal;j++)&#123;//进行逐个匹配，寻找对应字符哈弗曼节点 if(HT[j].data == ch)&#123; int StrLen = 0; while(HT[j].bit[StrLen] != &#x27;\\0&#x27;)//计算该节点字符的编码比特数 StrLen++; //fprintf(fpW,&quot;%s&quot;,HT[j].bit); for(int k = 0;k &lt; StrLen;k++)&#123; if(HT[j].bit[k] == &#x27;0&#x27;) c = c &lt;&lt; 1; else if(HT[j].bit[k] == &#x27;1&#x27;) c = (c &lt;&lt; 1)|1; else fprintf(stderr,&quot;Bit output error!\\n&quot;); length++; if(i == n-1 &amp;&amp; length % 8 != 0)&#123;//最后一个节点需要记录补充编码数 while(length%8!=0)&#123; c = c &lt;&lt; 1; length++; sup++; &#125; &#125; if(length % 8 == 0 &amp;&amp; length &gt; 0) fwrite(&amp;c,1,1,fpW); &#125; //fwrite(HT[i].bit,1,sizeof(HT[i].bit),fpW); &#125; &#125; &#125; fseek(fpW,0,SEEK_SET); //fwrite(&amp;length,sizeof(int),1,fpW); fwrite(&amp;sup,sizeof(int),1,fpW); //fwrite(str,sizeof(unsigned char),length,fpW);&#125;void InterfaceFile(char *infile,char *outfile)&#123; fprintf(stdout,&quot;***Welcome to the Huffman Encoding/Decoding System:***\\n&quot;); fprintf(stdout,&quot;*** ***\\n&quot;); fprintf(stdout,&quot;Please input the input file name(including the postfix):&quot;); gets(infile); fprintf(stdout,&quot;Please input the output file name(including the postfix):&quot;); gets(outfile);&#125;void InterfaceNum(int &amp;num)&#123; fprintf(stdout,&quot;***Please choose which operation you&#x27;d like to do:****\\n&quot;); fprintf(stdout,&quot;*** ***\\n&quot;); fprintf(stdout,&quot;***1_Encoding 2_Decoding ***\\n&quot;); while(fscanf(stdin,&quot;%d&quot;,&amp;num) &amp;&amp; (num != 1 &amp;&amp; num != 2))&#123; fprintf(stdout,&quot;The number is out of range.\\nPlease input again:&quot;); &#125;&#125;int main()&#123; FILE *fpR,*fpW; char infile[255],outfile[255]; InterfaceFile(infile,outfile); if((fpR = fopen(infile,&quot;ab+&quot;)) == NULL)&#123; fprintf(stderr,&quot;File_Read open error!\\n&quot;); exit(1); &#125; if((fpW = fopen(outfile,&quot;wb+&quot;)) == NULL)&#123; fprintf(stderr,&quot;File_Write open error!\\n&quot;); exit(2); &#125; HuffmanTree HT; //unsigned char ch;//编码字符 int n = 0,nReal = 0;//文件中字符数量n，哈弗曼节点数量nReal int num = 0;//选择方案 InterfaceNum(num); switch(num)&#123; case 1: Init(fpR,HT,nReal,n); BuildTree(HT,nReal); Encode(HT,nReal); EncodeOutput(HT,fpR,fpW,n,nReal); break; case 2: Decode(HT,n,nReal,fpR,fpW); break; &#125; fclose(fpR); fclose(fpW); return 0;&#125;","categories":[{"name":"专业","slug":"pro","permalink":"https://sean10.github.io/categories/pro/"}],"tags":[{"name":"Huffman","slug":"Huffman","permalink":"https://sean10.github.io/tags/Huffman/"},{"name":"压缩","slug":"压缩","permalink":"https://sean10.github.io/tags/%E5%8E%8B%E7%BC%A9/"}]},{"title":"蒙特卡洛算法（简单理解）","slug":"蒙特卡洛算法（简单理解）","date":"2015-12-09T09:23:00.000Z","updated":"2023-03-18T15:11:14.850Z","comments":true,"path":"2015/12/09/蒙特卡洛算法（简单理解）/","link":"","permalink":"https://sean10.github.io/2015/12/09/%E8%92%99%E7%89%B9%E5%8D%A1%E6%B4%9B%E7%AE%97%E6%B3%95%EF%BC%88%E7%AE%80%E5%8D%95%E7%90%86%E8%A7%A3%EF%BC%89/","excerpt":"","text":"###蒙特卡洛算法(Monte Carlo Algorithm) 在这本书里面，前面我们已经学到的算法都是属于确定性算法。有这样一种情况，一个确定性算法不得不仔细判断大量的甚至指数级的可能事件。在这种情况下，我们用到了下面现在我们要学习的一种特殊类的概率算法。该算法在不同的运行步数下提供随机性的选择，在应对决策问题的情况下，这种算法叫做蒙特卡洛算法。 A Monte Carlo algorithm for a decision problem uses a sequence of tests. The probability that the algorithm answers the decision problem correctly increases as more tests are carried out. At each step of the algorithm, possible responses are “true,” which means that the answer is “true” and no additional iterations are needed, or “unknown,” which means that the answer could be either “true” or “false.” After running all the iterations in such an algorithm, the final answer produced is “true” if at least one iteration yields the answer “true,” and the answer is “false” if every iteration yields the answer “unknown.” If the correct answer is “false,” then the algorithm answers “false,” because every iteration will yield “unknown.” However, if the correct answer is “true,” then the algorithm could answer either “true” or “false,” because it may be possible that each iteration produced the response “unknown” even though the correct response was “true.” We will show that this possibility becomes extremely unlikely as the number of tests increases. 决策问题只有“对”与“错”两种答案。在每一步迭代中，如果决策是“对”，意味着回答是“对”，并且与算法的其他迭代无关；也可能回应“未知”，意味着答案可能是“对”也可能是“错”。在全部均迭代过后，如果至少有一次迭代中生成了结果“对”，那么结果就为”对“；如果每个重复生成的回答都是”未知“，那么结果就为”错“。 然而，如果正确答案是”对“，而算法可以回答”对“或”错“，有可能所有的迭代均得到的回答是”未知“。（这就是其中的小概率的错误概率。） （这一段是我对书上的翻译，我理解下来，这段描述的其实是拉斯维加斯算法吧，是不是我理解错了，希望明白的人能指正一下） 对于蒙特卡洛算法，是实验样例越多，得到的结果也就愈发靠近正确的结果。 与蒙特卡洛算法相对的另一种随机算法，叫做拉斯维加斯算法，同样是随机抽样，样本数越多，这个算法增加的只有找到正确结果的概率，他得到的只有对与错，没找到正确的结果就没有意义。 参考其他资料对蒙特卡洛算法的理解是，蒙特卡洛算法是利用一种满足平均分布的随机抽样达成的计算数学期望的方法。其主要计算的是近似真值。也就是说他主要是从样本数中找对的结果，然后计算”对“的结果占全部样本数的概率，其方法重点是在于抽样的过程。 Ps.果然《离散数学》里面的各方面内容都只是各领域最简单的内容，关于蒙特卡洛算法，这里连抽样(sample)的单词都并没有用到，用了一些常用（多义）的单词，不看其他资料，完全不能理解呀。 参考资料： [1]http://www.zhihu.com/question/20254139 [2]http://www.cnblogs.com/daniel-D/p/3388724.html [3]https://en.wikipedia.org/wiki/Monte_Carlo_method","categories":[{"name":"专业","slug":"pro","permalink":"https://sean10.github.io/categories/pro/"}],"tags":[{"name":"离散数学","slug":"离散数学","permalink":"https://sean10.github.io/tags/%E7%A6%BB%E6%95%A3%E6%95%B0%E5%AD%A6/"}]},{"title":"条件概率","slug":"条件概率","date":"2015-12-02T13:19:00.000Z","updated":"2023-03-18T15:11:14.838Z","comments":true,"path":"2015/12/02/条件概率/","link":"","permalink":"https://sean10.github.io/2015/12/02/%E6%9D%A1%E4%BB%B6%E6%A6%82%E7%8E%87/","excerpt":"","text":"定义1.假设\\(S\\)是一个有\\(n\\)个元素的集合，均匀分布分配给\\(S\\)的每个元素\\(\\frac1n\\)的概率。 定义2.事件\\(E\\)的概率是\\(E\\)中所有结果出现的概率之和。如下：\\[p(E)=\\sum_{s \\in E}p(s)\\]. （注意：当\\(E\\)是一个有限集合时，\\(\\sum_{s \\in E}p(s)\\)是一个收敛有限级数。） 这里事件的各个结果的概率计算依照拉普拉斯概率的计算即可。 从一个带有均匀分配（也可叫做一致分布）的样本空间中选择一个元素的实验叫做随机选取元素\\(S\\)。 在这个部分，带有数个结果的事件的补全概率的计算依旧遵循拉普拉斯的传统的计算。 \\[p(E_1 \\cup E_2)=p(E_1)+p(E_2)-p(E_1 \\cap E_2)\\]. 定理1.如果\\(E_1,E_2,\\dots\\) 是一序列成对出现的样本空间\\(S\\)中的不相交的事件，那么\\[p \\left(\\bigcup_i E_i \\right)=\\sum_i{p(E_i)}\\]. （注意这个定义在一序列事件\\(E_1,E_2,\\dots\\)是由有限或可数数量的成对不想交的事件组成的时候应用） ###条件概率 &gt;定义3.令\\(E\\)和\\(F\\)作为\\(p(F)&gt;0\\)的事件。给出条件\\(F\\)的\\(E\\)的条件概率写作\\(p(E|F),定义为\\)\\(p(E|F)=\\cfrac{p(E \\cap F)}{p(F)}\\)$. 依照这个公式，目前来看，还是比较容易计算的。 ###独立性 一个硬币被掷3次，告诉我们第一次是背面，3次中出现奇数次背面的概率是多少？从上面的条件概率的公式中，我们可以得到\\(\\cfrac{\\cfrac14}{\\cfrac48}=\\cfrac12\\).即便没有告诉我们第一次是背面，得到的概率同样也是\\(\\cfrac12\\)。这样概率并没有受到影响的两个事件，就叫做独立事件。 定义4.事件\\(E\\)和\\(F\\)是独立的，当且仅当\\(p(E \\cap F)=p(E)p(F)\\). 定义5.当且仅当对于所有对整数\\(i\\)和\\(j\\) \\(（1\\leq i \\leq j \\leq n)\\)有\\(p(E_i \\cap E_j)=p(E_i)p(E_j)\\)，事件\\(E_1,E_2,\\dots,E_n\\)是成对独立的。如果对于$i_j,j=1,2,,m $，是\\(1 \\leq i_1 \\leq i_2 \\leq \\dots \\leq i_m \\leq n\\) 和\\(m \\geq 2\\)的整数，那么\\(p(E_{i_1}\\cap E_{i_2}\\cap \\dots \\cap E_{i_m})=p(E_{i_1})p(E_{i_2})\\dots p(E_{i_m})\\)这些事件是相互独立的。 从定义5，我们可以看到每个\\(n\\)个相互独立事件的集合也是成对独立的。然而\\(n\\)个成对独立的时间并不一定是相互独立的。 （成对独立只对于两个事件之前，而相互独立是\\(n\\)个之间之间均独立，差别就在这里了） ###伯努利实验和二项分布（Bernoulli Trials and the Binomial Distribution) &gt;每个具有两个可能结果的实验表现称之为伯努利实验。 &gt;一般来说，伯努利实验的可能结果被称为成功或者失败. 定理2.实际上在\\(n\\)格独立伯努利实践中\\(k\\)个成功的概率，在成功的概率为\\(p\\)、失败的概率为\\(q=1-p\\)的条件下是\\[C(n,k)p^kq^{n-k}\\]. 我们也常写作\\(b(k;n,p)\\).我们把这个函数(为什么叫function，不太明白）叫做二项分布。 \\[\\sum^n_{k=0}C(n,k)p^kq^{n-k}=(p+q)^n=1.\\] ###随机变量 &gt;定义6.一个随机变量是一个从实验的样本空间映射到实数集合的函数。因此，一个随机变量分配一个实数到每个可能结果。 注意：随机变量并不是变量，也不随机。 &gt;定义7.在样本空间\\(S\\)中的随机变量\\(X\\)的分配是对所有\\(r \\in X(S),p(X=r)\\)是\\(X\\)取值\\(r\\)的概率的对\\((r,p(X=r))\\)的集合。（在这个分配中的对的集合是由对\\(r \\in X(S)\\)的概率\\(p(X=r)\\)决定的。） ####生日问题 生日问题是寻找房间里最少的人数使得至少有2个人同一天生日的概率大于\\(\\frac12\\). 答：首先，我们列出几条假设。我们假设在一个房间里的人们的生日均是独立的。更进一步，我们假设每个生日是等可能的并且一年里有366天。（实际上，在一年里更多的人出生在一年里的相同的一些日子里，比如包括新年在内的一些节日后的9个月里） 为了找到这个可能性，我们首先计算这些人有全部都有不同生日的概率\\(p_n\\)。然后，至少2个人有相同生日的概率为\\(1-p_n\\)。为了计算\\(p_n\\)，我们姑且认定\\(n\\)个人的生日是遵循一定顺序的。想象一下，他们在一个时刻一个个进入房间；我们将会计算每个人进入房间时与已经在房间里的人的生日不同的概率。 第一个进入房间的人的生日当然不会匹配到任何在房间里的人的生日。第二个人的生日不同于第一个人的概率是$因为当第二个人出生在除了第一个人的生日之外的\\(365\\)天里时，他们的生日是不同的。（这个对每个人出生在\\(366\\)天里任何一天等可能的假设保证了这个和后续步骤） 第三个人有不同生日的概率是\\(\\cfrac{364}{366}。延伸开来，对于第\\)j\\(个人(2 \\leq j \\leq 366)，有一个不同于其他\\)n-1\\(个人的生日的概率是\\)\\(\\cfrac{366-(j-1)}{366}=\\cfrac{367-j}{366}.\\)$ 因为已经假设在房间里的人的生日均是独立的，我们就可以得出结论这房间里的\\(n\\)个人有不同生日概率是\\[p_n=\\cfrac{365}{366}\\cfrac{364}{366}\\cfrac{363}{366}\\dots \\cfrac{367-n}{366}.\\] 随之，我们得到\\[1-p_n=1-\\cfrac{365}{366}\\cfrac{364}{366}\\cfrac{363}{366}\\dots \\cfrac{367-n}{366}.\\] 接下来为了找到最少的人数使得其概率大于\\(\\cfrac12\\)，我们逐渐带入增大的\\(n\\)来计算（虽然可以用微积分，但是这里不使用。话说怎么用？我忘了）。我们会发现\\(n=22,1-p_n \\approx 0.475;n=23,1-p_n \\approx 0.506\\)。因此我们得知最少只要23个人即可使得房间内的人至少有2个人的生日相同的概率为\\(\\cfrac12\\)。 哈希的重合概率计算和生日问题类似。","categories":[{"name":"专业","slug":"pro","permalink":"https://sean10.github.io/categories/pro/"}],"tags":[{"name":"离散数学","slug":"离散数学","permalink":"https://sean10.github.io/tags/%E7%A6%BB%E6%95%A3%E6%95%B0%E5%AD%A6/"},{"name":"概率","slug":"概率","permalink":"https://sean10.github.io/tags/%E6%A6%82%E7%8E%87/"}]},{"title":"有限概率（拉普拉斯概率）","slug":"有限概率（拉普拉斯概率）","date":"2015-12-02T11:44:00.000Z","updated":"2023-03-18T15:11:14.887Z","comments":true,"path":"2015/12/02/有限概率（拉普拉斯概率）/","link":"","permalink":"https://sean10.github.io/2015/12/02/%E6%9C%89%E9%99%90%E6%A6%82%E7%8E%87%EF%BC%88%E6%8B%89%E6%99%AE%E6%8B%89%E6%96%AF%E6%A6%82%E7%8E%87%EF%BC%89/","excerpt":"","text":"###有限概率（拉普拉斯概率） 定义1.如果\\(S\\)是一个等可能结构的有限非空样本空间，\\(E\\)是一个作为\\(S\\)的子集的一个事件，那么\\(E\\)的概率为\\(p(E)=\\cfrac{|E|}{|S|}\\). 定理1.让\\(E\\)成为一个样本空间\\(S\\)中的一个事件。事件\\(\\overline{E}=S-E\\)发生的概率，即事件\\(E\\)的补全事件，由以下公式给出\\[p(\\overline{E})=1-p(E)\\]. ###事件补全、联合概率 &gt;定理2.让\\(E_1\\)和\\(E_2\\)成为样本空间\\(S\\)中的时间，那么\\(p(E_1 \\cup E_2)=p(E_1)+p(E_2)-p(E_1 \\cap E_2)\\). ###概率性原因 没什么内容，都是概率之前学过的基础，就下面这个问题比较有意思。 ####蒙提霍尔问题 &gt;蒙提霍尔问题就是在一个游戏中，有三扇门，一扇门背后是奖品，两扇门背后是山羊，参加者可以在上台前选择其中一扇门，上台之后，主持人会从剩下的两扇门中选择一扇背后没有奖品的门打开，然后给参加者一个更换选择的机会。 问：如果你更换，会不会有更大的概率拿到奖品。 这里的问题以前看到过流言终结者，那里面采用的方法是统计概率，得到的结果是2/3的中签率。 在更换之前的是先验概率，为1/3。 得到一扇门打开之后的是后验概率（条件概率）。 举个例子： 比如10个人抽一个人值日，这是一个事件，概率是1/10. 如果一个人打开了他的签，他并不值日，他的事件和你的事件是两回事，概率并不相关。 但如果你知道了他的未中签，给你再选择的机会，那就是1/9. （概率永远会变）变了一定是事件变了。 回到这个例子，如果你始终不更换你的选择，你的中签率就是1/3，这里就算主持人打开了门，但你不重新选择，所以你始终是1/3.这是不相关的两件事。 如果你会更改选择，那么简单地来说，因为事件改变为了剩下两个一扇奖品一扇山羊，这样你的概率一定会大于等于1/2. 假如我选两扇门，中奖概率一定是2/3.这是确定的事件，确定的概率。 不让你选择两个，其实换个角度，就是比如有ABC三扇门，我想选AB，我就先选C，然后主持人会在AB里选择一扇门，然后我就可以更换到AB中的那扇没被打开的门了。这样事件没有改变，很明显， 中奖概率都是2/3.","categories":[{"name":"专业","slug":"pro","permalink":"https://sean10.github.io/categories/pro/"}],"tags":[{"name":"离散数学","slug":"离散数学","permalink":"https://sean10.github.io/tags/%E7%A6%BB%E6%95%A3%E6%95%B0%E5%AD%A6/"},{"name":"概率","slug":"概率","permalink":"https://sean10.github.io/tags/%E6%A6%82%E7%8E%87/"}]},{"title":"大学物理实验 考点总结","slug":"大学物理实验-考点总结","date":"2015-11-30T14:42:00.000Z","updated":"2023-03-18T15:11:14.830Z","comments":true,"path":"2015/11/30/大学物理实验-考点总结/","link":"","permalink":"https://sean10.github.io/2015/11/30/%E5%A4%A7%E5%AD%A6%E7%89%A9%E7%90%86%E5%AE%9E%E9%AA%8C-%E8%80%83%E7%82%B9%E6%80%BB%E7%BB%93/","excerpt":"","text":"大物实验 考点总结 误差 测量误差可以用绝对误差，也可以用相对误差表示： \\[绝对误差=测量结果-真值\\] \\[相对误差=\\cfrac{绝对误差}{真值}\\] 误差分类： (1)系统误差(2)随机误差(3)粗大误差 测量结果的评价 评价测量结果，反应测量误差大小，常用到精密度、正确度和准确度3个概念。 精密度反映随机误差大小的程度，它是对测量结果的重复性的评价。精密度高是指测量的重复性好，各次测量值的分布密集，随机误差小。但是，精密度不能反映系统误差的大小。精密度反映测量值离散程度。 正确度反映系统误差大小的程度。正确度高是指测量数据的算术平均值偏离真值较小，测量的系统误差小。但是正确度不能确定数据分散的情况，即不能反映随机误差的大小。 准确度反映系统误差与随机误差综合大小的程度。准确度高是指测量结果既精密又正确，即随机误差与系统误差均小。 常用的测量方法有异号法、交换法、替代法、对称法。 服从正态分布的随机误差 服从正态分布的随机误差具有下列特点： (1)单峰性——绝对值小的误差比绝对值大的误差出现的概率答； (2)对称性——大小相等而符号相反的误差出现的概率相同； (3)有界性——在一定的测量条件下，误差的绝对值不超过一定的限度； (4)抵偿性——误差的算术平均值随测量次数\\(n\\)的增加而趋于零。 当测量次数无穷多或足够多时，测量值的误差分布才接近正态分布，但是当测量次数较少时（例如，少于10次，物理实验教学中一般取\\(n=6\\sim 10\\)次），测量值的误差分布将明显偏离正态分布，而遵从\\(t\\)分布，又称为学生分布。\\(t\\)分布曲线与正态分布曲线的形状类似，但是\\(t\\)分布曲线的峰值低于正态分布；而且\\(t\\)分布曲线上部较窄，下部较宽。 为什么置信概率取0.95 不确定度的\\(A\\)类（采用统计方法评定的\\(A\\)类不确定度）分量用\\(u_A(x)\\)表示。物理实验中\\(u_A(x)\\)一般用多次测量平均值的标准偏差\\(s(\\overline{x})\\)与\\(t\\)因子\\(t_p\\)的乘积来估算，即\\[u_A(x)=t_ps(\\overline x)\\] 式中，\\(t\\)因子\\(t_p\\)是与测量次数\\(n\\)和对应的置信概率\\(p\\)有关，当置信概率为\\(p=0.95\\)，测量次数\\(n=6\\)时，我们可以查到\\(t_{0.95}/\\sqrt{n} \\approx 1\\)，则有\\[u_A(x)=s(x)\\] 即在置信概率为\\(0.95\\)的前提下，测量次数\\(n=6\\)，\\(A\\)类不确定度可以直接用测量值的标准偏差\\(s(x)\\)估算。 因此，在未加说明时，普遍采取置信概率\\(p=0.95\\)。 测量不确定度和结果的表达 不确定度由两类不确定度合成 1. A类不确定度：采用统计方法评定的不确定度，即对多次测量的数据进行处理而得到的不确定度，以\\(u_A(x)\\)表示。 2. B类不确定度：采用非统计方法评定的不确定度，即\\(u_A(x)\\),常常用仪器误差\\(\\Delta_仪\\)来表示。 （一般来说这个仪器误差会给出，所以不需要背） 合成不确定度与测量结果的表达 下式就是不确定度的合成公式： \\[u(x)=\\sqrt{u^2_A(x)+u^2_B(x)}\\tag {1.1}\\] 完整的数据处理结果，标准形式如下： \\[\\begin{cases}x=\\overline {x} \\pm u(x) \\\\\\\\ u_r=\\cfrac{u(x)}{\\overline {x}} \\times 100\\% \\end{cases}\\tag{1.2}\\] 式中，\\(\\overline x\\)为多次测量的平均值，\\(u(x)\\)为合成不确定度，\\(u_r\\)是两者的比值，称为测量的相对不确定度。 不确定度的求解 直接测量不确定度的求解过程 1.单次测量 因为我们的实验过程都是指定的，并不需要我们自己来构思实验过程，所以对于测量单次或者多次无需判断，这部分不在考点内。 当遇到测量结果是单次测量时，我们的不确定度只有\\(u_B(x)\\)一项。它的取值有两种，一种是仪器标定的最大误差限（暂时没遇到，如果有应该会在型号说明那把），第二种是实验室给出的最大允许误差\\(u(x)=u_B(x)=\\Delta_仪\\)。如果两种都有，取较大者。 2.多次测量 多次测量时，不确定度一般按照下列过程进行计算： * 求多次的测量数据的平均值\\(\\overline{x}=\\sum \\frac{x_i}{n}\\); * 修正已知系统误差，得到测量值，例如，已知螺旋测微仪的零点误差为\\(d_0\\)，修正后的测量结果为\\(d=d_测-d_0\\)； * 用贝塞尔公式计算标准误差\\[s(x)=\\sqrt{\\cfrac{\\sum_{i=1}^{n} (x_i-\\overline{x})^2}{n-1}}\\] * 根据仪器标定的最大误差限，或实验室给出的最大允许误差，确定\\(u_B(x)\\)； * 根据$u_A(x)和u_B(x)求合成不确定度 \\[u(x)=\\sqrt{u^2_A(x)+u^2_B(x)}$ ； * 计算相对不确定度$u_r(x)=\\cfrac{u(x)}{\\overline {x}} \\times 100 \\%$; * 给出测量结果\\] \\[\\begin{cases}x=\\overline{x}\\pm u(x) \\\\\\\\ u_r=\\cfrac{u(x)}{\\overline x}\\times 100 \\% \\end{cases}\\] $$ 间接测量的不确定度 在实际测量中，我们遇到的往往是间接测量，因此间接测量具有非常重要的意义。假设物理量\\(F\\)是\\(n\\)个独立的直接测量量\\(x,y,z,\\cdots\\)的函数，即\\(F=f(x,y,z,\\cdots)\\)，如果它们相互独立，则\\(F\\)的不确定度可由各直接测量量的不确定度合成，即\\[u(F)=\\sqrt{\\left(\\cfrac {\\partial{f}}{\\partial {x}}\\right)^2 u^2 (x)+\\left(\\cfrac {\\partial{f}}{\\partial {y}}\\right)^2 u^2 (y)+\\left(\\cfrac {\\partial{f}}{\\partial {z}}\\right)^2 u^2 (z)+\\cdots}\\] 式中，\\(u(x),u(y),u(z)\\)为各直接测量量\\(x,y,z,\\cdots\\)的不确定度。 当\\(F=f(x,y,z,\\cdots)\\)中各观测量之间的关系是乘、除或方幂时，采用相对不确定度的表达方式，可以大大简化合成不确定度的运算。 方法是先取自然对数，然后作不确定度的合成，即 \\[u(F)=\\sqrt{\\left(\\cfrac{\\partial{lnf}}{\\partial x}\\right)^2u^2 (x)+\\left(\\cfrac{\\partial{lnf}}{\\partial y}\\right)^2u^2 (y)+\\left(\\cfrac{\\partial{lnf}}{\\partial z}\\right)^2u^2 (z)+\\cdots}\\] 间接测量不确定度的计算过程类似直接测量的计算过程，这里就不写了，只是将\\(u(x)\\)替换成\\(u(F)\\)。 ### 有效数字及其运算法则 #### 有效数字 对于有效数字注意以下几点即可 有效数字位数多少的计算是从测量结果的第一位（最高位）非零数字开始，到最后一位数。 数字结尾的0不应随便取舍，因为它与有效数字密切相关。例如，\\(103000\\)与\\(1.03\\times 10^5\\)不一样，前者有6位有效数字，而后者只剩下3位。 常用数学常数的有效位数（即\\(e\\)、\\(\\pi等\\))，可根据需要进行取舍，一般取位应比参加运算各数中有效位数最多的数再多一位。 在仪器上直接读取测量结果时，有效数字的多少是由被测量的大小及仪器的精度决定。正确的读数，应在仪器最小分度以下再估读一位，除非有特殊说明该仪器不需要估读。如千分尺等指针式器具，加上我们估读的那位，才读到千分位。而精密数字显示仪器和游标仪器就不用估读。 有效数字的近似运算法则 在加减法运算中，有效数字取决于参与运算的数字中末位位数最高的那个数。 乘除法运算的有效位数取决于参与运算数字中有效位数最少的那个数，必要时可多取一位。(当两个乘数的第一位数相乘大于10，则多取一位） 四则运算的基本原则与以上相同。 特殊函数的运算（三角函数、对数） 这里一定是个考点。 例：已知角度为\\(15^\\circ21’\\)，求\\(sinx\\)。 答：在x的最后一位数上取1个单位作为\\(x\\)的不确定度，即\\(u_{min}=\\Delta=1&#39;\\)，将它化为弧度有\\(\\Delta x=0.000\\ 29rad\\)；设\\(y=sinx\\),并对其求微分，得\\(\\Delta y=cosx\\Delta x \\approx 0.000\\ 28\\)，不准确位是小数点后的第4位，因此\\(sin x\\)应取到小数点后的第4位，即\\(sinx=0.264\\ 7\\)。 如果上述角度是\\(15^\\circ21&#39;10&#39;&#39;\\),则\\(\\Delta x=1&#39;&#39;=0.000\\ 004\\ 85 rad\\)，可算出\\(u(y)=cosx \\Delta x \\approx 0.000\\ 004\\ 7\\),不准确位是小数点后第6位，因此\\(sinx\\)应取到小数点后的第6位，即\\(sinx = 0.264\\ 761\\)。 例：已知\\(x=57.8\\),求\\(lg\\ x\\)。 答：设\\(y=lg\\ x\\),已知\\(u_{min}=\\Delta x=0.1\\),有\\(\\Delta y=\\Delta(ln\\ x/ln\\ 10)=0.434\\ 3\\Delta x /x \\approx0.000\\ 75\\),因此\\(lg\\ x\\)应取到小数点后第4位，即\\(lg\\ x =1.761\\ 9\\)。 综上所述，总结如下： 加、减法运算，以参加运算各量中有效数字末位最高的为准，并与之对齐； 乘、除法运算，以参加运算各量中有效数字最少的为准，必要时可多取一位。(当两个乘数的第一位数相乘大于10，则多取一位） 混合四则运算按以上原则进行； 特殊函数运算，通过微分关系进行； 数据的修约和测量结果的表述 不确定度的有效位数在一般情况下，保留一位，至多不超过两位。 具体：如果不确定度有效位数的第一位数小于或等于3，允许保留2位有效数字；如果不确定度有效位数的第一位数大于3，则只能保留一位有效数字 （在实际中经常会遇到测量结果与不确定度的有效位数发生矛盾的情况，原则是以不确定度的有效位数确定测量结果的有效位数，因此在计算测量结果时不要过早地将数字截断） 数据截断时，剩余的尾数按”小于5舍弃，大于5进位，等于5凑偶” 等于5凑偶的意思是当尾数等于5，且5后没有其他不为零的数字时，如果它前面的数是奇数，则加1，将其凑成偶数，如果是偶数则不变。 常用数据处理方法 作图法 1.选择合适的坐标分度值，确定坐标纸的大小: 坐标分度值的选取应能反映测量值的有效位数，一般以 1～2mm对应于测量仪表的最小分度值或对应于测量值的次末位数）。 2. 标明坐标轴： 用粗实线画坐标轴，用箭头标轴方向，标坐标轴的名称或符号、单位,再按顺序标出坐标轴整分格上的量值。 3.标实验点： 实验点可用“+\"、 “\\(\\times\\)”、“\\(\\circ\\)”等符号标出（同一坐标系下不同曲线用不同的符号）。 4. 连成图线： 用直尺、曲线板等把点连成直线、光滑曲线。一般不强求直线或曲线通过每个实验点，应使图线线正穿过实验点时可以在两边的实验点与图线最为接近且分布大体均匀。图点处断开。 5.标出图线特征： 在图上空白位置标明实验条件或从图上得出的某些参数。如利用所绘直线可给出被测电阻R大小：从所绘直线上读取两点 A、B 的坐标就可求出 R 值。 6.标出图名： 在图线下方或空白位置写出图线的名称及某些必要的说明。 至此一张图完成 注意点 *问题：曲线太粗，不均匀，不光滑 应该用直尺、曲线板等工具把实验点连成光滑、均匀的细实线。 *问题：横轴坐标分度选取不当 横轴以3 cm 代表1 V，使作图和读图都很困难。实际在选择坐标分度值时，应既满足有效数字的要求又便于作图和读图，一般以1 mm 代表的量值是10的整数次幂或是其2倍或5倍。 图解法 实验曲线作出后，可由曲线求出经验公式及所含参数，称为图解法。物理实验中常见的有：直线，指数曲线，抛物线等。其中直线是最简单的一种。 建立经验公式的一般步骤： 第一步：根据曲线的形状判断曲线的类型； 第二步：由曲线的类型判断公式的特点，建立经验公式； *第三步：用实验数据来检验公式的准确度。 由曲线图直接建立经验公式是困难的，我们可以用变数置换法把曲线图改成直线图，再按建立直线方程的办法建立经验公式。 （1）确定直线图形的斜率和截距求测量结果 图线\\(y=kx+b\\)，可在图线上选取两点\\(P_1(x_1,y_1)\\)和\\(P_2(x_2,y_2)\\)（不能用原来测量的点）计算其斜率：\\[k=\\cfrac{y_2-y_1}{x_2-x_1}\\] \\(P_1\\)和\\(P_2\\)不要太靠近，以减小误差。其截距b是当\\(x=0\\)时的y值；或选取图上的任一点\\(P_3(x_3,y_3)\\)，带入\\(y=kx+b\\)中，并利用斜率公式得：\\[b=y3-\\cfrac{y_2-y_1}{x_2-x_1}x_3\\] 确定直线图形的斜率和截距以后，再根据斜率或截距求出所含的参量，从而得出测量结果。 （2）根据图线求出经验公式 这个就只是将函数适当转换成线性关系，不多说，这个初高中做得挺多的。 逐差法 在使用逐差法计算时，必须把测量数据分成高、低两组，对这两组实行对应项相减，不能采取逐项相减的办法处理数据。 为了保持多次测量的优点，体现出多次测量减小随机误差的目的，将一组等间隔连续测量数据（共\\(2n\\)次）按次序分成高低两组（两组次数应相同）。 一组为\\(x_0,x_1,\\cdots,x_n-1\\)，另一组为\\(x_n,x_{n+1},\\cdots,x_{2n-1}\\),取对应项的差值后再求平均值：\\[\\delta=\\frac 1n \\sum_{i=0}^{n-1}(x_{n+i}-x_i)\\] 标准偏差（即不确定度）为\\[s(\\delta)=\\sqrt{\\cfrac {\\sum_{i=0}^{n-1}[(x_{n+i}-x_i)-\\delta]^2}{n-1}}\\] 最小二乘法 设已知函数的形式为\\[y=bx+a\\] 式中，a和b为两个待定系数，成为回归系数；只有\\(x\\)为变量，由于只有一个变量，因此称为一元线性回归。 （1）回归系数的确定 回归系数a与b为\\[\\begin{cases} b=\\cfrac{\\overline{xy}-\\overline{x}\\overline{y}}{\\overline{x^2}-\\overline{x} ^2}\\\\\\\\ a=\\overline{y}-b\\overline{x} \\end{cases}\\] (2)相关系数的确定 为了判断所作的线性回归结果是否合理，引入线性回归相关系数的概念，相关系数以\\(r\\)表示，定义公式为\\[r=\\cfrac {\\overline{xy}-\\overline{x}\\overline{y}}{\\sqrt{(\\overline{x}^2-\\overline{x^2})(\\overline{y}^2-\\overline{y^2})}}\\] 相关系数\\(r\\)的取值范围为\\(-1&lt;r&lt;+1\\)。当\\(r&gt;0\\)时，回归直线的斜率为正，称为正相关。当\\(r&lt;0\\)时，回归直线的斜率为负，称为负相关。且\\(|r|\\)越接近1，说明数据点越靠近拟合曲线，即设定的回归方程越合理。 实验报告思考题 3.1示波器的使用 思考题： 1.如果波形不稳，总是向左或向右移动，该如何调节？ 答：检查触发源是否正确，如正确，调节触发电平，当Trig'D灯亮，波形稳定。 2.示波器“电平\"旋钮的作用是什么？什么时候需要调节它？观察李萨如图时，能否用它把图形稳定下来？ 答：点评是使观测喜好在屏幕上稳定显示的电位器；波形在屏幕上左右滚动时，调节此电平，波形可稳定；观测李萨如图时不起作用。 3.如果打开示波器后，只看到一个或两个移动的点而没有扫描线，是什么原因？应如何调整？如果看到的是一个或两个固定不动的点呢？ 答：扫描速度较低，将扫描时间因数往快调；处于X-Y状态，调到扫描A状态即可。 3.2空气中的声速测定 思考题： 1.调整信号的频率和移动接受换能器的位置（振幅法）都是为了使接受换能器的输出达到极大，并且都被称为共振，它们是一回事吗？ 答：不是。调整频率达到共振是指探头的谐振频率，使探头有最大输出功率。移动接收换能器的位置达到共振是使超声波在两探头间形成驻波。 2.行波比较测量声速实验中，将发送换能器的信号输入到CH1通道，接受换能器的信号输入到CH2通道，此时，示波器的触发源应如何选择？ 答：选择CH1通道，因为发生换能器的信号更强，更稳定。 3.在振幅法中，示波器上看不到接受换能器的输出波形，但连线无误，仪器和导线（电缆）无故障，以下三种分析是否合理？如原因属实，应当如何处理？ （1）信号源的频率偏离换能器共振频率太远； （2）激励发生器的信号幅度太小； （3）VOLTS/DIV选择不当。 答： （1）合理。调整信号源频率，使换能器工作在谐振频率上。 （2）合理。增加信号源的输出电压。 （3）合理。可能电压分度值过高，改变接收换能器信号输出端的VOLTS/DIV，放大接收信号。 4.振幅法中，如果极大值振幅超过荧光屏显示范围，有人认为以下三种调节方法可使信号不超出范围，你认为可行吗？ （1）改变示波器VOLTS/DIV旋钮的档位； （2）调节信号发生器的输出幅度； （3）调节信号发生器的频率； 答：（1）、（2）可行，仍能保证实验数据的准确性。（3）不行，频率变化，幅度仍不变。 5.实验中，能否固定发射器与接收器之间的距离，利用改变频率测声速？ 答：不行，\\(v=f\\lambda\\),无法测出波长。 6.利用目前的仪器设备可以实现对移动距离的测量吗？ 答：可以 3.3惠斯通电桥测量中值电阻 思考题： 1.使用交换法测未知电阻时\\(R_1,R_2\\)的阻值在交换前后是否可以改变？为什么？例如交换前\\(R_1=R_2=100.0 \\Omega\\),交换后\\(R_1&#39;=R_2&#39;=500.0\\Omega\\)。 答：不可以改变。因为改变没有意义。由数据处理可知，交换法的优势在于：消除\\(R_1,R_2\\)对测量\\(R_x\\)的影响，使之只与\\(R_s、R_s&#39;\\)有关，以下证明： \\[R_x=\\frac{R_1}{R_2}R_s，R_x=\\frac{R_2}{R_1}R_s&#39; \\\\\\\\ \\Rightarrow R_x=\\sqrt{\\cfrac{R_1}{R_2} \\cdot \\cfrac{R_2}{R_1} \\cdot R_s \\cdot R_s&#39;}\\]. 如果改变\\(R_1,R_2\\)，生成\\(R_1&#39;,R_2&#39;\\),在计算\\(u(x)\\)时会加入新的元素，增大误差；即使保证\\(\\cfrac{R_1&#39;}{R_2&#39;}=\\cfrac{R_1}{R_2}\\)，既增大了复杂度，在交换过程中也可能出错。 2.\\(AC5/3\\)检流计的“电计”和“短路”键的作用是什么？调零键下方的锁扣在什么位置才可以进行调零和测量（说明是露出红点还是白点），使用后应置于什么位置（是露出红点还是白点）？ 答：“电计”键：按下后检流计接通，相当于检流计的开关。 “短路”键：可以将检流计的两端短路，增大电磁阻尼作用，使指针停止摆动。 露出红点时可以调零和测量，使用后露出白点。 3.说明测量电路中滑线变阻器的作用 答：实验中，电键闭合前将滑线变阻器调至最大，方便检流计调节平衡，待基本调节平衡，再逐渐将其阻值调零，使电路中电流增大，提高精确度。 4.下列因素是否会加大测量误差 （1）电源电压大幅下降 （2）电源电压稍有波动 （3）检流计零点没有调准 （4）检流计灵敏度不够高 答：（1）会。电源电动势越低，电桥灵敏度越低，误差越大。 （2）不会。稍有波动的电源电压对电桥灵敏度的影响可忽略。 （3）会。电桥没有到达平衡状态，测量读数会有较大误差 （4）会，因为电桥灵敏度与检流计灵敏度成正比，检流计灵敏度不高，电桥灵敏度也不高，误差较大。 5.用给出的仪器自组单臂电桥，并用其测量表头（微安表）内阻。要求： （1）画出线路图； （2）写出设计思想及表头内阻的计算公式。 仪器：0.1级电阻箱一个：电阻箱有四个接线柱分别标有：\\(0.9\\Omega\\),\\(9.9\\Omega\\),\\(99999.9\\Omega\\).滑线变阻器一个：\\(500\\Omega\\),允许\\(2A\\)电流。微安表一个：\\(100\\mu A\\)，1.5级，内阻约为\\(1000\\Omega\\)。电源：3V干电池。开关导线若干。 答：（1） ewb 无视滑线变阻器和电源上的参数吧，这是用ewb画的，不要介意。 （2）利用电阻箱结构，将电阻箱拆成3个桥臂电阻，设为\\(R_1,R_2,R_3\\)，微安表内阻为\\(r\\),使\\(R_1:R_2=1：10\\),再调整\\(R_3\\)使电桥平衡，则\\(r=\\frac{R_1}{R_2}R_3\\)。k开关变化时，\\(\\mu A\\)示数不变，则平衡。 3.4开尔文电桥测量低值电阻 思考题： 1.写出金、银、铜、铁等常见金属的电阻率，试判断我们测量的材料可能是哪一种？ 答：\\(\\rho_金=0.024\\mu \\Omega\\cdot m\\);\\(\\rho_银=0.0175\\mu \\Omega\\cdot m\\);\\(\\rho_铜=0.016\\mu \\Omega\\cdot m\\);\\(\\rho_铁=0.0978\\mu\\Omega\\cdot m\\); 所以可能是铁棒。 2.比较单臂电桥与双臂电桥有何不同，至少给出三处 答：（1）单臂电桥是两端钮接法；双臂电桥是四端钮接法； （2）单臂电桥测量中值电阻；双臂电桥测量低值电阻； （3）双臂电桥比单臂电桥多一组桥壁。 3.用双臂电桥测量\\(1\\Omega\\)以下电阻时，如被测电阻\\(R_x\\)的两电压端引线电阻较大，对测量结果有无影响？若电流端引线电阻较大，对测量结果有无影响？ 答：电压端引线电阻较大对测量结果有影响，电流端引线电阻较大无影响。 3.5霍尔元件测磁场 思考题： 1. 为什么霍尔元件要选用半导体材料制作？ 答：霍尔效应是磁敏效应。霍尔系数的大小也决定霍尔效应的明显程度，已知霍尔系数\\(K_H=\\cfrac1{nqd}\\)，若载流子密度\\(n\\)较大时，霍尔系数\\(K_H\\)较小，则发生霍尔效应不明显。由于金属材料的载流子密度较大，而半导体的载流子密度比金属要小得多，为了让霍尔效应更明显，故选择半导体材料制作霍尔元件。 2.为什么霍尔元件通常做成薄片状？ 答：霍尔系数\\(K_H=\\cfrac1{nqd}\\)，当霍尔元件的厚度\\(d\\)越小，则霍尔系数\\(K_H=\\cfrac1{nqd}\\)越大。霍尔系数越大，霍尔效应越明显。故霍尔元件通常做成薄片状。 3. 如何判断实验中所用的霍尔元件是N型还是P型半导体材料？ 答：实验中的霍尔元件是\\(N\\)型半导体材料制作的。在半导体材料中，\\(N\\)型半导体材料的载流子迁移率比\\(P\\)型半导体材料答。判断实验中所用的霍尔元件是\\(N\\)型还是\\(P\\)型半导体材料关键看载流子的迁移率。（有更好的，希望能说一下） 4.霍尔元件的摆放方向和位置对霍尔效应测磁场的结果会有何影响？ 答：霍尔效应测磁场只能测出垂直于电流方向的磁场。 所以，必须保证电流方向与磁场方向垂直，不然测出的磁场只是垂直于电流方向的分量，测量值偏小。 3.6集成霍尔传感器与简谐振动 思考题： 1.测量弹簧的变化量时，如何从加有反射镜的游标尺上正确读数？ 答：调整底脚螺钉使实验装置铅直，调节砝码盘指针靠近游标卡尺的反射镜，读数时使反射镜上的刻线和砝码盘指针及其像重合，加减砝码应该保持砝码盘水平。 2.为使周期的测量更准确，测量时应注意什么？ 答： (1)测弹簧振子振动50次所用的时间，不再是10次。 (2)拉的时候一定要竖直向下，以保证弹簧振子只在竖直方向震动。 (3)调节霍尔片与磁钢之间的距离，尽量减小振动系统的震动幅度。 (4)保证振动过程中小灯泡交替亮、灭。 3.集成霍尔传感器有哪两种类型？其输出特点有什么不同？ 答：集成霍尔传感器按输出特点分为开关型输出和线性输出。 开关型输出其输出信号只有两种状态， 高电平或低电平。 线性输出指其输出信号的电压值随着磁场极性以及强度的变化而变化。 3.12液压拉伸法测量弹性模量 思考题： 1.如果实验中钢丝直径加倍，而其他条件不变，弹性模量将变为原来的几倍？ 答：直径加倍，弹性模量不变，因为弹性模量只与材料本身属性有关。 2.测量时，光杠杆的后脚应放在什么位置？ 答：测量时，光杠杆的后脚应置于与钢丝固定的圆形托盘上。 3.为什么实验中对不同的物理量采用不同的长度测量仪器来进行测量？ 答:不同的物理量大小范围不同，精度也不同，故物理量应寻找合适的测量仪器进行测量 4.能否用光杠杆法测量一块薄金属片的厚度？试作图说明。 答：如图所示，OA为平面镜，OB在平面上，OA与OB相固定，可绕O在竖直方向转动，\\(OB=S\\)，M点处有一光源，经平面镜反射到P点，\\(ON=L\\),在B下方未知金属片，其未知厚度d. 得如图关系。 \\(L、X、S\\)已知，则\\(tan2\\alpha=\\frac XL\\)，\\(2\\alpha \\to 0\\) \\(\\alpha = \\frac X{2L}\\),so\\(d=S tan\\alpha=s\\alpha=\\cfrac{XS}{2L}\\). 3.15分光计的调整和使用 思考题： 1.调节望远镜光轴与分光计的中心轴相垂直，应该调节哪些螺钉？如何判断望远镜光轴与分光计的中心轴已经垂直？ 答：用望远镜通倾角调平螺钉和载物台调平螺钉进行调节。 若望远镜光轴与分光计中心轴垂直，光学平行平板或三棱镜两个光学面反射的亮十字像，都能与望远镜分划板叉丝刻线上焦点重合。 2.调整平行光管能够发出平行光，应调节哪些螺钉？如何判断平行光管已经发出平行光？ 答：松开夹缝套筒锁紧螺钉，前后移动狭缝筒，能看到清晰地狭缝像。 3.调节载物台法线方向与分光计中心轴平行时，三棱镜为什么要按照下图在载物台上摆放？说明理由。 答：因为需要达到调整一个光学面的法线方向时，尽量不对另一个光学面的倾斜度产生影响。调节螺钉Z，改变光学面AB的法线方向，对光学面AC的法线方向无影响。调节螺钉X可改变光学面AC的法线方向而不会对光学面AB的倾斜度产生影响。 4.调节望远镜光轴与分光计的中心轴相垂直时，如果只在一个光学面观察到十字像，如何调节？ 答：当望远镜光轴和载物台都倾斜，但望远镜的光轴垂直或大致垂直于光学平行平板的镜面时，从望远镜中可观察到反射的十字像。将光学平行平板随载物台转过\\(180^\\circ\\)后，望远镜的光轴与光学平行平板不再有垂直或大致垂直的关系，反射的十字像则可能无法进入望远镜。因此，只能观察到一个光学平面反射的十字像。（粗调） 根据望远镜、光轴和载物台的倾斜方向，可分别判断反射的为进入望远镜的十字像，是在望远镜筒外的上方还是下方。由此，可决定进一步的调节方向，或者重新进行粗调。 5.为什么分光计采用双游标度数？两个度数之间有什么关系？ 答：为消除度盘与分光计中心轴轴之间的偏心差，两个游标相差约\\(180^\\circ\\). 6.三棱镜的分光原理是什么？ 答：根据入射光的不同波长，三棱镜的折射率不同，不同波长的出射光线的偏向角不同，因而形成色散光谱，达成分光。 4.9用非线性电路研究混沌现象 思考题： 1.如何理解“混沌是确定系统中的随机性行为”？ 答：混沌现象是指发生在确定性系统中的貌似随机的不规则运动，一个确定性理论描述的系统，其行为却表现为不确定性，即不可重复、不可预测性。 2.产生混沌的条件是什么？产生混沌现象有几种途径？ 答：产生混沌的必要条件是系统具有非线性因素，充分条件是描述系统的状态方程若是非自治的，则为二阶的；若自治，则至少需要3个以上变量。 产生途径：(1)倍周期分叉进入混沌 (2)阵发性途径 (3)准周期途径 3.通过本实验尝试阐述倍周期分叉、混沌、奇怪吸引子等概念的物理意义。 答：倍周期分叉：倍周期分叉是一个映射的稳定的周期，随着参数增大而加分叉的现象，是从周期窗口进入混沌的一种“方式”（老师划了条线，不知道什么意思） 混沌：确定的宏观的非线性系统在一定条件下所呈现的不确定的或不可预测的随机现象。 奇怪吸引子：把相空间中一定体积的点都取为初值时，这个区域的形状在演化过程中虽然改变可使体积不变。耗散的系统不同，相体积在演化过程中不断收缩，最终趋向于名为“吸引子”的某一局域空间内。 4.混沌现象的特征 答：(1)初值敏感性、长时间不可预测性：对具有内在随机性的混沌系统而言，从两个非常接近的初值出发的两个轨线在经过长时间演化之后，可能相距极远。一个细微的变化，可能系统的运动轨迹就会有大的变化，表现出其对初值的极度敏感、长时间不可预测性。 (2)内在随机性：从非线性系统变化的图像观察他们在混沌区的行为表现出随机不确定性。然而这种不确定性不是来源于外部环境的随机因素对系统运动的影响，二是由系统自发产生的。 (3)非规则的有序：混沌不是纯粹的无序，而是另一种类型的有序运动，混沌区的系统行为往往体现在无穷嵌套自相似（分形），这种不同层次上的结构相似性是标度变换下的不变形，体现出混沌运动的规律。 以上是个人的答案 原本在页面源码里的彩蛋放出来了。 &lt;彩蛋：链接: http://pan.baidu.com/s/1qW29mAK 密码: ag63&gt;","categories":[{"name":"专业","slug":"pro","permalink":"https://sean10.github.io/categories/pro/"}],"tags":[{"name":"物理","slug":"物理","permalink":"https://sean10.github.io/tags/%E7%89%A9%E7%90%86/"}]},{"title":"偏序集、格","slug":"偏序集、格","date":"2015-11-28T15:44:00.000Z","updated":"2023-03-18T15:11:14.905Z","comments":true,"path":"2015/11/28/偏序集、格/","link":"","permalink":"https://sean10.github.io/2015/11/28/%E5%81%8F%E5%BA%8F%E9%9B%86%E3%80%81%E6%A0%BC/","excerpt":"","text":"####重新看一下关于格的知识 具有极值性质的偏序集元素有许多重要应用。 其中偏序集的一个元素叫做极大的，当它不小于这个偏序集的任何其他元素，即在偏序集中是极大的。 这里有个问题，什么叫做极大的？偏序集难道只有大小关系吗，不是说关系是任意的吗。难道说这个偏序集的大小关系其实就是是否满足这个偏序集所指定的关系，满足即为大，不满足即为小？这样的话又有一个问题，之前定义也说到了，满足即称为可比的，不满足即称为不可比的，那么在这里要求极大元素时，不可比的两个元素怎么说呢？ 这里所说的极大，其实就是在这个偏序集中不存在第二个元素可以使得他作为被处理的关系，即关系的受者。这样的元素称为该偏序集的极大元素。 使用Hasse图可以很容易找到极大元素和极小元素，因为他们是这个图的顶和底。 那么为什么呢？通过这个图，我们得到的是一个各关系之间的比较，所以，图底的元素是已经消除了所有多余的必定存在的环和传递线的，剩下的既然他作为底或顶，就意味着他已经是唯一的运算的主体或完全的运算的客体存在的了。 这里又出现了两个新的名词，最大元素和最小元素。这两个元素的出现有什么意义呢？这两个名词限定了一个性质，那就是这两个人最大和最小都一定是唯一的，如果在Hasse图中在最高层次和最低层次出现了两个及以上的数量的元素，那么这个偏序集就不存在最大元素和最小元素了。 这里保留一个问题，最大元素和最小元素的存在价值？ 上界和下界是完全不一样的，首先从关键性质上就已经发生了偏差。最大元素和最小元素有个性质是必定要是唯一的才行，而上界和下界就完全没有这样的性质，完全可以存在好多个，只要满足对该子集中所有的元素都满足关系，就可以称之为其上界和下界。 其次从范围上，有所区别，比如最大元素和最小元素其实在定义中并没有提到可以用到偏序集的子集当中，而这里上界和下界主要就是用在偏序集的子集中。 接下来，出现了两个关键新名词，最小上界和最大下界。 而最大下界和最小上界就是意味着，在上界和下界中进行比较，其中最小的称之为最小上界，以此类推，最大的就称之为最大下界了。 最小上界和最大下界估计接下来会有很大的作用，因为在这里书上给了他一个定义GLB(A)和LUB(A) ####好啦，接下来整章中最重要的BOSS登场了，格。 格的首先的性质就要求一个偏序集中的每对元素存在最小上界和最大下界。这里有个很重要的修饰词——每对，任意对元素的集合都必须得存在最小上界和最大下界。 以字母序排列的偏序集长得我觉得就比较像格。 这里稍微说道，格在布尔代数中起到了非常重要的性质。 这里可以让我们保留一下期盼。（待以后看到了补充） 书上分析是否是格，出现了一个没见过的判断，用到的原因是说3个元素的任意一个的在这个偏序集中的序都不大于另两个。 这里的序是不是就是所谓的链接的大小关系呢？就是说因为他们三个元素与他们以下的元素都形成了相等的3条线，故三者相等，不存在其中一个大于另两个之说，也就导致了最小上界不存在。故不为格？ 这是一个猜想，姑且保留先。 ####信息流的格模型 在许多设置中，从一个人或计算机程序到另一个人或计算机程序的信息流要受到限制，这可以通过安全权限来实现。 我们可以使用格的模型来表示不同的信息流策略。 （这句话是什么意思，不能理解，什么叫做策略，又怎么来表示） 例如，一个通用的信息流策略是用于政府或军事系统中的多级安全策略。为每组信息分配一个安全级别，并且每个安全级别用一个对（A,C）表示，其中A是权限级别，C是种类，然后允许人和计算机程序从一个被特别限制的安全类的集合中访问信息。 （感觉这里并咩有说清楚，A和C是如何形成了一个偏序集的） 在美国政府中，使用的典型的权限级别是不保密（0）、秘密（1）、机密（2）和绝密（3）。在安全级别中使用的种类是一个集合的子集，这个集合含有与一个特定行业领域相关的所有的分布。每个分部表示一个指定的对象域。 （分部和对象域又是什么？完全没有提到） 例如，如果分部的集合是{间谍，鼹鼠，双重间谍}，那么存在8种不同的分类，分部集合有8个子集，对于每个子集有一类，例如{间谍，鼹鼠} （这里应该是根据关系进行了任意的组合，但是也没有说道这两个种类之间的关系） 我们可以对安全类排序，规定 。信息允许从安全类（A1，C1}流向安全类（A2，C2）当且仅当（A1，C1）对(A2，C2)满足那个关系。例如，信息允许从安全类（机密，{间谍，鼹鼠}）流向安全类{绝密，{间谍，鼹鼠，双重间谍}}。反之，信息不允许从安全类（绝密，{间谍，鼹鼠}）流向安全类（机密，{间谍，鼹鼠，双重间谍}）或（绝密，{间谍}）； （暂时还是不理解） ####拓扑排序 假设一个项目由20个任务构成。某些人武只能在其他任务结束后完成。如何找到这些任务的顺序（感觉这个有点像路径了，比如CPM） 定义，如果只要aRb就有a与b满足那样的关系，则称一个全序 与偏序R是相容的（相容又是一个新名词）。 从一个偏序构造一个相容的全序叫做拓扑排序，我们需要使用引理。（引理看起来很重要）","categories":[{"name":"专业","slug":"pro","permalink":"https://sean10.github.io/categories/pro/"}],"tags":[{"name":"离散数学","slug":"离散数学","permalink":"https://sean10.github.io/tags/%E7%A6%BB%E6%95%A3%E6%95%B0%E5%AD%A6/"}]},{"title":"《沉默的大多数》跳出手掌心","slug":"《沉默的大多数》跳出手掌心","date":"2015-11-27T15:56:00.000Z","updated":"2023-03-18T15:11:14.855Z","comments":true,"path":"2015/11/27/《沉默的大多数》跳出手掌心/","link":"","permalink":"https://sean10.github.io/2015/11/27/%E3%80%8A%E6%B2%89%E9%BB%98%E7%9A%84%E5%A4%A7%E5%A4%9A%E6%95%B0%E3%80%8B%E8%B7%B3%E5%87%BA%E6%89%8B%E6%8E%8C%E5%BF%83/","excerpt":"","text":"近来读了C．P．斯诺的《两种文化》。这本书里谈到的事倒是不新鲜，比方说，斯诺先生把知识分子分成了科学知识分子和文学（人文）知识分子两类，而且说，有两种文化，一种是科学文化，一种是文学（人文）文化。现在的每个知识分子，他的事业必定在其中一种之中。 我要谈到的事，其实与斯诺先生的书只有一点关系，那就是，我以为，把两种文化合在一起，就是人类前途所系。这么说还不大准确，实际上，是创造了这两种文化的活动——人类的思索，才真正是人类前途之所系。尤瑟纳尔女士借阿德里安之口云，当一个人写作或计算时，就超越了性别，甚至超越了人类——当你写作和计算时，就是在思索。思索是人类的前途所系，故此，思索的人，超越了现世的人类。这句话讲得是非常之好的，只是讲得过于简单。实际上，并不是每一种写作或计算都可以超越人类。这种情况并不多见，但是非常的重要。 现在我又想起了另一件事，乍看上去离题甚远：八十年代，美国通过了一个计划，拨出几百亿美元的资金，要在最短时间之内攻克癌症。结果却不令人满意，有些人甚至说该计划贻人笑柄，因为花了那么多钱，也没找出一种特效疗法。这件事说明，有了使不尽的钱，也不见得能做出突破性的发现。实际上，人类历史上任何一种天才的发现都不是金钱直接作用的结果。金钱、权力，这在现世上是最重要的东西，是人类生活的一面，但还有另一面。说到天才的发现，我们就要谈到天才、灵感、福至心灵、灵机一动等等，决不会说它们是某些人有了钱、升了官，一高兴想出来的。我要说的就是：沉默地思索，是人类生活的另外一面。就以攻克癌症为例，科学家默默地想科学、做科学，不定哪一天就做出一个发现，彻底解决了这个问题。但是，如果要约定一个期限，则不管你给多少钱也未必能成功。对于现代科技来说，资金设备等等固然重要，但天才的思想依然是最主要的动力。一种发现或发明可以赚到很多钱，但有了钱也未必能造出所要的发明。思索是一道大门，通向现世上没有的东西，通到现在人类想不到的地方。以科学为例，这个道理就是明明白白的。 科学知识分子很容易把自己的工作看作超越人类的事业，但人文知识分子就很难想到这一点。就以文学艺术为例，我们这里要求它面向社会、面向生活，甚至要求它对现世的人有益，弘扬民族文化等等，这样就越说越小了。诚然，文学艺术等等，要为现世的人所欣赏，但也不仅限于此。莎士比亚的戏现在还在演，将来也要演。你从莎翁在世时的英国的角度出发，绝想象不到会有这样的事。自然科学的成果，有一些现在的人类已经用上了，但据我所知，没用上的还很多。倘若你把没用上的通通取消，科学就不成其为科学。我上大学时，有一次我的数学教授在课堂上讲到：我现在所教的数学，你们也许一生都用不到，但我还要教，因为这些知识是好的，应该让你们知道。这位老师的胸襟之高远，使我终生佩服。我还要说，像这样的胸襟，在中国人文知识分子中间很少见到。 倘若我说，科学知识分子比人文知识分子人品高尚，肯定是不对的。科学知识分子里也有卑鄙之徒，比方说，前苏联的李森科。但我未听到谁对他的学说说过什么太难听的话，更没有听到谁做过这样细致的分析：李森科学说中某个谬误，和他的卑鄙内心的某一块是紧密相连的。倘若李森科不值得尊敬，李森科所从事的事业——生物学——依旧值得尊重。在科学上，有错误的学说，没有卑鄙的学说；就是李森科这样卑鄙的人为生物学所做的工作也不能说是卑鄙的行径。这样的道德标准显然不能适用于现在中国的艺术论坛，不信你就看看别人是怎样评论贾平凹先生的《废都》的。很显然，现在在中国，文学不是一种超越现世、超越人类的事业。我们评论它的标准，和三姑六婆评价身边发生的琐事的标准，没有什么不同。贾先生写了一部《废都》，就如某位大嫂穿了旗袍出门，我们不但要说衣服不好看，还要想想她的动机是什么，是不是想要勾引谁。另外哪位先生或女士写了什么好书，称赞他的话必是功在世道人心，就如称赞哪位女士相夫教子、孝敬公婆是一样的。当然，假如我说现在中国对文艺只有这样一种标准，那就是恶毒的诽谤。杜拉斯的《情人》问世不久，一下就出了四种译本（包括台湾的译本），电影《辛德勒的名单》国内尚未见到，好评就不绝于耳。我们说，这些将是传世之作，那就不是用现世的标准、道德的标准来评判的。这种标准从来不用之于中国人。由此得到一个结论，那就是在文学艺术的领域，外国人可以做超越人类的事业，中国人却不能。 在文学艺术及其他人文的领域之内，国人的确是在使用一种双重标准，那就是对外国人的作品，用艺术或科学的标准来审评；而对中国人的作品，则用道德的标准来审评。这种想法的背后，是把外国人当成另外一个物种，这样对他们的成就就能客观地评价；对本国人则当作同种，只有主观的评价，因此我们的文化事业最主要的内容不是它的成就，而是它的界限；此种界限为大家所认同，谁敢越界就要被群起而攻之。当年孟子如此来评价杨朱和墨子：“无君无父，是禽兽也。”现在我们则如此地评价《废都》和一些在国外获奖的电影。这些作品好不好可以另论，总不能说人家的工作是“禽兽行”，或者是“崇洋媚外”。身为一个中国人，最大的痛苦是忍受别人“推己及人”的次数，比世界上任何地方的人都要多。我要说的不是自己不喜欢做中国人（这是我最喜欢的事），我要说的是，这对文化事业的发展很是不利。 我认为，当我们认真地评价艺术时，所用的标准和科学上的标准有共通之处，那就是不依据现世的利害得失，只论其对不对（科学）、美不美（艺术）。此种标准我称为智慧的标准。假设有一种人类之外的智能生物，我们当然期望它们除了理解人类在科学上的成就之外，还能理解人类在艺术上的成就，故此，智慧就超越了人类。有些人会以为人类之外的东西能欣赏人类的艺术是不可能的，那么我敢和你打赌，此种生物在读到尤瑟纳尔女士的书时，读到某一句必会击节赞赏，对人类拥有的胸襟给予肯定；至于它能不能欣赏《红楼梦》，我倒不敢赌。但我敢断言，这种标准是存在的。从这种标准来看，人类侥幸拥有了智慧，就该善用它，成就种种事业，其中就包括了文学艺术在内。用这样的标准来度量，小说家力图写出一本前所未有的书，正如科学家力图做出发现，是值得赞美的事。当然，还有别的标准，那就是念念不忘自己是个人，家住某某胡同某某号，周围有三姑六婆，应该循规蹈矩地过一生，倘有余力，就该发大财，当大官，让别人说你好。这后一种标准是个人幸福之所系，自然不可忘记，但作为一个现代知识分子，前一种标准也该记住一些。 一个知识分子在面对文化遗产时，必定会觉得它浩浩洋洋，仰之弥高。这些东西是数千年来人类智慧的积累，当然是值得尊重的。不过，我以为它的来源更值得尊重，那就是活着的人们所拥有的智慧。这种东西就如一汪活水，所有的文化遗产都是它的沉积物。这些活水之中的一小份可以存在于你我的脑子里，照我看来，这是世界上最美好的事情。保存在文化遗产里的智慧让人尊敬，而活人头脑里的智慧更让人抱有无限的期望。我喜欢看到人们取得各种成就，尤其是喜欢看到现在的中国人取得任何一种成就。智慧永远指向虚无之境，从虚无中生出知识和美；而不是死死盯住现时、现事和现在的人。我认为，把智慧的范围限定在某个小圈子里，换言之，限定在一时、一地、一些人、一种文化传统这样一种界限之内是不对的；因为假如智慧是为了产生、生产或发现现在没有的东西，那么前述的界限就不应当存在。不幸的是，中国最重大的文化遗产，正是这样一种界限，就像如来佛的手掌一样，谁也跳不出来；而现代的主流文化却诞生在西方。 在中国做知识分子，有一种传统的模式，可能是孔孟，也可能是程朱传下来的，那就是自己先去做个循规蹈矩的人，做出了模样，做出了乐趣，再去管别人。我小的时候，从小学到中学，班上都有这样的好同学，背着手听讲，当上了小班长，再去管别人。现在也是这样，先是好好地求学，当了知名理论家、批评家，再去匡正世道人心。当然，这是做人的诀窍。做个知识分子，似乎稍嫌不够；除了把世道和人心匡得正正的，还该干点别的。由这样的模式，自然会产生一种学堂式的气氛，先是求学，受教，攒到了一定程度，就来教别人，管别人。如此一种学堂开办数千年来，总是同一些知识在其中循环，并未产生一种面向未来、超越人类的文化——谁要骂我是民族虚无主义，就骂好了，反正我从小就不是好同学——只产生了一个极沉重的传统，无数的聪明才智被白白消磨掉。倘若说到世道人心，我承认没有比中国文化更好的传统——所以我们这里就永远只有世道人心，有不了别的。 总之，说到知识分子的职责，我认为还有一种传统可循：那就是面向未来，取得成就。古往今来的一切大智者无不是这样做的。这两种知识分子的形象可以这样分界，前一种一世的修为，是要做个如来佛，让别人永世跳不出他的手掌心；后一种是想在一生一世之中，只要能跳出别人的手掌心就满意了。我想说的就是，希望大家都做后一种知识分子，因为不管是谁的手掌心，都太小了。 我们可能算得上是未来的知识分子，现在至少我自认认识的还远远不够多。我们的最大的价值确实是在于思考，现在我在努力养成的习惯正是无时无刻的思考。 在博客园里的大部分人想必都是已经达到了一定的水平的程序员（我是少部分还在学习中的层次），我们其实也算得上是科学方面的知识分子，我们都是科技的受利者，在使用当下的科技谋生。在互联网产业中，如同乔布斯的创业者其实也可以算得上是在试图引发时代的变革、进化吧，工作确实算得上是超越人类的事业。而人文，对于理工科的我们，感受到的恐怕最为明显的只有精神的放松的作用了罢，于没有闲情逸致消遣人文的人，对于人文的超越性确实会很难理解了。 对于人文的理解，我看的书还不够深，我也不太理解，这点期待其他人的想法。 对于知识分子智慧的标准，我们虽然追求第一个标准，不想遵循粗鄙的第二个标准。然而第二个标准却是生活必然，超然于第二个标准实在需要一定的物质、精神高度才可。 于程序员的世界，求学是永久的，我们始终面向未来，在不断的跳出其他人的手掌心，可能也会让其他人进入自己的手掌心，我们不正进入了Linus等人的手掌吗？如来佛也只是佛之一种，在我们的世界，并不存在万佛之祖，即便是Linus也是在其他人手中学习着的。 话虽如此，环境虽然面向未来，我们依旧要时刻保持虚心的态度学习，否则恐怕就会成为悟空，只不过是被自己的五指山镇压。","categories":[{"name":"随想","slug":"thinking","permalink":"https://sean10.github.io/categories/thinking/"}],"tags":[{"name":"书评","slug":"书评","permalink":"https://sean10.github.io/tags/%E4%B9%A6%E8%AF%84/"},{"name":"王小波","slug":"王小波","permalink":"https://sean10.github.io/tags/%E7%8E%8B%E5%B0%8F%E6%B3%A2/"},{"name":"思考","slug":"思考","permalink":"https://sean10.github.io/tags/%E6%80%9D%E8%80%83/"}]},{"title":"《沉默的大多数》序言","slug":"《沉默的大多数》序言","date":"2015-11-26T10:09:00.000Z","updated":"2023-03-18T15:11:14.814Z","comments":true,"path":"2015/11/26/《沉默的大多数》序言/","link":"","permalink":"https://sean10.github.io/2015/11/26/%E3%80%8A%E6%B2%89%E9%BB%98%E7%9A%84%E5%A4%A7%E5%A4%9A%E6%95%B0%E3%80%8B%E5%BA%8F%E8%A8%80/","excerpt":"","text":"年轻时读萧伯纳的剧本《芭芭拉少校》，有场戏给我留下了深刻的印象：工业巨头安德谢夫老爷子见到了多年不见的儿子斯泰芬，问他对做什么有兴趣。这个年轻人在科学、文艺、法律等一切方面一无所长，但他说自己有一项长处：会明辨是非。老爷子把自己的儿子暴损了一通，说这件事难倒了一切科学家、政治家、哲学家，怎么你什么都不会，就会一个明辨是非？我看到这段文章时只有二十来岁，登时痛下决心，说这辈子我干什么都可以，就是不能做一个一无所能，就能明辨是非的人。因为这个原故，我成了沉默的大多数的一员。我年轻时所见的人，只掌握了一些粗浅（且不说是荒谬）的原则，就以为无所不知，对世界妄加判断，结果整个世界都深受其害。直到我年登不惑，才明白萧翁的见解原有偏颇之处；但这是后话——无论如何，萧翁的这些议论，对那些浅薄之辈、狂妄之辈，总是一种解毒剂。 萧翁说明辨是非难，是因为这些是非都在伦理的领域之内。俗话说得好，此人之肉，彼人之毒；一件对此人有利的事，难免会伤害另一个人。真正的君子知道，自己的见解受所处环境左右，未必是公平的；所以他觉得明辨是非是难的。倘若某人以为自己是社会的精英，以为自己的见解一定对，虽然有狂妄之嫌，但他会觉得明辨是非很容易。明了萧翁这重意思以后，我很以做明辨是非的专家为耻——但这已经是二十年前的事了。当时我是年轻人，觉得能洁身自好，不去害别人就可以了。现在我是中年人——一个社会里，中年人要负很重的责任：要对社会负责，要对年轻人负责，不能只顾自己。因为这个原故，我开始写杂文。现在奉献给读者的这本杂文集，篇篇都在明辨是非，而且都在打我自己的嘴。 伦理问题虽难，但却不是不能讨论。罗素先生云，真正的伦理原则把人人同等看待。考虑伦理问题时，想替每个人都想一遍是不可能的事，但你可以说，这是我的一得之见，然后说出自己的意见，把是非交付公论。讨论伦理问题时也可以保持良心的清白——这是我最近的体会；但不是我打破沉默的动机。假设有一个领域，谦虚的人、明理的人以为它太困难、太暧昧，不肯说话，那么开口说话的就必然是浅薄之徒、狂妄之辈。这导致一种负筛选：越是傻子越敢叫唤——马上我就要说到，这些傻子也不见得是真的傻，但喊出来的都是傻话。久而久之，对中国人的名声也有很大的损害。前些时见到个外国人，他说：听说你们中国人都在说“不”？这简直是把我们都当傻子看待。我很不客气地答道：物以类聚，人以群分。你认识的中国人都说“不”，但我不认识这样的人。这倒不是唬外国人，我认识很多明理的人，但他们都在沉默中，因为他们都珍视自己的清白。但我以为，伦理问题太过重要，已经不容我顾及自身的清白。 伦理（尤其是社会伦理）问题的重要，在于它是大家的事——大家的意思就是包括我在内。我在这个领域里有话要说，首先就是：我要反对愚蠢。一个只会明辨是非的人总是凭胸中的浩然正气做出一个判断，然后加上一句：难道这不是不言而喻的吗？任何受过一点科学训练的人都知道，这世界上简直找不到什么不言而喻的事，所以这就叫做愚蠢。在我们这个国家里，傻有时能成为一种威慑。假如乡下一位农妇养了五个傻儿子，既不会讲理，又不懂王法，就会和人打架，这家人就能得点便宜。聪明人也能看到这种便宜，而且装傻谁不会呢——所以装傻就成为一种风气。我也可以写装傻的文章，不只是可以，我是写过的——“文革”里谁没写过批判稿呢。但装傻是要不得的，装开了头就不好收拾，只好装到底，最后弄假成真。我知道一个例子是这样的：某人“文革”里装傻写批判稿，原本是想搞点小好处，谁知一不小心上了《人民日报》头版头条，成了风云人物。到了这一步，我也不知他是真傻假傻了。再以后就被人整成了“三种人”。到了这个地步，就只好装下去了，真傻犯错误处理还能轻些呀。 我反对愚蠢，不是反对天生就笨的人，这种人只是极少数，而且这种人还盼着变聪明。在这个世界上，大多数愚蠢里都含有假装和弄假成真的成分；但这一点并不是我的发现，是萧伯纳告诉我的。在他的《匹克梅梁》里，息金斯教授遇上了一个假痴不癫的杜特立尔先生。息教授问：你是恶棍还是傻瓜？这就是问：你假傻真傻？杜先生答：两样都有点，先生，凡人两样都得有点呀。在我身上，后者的成分多，前者的成分少；而且我讨厌装傻，渴望变聪明。所以我才会写这本书。 在社会伦理的领域里我还想反对无趣，也就是说，要反对庄严肃穆的假正经。据我的考察，在一个宽松的社会里，人们可以收获到优雅，收获到精雕细琢的浪漫；在一个呆板的社会里，人们可以收获到幽默——起码是黑色的幽默。就是在我呆的这个社会里，什么都收获不到，这可是件让人吃惊的事情。看过但丁《神曲》的人就会知道，对人来说，刀山剑树火海油锅都不算严酷，最严酷的是寒冰地狱，把人冻在那里一动都不能动。假如一个社会的宗旨就是反对有趣，那它比寒冰地狱又有不如。在这个领域里发议论的人总是在说：这个不宜提倡，那个不宜提倡。仿佛人活着就是为了被提倡。要真是这样，就不如不活。罗素先生说，参差多态乃是幸福的本源——弟兄姐妹们，让我们睁开眼睛往周围看看，所谓的参差多态，它在哪里呢。 在萧翁的《芭芭拉少校》中，安德谢夫家族的每一代都要留下一句至理名言。那些话都编得很有意思，其中有一句是：人人有权争胜负，无人有权论是非。这话也很有意思，但它是句玩笑。实际上，人只要争得了论是非的权力，他已经不战而胜了。我对自己的要求很低：我活在世上，无非想要明白些道理，遇见些有趣的事。倘能如我所愿，我的一生就算成功。为此也要去论是非，否则道理不给你明白，有趣的事也不让你遇到。我开始得太晚了，很可能做不成什么，但我总得申明我的态度，所以就有了这本书——为我自己，也代表沉默的大多数。 王小波 1997年3月20日 明辨是非确实不值得自称，正如作者所说，是非与社会伦理相关，受环境影响，辨出的是非是与视野确切相关的。 当下的我们大部分人还年轻，阅历并不能算是很丰富，可能看了不少书、电影、段子，即便这些都是建立在真实之上的，那也只是真实的局部，我们认识的与亲身经历的往往相差甚远。往往通过网络看到一些时事时，看到结果与自己的判断差不多，自以为自己辨别的不错。其实都是假象，其中一个原因，就是人总会自觉的美化自己。就像看答案做作业，你总会觉得这些题好简单，很容易就写出来；而实际脱离答案时，建立的思路却远不上道。辨别是非并不是像我们当下想象的那么简单地能力，正如作者所言，年轻时还是少言是非多做自己的事为好。 必须着重强调一下的是，少言是非。少言并不是对一切保持沉默，即便是自己该发言的时候。少言仅仅只是指不要对不关自己的事情，不切身的事情，妄下评论。对于与自己相关之事，单纯发表真实的想法并不为过。 而在相关、且并非时下不正常的时候，不发表自己的真实想法，以装傻糊弄他人占些便宜，这就是在损伤自己的良心了。仅从我们个人自身来谈，对于并非聪明绝顶的、我们这样的普通人来说，装傻装着装着习惯了，贪小便宜习惯了，那可就真的习惯了装傻的思维方式了。至少于我，装傻是不可行的，否则我必定会习惯局限性的思考，忘记了探索思维的深度。而且吧，如果是真傻，那还只是自己的思维的广度不足，对某些事真的不懂，学着学着就不傻了。假傻，那可就没辙了，时间会让你习惯成真傻的。 对无趣这段，所幸当下的我们的社会其实还是不错的了，至少对于网上的我们，还是能做些越矩的事的。 有态度，慢慢做，做到哪收获到哪，对我来说，当下也足够了。","categories":[{"name":"随想","slug":"thinking","permalink":"https://sean10.github.io/categories/thinking/"}],"tags":[{"name":"书评","slug":"书评","permalink":"https://sean10.github.io/tags/%E4%B9%A6%E8%AF%84/"},{"name":"王小波","slug":"王小波","permalink":"https://sean10.github.io/tags/%E7%8E%8B%E5%B0%8F%E6%B3%A2/"}]},{"title":"关于Warshall、Roy对寻找传递闭包方法的不同表达的探讨","slug":"关于Warshall、Roy对寻找传递闭包方法的不同表达的探讨","date":"2015-11-17T11:23:00.000Z","updated":"2023-03-18T15:11:14.889Z","comments":true,"path":"2015/11/17/关于Warshall、Roy对寻找传递闭包方法的不同表达的探讨/","link":"","permalink":"https://sean10.github.io/2015/11/17/%E5%85%B3%E4%BA%8EWarshall%E3%80%81Roy%E5%AF%B9%E5%AF%BB%E6%89%BE%E4%BC%A0%E9%80%92%E9%97%AD%E5%8C%85%E6%96%B9%E6%B3%95%E7%9A%84%E4%B8%8D%E5%90%8C%E8%A1%A8%E8%BE%BE%E7%9A%84%E6%8E%A2%E8%AE%A8/","excerpt":"","text":"一、引言 在计算机科学中，Floyd-Warshell-Roy算法是用于在有向图或负权图中寻找最短路径的一种算法。运行一次能够找到所有两个顶点间的最短路径，不过并不输出所有路径。该算法同时也可以被用于寻找关系R的传递闭包。 Floyd-Warshell算法是一个动态规划的例子，在1962年为Robert Floyd发表。然而，在1959年，相同的算法已经被Bernard Roy发表。同年，Stephen Warshell发表了找到传递闭包的这个算法。三人被认定为独立发现这个算法。 该算法的主要作用是将常规算法的时间复杂度由Θ(n4)降低到了Θ(n3). 本文中，我们出于寻找Roy、Warshall的算法被认定为独立发现的的缘由对两人的算法进行分析。 二、分析与讨论 1. Warshall 算法 1234567procedure Warshall (MR : n × n zero–one matrix)W : = MRfor k : = 1 to n for i : = 1 to n for j : = 1 to n w_ij : = w_ij ∨ (w_ik)∧ w_kj )return W&#123;W = [w_ij] is MR∗&#125; essay_ essay_ essay 三、结论 虽然Bernard Roy 提出该算法在Robert Floyd和Stephen Warshall之前，但他论文的主体依旧是以对图的定义为主，而Warshall 和Floyd两人同年发表了成文的简单算法。所以，可能这是一部分影响单独发表的原因。 四、展望 根据[1]，我们知道了Roy的传递闭包计算方法是采用了Kleene已经提出了的深层技术，而Warshall和Floyd则是采用了第三个参数。不过基于时间以及水平原因，并没有能够找到这两者之间所说的深层技术，也并没能确定是否Warshall和Floyd所采用的关键技术是在于中间点k。因而，可以沿这个方向继续接下去进行查询发掘。 五、参考文献 [1]. Jeff Erickson, Kleene-Roy-Floyd-Warshall. [https://courses.engr.illinois.edu/cs498dl1/sp2015/notes/22-apsp.pdf] [2]. Warshall, Stephen (January 1962). \"A theorem on Boolean matrices\". Journal of the ACM 9 (1): 11–12. doi:10.1145/321105.321107 . [3]. Roy, B. \"Transitivité et connexité.\" C. R. Acad. Sci. Paris 249, 216-218, 1959. [http://gallica.bnf.fr/ark:/12148/bpt6k3201c] [4]. Bouyssou, D., Jacquet-Lagrèze, E., Perny, P., Slowiński, R., Vanderpooten, D., Vincke, P,《Aiding Decisions with Multiple Criteria: Essays in Honor of Bernard Roy》,24,2001. [5]. Wikipedia. [https://en.wikipedia.org/wiki/Floyd%E2%80%93Warshall_algorithm] [6]. Purdom, Paul, Jr. “A Transitive Closure Algorithm.” Bit 10, no. 1 (March 1970): 76–94. doi:10.1007/BF01940892.","categories":[{"name":"专业","slug":"pro","permalink":"https://sean10.github.io/categories/pro/"}],"tags":[{"name":"离散数学","slug":"离散数学","permalink":"https://sean10.github.io/tags/%E7%A6%BB%E6%95%A3%E6%95%B0%E5%AD%A6/"}]},{"title":"离散数学——hamming码最小距离","slug":"离散数学——hamming码最小距离","date":"2015-11-14T16:12:00.000Z","updated":"2023-03-18T15:11:14.879Z","comments":true,"path":"2015/11/15/离散数学——hamming码最小距离/","link":"","permalink":"https://sean10.github.io/2015/11/15/%E7%A6%BB%E6%95%A3%E6%95%B0%E5%AD%A6%E2%80%94%E2%80%94hamming%E7%A0%81%E6%9C%80%E5%B0%8F%E8%B7%9D%E7%A6%BB/","excerpt":"","text":"1：给定H(读取文件方式，第一行两个整数m,n，第二行 m(n-m)个0或1，也就是矩阵H的上半部分，下半部单位矩阵自行生成)，计算群码编码函数e_H。计算该编码函数能检测到多少位错误，交互输出字的码字。 输入文件：in.txt，示例：第一行两个整数，第二行累计mxr个整数。所有整数都用一个空格分隔。 3 5 1 0 1 0 0 1 无输出文件。 2：针对(8,12)编码e，找出最小距离最大的群码编码函数，输出H及最小距离。 无输入文件 输出文件：out.txt，示例，矩阵按行输出 1 1 0 0 0 0 1 0 .... 0 1 0 1 (以上总共256行，此行为说明，程序不输出) H的最小距离是：3 以下是代码 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687#include &lt;stdio.h&gt;#include &lt;string.h&gt;#include &lt;stdlib.h&gt;int int_pow(int x,int e)&#123; int ans = 1; while(e--) ans*=x; return ans;&#125;void GetBinary(int* mb,int m, int i)&#123; for(int j = m;j &gt;= 1;j--)&#123; mb[j] = i%2; i/=2; &#125;&#125;void CntBinary(int *mb, int n ,int &amp;min)&#123; int cnt = 0; for(int i = 1;i &lt;= n;i++)&#123; if(mb[i] == 1) cnt++; &#125; if(cnt &lt; min) min = cnt;&#125;int main()&#123; //freopen(&quot;in.txt&quot;,&quot;r&quot;,stdin); FILE *fp = fopen(&quot;in.txt&quot;,&quot;r&quot;); if(fp == NULL) printf(&quot;ERROR OPEN.\\n&quot;); int m,n; int ma[100][100]; fscanf(fp,&quot; %d %d&quot;,&amp;m,&amp;n); for(int i = 1;i &lt;= m;i++)&#123;//行列互换 for(int j = 1;j &lt;= n-m;j++)&#123; fscanf(fp,&quot; %d&quot;,&amp;ma[i][j]); &#125; &#125; /* for(int i = 1;i &lt;= m;i++)&#123; for(int j = 1;j &lt;= n-m;j++) printf(&quot;%d&quot;,ma[i][j]); printf(&quot;\\n&quot;); &#125; */ int mb[100]; int mc[100]; int min = m; for(int i = 1;i &lt; int_pow(2,m);i++)&#123; GetBinary(mb,m,i); for(int j = m+1;j &lt;= n;j++) mc[j] = 0; for(int j = 1;j &lt;= m;j++) mc[j]=mb[j]; for(int j = m+1;j &lt;= n;j++)&#123; for(int k = 1;k &lt;= m;k++)&#123; mc[j] += mb[k]*ma[k][j-m]; &#125; mc[j] %= 2; &#125; CntBinary(mc,n,min); &#125; printf(&quot;The minimum hamming distance is:%d\\n&quot;,min); for(int i = 1;i &lt;= m;i++) scanf(&quot; %d&quot;,&amp;mb[i]); for(int i = 0;i &lt;= n;i++) mc[i] = 0; for(int i = 1;i &lt;= m;i++) mc[i]=mb[i]; for(int i = m+1;i &lt;= n;i++)&#123; for(int j = 1;j &lt;= m;j++)&#123; mc[i] += mb[j]*ma[j][i-m]; &#125; mc[i] %= 2; &#125; printf(&quot;The code word is:&quot;); for(int i = 1;i &lt;= n;i++) printf(&quot;%d&quot;,mc[i]); printf(&quot;\\n&quot;); return 0;&#125; 第二题这里，依照以下定理自己手算奇偶校验矩阵就比较简单了，最小距离最大的充要条件是奇偶校验矩阵任意两行线性无关。 定理是(n,k)线性分组码的最小Hamming距离为d的充要条件是，H矩阵中任意d-1列线性无关。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#include &lt;string.h&gt;#define N 256int int_pow(int x,int e)&#123; int ans = 1; while(e--) ans*=x; return ans;&#125;void GetBinary(int* mb,int m, int i)&#123; for(int j = m;j &gt;= 1;j--)&#123; mb[j] = i%2; i/=2; &#125;&#125;void CntBinary(int *mb, int m ,int &amp;min)&#123; int cnt = 0; for(int i = 1;i &lt;= m;i++)&#123; if(mb[i] == 1) cnt++; &#125; if(cnt &lt; min) min = cnt;&#125;int main()&#123; FILE *fp=fopen(&quot;out.txt&quot;,&quot;w&quot;); int m = 8,n = 12; int ma[N][5]=&#123;&#123;0,0,0,0,0&#125;, &#123;0,1,1,0,0&#125;, &#123;0,0,1,1,0&#125;, &#123;0,1,1,0,1&#125;, &#123;0,1,1,1,0&#125;, &#123;0,1,0,0,1&#125;, &#123;0,0,1,0,1&#125;, &#123;0,1,0,1,0&#125;, &#123;0,0,0,1,1&#125;&#125;; /* for(int i = 0;i &lt; 8;i++)&#123; for(int j = 0;j &lt; 4;j++)&#123; printf(&quot;%d&quot;,H[i][j]); &#125; printf(&quot;\\n&quot;); &#125; */ int mb[N]; int mc[N]; int min = m; for(int i = 1;i &lt; int_pow(2,m);i++)&#123; GetBinary(mb,m,i); for(int j = m+1;j &lt;= n;j++) mc[j] = 0; for(int j = 1;j &lt;= m;j++) mc[j]=mb[j]; for(int j = m+1;j &lt;= n;j++)&#123; for(int k = 1;k &lt;= m;k++)&#123; mc[j] += mb[k]*ma[k][j-m]; &#125; mc[j] %= 2; &#125; for(int j = m+1;j &lt;= n;j++) fprintf(fp,&quot;%d\\t&quot;,mc[j]); fprintf(fp,&quot;\\n&quot;); CntBinary(mc,n,min); &#125; fprintf(fp,&quot;The maximum of all the minimum distance is:%d\\n&quot;,min); return 0;&#125;","categories":[{"name":"专业","slug":"pro","permalink":"https://sean10.github.io/categories/pro/"}],"tags":[{"name":"离散数学","slug":"离散数学","permalink":"https://sean10.github.io/tags/%E7%A6%BB%E6%95%A3%E6%95%B0%E5%AD%A6/"},{"name":"校验码","slug":"校验码","permalink":"https://sean10.github.io/tags/%E6%A0%A1%E9%AA%8C%E7%A0%81/"}]},{"title":"十二年小说、游戏杂忆","slug":"十二年小说、游戏杂忆","date":"2015-11-13T16:24:00.000Z","updated":"2023-03-18T15:11:14.906Z","comments":true,"path":"2015/11/14/十二年小说、游戏杂忆/","link":"","permalink":"https://sean10.github.io/2015/11/14/%E5%8D%81%E4%BA%8C%E5%B9%B4%E5%B0%8F%E8%AF%B4%E3%80%81%E6%B8%B8%E6%88%8F%E6%9D%82%E5%BF%86/","excerpt":"","text":"##十二年小说、游戏杂忆 还留有印象的小说，应该是预备班时看的了。那时，似乎是刚尝试用电脑看小说，那个时候看的第一本书应该是心梦无痕的《七界传说》。现在脑海里还留有一个印象，那时相当懵懂的我看到里面男主和女主的交流就很害羞，快速跳过。现在想来，那个时代的我们还真是单纯。现在再看，这类的文字过眼即忘了。 虽说印象里只剩下初中看的书了，不过小学的时候去图书馆也很频繁，那个时候记得一天差不多要去图书馆3、4次，除了图书管理员的任务之外，经常去借各种各样的书。印象里还有一本翻了整整一系列，当时最后好像也没看懂的小说《头重脚轻》。 虽然当时的图书馆拥有的书量相比现在去的图书馆数百乃至数千个书架不能比，记得图书馆只有8个书架，不过对于小时候的我来说足够看很久了。印象最深的就是有一个月因为上课也在偷偷的看书，一天要去借好几次，一次3本，最终月借书量达到了红色警戒线（150左右吧）。（貌似也因为这个，学校的大队长第一次和我聊了会，印象颇深呢！） 很可惜初中虽然图书库存不少，不过对于学生的开放实在是不人性。图书室开放时间只有工作日的中午20分钟，加上初中很注重抓紧中午时间上课讲题，也就不再有机会去图书馆了。也就在那个时候，似乎网络游戏开始流行了，原本那时看书似乎就只是为了打磨时间，作为一种休闲，自然游戏在初中替代了我心目中书的地位。 印象里，在小学的时候在同学的带领下玩过一段时间的QQ幻想，不过因为点卡要收费，也没玩多久。 初中看不了纸质书以后，有空就在电脑上看小说。一次看小说时，一个游戏的广告始终停留在页首，然后就去玩了《昆仑世界》（那个时候还叫《昆仑》），似乎玩了整整一两年，最后还是被迫离开（因为注册时还没有验证邮箱、验证密保之说，最后账号密码被人修改，无法找回）。 因为游戏数年的努力都化成飞灰，无心重头再来，毕竟所在服务器大家也都是养老休闲的了。大家都是熟人了。没什么新颖的花样了。我便转投了同平台的《三国风云》，同样持续了一年多的样子。这次的离开是因为玩了好多个新区了，对于游戏模式摸得比较清楚了，对RMB的作用无力了之后离开的。 最后一个网页策略游戏，是腾讯的七雄争霸了。之前的游戏里因为可接触游戏的工作时间只有周末，经常被同期的人甩开很多，时间和RMB都不如其他人，自然毫无竞争力。在这个游戏里，因为支持手机网页登陆进行操作，我似乎一直坚持玩到了高一。最后的战绩也还算是不错的，进入了同服务器的次强的联盟。那个时候早上玩一次，晚上玩一次，投入的时间毕竟不少。 在玩网页游戏的过程中也去接触了不少腾讯的客户端游戏（因为懒，熟悉的平台的游戏最方便了），DNF。现在想来，自己的游戏经历还真是挺丰富的，可惜唯一真正投入去研究发展攻略、甚至写过游戏攻略的只有第一、第二个网页游戏了。后面就没有用过心了。 回到书，初中因为硬性条件的不支持，加上外界的吸引，就远离了书。而电子书（那时不懂有pdf扫描本，主要看的就是网络小说），接触的倒也不能算是多。 严格来说，接触最多的时间应该是高中的时候了，那个时候似乎智能手机渐渐开始普及，在移动终端上看小说的网页阅读器似乎也被完成了。我就在手机上看了各式各样的网络小说。当时起点、红袖添香等小说网站的排行榜、完本小说榜等等数十页目录喜欢的都被刷尽了。 不过，这些小说的内容都极其雷同。即便是现在的小说的内容，其实和3、4年前也完全没有什么成长。唯一的变化恐怕就是内容的细节变得更加丰满了吧，添加了越来越多的设定。比如，宿敌的猪队友呀，高智商的宿敌呀。 因为剧情比较简单，内容之间唯一的衔接也就是时间和地点了。并没有太多的伏笔。 当时看的比较多的是玄幻、奇幻、游戏之类的小说。玄幻、奇幻这两本小说的基本内容都是升级练功、扮猪吃虎、男主智商最高呀之类的。从正常的小说的角度来说，围绕着主角来描写内容，剧情主线这样发展是无可厚非的。 我看过的三少、西红柿、辰东等人的书都是这般。现在想来，这些小说并没有太多的泪点，对自己可以说是一点经验都没有收获了。 那个时候，无人引领，在庞杂的书海中肆意，丢失的时间实在是太多了。 话虽如此，现在依旧偶尔会在做自己的事的时候刷一下同人小说。 小说仿佛一股瘾，开始了便停不下来。 尤其，我还挺喜欢看动漫的，现在看动漫同人小说，好多都能满足我希望在原作中看到的剧情（顺带一提，因为我看到喜欢的动漫，剧情不全的话，基本我都会去看他的轻小说本，没有轻小说就去看看漫画本）。也有不少动漫是游戏改编的，没有时间去体验游戏，便藉由其他专业的宅的小说中体会剧情了。 基于这样的原因下，我恐怕也只能克制一下阅读的频率和时间，把重心放在学习上了。","categories":[{"name":"随想","slug":"thinking","permalink":"https://sean10.github.io/categories/thinking/"}],"tags":[{"name":"小记","slug":"小记","permalink":"https://sean10.github.io/tags/%E5%B0%8F%E8%AE%B0/"}]},{"title":"《爱的艺术》人类超越了本能","slug":"《爱的艺术》人类超越了本能","date":"2015-11-07T16:10:00.000Z","updated":"2023-03-18T15:11:14.901Z","comments":true,"path":"2015/11/08/《爱的艺术》人类超越了本能/","link":"","permalink":"https://sean10.github.io/2015/11/08/%E3%80%8A%E7%88%B1%E7%9A%84%E8%89%BA%E6%9C%AF%E3%80%8B%E4%BA%BA%E7%B1%BB%E8%B6%85%E8%B6%8A%E4%BA%86%E6%9C%AC%E8%83%BD/","excerpt":"","text":"第二章 爱情的理论 (一) 爱情是对人类生存问题的回答 爱情的每一个理论必须要以人的理论、人的生存理论为前提。我们所能看到的动物的爱情或者更确切地说动物身上类似爱情的东西，主要是动物的一部分本 能。在人身上只能看到这一本能的残余。人的存在的根本要点是人超越了动物界，超越了本能的适应性，脱离了自然-尽管人永远不可能完全脱离自然。人继续是自然的一部分，但又同自然分离，永远不可能再同自然合二为一。人从天堂里被赶出来后失去了同自然的和谐状态，带有火剑的天神就挡住了人的归路。人只能继续前进，不断发展人的理智，用一种新的，充满人性的和谐去取代永不复返的类人猿时代的和谐。 爱情的理论必须以人的理论、人的生存理论为前提，这时毋庸置疑的。唯有超越了本能的人类才能在超越了本能的范畴里讨论爱情。毕竟，假如在动物的本能的范畴内讨论爱情，那般的爱情就只是弗洛伊德所一直坚持着的性的爱。以性为根本的爱并不是本书所讨论的艺术的爱的范畴。 人的存在的根本要点是人超越了动物界，超越了本能的适应性，脱离了自然。为什么说脱离了自然呢？这句话的理解恐怕不能从常规的现实性的接触与否来理解脱离的含义，这里的脱离只是指人已经不再为自然所操控，不再完全只是听从本能而行动。这同时也解释了下一句，为什么说“尽管人永远不可能完全脱离自然。人继续是自然的一部分，但又同自然分离，永远不可能再同自然合二为一。” 人从天堂里被赶出来后失去了同自然的和谐状态。因为原本的动物性的人类遵循本能，而无需也不会考虑到寂寞、生存中的心灵的问题，以本能为心。而脱离了伊甸园无忧无虑本能状态的人类当前脱离了乌托邦，知道终究已经知道，不可能再回到无知的状态，火剑的天神就挡住了人的归路。人只有从另一个方向——全知的方向去找寻属于人类的新的和谐。 人一生下来-亦指种族和个人-就从一个确定的环境，如本能，被推到一个不确定的，完全开放的环境中去。人只了解过去，对未来-除了知道要以死亡告终外-一无所知。 人类离开已知的本能，来到了理智的世界。理智的世界便是所谓的未来，唯一的知晓仅是人终将体验到的死亡的经验。 不过这里，其实人类对于过去也并不了解。经历过的终究只有现在的一瞬间，过去了终究就是过去了，过去并不会停滞。唯一停滞于我们脑海中的只有过去的现在的那些印象。印象只是过去的部分展开。因而，人类对过去和未来一无所知。","categories":[{"name":"随想","slug":"thinking","permalink":"https://sean10.github.io/categories/thinking/"}],"tags":[{"name":"读书笔记","slug":"读书笔记","permalink":"https://sean10.github.io/tags/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/"},{"name":"爱的艺术","slug":"爱的艺术","permalink":"https://sean10.github.io/tags/%E7%88%B1%E7%9A%84%E8%89%BA%E6%9C%AF/"},{"name":"爱情","slug":"爱情","permalink":"https://sean10.github.io/tags/%E7%88%B1%E6%83%85/"}]},{"title":"读《弗洛伊德：作家与白日梦》","slug":"读《弗洛伊德：作家与白日梦》","date":"2015-11-04T10:31:00.000Z","updated":"2023-03-18T15:11:14.852Z","comments":true,"path":"2015/11/04/读《弗洛伊德：作家与白日梦》/","link":"","permalink":"https://sean10.github.io/2015/11/04/%E8%AF%BB%E3%80%8A%E5%BC%97%E6%B4%9B%E4%BC%8A%E5%BE%B7%EF%BC%9A%E4%BD%9C%E5%AE%B6%E4%B8%8E%E7%99%BD%E6%97%A5%E6%A2%A6%E3%80%8B/","excerpt":"","text":"##读《弗洛伊德：作家与白日梦》 在弗洛伊德的这篇论文中，我的理解的含义是作家的作品便是他们的幻想的一种表达，只是借小说等形式展露而不必为让其他人窥探自己的内心自我而感到害羞。在弗洛伊德看来，这种白日梦依旧是符合他对梦的解析的，这里的幻想就如同孩童时期的梦，只是通过外加刺激唤醒了孩童时期的记忆。 到文章最后，弗洛伊德将话题延伸至了对自我的分析，主体由第三者的作家转向了小说的读者——我们自己。他对于读者对小说的满足感的分析还只是处于找到方向、尚未完全深入的状态。至此，他提出了几种可能性。 作家提供给我们的所有美学快乐都具有”直观快乐“的性质，我们对一部富有想象力的作品的欣赏实际来自我们精神上紧张状态的消除。甚至有可能是，这种效果有相当一部分归因于作家能够使我们享受到自己的白日梦而又不必去自责或害羞。 以上是第一遍泛读得到的结论。 接下来我们细细地分析一下这篇论文。 我们这些门外汉总是以强烈的好奇心理去理解——恰如把类似的问题送给阿里奥斯托 [1]的那位红衣主教——与众不同的作家从哪处渊源发掘了他的素材，他又如何加工组织这些素材以至于使我们产生如此深刻的印象，在我们的心中激发起连我们自己都不曾料想的情感。 假如我们向作家讨教，他本人也难以解释，即使解释了也不会令我们满意，正因为如此，这便使我们产生更加浓厚的兴趣。即使我们都彻底了解作家是怎样选取素材的，了解创造想象形式的艺术的真谛，也不可能帮助我们把自己修炼成为作家。 即便是到了现在，作家加工组织素材的方式依旧是这般。因为各人的思想是不同的，借用弗洛伊德的名词，也就是自我是不同的。最终组织完成的作品终究不同。 用计算机术语来说，作家能够明确的说得出的只是他组织的一定的过程，至于是如何有了对素材那般这般的组织方式，即便是他自身也是不知道的。做后我们得知的仅仅只是每个模块的函数运行，完全不知道函数内部的源代码是如何，仅仅只是得到了一个个的黑盒。 既然无从得知，那么这篇文章的目的是让我们知道什么呢？ 如果我们至少在自身或在像自身的人们身上发现一种能动性与文学创作在某种方式上相类似，那该多么令人欣慰。检验这种能动性将使我们有希望对作家的创作做出解释。的确，这种情况的可能性是有的。作家自己也毕竟喜欢缩短他们自己的本性和人类的共性之间的距离；因此，他们一再鼓励我们相信，每一个人在心灵深处都是一位诗人。只要有人，就有诗人。 假如存在一种能动性与文学创作相类似，那么恐怕就能使得世界上充斥艺术的天才了。能动性是一种可以用理工科的方法进行理性分析的心理学产物，也就意味着存在一种可能性被进行编码分析的。 不过，这种可能也已经只是过去式了。人工智能（AI）假设使用模拟人脑的方式来进行编程，那么所需进行的计算量已经远远超出当今时代的计算机所能完成的计算量，即便程序的时间复杂度达到了最优，不过依旧是只有划时代的量子电脑或是尚未诞生的生物电脑、亦或是曾经被提出过的神经计算机才能完成的。而量子级、生物级尚且还太遥远，神经计算机则有些超想象。记得当时杂志上的介绍是这样的，神经计算机将完成人脑的全脑模型，不过神经计算机的制造前提也是仿人脑运行原理研制。要对人脑回路进行理性建模，尚且还在路上。 可以说人虽然存在，但心中的诗人可能永世不会醒来。 作家的本性与人类的共性至少在当下依旧只是一个无穷接近。 我们是不是应该在童年时代寻觅富于想象力的能动性的第一道轨迹呢？孩子最喜欢的最投入的活动是游戏(play)和玩耍(games）。难道我们不可以说每一个孩子在游戏时的表现行为俨然是一位作家吗？他在游戏中创造着一个属于自己的世界，或者说，是他在用自己喜爱的新方式重新组合他那个世界里的事物。如果认为他对待他那个世界的态度不够严肃，那就错了；恰恰相反，他在游戏时非常认真，并且在上面倾注了极大的热情。与玩耍相对的并不是严肃认真，而是实实在在。尽管他把情绪和精力投注于游戏世界，也还是能够很好地将游戏世界和现实世界区分开来的；他喜欢把想象中的物体和情境与现实世界中的有形的、看得见的事物联系起来。这种联系是区别孩子的“游戏”与“幻想”(phantasying)的根本依据。 弗洛伊德所说的能动性是能够通过人脑学习的，对于人的无穷可能性来说，还是相当现实的。 作家的工作与孩子游戏时的行为是一样的。他创造了一个他很当真的幻想世界——也就是说，这是一个他以极大的热情创造的世界——同时他又严格地将其与现实世界区分开来。语言保留了孩子们做的游戏和诗歌创作之间的这种关系。（在德语中）这种富有想象力的创作形式被称之为“Spiel”（游戏），这种创作形式与现实世界里的事物相联系，并具备表现能力。其作品称做“Lustspiel”或“Trauerspied”（“喜剧”或者“悲剧”，字面上可以叫做“快乐游戏”或“伤感游戏”），把那些从事表演艺术的人称做“Schauspieler”（“演员”字面上可以叫做“做游戏人”）。无论如何，作家幻想世界的非真实性对他的艺术技巧具有举足轻重的作用；因为许多事情就是这样，如果它们是真实的，就不能给人带来娱乐，在虚构的剧作中却能够带来娱乐。有许多动人心弦的剧情本身在实际上是令人悲伤的，但在一个作家的作品上演中，却能变成听众和观众的一个快乐的源泉。 幻想才能带来欢乐。 下面我们将从另一个角度，花更多些时间对现实世界与戏剧进行比较。当孩子长大成人不再做游戏时，在他经过几十年的劳作之后，以严肃的态度面对现实生活时，他或许在某一天会发现自己处于再次消除了戏剧与现实之间差别的心理情境（mental situation)之中。 作为成年人，他能够回想起童年时代游戏时所怀有的那种认真严肃的态度；如果把今天显然严肃的工作当成童年时代的游戏，他便可以抛却现实生活强加给的过于沉重的负担，从而通过幽默的方式得到大量的快乐 [2]。 由此所见，当人们长大后便停止了游戏，他们似乎也放弃了从游戏中所获得快乐的受益。但是不管是谁，只要他了解人类的心理，他就会知道，对一个人来说，如果让他放弃自己曾体验过的快乐那几乎比登天还难。事实上，我们从不放弃任何东西，我们只是用这一样东西去交换另外一样东西。看上去是被抛弃的东西实际上变成了代替物或代用品。同样，长大了的孩子当他停止游戏时，除去和真实事物的联系之外，他什么也没抛弃；代替游戏的是幻想。他在空中建造楼阁，去创造所谓的“白日梦”(day-dreaming)。我相信大多数人都在他们的生活中的某时某刻构造幻想。这是一个长期以来被忽视的事实，因此，它的重要性也就未被充分地认识到。 成年人以幻想来替代游戏？想来倒确实是这样。所谓的童心未泯恐怕就是偶尔将幻想化作现实，进行游戏。 观察人们的幻想比起观察儿童的游戏来困难得多。说真的，一个孩子要么独自游戏，要么以做游戏为目的而和其他孩子一起构成了一个封闭的精神系统；尽管在大人面前他们可能不做游戏，但在一方面，他们也从不在大人面前掩饰自己的游戏。与孩子相反，成年人却羞于表现自己的幻想，并且向其他人隐瞒自己的幻想。他珍爱自己的幻想恰如对待自己的私有财产那样。通常，他宁愿承认自己的不轨行为和过失，也不愿把自己的幻想向任何人透露。造成这种情况的原因可能是，他相信只有他创造了这样的幻想，岂不知在别人那里这种创造也相当普遍。做游戏的人和创造幻想的人在行为上的这种不同是由于两种活动的动机(motives)不同的缘故，然而它们却是互相依附的。 成年人封闭自己的内心，恐怕也正是因此当下的人们对通过行为表情等来分析对方的心理非常的感兴趣。 孩子的游戏是由其愿望所决定的：事实上是惟一的愿望(wish)——这个愿望在他的成长过程中起了很大的促进作用——希望长大成人。他总是做“已经长大”的游戏，在这种游戏中他模仿他所知道的年长者的生活方式，他没有理由掩饰这个愿望，而在成年人那里，情况就不同了，而应该在真实世界中去扮演某个角色；另一方面，他意识到把引起他幻想的一些愿望隐藏起来至关重要。于是，他就会为那些幼稚的不被允许的幻想而感到羞愧。 但是，你们会问，既然人们把他们的幻想搞得如此神秘，那么对这个问题我们又怎么会知道得如此之多呢？事情是这样的：人类中有这样一类，他们的灵魂里有一位严厉的女神(goddess)——必然性(necessity)——让他们讲述他们经受的苦难，说出给他们带来幸福 [3]的东西。他们是些神经性疾病(nervous illness)的受害者，他们不得不把自己的幻想讲出来，告诉医生，希望医生采用心理疗法(mental treatment)治愈他们的疾病。这是我们的最好的信息来源，我们据此找到了充分的理由假设；如果病人对我们守口如瓶，我们从健康人的口中也不可能有所闻。 现在，让我们来认识一下幻想的几个特征。我们可以断言，一个幸福的人从来不会去幻想，只有那些愿望难以满足的人才去幻想。幻想的动力是尚未满足的愿望，每一个幻想都是一个愿望的满足，都是对令人不满足的现实的补偿。这些充当动力的愿望因幻想者的性别、性格和环境的不同而各异；但它们又很自然地分成两大主要类别。他们要么是野心的愿望，这类愿望提高幻想者的人格；要么是性的愿望。在年轻的女子身上，性的愿望几乎总是占据主要地位，因为她们的野心通常都被性欲倾向所同化。在年轻的男子身上，自私的、野心的愿望和性的愿望相当明显地并驾齐驱。但是，我们不准备强调两种倾向之间的对立；我们更愿强调这样一个事实：它们经常结合在一块。正像在许多教堂祭坛后壁的装饰画中，捐献者的肖像可在画面的某个角落里看到一样，在大多数野心幻想中，我们也会在这个或那个角落里发 现一位女子，为了她，幻想的创造者表演了他的全部英雄行为，并把其所有的胜利果实堆放在她的脚下。大家看得出，在这样的幻想中，的确存在着想掩饰幻想的非常强烈的动机；受过良好教养的女子只允许有最低限度的性欲需求，青年男子必须学会压抑对自身利益的过分关注，以便在其他人也有着同样强烈要求的人际社会中找到可以适应自己的位置。 这一段就非常的贴合弗洛伊德的想法了，一切的本质原因都是本能的性。姑且不去探讨弗洛伊德的理论时下的正确性。幻想确实是愿望无法满足之后的产物，现实无法满足才不得进入梦的世界来实现。 我们不能认为这类想象活动的产物——各式各样的幻想，空中楼阁和白日梦——是已经定型或不可改变的东西。恰恰相反，它们随着幻想者对生活的理解的变换而变换，随着幻想者处境的每一个变化而变化，从每一个新鲜活泼的印象中去接受被称为“日戳”（date-mark）的印象。一般来说，幻想与时间之间的关系是至关重要的。我们可以说幻想似乎在三个时间之间徘徊——我们的想象经历三个时刻。心理活动与某些现时的印象相关联，和某些现时的诱发心理活动的事件有关，这些事件可以引起主体的一个重大愿望。心理活动由此而退回到对早年经历的记忆（通常是童年时代的经历），在这个时期该重大愿望曾得到过满足，于是在幻想中便创造了一个与未来相联系的场景来表现愿望满足的情况。心理活动如此创造出来的东西叫做白日梦或者是幻想，其根源在于刺激其产生的事件和某段经历的记忆。这样，过去，现在和未来就串联在一起了，愿望这根轴线贯穿于其中。 举一个非常普通的例子就可以把我所说的这些问题解释得很清楚。我们以一个贫穷孤儿为例，你已经给了他某个雇主的地址，他也许在那里能够找到一份工作。在去看雇主的路上，他可能沉湎于与产生与当时情景相适应的白日梦之中。他幻想的事情或许是这类事情：他找到了工作，并且得到新雇主对他的器重，自己成为企业里面举足轻重不可缺少的人物，既而被雇主的家庭所接纳，和这家的年轻而又妩媚迷人的女儿结了婚，随后又成为企业的董事，初始是作为雇主的合股人，而后就成了他的继承人。在这种幻想中，白日梦者重新获得他在幸福的童年时曾拥有的东西——庇护他的家庭，疼爱他的双亲以及他最初一见钟情的妙龄佳人。从这个例子中你可以看到，愿望利用一个现时的场合，在过去经历的基础上描绘出一幅未来的画面。 白日梦是随时变化的毫无疑问，为现实中某物所激发便随时可能增减内容。在此不去论证了。 关于幻想还有许多方面值得研究；但我将尽可能扼要地说明其中的某几点。如果幻想变得过于丰富多彩、强烈无比的话，那么神经症和精神病就处于待发作状态。另外，幻想是我们的病人经常抱怨的苦恼病状的直接心理预兆。它像一条宽敞的岔道伸向病理学范畴。 我不能略而不谈幻想与梦之间的关系。我们在夜里所做的梦就属此类幻想，这一点我们可以通过梦之分析来证实 [4]。很久以前语言就以其无与伦比的智慧对梦的本质问题下了定论，把漫无边际的幻想创造命名为“白日梦”。如果我们对我们的梦的意义总觉得含糊不清的话，那是因为夜间的环境使我们产生一些令自己羞惭的愿望；这些愿望我们必须对自己隐瞒，所以它们受到压抑，压入潜意识之中。这种受压抑的愿望及其派生物只允许以一种极其歪曲的形式表现出来。当科学工作已能成功地解释梦变形的这种因素时，就不难识别夜间的梦和白日梦——即我们非常了解的幻想一样，是愿望的满足。 梦的解析的问题姑且搁置。 关于幻想的问题就谈这些。现在来谈一下作家。我们真可以将富有想象力的作家和“光天化日之下的梦幻者” [5]做一比较，把他的创作和白日梦做比较吗？这里，我们必须先弄清楚一个问题。我们必须区分开这两类作家：像古代的史诗作家和悲剧作家那样接收现成题材的作家和似乎是由自己选择题材创作的作家。我们在进行比较时，将主要针对后一类作家，不去选择那些批评家顶礼推崇的作家，而是选择那些名气不十分大，但却拥有最广大、最热衷的男女读者的长篇小说，传奇文学和短篇小说的作者。在所有这些小说作者的作品中有一个特点我们肯定能看得出：每一部作品都有一个主角，这个主角是读者兴趣的中心，作家试图用尽一切可能的表现手法来使该主角赢得我们的同情，作者似乎将他置于一个特殊的神袛的庇护之下。假如在我的小说的某一章的结尾，我把主角遗弃，让他受伤流血，神志昏迷，那么我肯定在下一章的开头会读到他正得到精心的治疗护理，逐渐恢复健康；如果第一卷以他乘的船在海上遇到暴风雨而下沉为结尾，那么我还可以肯定，在第二卷的开头就会读到他奇迹般地获救——没有获救这个情节，小说将无法写下去。我带着安全感跟随主角走过他那危险的历程，这正是在现实生活中一位英雄跳进水中去拯救一个落水者时的感觉，或者是他为了对敌兵群猛烈攻击而把自己的身躯暴露在敌人的炮火之下时的感觉。这种感觉是真正英雄的感觉，我们一位最优秀的作家曾用一句盖世无双的话表达过：“我不会出事！” [6]然而，通过这种不受伤害、英雄不死的特性，我们似乎可以立即认出每场白日梦及每篇小说里的主角如出一辙 [7]，都是一个“惟我独尊的自我”。 这些自我中心小说在其它方面也表现出类似性。小说中的所有女人总是爱上了男主角，这一点，很难说是对现实的描写。但是，作为白日梦必要的构成因素却很容易被理解。同样，作者根本无视现实生活中所见到的人物性格的多样性，而将小说中的其他人物整齐地分成好人与坏人。“好人”是自我的助手，而“坏人”则成为自我的敌人和对手，这个自我就是故事的主角。 小说是围绕主角展开描写的，自然无法否认主角的好运。无论如何，都不得不承认对个人的自我的放大的小说读上去充斥着好运的感觉。 我们十分清楚，许多富于想象的作品和天真的白日梦模式相距甚远；但我仍不能消除这种怀疑：即使偏离白日梦模式最远的作品也可以通过不间断的，一系列的过渡事件与白日梦相联系。我注意到被人们称为“心理小说”(psychological novels)的作品中只有一个人物—就是那个通过内心描写的主角。作者好像坐在主人公的脑袋里，从外部来观察其他人物。毋庸置疑，一般来说心理小说之所以具有其特殊性，是因为现代作家倾向于凭借自我观察(self-observation) ,将他的主人公分裂成许多部分自我（part-egos),结果是作家把自己的心理生活中相冲突的几个倾向在几个主角身上体现出来。某些小说或许可称之为“怪诞”(eccentric)小说，似乎与白日梦的类型形成非常特殊的对比。在这些小说里，被作为主角介绍给读者的人物仅仅扮演着一个很小的角色，他犹如一位旁观者静观其他人的活动以及遭受的痛苦。 左拉的许多后期作品都属于这一类。但是我必须指出，通过对创造性的作家和在某些方面背离所谓规范的作家做个人精神分析，我们发现白日梦具有与“怪诞”小说类似的特点，即自我满足于充当旁观者的角色。 怪诞小说放大了对其他人的自我的猜测，从另一种角度形成了一种引领全书气氛的幻想。 如果我们想让富于想象力的作家和白日梦者、诗歌创作与白日梦之间的比较有某种价值的话，那就必须首先以某种方式表现出其有效性。譬如，我应试着对这些作者作品中所运用我们在前面论及的关于幻想、三个时间和贯穿三个时间的愿望之间的关系命题；借助于此我们还可以试着研究一下作者的生活与其作品之间的联系。一般来说，无人知晓在研究这个问题时应设想什么样的预期成果，而且人们常常把这种联系看得过于简单。借助于我们对幻想研究所得，我们应该预料以下的事态：现时的一个强烈经验唤起作家对早年某个经历（通常是童年时代）的记忆，在此记忆中又产生一个在其作品中可以得到满足的愿望。其作品本身能够显示出近期的诱发事件和旧时的记忆这些因素 [8]。 不要被这个程式的复杂性吓倒了。我猜想事实将会证明它是一种极为罕见的方式。然而，它或许包含着弄清事实真相的第一步；根据我所做的一些实验，我倾向于认为对于作品的这种研究方式不会是劳而无功的。你将不会忘记，对于作家生活中的童年时代的记忆的强调——这种强调或许令人莫名其妙——归根到底来自于这种假设：一篇具有创见性的作品像一场白日梦一样，是童年时代曾经做过的游戏的继续，也是这类游戏的替代物。 然而，我们不能忘记回到我们该认识的那类富有想象力的作品，这类作品并非是独创性的写作，而是现成的和熟悉的素材的改造加工。即使在这里，作家也拥有相当范围的自主权，这种自主权可表现在素材的遴选以及素材的千变万化上，这种变化的范围又相当广泛。不过就现有的素材来说，它来自流行的神话、传说及童话故事的宝库。对诸如此类民间心理构造的研究还远远够完善，但极有可能的是，诸如神话故事这类传说是所有民族充满愿望的幻想，也是人类年轻时期的尚未宗教化的梦幻歪曲后的残迹。 你会说，尽管在我的论文题目中我把作家放在首位，但我对作家的论述比对幻想的论述少得多。我意识到了这一点，但我这么做是有理由的，因为我推导出了我们现在所拥有的认识。我所能够做到的一切，就是提出一些鼓励和建议，从对于幻想的研究着手，导向作家选择其文学素材的问题的研究。至于另外的问题——作家采用什么手段来激发我们内心的感情效应——截止目前我们还根本没有涉及到这个问题。但我至少乐于向你指明一条从我们对幻想的讨论一直通向诗的效应问题的道路。 你会记得我曾论述过，白日梦幻者由于他感到有理由对自己创造的幻想而害羞，从而小心谨慎地向别人隐瞒自己的幻想。现在我应该补充说明，即使他打算把这些幻想告诉我们，这种倾诉也不会给我们带来任何快乐。我们听到这些幻想时会产生反感或者深感扫兴。但是当一位作家给我们献上他的戏剧或者把我们习惯于当作他个人的白日梦的故事时，我们就会体验到极大的快乐，这种快乐极有可能由许多来源汇集而产生。作家如何达到这一目的，那是他内心深处的秘密；诗歌艺术的精华存在于克服使我们心中感到厌恶的后果的技巧，这种厌恶感毫无疑问地与一个“自我”和其他“自我”之间产生的隔阂相联系。我们可以猜测到这种技巧的两个方法：作家通过改变和掩饰其利己主义的白日梦以软化它们的利己性质；他以纯形式的——即美学的——快感来收买我们这些读者。我们给这类快乐命名为“额外刺激”(incentive bonus)或“前期快乐”(fore pleasure)。作者向我们提供这种快乐是为了有可能从更深的精神源泉中释放出更大的快乐 [9]。从我的观点来讲，作家提供给我们的所有美学快乐都具有这种“直观快乐”的性质，我们对一部富有想象力的作品的欣赏实际来自我们精神上紧张状态的消除。甚至有可能是，这种效果有相当一部分归因于作家能够使我们享受到自己的白日梦而又不必去自责或害羞。这个认识成果就把我们引向新的、有刺激性的、复杂难懂的调查研究工作的门槛；但同时，至少是目前，它也把我们带到我们讨论的终点。 对最后这一部分的理解依旧与一开始相同。 阅读这类文字，看来思维能力还是有所欠缺，需要加大练习。 【1】红衣主教伊波里托·德埃斯特(Ippolito d' Este)是阿里奥斯托的第一个保护人，阿里奥斯托(Ariosto)的《疯狂的奥兰多》就是献给他的。诗人得到的惟一报答是红衣主教提出的向题：“罗多维柯，你从哪儿找到这么多故事？” 【2】参阅弗洛伊德的《诙谐及其与潜意识的关系》（1905c）第七章第七节。 【3】这是指歌德的剧本《托夸多•诺索》最后一场中主角兼诗人所吟诵的诗句： 当人类在痛苦中沉默， 神让我讲述我的苦痛。 【4】 参阅弗洛伊德的《释梦》（1900a）。 【5】［Der Träumer am hellichten Tag］ 【6】“Es Kann dir nixg schehen！”\"这句话出自弗洛伊德喜爱的维也纳剧作家安泽格鲁伯(Anzengruber)之口。参阅《对目前战争与死亡的看法》(1915b)标准版，第14卷，第296页。 【7】 参阅《论自恋》(1914c)，标准版，第14卷，第91页。 【8】弗洛伊德在1898年7月7日致弗利斯的信中讨论迈耶尔(C. F. Meyer)创作的短篇小说的主题时，已经提出过类似的观点（弗洛伊德，1950a，信92)。 【9】弗洛伊德把“前期快乐”和“额外刺激”的理论应用在《诙谐及其与潜意识的关系，（1905c）第四章最后一段中。在《性学三论》中，弗洛伊德又讨论了“前期快乐”的本质。 参考文献： 1.《作家与白日梦》，弗洛伊德，1908","categories":[{"name":"随想","slug":"thinking","permalink":"https://sean10.github.io/categories/thinking/"}],"tags":[{"name":"梦","slug":"梦","permalink":"https://sean10.github.io/tags/%E6%A2%A6/"}]},{"title":"《爱的艺术》爱的误解——对象，状态","slug":"《爱的艺术》爱的误解——对象，状态","date":"2015-11-04T03:04:00.000Z","updated":"2023-03-18T15:11:14.875Z","comments":true,"path":"2015/11/04/《爱的艺术》爱的误解——对象，状态/","link":"","permalink":"https://sean10.github.io/2015/11/04/%E3%80%8A%E7%88%B1%E7%9A%84%E8%89%BA%E6%9C%AF%E3%80%8B%E7%88%B1%E7%9A%84%E8%AF%AF%E8%A7%A3%E2%80%94%E2%80%94%E5%AF%B9%E8%B1%A1%EF%BC%8C%E7%8A%B6%E6%80%81/","excerpt":"","text":"当然，那并不是说人们认为爱不重要。人们渴望着爱，他们没完没了地观看有关换了和悲哀的爱情故事的电影，倾听很多毫无价值的爱情歌曲——爱呢日，几乎每一个人都认为，爱是没有什么可学的。 对于爱情的渴望，确实每个人都无可避免。不论是因为生理上的荷尔蒙，还是因为心理上对解脱寂寞的向往，爱情作为温柔乡，所有人都有着对理想的安神处的希望。不过，这样的渴望，毕竟正如上一段所说的，并不是所有人都能接受将其作为艺术来学习的。 这种特殊的态度基于几个前提，而这些前提往往分别地或共同地支持这种态度。__大多数人把爱只是简单地看成被爱的问题，而不是爱人及自己有无爱人的能力的问题。__因此，在他们看来，问题是怎样被爱，怎样得到爱，怎样变得可爱。为了追求这个目的，他们采用几条途径：其一，尽可能取得成功，取得与个人的社会地位相称的权利和财富，这条途径特别为男人所采用，其二，梳妆打扮、衣着华丽，使自己更富有吸引力，这条途径尤其为女人所采用。其它一些被男人和女人采用的、使自己富有吸引力的途径是养成令人愉快的生活习惯，谈笑风生，助人为乐，千寻而布帽烦别人。有很多让自己变得可爱的途径，类似于是自己取得成功的那些途径，如”赢得朋友，影响他人“。其实，在我们的文化观念中，大多数人所指的”可爱“基本上是时髦和性吸引力的混合物。 这个第一个前提，如何理解呢？ 从一定角度来说，其实他们地方法并没有做错。因为都是采取提高个人本身的固定价值来提高被关注率，相比只是提高自己追求的成功率的艺术的学习来说，可能这样的方法对于非主动的、以及并不知晓自己爱什么样的人、自己能爱什么样的人的人来说，更为恰当一些。 不过从弗洛姆的角度来理解的话，这些人都只是在选择发展让自己能吸引大量异性的方式，毕竟这样的方法可以让自己在更多的异性中拥有更好的印象，更容易吸引来自己喜欢的异性。当然，有方向的人明显不是属于这类人。 隐藏在“爱没有什么可学的态度“后面的第二个前提是：__爱的问题就是爱的对象问题，而不是爱的能力问题。__人们认为爱是简单地，但是要找到一个合适的爱的对象——或为其所爱——则是困难的。持这种态度有几个原因，它们同现代社会发展是密切相关的，其中之一是__20世纪对”爱的对象“的选择发生了巨大变化__。在维多利亚时代，爱，正如在很多传统文化中一样，通常来讲并不是一种自发的并导致婚姻的隐私经验；相反，婚姻是通过传统的风俗习惯确定的——要么通过双方家庭，要么通过一个媒人，或者不需要中间人的介绍。婚姻实在考虑社会需要的基础上最后做出的决定，一旦做出婚姻的决定，爱就理所当然地发展下去。在过去几代人中，浪漫式的爱的思想在西方世界中极为普遍。在美国，虽然并非完全不考虑传统的爱，但是人们在很大的程度上寻求的是”浪漫式“的爱，寻求导致婚姻的爱的隐私经验。在爱的方面，这种自由的新思想，同爱的作用相比，大大地增加了爱的对象的重要性。 确实，这个前提可以说是即便是到了现在，同样是作为最大的理由被人认所使用着。欧美可能在20世纪就已经结束了完全传统式的爱，而对于我们来说，可能80后90后才是渐渐在试图摆脱传统式的爱的人，所以可以说是这本书非但没有过时，而且非常的适合于我们这代人阅读。罗曼蒂克的爱情正在为不少人所追求，不过也已经经过了几年的浪漫，现在普遍大部分人都已经意识到了现实的残酷，现在正是处在传统与浪漫式的婚姻的交集诞生新的婚姻构成的时代。自由式的爱，之后对于对象可能会更为偏重了，可能将不再完全以传统的背景作为条件，更多的是考虑人本身，人本省的潜力以及远见等。 同这种爱的对象因素密切相关而又具有当代文化特色的另一个特点是，__我们的整个文化基于购买欲上，基于互利交易的观点上。__现代人的快乐就在于一股劲溜达商店，浏览商品橱窗，用现金或通过分期付款来购买它能支付得起的一切。他或她以同样的方式对待人。对男人来讲，具有吸引力的女人是他们所追求的极好的东西；对于女人来讲，具有吸引力的男人，是她们所追求的极好的东西。”吸引力“通常意味着在人格市场上被追求的流行的优质产品。特别使人富有吸引力的因素，无论在精神上或在物质上都是由时代风尚决定的。在20年代，一个酗酒、抽烟、泼辣、富有性感的女人是具有吸引力的；今天时代风尚更多地要求女性贤惠和羞怯。19世纪末二十世纪初，男人一定要雄心勃勃、富有进取心——今天他必须谙熟世故、善于交际、恢宏大度——以便成为一种具有吸引力的”产品“。在任何情况下，只有考虑到这种具有人性的商品不超过自己所能购买的范围，才常常会产生爱上一个人的感受。我只是一心为了交易。从社会价值来看，爱的对象应该是逞心如意的；同时爱的对象也考虑到我的全部财产和潜在能力而应该需要我。因此，两个人根据他们自己交换价值的条件，一旦在市场上发现有最好的对象，他们就产生了爱。象购买不动产一样，能发挥的潜力在这种交易中常常起相当大的作用。在市侩型意识流行的文化中，在物质上的成功具有特殊价值的文化中，人的爱情关系和条件商品市场与劳动力市场的交换，都遵循统一模式，这种现象是不足为奇的。 爱的对象的寻求确实已经可以称之为互利交易。一般来说，只有在物质、潜在能力相近的人之中才更能产生共同地想法，在婚姻之中也才更能具有互相理解的可能，为了未来的幸福，可以说是这样的互利交易的观点是最合适、最优的方案。 认为爱没有什么科学的第三个错误在于__混淆了”爱上“一个人的最初经验和对一个人”爱“的永久状态——或者我们不妨说”处于“爱一个人的永久状态。__假如两个素昧平生的陌生人，像我们大家一样，突然让两人之间的大墙dota，他们感到越来越近，最后成为一体，那么成为一体的一刹那是生活中经历最快乐最兴奋的时刻。对于已被隔绝，孤寂而没有爱的人来说，它更是美妙而神奇。这种意外的亲密奇遇，只要跟性的吸引和性的高潮结合起来，或者为性的吸引和性的高潮所驱动，常常是很容易产生的。但是，这种爱就其本性而言并不长久，只是昙花一现。这两个人渐渐熟悉，而亲密行为的神奇色彩却日渐褪去，直至最后他们地冲突、失望及相互间的厌烦把最初剩下的兴奋经验葬送殆尽。然而，开始时他们根本不知道这些，事实上，他们只是把相互间如痴如醉的迷狂状态当做双方强烈地爱的明证；与此同时，他也许仅仅表明他们以前孤独的程度。 爱的状态被误解是当下热恋的情侣分手的最普遍原因。这里稍稍提一下，第二个原因恐怕就是上一段所说的互利交易中最优的不满足。对于刚脱离孤寂时的充实感误认为是真实的双方之间的爱，将爱的情感的最高峰误认为是未来持久的爱的平均值，自然会对之后的爱的情感的滑坡感到不满，厌烦。从持久的角度来看，爱情理应是平和的，而非燃烧殆尽一般的瞬时的轰轰烈烈。不过，这里有一个问题。 什么样的轰轰烈烈是不正常的呢？对于在选择对象之时的突如其来的一种憧憬，同样也是一种强烈地情感，只是并未形成双方之间的关系，依旧只是单相思。这样的情感在双方之间建立桥梁之后，是否会形成真实平和的爱情呢？还是说，这只是一时的荷尔蒙原因，更需要做的是冷静，待一定时间之后便能明白自己真实的情感？ 尽管这种态度——再没有什么东西比爱更容易的了——得到截然相反的证明，可是它仍旧成为一种对爱流行的看法。几乎没有哪一种活动，哪一项事业会像爱那样一开始充满着希冀和期望，而最后又常常失败。如果在其它的活动中出现这种情况，人们也许会渴望知道失败的原因，渴望学会怎样做得更好一些，或者干脆放弃这种活动。既然在的问题上，人们要放弃爱是不可能的，那么似乎只有一种合适的办法来克服爱的失败，这种办法乃是探讨爱的失败的原因，进而探究爱的意义。 探究爱的原因，进而探讨爱的意义正是我们阅读这本书的目的。","categories":[{"name":"随想","slug":"thinking","permalink":"https://sean10.github.io/categories/thinking/"}],"tags":[{"name":"读书笔记","slug":"读书笔记","permalink":"https://sean10.github.io/tags/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/"},{"name":"爱的艺术","slug":"爱的艺术","permalink":"https://sean10.github.io/tags/%E7%88%B1%E7%9A%84%E8%89%BA%E6%9C%AF/"},{"name":"爱情","slug":"爱情","permalink":"https://sean10.github.io/tags/%E7%88%B1%E6%83%85/"}]},{"title":"商半群的计算总结","slug":"商半群的计算总结","date":"2015-11-03T12:06:00.000Z","updated":"2023-03-18T15:11:14.867Z","comments":true,"path":"2015/11/03/商半群的计算总结/","link":"","permalink":"https://sean10.github.io/2015/11/03/%E5%95%86%E5%8D%8A%E7%BE%A4%E7%9A%84%E8%AE%A1%E7%AE%97%E6%80%BB%E7%BB%93/","excerpt":"","text":"##商半群的计算总结 看商半群的题看了好久，一直没看懂几个条件是什么意思，重头翻书，总算找到一些思路，是自己的基础没学好的缘故。 以下来分享以下我的计算方式，因为没有找到答案，我也不好说一定对。 首先，必须要明白商集的相关基础知识。 &gt; huafen huafen2 A的商集就是对集合A进行一个划分，所有划分的子集之间交集为空集，同时并集又为A。 看下图就能理解他是如何划分的了 example1 dingli1 explore 这两段讲的很清楚。 dingli2 example2 根据这个例子，我们理解了得到的集合的等价关系应该怎么写出来。 依据划分的块进行相关元素的全排列。 explore2 这个例子告诉了我们商集通过等价类应该如何表达。 &gt; example2 example3 接下来回到群的内容 definition3 这一段的(a)给了我们进行商半群的运算表的计算的条件。 等价类的二元运算就是先计算方括号内的，得到的等价类就是所求等价类 让我们来看一道题 question 在这里我们只做a题，b题暂时不涉及 我的答案是以下 &gt; ans 我对商半群的计算的认识就是以上的过程了。","categories":[{"name":"专业","slug":"pro","permalink":"https://sean10.github.io/categories/pro/"}],"tags":[{"name":"离散数学","slug":"离散数学","permalink":"https://sean10.github.io/tags/%E7%A6%BB%E6%95%A3%E6%95%B0%E5%AD%A6/"},{"name":"群论","slug":"群论","permalink":"https://sean10.github.io/tags/%E7%BE%A4%E8%AE%BA/"}]},{"title":"论勇气","slug":"论勇气","date":"2015-11-01T13:50:00.000Z","updated":"2023-03-18T15:11:14.857Z","comments":true,"path":"2015/11/01/论勇气/","link":"","permalink":"https://sean10.github.io/2015/11/01/%E8%AE%BA%E5%8B%87%E6%B0%94/","excerpt":"","text":"作为交英语作业前的一次头脑风暴，以中文来记录自己所暂时能想到的。 虽然本打算看完《存在的勇气》，再写的，时间不够，姑且量力而为了。 勇气，依据维基百科，是一种面对痛苦、危险、威胁、不定的选择和希望。 生理上的勇气是面对物理上的疼痛、困难、死亡抑或是死亡的威胁下的勇气，而心理上的勇气则是一种能够在面对流行的二元选择、羞愧、流言、气馁、个人损失下做出正确选择的能力。 在这里，我们考虑的更多的是心理上的广义范围内的勇气。 知道了定义，那么为什么勇气值得我们来探讨呢？ 勇气在哪些方面具有存在的价值呢？先从生命必须品的方向来说，勇气是生存必要的吗？并非生存必须品，所以它的价值对不同的人来说并不相同。 勇气，面对选择，能做出决断。 对于处在追求路上的人来说，毫无疑问，勇气是必须的。说的通俗，唯有勇气，方可乘风破浪。 反之，对于已经有所实现自身所需的人，已经只需要随性而为了。已经无需勇气来推动了。 回到实际，我们大部分人还是处在第一种，勇气自然是必备之物。那么，说的细致一些，我们应该怎么做呢？ 果断，在我看来，是最先需要具备的。当然，并非莽撞。在当下这个快节奏的大数据时代，时间是最充足的，但同样也是最紧缺的。在技术的支持下，传输、计算等硬性时间都已经得到了大幅度的缩减，人与非生命体最大的长处当前正可以得到最大限度的发挥。不过，技术的存在，也给人类的思维提供了更多的乌托邦，对我个人而言，网络的娱乐功能仿佛罂粟一般让人沉迷、无可自拔。原本膨胀的弹性时间也渐渐萎缩，仿佛统计回归一般。人的普遍成长是必须按部就班的，指数级提高的思维水平果然只是乌托邦吗。该放则放，当机立断，于我，是必须的。 其次，单纯，也必然需要作为元素之一。同样，基于信息时代，互联网的世界实在是丰富。在进入计算机专业之前，对互联网的了解，我仅仅只是基于世人都知道的，使得全世界达成了互连，可以在转瞬之间了解到世界对面的人的消息。然而，当时的我还是小看了数据。虽说当下距离互联网的诞生并没有多久，仅仅数十年罢，然而数据的累积早已不是个人之力可穷经其目录的了。如今，仅仅只是针对专业所及，所能学习的方面便已经多达数十种常用语言，而时间仅有那些，我一开始试图囫囵吞枣，太过贪心，一年一事无成，仅仅皆有所知。而其他人，虽然并不知晓其他方面的技术，但已经对一种语言的开发钻研至深。单纯的勇往直前，在如今繁杂的时代，不可或缺。否则，仅仅只能收获中庸。 当前，想来，要素并无需太多，唯二已经足够。 论勇气，当下只能想到这些了。","categories":[{"name":"随想","slug":"thinking","permalink":"https://sean10.github.io/categories/thinking/"}],"tags":[{"name":"勇气","slug":"勇气","permalink":"https://sean10.github.io/tags/%E5%8B%87%E6%B0%94/"}]},{"title":"《爱的艺术》爱是艺术吗？","slug":"《爱的艺术》爱是艺术吗？","date":"2015-10-31T16:00:00.000Z","updated":"2023-03-18T15:11:14.820Z","comments":true,"path":"2015/11/01/《爱的艺术》爱是艺术吗？/","link":"","permalink":"https://sean10.github.io/2015/11/01/%E3%80%8A%E7%88%B1%E7%9A%84%E8%89%BA%E6%9C%AF%E3%80%8B%E7%88%B1%E6%98%AF%E8%89%BA%E6%9C%AF%E5%90%97%EF%BC%9F/","excerpt":"##《爱的艺术》爱是艺术吗？ 上一次翻开这本书还是2年前了，是它引领了我进入哲学的世界，不知现在再翻开能不能有新的理解。","text":"##《爱的艺术》爱是艺术吗？ 上一次翻开这本书还是2年前了，是它引领了我进入哲学的世界，不知现在再翻开能不能有新的理解。 重读第一章 爱是一门艺术吗？如果爱是一门艺术，那就要求人们有这方面的知识并付出努力。或者爱仅仅是一种偶然产生的令人心荡神怡的感受，只有幸运儿才能“堕入”爱的情网呢？这本小册子以第一种假设为基础，而大多数人毫无疑问相信第二种假设。 假如爱是一门艺术，那么所有人就不得不进行学习，耗费心力。虽然可能可以换来一个成功的爱的概率，然而与不用耗费丝毫心力甚至时间、唯一的需求就只是听从天命等待运气的光临的第二种选择来说，毫无疑问的大部分人都会不经思考的、轻易地相信了第二种选择。 然而原因是什么呢？是因为人的本性吗，对于一些如同爱一般的非具象化的非显然必要存在于现实的元素，自然的惰性占据了优势吗？不深思相信爱是艺术与否的利弊，便做出了舍弃努力的可能的概率。 不过，仔细想来，其实这样的分析也是片面的。要知道，对于大部分人，只要没有陷入对娱乐等迷恋，能够提高自己的技能一定是不会轻易放弃的。恐怕，更大的原因只是，爱的因素毕竟不止是掌握了这门艺术与否，至少在深度掌握这门艺术之前，其他的如同外貌等不可掌控因素占据了更大的话语权。而一门艺术的高度掌握从来不是轻易可以达成的，是需要大量的努力的。一旦达成了一定的艺术的学习，然而却依旧没有得到爱，那般的打击下，便意味着短时间之内将无力改变。在未大成之际，失败的可能性更大的情况下，既然能够不去面对失败，大部分人理所当然会去选择躲避吧。","categories":[{"name":"随想","slug":"thinking","permalink":"https://sean10.github.io/categories/thinking/"}],"tags":[{"name":"读书笔记","slug":"读书笔记","permalink":"https://sean10.github.io/tags/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/"},{"name":"爱的艺术","slug":"爱的艺术","permalink":"https://sean10.github.io/tags/%E7%88%B1%E7%9A%84%E8%89%BA%E6%9C%AF/"},{"name":"爱情","slug":"爱情","permalink":"https://sean10.github.io/tags/%E7%88%B1%E6%83%85/"}]},{"title":"【Discrete Mathematics】Relations【2015.10.31更新】","slug":"【Discrete-Mathematics】Relations【2015-10-31更新】","date":"2015-10-29T13:22:00.000Z","updated":"2023-03-18T15:11:14.885Z","comments":true,"path":"2015/10/29/【Discrete-Mathematics】Relations【2015-10-31更新】/","link":"","permalink":"https://sean10.github.io/2015/10/29/%E3%80%90Discrete-Mathematics%E3%80%91Relations%E3%80%902015-10-31%E6%9B%B4%E6%96%B0%E3%80%91/","excerpt":"","text":"【Discrete Mathematics】Relations 这是离散数学课的个人阶段性总结，如有纰漏，敬请指出，一起学习~太过简单，也请见谅Orz 使用教材为《离散数学及其应用》（第7版.英文版） 现在主要拉定义，加上个人理解= = Chapter 9.1 Relations and their properties Definition1. Let A and B be sets. A binary relation from A to B is a subset of A × B._ 二元关系就是序偶的集合R，记号为aRb，表示(a,b). 函数是关系的一种。对应于集合A的每一个元素，恰好有且仅有一个集合B中的元素与之对应。 Definition2. A relation on a set A is relation from A to A. Definition3. A relation R on a set A is called reflexive if (a, a)R for every element a A. Remark.我们看到a((a,a)R),那么集合上的关系是自反的。这里的论域是A中所有元素的集合。 Definition4. A relation R on a set A is called symmetric if(b,a) R whenever (a,b)R ,for all a,b A. A relation R on a set A such that for all a,b A, if (a,b) R and (b,a) R, then a = b is called antisymmetric. Remark.使用量词，可以看到如果a b((a,b) R -&gt; (b,a) R),则A上的关系R是对称的。类似的，如果a b(((a,b) R ^ (b,a) R)-&gt;(a=b),则A上的关系R是反对称的。 就是说，关系R是对称的，当且仅当如果a与b相关则b与a就相关，关系R是反对称的，当且仅当不存在由不同元素a和b构成的序偶使得a与b相关并且b与a也相关。对称与反对称的概念不是对立的，因为一个关系可以同时有这两种性质或者两种性质都没有。一个关系如果包含了某些形如(a,b)的对，其中a != b，这个关系就不可能同时是对称和反对称的。 Definition5. A relation R on a set A is called transitive if whenever (a,b) R and (b,c) R,then (a,c) R,for all a,b,c A. Remark.使用量词，我们可以看到在集合A上的关系R是传递的，如果a b c(((a,b)R ^(b,c)R)-&gt; (a,c)R). Definition6. Let R be a relation from a set A to a set B and S a relation from B to a set C.The composite of R and S is the relation consisting of ordered pairs(a,c),where aA,cC,and for which there exists an element b B such that (a,b) R and (b,c) S.We denote the composite of R and S by SR. Definition7. Let R be a relation on the set A.The powers R^n,n= 1,2,3...,are defined recursively by R^1=R and R^(n+1) = R^nR. Theorem1. The relation R on a set A is transitive if and only if R^n R for n = 1,2,3... Supplement A relation R on the set A is irreflexive if for every a A,(a,a) R.That is ,R is irreflexive if no element in A is related to itself. A relation R is called asymmetric if (a,b)R implies that (b,a) R. Let R be a relation from a set A to a set B.The inverse relation from B to A,denoted by R^-1 ,is the set of ordered pairs {(b,a)|(a,b)}.The complementary relation R is the set of ordered pairs{(a,b)|(a,b)R}. Chapter 9.2 n-ary relations and their applications Definition1. Let A1,A2,...An be sets.An n-ary relation on these sets is a subset of A1×A2×...×An.The sets A1,A2,...An are called the domains of the relation ,and n is called its degree. __*Supplement__ Relations used to represent databases are also called tables, because these relations are often displayed as tables. Each column of the table corresponds to an attribute of the database. For instance, the same database of students is displayed in Table 1. The attributes of this database are Student Name, ID Number, Major, and GPA. A domain of an n-ary relation is called a primary key when the value of the n-tuple from this domain determines the n-tuple. That is, a domain is a primary key when no two n-tuples in the relation have the same value from this domain. Records are often added to or deleted from databases. Because of this, the property that a domain is a primary key is time-dependent.Consequently, a primary key should be chosen that remains one whenever the database is changed. The current collection of n-tuples in a relation is called the extension of the relation. The more permanent part of a database, including the name and attributes of the database, is called its intension. When selecting a primary key, the goal should be to select a key that can serve as a primary key for all possible extensions of the database. To do this, it is necessary to examine the intension of the database to understand the set of possible n-tuples that can occur in an extension. Combinations of domains can also uniquely identify n-tuples in an n-ary relation. When the values of a set of domains determine an n-tuple in a relation, the Cartesian product of these domains is called a composite key. Definition2. Let R be an n-ary relation and C a condition that elements in R may satisfy. Then the selection operator sC maps the n-ary relation R to the n-ary relation of all n-tuples from R that satisfy the condition C. Definition3. The projection P(i1,i2,...,im) where i1 &lt; i2 &lt; · · · &lt; im, maps the n-tuple (a1, a2, . . . , an) to the m-tuple (a(i1), a(i2), . . . , a(im)), where m ≤ n. Definition4. Let R be a relation of degree m and S a relation of degree n. The join Jp(R, S), where p ≤ m and p ≤ n, is a relation of degree m + n − p that consists of all (m + n − p)-tuples (a1, a2, . . . , a(m−p), c1, c2, . . . , cp, b1, b2, . . . , b(n−p)), where the m-tuple (a1, a2, . . . , a(m−p), c1, c2, . . . , c(p)) belongs to R and the n-tuple (c1, c2, . . . , cp, b1, b2, . . . ,b(n−p)) belongs to S. Chapter 9.3 representing relations Representing relations using Matrices A relation between finite sets can be represented using a zero–one matrix. Suppose that R is a relation from A = {a1, a2, . . . , am} to B = {b1, b2, . . . , bn}. (Here the elements of the sets A and B have been listed in a particular, but arbitrary, order. Furthermore, when A = B we use the same ordering for A and B.) The relation R can be represented by the matrix MR = [mij], where m(ij)={1 if(ai,bj)R,0 if(ai,bj)R}. matrix Representing relations using Digraphs We have shown that a relation can be represented by listing all of its ordered pairs or by using a zero–one matrix. There is another important way of representing a relation using a pictorial representation. Each element of the set is represented by a point, and each ordered pair is represented using an arc with its direction indicated by an arrow. We use such pictorial representations when we think of relations on a finite set as directed graphs, or digraphs. __Definition1. A directed graph, or digraph, consists of a set V of vertices (or nodes) together with a set E of ordered pairs of elements of V called edges (or arcs). The vertex a is called the initial vertex of the edge (a, b), and the vertex b is called the terminal vertex of this edge. An edge of the form (a, a) is represented using an arc from the vertex a back to itself. Such an edge is called a loop. Chapter9.4 closures of relations The relation R = {(1, 1), (1, 2), (2, 1), (3, 2)} on the set A = {1, 2, 3} is not reflexive. How can we produce a reflexive relation containing R that is as small as possible? This can be done by adding (2, 2) and (3, 3) to R, because these are the only pairs of the form (a, a) that are not in R. Clearly, this new relation contains R. Furthermore, any reflexive relation that contains R must also contain (2, 2) and (3, 3). Because this relation contains R, is reflexive, and is contained within every reflexive relation that contains R, it is called the reflexive closure of R. Paths in Directed Graphs &gt;Definition1. A path from a to b in the directed graph G is a sequence of edges (x0, x1), (x1, x2), (x2, x3), . . . , (xn−1, xn) in G, where n is a nonnegative integer, and x0 = a and xn = b, that is, a sequence of edges where the terminal vertex of an edge is the same as the initial vertex in the next edge in the path. This path is denoted by x0, x1, x2, . . . , xn−1, xn and has length n. We view the empty set of edges as a path of length zero from a to a. A path of length n ≥ 1 that begins and ends at the same vertex is called a circuit or cycle. Theorem1. Let R be a relation on a set A. There is a path of length n, where n is a positive integer, from a to b if and only if (a, b) ∈ Rn. Definition2. Let R be a relation on a set A. The connectivity relation R* consists of the pairs (a, b) such that there is a path of length at least one from a to b in R. Because Rn consists of the pairs (a, b) such that there is a path of length n from a to b, it follows that R* is the union of all the sets Rn. In other words, formula1 Theorem2. The transitive closure of a relation R equals the connectivity relation R*. Lemma1. Let A be a set with n elements, and let R be a relation on A. If there is a path of length at least one in R from a to b, then there is such a path with length not exceeding n. Moreover, when a != b, if there is a path of length at least one in R from a to b, then there is such a path with length not exceeding n − 1. path Theorem3. Let MR be the zero–one matrix of the relation R on a set with n elements. Then the zero–one matrix of the transitive closure R* is formula2 Lemma2. algorithm Chapter9.5 Equivalence Relations Definition1. A relation on a set A is called an equivalence relation if it is reflexive, symmetric, and transitive. Definition2. Two elements a and b that are related by an equivalence relation are called equivalent. The notation a~b is often used to denote that a and b are equivalent elements with respect to a particular equivalence relation. Definition3. Let R be an equivalence relation on a set A. The set of all elements that are related to an element a of A is called the equivalence class of a. The equivalence class of a with respect to R is denoted by [a]R. When only one relation is under consideration, we can delete the subscript R and write [a] for this equivalence class. In other words, if R is an equivalence relation on a set A, the equivalence class of the element a is [a]R = {s | (a, s) ∈ R}. If b ∈ [a]R, then b is called a representative of this equivalence class. Any element of a class can be used as a representative of this class. That is, there is nothing special about the particular element chosen as the representative of the class. Theorem1. Let R be an equivalence relation on a set A. These statements for elements a and b of A are equivalent:(i) aRb (ii) [a] = [b] (iii) [a]∩[b] != 0 Theorem2. Let R be an equivalence relation on a set S. Then the equivalence classes of R form a partition of S. Conversely, given a partition {Ai | i ∈ I} of the set S, there is an equivalence relation R that has the sets Ai, i ∈ I, as its equivalence classes. a partition of a set S is a collection of disjoint nonempty subsets of S that have S as their union. In other words, the collection of subsets Ai, i ∈ I (where I is an index set) forms a partition of S if and only if Ai != 0 for i ∈ I, Ai ∩ Aj = 0 when i != j, and c Supplement A partition P1 is called a refinement of the partition P2 if every set in P1 is a subset of one of the sets in P2. Chapter9.6 Partial Orderings Definition1. A relation R on a set S is called a partial ordering or partial order if it is reflexive, antisymmetric, and transitive. A set S together with a partial ordering R is called a partially ordered set, or poset, and is denoted by (S, R). Members of S are called elements of the poset. Definition2. 4 Definition3. 3 Definition4. 2 Theorem1. 1 这一章就这样了，都是基础，摘录一下。找离散的符号太困难了，只能贴图了。","categories":[{"name":"专业","slug":"pro","permalink":"https://sean10.github.io/categories/pro/"}],"tags":[{"name":"离散数学","slug":"离散数学","permalink":"https://sean10.github.io/tags/%E7%A6%BB%E6%95%A3%E6%95%B0%E5%AD%A6/"},{"name":"关系","slug":"关系","permalink":"https://sean10.github.io/tags/%E5%85%B3%E7%B3%BB/"}]},{"title":"《龙珠之复活的F》休闲的龙珠","slug":"《龙珠之复活的F》休闲的龙珠","date":"2015-10-25T12:14:00.000Z","updated":"2023-03-18T15:11:14.902Z","comments":true,"path":"2015/10/25/《龙珠之复活的F》休闲的龙珠/","link":"","permalink":"https://sean10.github.io/2015/10/25/%E3%80%8A%E9%BE%99%E7%8F%A0%E4%B9%8B%E5%A4%8D%E6%B4%BB%E7%9A%84F%E3%80%8B%E4%BC%91%E9%97%B2%E7%9A%84%E9%BE%99%E7%8F%A0/","excerpt":"稍稍温习了一下《龙珠之复活的F》，给我的印象就是现在出的龙珠的风格都已经趋于休闲了呢。《神与神》以及现在的这部，两部的剧情里都已经不再是以前的需要拼命才能拥有足够的战斗力了，现在已经偏向去日常化了，悟空的天真粗心的个性也愈发凸显了，虽说是主角，到了动漫的末期之后，配角反倒是和他拥有了同样的镜头率。","text":"稍稍温习了一下《龙珠之复活的F》，给我的印象就是现在出的龙珠的风格都已经趋于休闲了呢。《神与神》以及现在的这部，两部的剧情里都已经不再是以前的需要拼命才能拥有足够的战斗力了，现在已经偏向去日常化了，悟空的天真粗心的个性也愈发凸显了，虽说是主角，到了动漫的末期之后，配角反倒是和他拥有了同样的镜头率。 在这部中，弗利萨虽然复活了，然而这次他的身份却变成了丑角一般，只是在剧情中担任吐槽、被悟空、贝吉塔嘲讽的角色，感觉倒是略萌了。对于剧情中弗利萨半年就拥有了悟空整部龙珠Z经历之后的战斗力这点就不予评价了，龙珠的战斗力已经混乱了。在这里，悟空和贝吉塔两人都能轻松变身上一部中透露出的超级赛亚神变身之后的第一形态，秒杀弗利萨本不是问题，后面几十分钟真的只是日常的对话了，就像其他人说的，这一部剧场版的主旨在于凸显悟空的粗心大意，果不其然，剧情最后，弗利萨趁他们没注意，灭了地球，然后所幸一开始作者就已经给这个坑作了铺垫，维斯简单逆转时间，给他们提供了弥补的机会。不再让人后悔，也不再有紧张的气氛，整部动漫都沉浸在欢愉的气氛中。换个角度，也就是主角们已经不再有曾经的紧迫感提高实力，一切都只是消遣尔尔。 从原著者的角度，可能这样的发展是最好的，不是无止境的超4、超5下去，而是进入神的境界，体会自然。然而，从某种角度，合理同时也便是开始平凡的选择。想必大家也有同样的感觉罢，美好的结局永远不是能够想象到的，唯有留下一丝悬念的结局才能让人联想，并富有一丝完结的感伤。如今的龙珠原著，满满的日常化的风格，对我来说，已经只能是偶尔的娱乐了，相比，同人之作的《龙珠GT》给我的美好印象更为深刻了，最后悟空的别离，以及最后的以下下代的子孙重现悟空、贝吉塔的故事更为让人赞赏、让人意识到真的结束了，大家都成长了。至于其他的不断发掘宇宙本质、去其他宇宙找对手的同人就算了，虽说是遵循了主线，然而我作为观众，真的累了，看龙珠成长过来，如今大学了，希望的真的是结束了。 我对GT已经很满足了。","categories":[{"name":"随想","slug":"thinking","permalink":"https://sean10.github.io/categories/thinking/"}],"tags":[{"name":"日本","slug":"日本","permalink":"https://sean10.github.io/tags/%E6%97%A5%E6%9C%AC/"},{"name":"动漫","slug":"动漫","permalink":"https://sean10.github.io/tags/%E5%8A%A8%E6%BC%AB/"},{"name":"影评","slug":"影评","permalink":"https://sean10.github.io/tags/%E5%BD%B1%E8%AF%84/"}]},{"title":"Ubuntu+win7安装总结——查询不到win7分区问题","slug":"Ubuntu-win7安装总结——查询不到win7分区问题","date":"2015-10-24T12:01:00.000Z","updated":"2023-03-18T15:11:14.900Z","comments":true,"path":"2015/10/24/Ubuntu-win7安装总结——查询不到win7分区问题/","link":"","permalink":"https://sean10.github.io/2015/10/24/Ubuntu-win7%E5%AE%89%E8%A3%85%E6%80%BB%E7%BB%93%E2%80%94%E2%80%94%E6%9F%A5%E8%AF%A2%E4%B8%8D%E5%88%B0win7%E5%88%86%E5%8C%BA%E9%97%AE%E9%A2%98/","excerpt":"","text":"这两天在学校计划装个linux以后用来写代码，windows下面就专心玩好了。 本来搜了下经验，以为很轻松（虽然事实上知道怎么弄，不出错就确实很轻松啦）。然后，就那么把原来的win7系统不自觉的全格了，直到花了1天半的时间之后，搜linux下怎么看不到win7的硬盘搜不到结果，忽然点开linux下的computer的property看了下之后，发现原本一直以为的linux只是在隔出来的50G下玩的，事实上是500G。 然后，明白了，数据全没了。（虽然已经备份，但是对于一些下载的计划看的资料丢了，也是比较难很快接受）。 OK，知道现在电脑里什么都没了以后，轻松了/ 因为觉得在Linux下装win7，事后的引导什么的可能会很麻烦，就依旧先刻个win7的U盘，在win7安装之后安装ubuntu。 这里的win7是从msdn里下载的应该说是最纯净的win7，因为连个网卡驱动都没有，还好周边有一台老式机，下载了一个拷过来才用上的网络。 接下来就是唯一导致这次安装错误的幕后黑手。 windows下准备好ultraiso刻录好的ubuntu的U盘。 开机进入选择启动（lenovo是F12进入，我电脑已经设置为Legacybios，所以不太了解win8双系统uefi该怎么设置） 进入ubuntu安装界面以后，之前都按continue就可以，到分区前一步，如果显示出已检测到win7系统，那么就说明你硬盘格式和标识都是正确的，下一步也就不会出现下一步不显示win7已经分好的磁盘的问题了。 如果没有显示检测出win7，现在按照我查的资料来理解。 安装win7的时候是MBR分区模式，安装ubuntu时，自动识别为GPT分区模式，执行以下命令就可以让Ubuntu以MBR执行。 在试用版里输入一下命令即可 &lt;pre class=\"brush:bash\";&gt;sudo dd if=/dev/zero of=/dev/sda bs=1 count=8 seek=512 这会抹去 Primary GPT header 里的 GPT signature。请不要输错任何一个字，包括空格。 有其他人说也可以在bios设置里设置Legacyonly.我电脑没有这个选项，不确定在什么上有那个。 以上。","categories":[{"name":"专业","slug":"pro","permalink":"https://sean10.github.io/categories/pro/"}],"tags":[{"name":"app","slug":"app","permalink":"https://sean10.github.io/tags/app/"}]},{"title":"Ubuntu下安装xampp总结","slug":"Ubuntu下安装xampp总结","date":"2015-10-24T11:59:00.000Z","updated":"2023-03-18T15:11:14.900Z","comments":true,"path":"2015/10/24/Ubuntu下安装xampp总结/","link":"","permalink":"https://sean10.github.io/2015/10/24/Ubuntu%E4%B8%8B%E5%AE%89%E8%A3%85xampp%E6%80%BB%E7%BB%93/","excerpt":"","text":"初用linux，对于指令还不太熟悉，在安装xampp过程中，一部分情况和其他教程不太符合，摸索着弄了一下。 在一开始没有用wget下载，在图形界面下下载的。 然后移动入opt文件夹，这里一开始始终弄不到管理员权限，不安装其他软件的情况下好像图形界面下取得不到管理员权限。 我用的是 &lt;pre class=\"brush:bash\";&gt;然后用cd进入该文件夹 对文件权限设置可执行 &lt;pre class=\"brush:bash\";&gt;chmod +x 文件名 然后启动文件 &lt;pre class=\"brush:bash\";&gt;./opt/文件名 即可","categories":[{"name":"专业","slug":"pro","permalink":"https://sean10.github.io/categories/pro/"}],"tags":[{"name":"app","slug":"app","permalink":"https://sean10.github.io/tags/app/"}]},{"title":"F.lux——自动调整屏幕亮度与颜色，降低蓝光","slug":"F-lux——自动调整屏幕亮度与颜色，降低蓝光","date":"2015-10-24T11:48:00.000Z","updated":"2023-03-18T15:11:14.904Z","comments":true,"path":"2015/10/24/F-lux——自动调整屏幕亮度与颜色，降低蓝光/","link":"","permalink":"https://sean10.github.io/2015/10/24/F-lux%E2%80%94%E2%80%94%E8%87%AA%E5%8A%A8%E8%B0%83%E6%95%B4%E5%B1%8F%E5%B9%95%E4%BA%AE%E5%BA%A6%E4%B8%8E%E9%A2%9C%E8%89%B2%EF%BC%8C%E9%99%8D%E4%BD%8E%E8%93%9D%E5%85%89/","excerpt":"","text":"看电脑看的比较多，眼睛很容易干涩，这种方法，效果还不错。 linux下直接按照以下命令就可以了 sudo add-apt-repository ppa:kilian/f.lux sudo apt-get update sudo apt-get install fluxgui windows下进入以下网址下载即可 https://justgetflux.com/dlwin.html","categories":[{"name":"专业","slug":"pro","permalink":"https://sean10.github.io/categories/pro/"}],"tags":[{"name":"App","slug":"App","permalink":"https://sean10.github.io/tags/App/"}]},{"title":"《六花的勇者》推理的勇者,黑化超凡or普通平淡","slug":"《六花的勇者》推理的勇者，黑化超凡or普通平淡","date":"2015-10-24T11:43:00.000Z","updated":"2023-03-18T15:11:14.835Z","comments":true,"path":"2015/10/24/《六花的勇者》推理的勇者，黑化超凡or普通平淡/","link":"","permalink":"https://sean10.github.io/2015/10/24/%E3%80%8A%E5%85%AD%E8%8A%B1%E7%9A%84%E5%8B%87%E8%80%85%E3%80%8B%E6%8E%A8%E7%90%86%E7%9A%84%E5%8B%87%E8%80%85%EF%BC%8C%E9%BB%91%E5%8C%96%E8%B6%85%E5%87%A1or%E6%99%AE%E9%80%9A%E5%B9%B3%E6%B7%A1/","excerpt":"新番刚出的时候，本以为是一部老套剧情讲述勇者组队刷魔王的故事。 而在最近看到其他人的推荐时，我才明白自己想错太多了。 剧情不复常见的勇者斗魔王，这仅仅只是一个从未漏出魔王对象的背景，真实的目的是开展一部杀人游戏。 从剧情角度的新颖来看，《六花的勇者》是和《魔王勇者》一般，对于针对性的受众——推理爱好者而言，是非常值得一看的。 《六花的勇者》的作者山形石雄在这之前写过《战斗司书》系列，早在07年已经被做成了动漫，可能是因为观看的平台少的缘故，之前并没有看到过这部的踪迹，单看百科的介绍，以人生化作的书为争夺中心，展开正方与反方的争夺，单单这样的设定，已经足以勾起我的兴趣。","text":"新番刚出的时候，本以为是一部老套剧情讲述勇者组队刷魔王的故事。 而在最近看到其他人的推荐时，我才明白自己想错太多了。 剧情不复常见的勇者斗魔王，这仅仅只是一个从未漏出魔王对象的背景，真实的目的是开展一部杀人游戏。 从剧情角度的新颖来看，《六花的勇者》是和《魔王勇者》一般，对于针对性的受众——推理爱好者而言，是非常值得一看的。 《六花的勇者》的作者山形石雄在这之前写过《战斗司书》系列，早在07年已经被做成了动漫，可能是因为观看的平台少的缘故，之前并没有看到过这部的踪迹，单看百科的介绍，以人生化作的书为争夺中心，展开正方与反方的争夺，单单这样的设定，已经足以勾起我的兴趣。 以下剧透 本部轻小说，围绕六花的6名天选勇者集合前往魔神领地沉默魔神背景，以自称地表上最强的男人与公主汇合、与半人半魔之女产生交际为铺垫，进入汇合之处，7人共同拥有勇者之六花，男主展开自己历经数年锻炼而来的综合能力，将真正的叛徒公主给成功的推理了出来。公主的真实想法是借牺牲50万人，实现永久的人与魔共存的和平。从长期高位的人来看，这样的想法其实相当合理，或者说这样的计划才是能有所成就者所会做的。作者如此的剧情可谓别出心裁，从中映射了高位决策者与低位小聪明者之间的大局观的差距，剧本中，是以大局者为之拒绝，始终在幕后执行自己的宏伟计划。而男主的单纯天真想法则在荧幕前作为主线展示。 在动漫的最后一幕，揭示了作者埋的一个大坑，真正的第6位六花登场了，动漫将这作为悬念遗留了下来，由此来看，该动画的制作公司还是有计划继续第二季的，不过当然这也是要看在观众群中的反响了。不过按照后续的轻小说的剧情来看，下一部的剧情恐怕也主要只会是男主在带领其他6人对抗魔神军三大统帅的过程中发现自己的真实身份——魔神三大统帅之一在人类中埋下的伏笔，然后男主继续斗智斗勇。并没有看过这部的轻小说，姑且凭经历猜测一下罢，按照动漫已知的铺垫来说，有2种最终结果的可能性。 第一种，也是我最不希望看到的，男主最后走上了一条最平淡也是最泛滥的道路，组队斗智斗勇打败了魔神中三大统帅之一也是他的身份的幕后黑手泰格纽。那么就确实完全没有什么必要出第二季了。 第二种，将公主的行动由幕后转向幕前，将男主的心理、眼界的成长确实的刻画出来，让男主成为一个黑化的人，不过这样的设定如果是同人，一定会有不少人欣赏，不过对于原著作者，这样舍弃自己的人物原本的设定，并不一定是一个好的选择，至少从我已有的经历来看，还从未看到过设定更改的动漫。比如大爱的《罪恶王冠》中，虽然男主和男配在剧情的中间实现了性格的黑化以及反转，然而在剧情的结束，还是以男主觉悟了、男配只是本性的展露作为结局。所以再看《六花》，作者只可能以第一种选择结束，想要看到第二种非主流路线，只可能在同人中找寻了。 再看轻小说与动漫的差异，本作动画化的构成、脚本作家是浦田达彦，《境界上的地平线》的脚本作家，暂时还感觉不到各集之间的剧情分配的不足之处，而人设上走了常见的勇者斗魔王的风格，粗旷不失细腻，对我来说还是感觉不错的了。 《六花的勇者》还是值得好评的。","categories":[{"name":"随想","slug":"thinking","permalink":"https://sean10.github.io/categories/thinking/"}],"tags":[{"name":"日本","slug":"日本","permalink":"https://sean10.github.io/tags/%E6%97%A5%E6%9C%AC/"},{"name":"动漫","slug":"动漫","permalink":"https://sean10.github.io/tags/%E5%8A%A8%E6%BC%AB/"},{"name":"影评","slug":"影评","permalink":"https://sean10.github.io/tags/%E5%BD%B1%E8%AF%84/"}]}],"categories":[{"name":"专业","slug":"pro","permalink":"https://sean10.github.io/categories/pro/"},{"name":"随想","slug":"thinking","permalink":"https://sean10.github.io/categories/thinking/"},{"name":"算法","slug":"algorithm","permalink":"https://sean10.github.io/categories/algorithm/"}],"tags":[{"name":"网络","slug":"网络","permalink":"https://sean10.github.io/tags/%E7%BD%91%E7%BB%9C/"},{"name":"TCP","slug":"TCP","permalink":"https://sean10.github.io/tags/TCP/"},{"name":"大模型","slug":"大模型","permalink":"https://sean10.github.io/tags/%E5%A4%A7%E6%A8%A1%E5%9E%8B/"},{"name":"AI","slug":"AI","permalink":"https://sean10.github.io/tags/AI/"},{"name":"开源","slug":"开源","permalink":"https://sean10.github.io/tags/%E5%BC%80%E6%BA%90/"},{"name":"ceph","slug":"ceph","permalink":"https://sean10.github.io/tags/ceph/"},{"name":"fio","slug":"fio","permalink":"https://sean10.github.io/tags/fio/"},{"name":"consistency","slug":"consistency","permalink":"https://sean10.github.io/tags/consistency/"},{"name":"snapshot","slug":"snapshot","permalink":"https://sean10.github.io/tags/snapshot/"},{"name":"upgrade","slug":"upgrade","permalink":"https://sean10.github.io/tags/upgrade/"},{"name":"cephalocon","slug":"cephalocon","permalink":"https://sean10.github.io/tags/cephalocon/"},{"name":"snap","slug":"snap","permalink":"https://sean10.github.io/tags/snap/"},{"name":"hexo","slug":"hexo","permalink":"https://sean10.github.io/tags/hexo/"},{"name":"项目","slug":"项目","permalink":"https://sean10.github.io/tags/%E9%A1%B9%E7%9B%AE/"},{"name":"流程","slug":"流程","permalink":"https://sean10.github.io/tags/%E6%B5%81%E7%A8%8B/"},{"name":"vscode","slug":"vscode","permalink":"https://sean10.github.io/tags/vscode/"},{"name":"markdown","slug":"markdown","permalink":"https://sean10.github.io/tags/markdown/"},{"name":"community","slug":"community","permalink":"https://sean10.github.io/tags/community/"},{"name":"mac","slug":"mac","permalink":"https://sean10.github.io/tags/mac/"},{"name":"hammerspoon","slug":"hammerspoon","permalink":"https://sean10.github.io/tags/hammerspoon/"},{"name":"Alfred","slug":"Alfred","permalink":"https://sean10.github.io/tags/Alfred/"},{"name":"extension","slug":"extension","permalink":"https://sean10.github.io/tags/extension/"},{"name":"dashboard","slug":"dashboard","permalink":"https://sean10.github.io/tags/dashboard/"},{"name":"高可用","slug":"高可用","permalink":"https://sean10.github.io/tags/%E9%AB%98%E5%8F%AF%E7%94%A8/"},{"name":"keepalived","slug":"keepalived","permalink":"https://sean10.github.io/tags/keepalived/"},{"name":"团队","slug":"团队","permalink":"https://sean10.github.io/tags/%E5%9B%A2%E9%98%9F/"},{"name":"绩效","slug":"绩效","permalink":"https://sean10.github.io/tags/%E7%BB%A9%E6%95%88/"},{"name":"技术","slug":"技术","permalink":"https://sean10.github.io/tags/%E6%8A%80%E6%9C%AF/"},{"name":"wechat","slug":"wechat","permalink":"https://sean10.github.io/tags/wechat/"},{"name":"ffmpeg","slug":"ffmpeg","permalink":"https://sean10.github.io/tags/ffmpeg/"},{"name":"linux","slug":"linux","permalink":"https://sean10.github.io/tags/linux/"},{"name":"IO","slug":"IO","permalink":"https://sean10.github.io/tags/IO/"},{"name":"存储","slug":"存储","permalink":"https://sean10.github.io/tags/%E5%AD%98%E5%82%A8/"},{"name":"python","slug":"python","permalink":"https://sean10.github.io/tags/python/"},{"name":"log","slug":"log","permalink":"https://sean10.github.io/tags/log/"},{"name":"library","slug":"library","permalink":"https://sean10.github.io/tags/library/"},{"name":"docker","slug":"docker","permalink":"https://sean10.github.io/tags/docker/"},{"name":"编译","slug":"编译","permalink":"https://sean10.github.io/tags/%E7%BC%96%E8%AF%91/"},{"name":"mon","slug":"mon","permalink":"https://sean10.github.io/tags/mon/"},{"name":"超时","slug":"超时","permalink":"https://sean10.github.io/tags/%E8%B6%85%E6%97%B6/"},{"name":"systemd","slug":"systemd","permalink":"https://sean10.github.io/tags/systemd/"},{"name":"service","slug":"service","permalink":"https://sean10.github.io/tags/service/"},{"name":"分布式","slug":"分布式","permalink":"https://sean10.github.io/tags/%E5%88%86%E5%B8%83%E5%BC%8F/"},{"name":"摘录","slug":"摘录","permalink":"https://sean10.github.io/tags/%E6%91%98%E5%BD%95/"},{"name":"时钟","slug":"时钟","permalink":"https://sean10.github.io/tags/%E6%97%B6%E9%92%9F/"},{"name":"论文","slug":"论文","permalink":"https://sean10.github.io/tags/%E8%AE%BA%E6%96%87/"},{"name":"缓存","slug":"缓存","permalink":"https://sean10.github.io/tags/%E7%BC%93%E5%AD%98/"},{"name":"gossip","slug":"gossip","permalink":"https://sean10.github.io/tags/gossip/"},{"name":"arch","slug":"arch","permalink":"https://sean10.github.io/tags/arch/"},{"name":"ansible","slug":"ansible","permalink":"https://sean10.github.io/tags/ansible/"},{"name":"OpenAPI","slug":"OpenAPI","permalink":"https://sean10.github.io/tags/OpenAPI/"},{"name":"API","slug":"API","permalink":"https://sean10.github.io/tags/API/"},{"name":"SDK","slug":"SDK","permalink":"https://sean10.github.io/tags/SDK/"},{"name":"游戏王","slug":"游戏王","permalink":"https://sean10.github.io/tags/%E6%B8%B8%E6%88%8F%E7%8E%8B/"},{"name":"ygo","slug":"ygo","permalink":"https://sean10.github.io/tags/ygo/"},{"name":"zotero","slug":"zotero","permalink":"https://sean10.github.io/tags/zotero/"},{"name":"总结","slug":"总结","permalink":"https://sean10.github.io/tags/%E6%80%BB%E7%BB%93/"},{"name":"ELK","slug":"ELK","permalink":"https://sean10.github.io/tags/ELK/"},{"name":"laptop","slug":"laptop","permalink":"https://sean10.github.io/tags/laptop/"},{"name":"高铁","slug":"高铁","permalink":"https://sean10.github.io/tags/%E9%AB%98%E9%93%81/"},{"name":"CentOS","slug":"CentOS","permalink":"https://sean10.github.io/tags/CentOS/"},{"name":"CLI","slug":"CLI","permalink":"https://sean10.github.io/tags/CLI/"},{"name":"http","slug":"http","permalink":"https://sean10.github.io/tags/http/"},{"name":"system","slug":"system","permalink":"https://sean10.github.io/tags/system/"},{"name":"git","slug":"git","permalink":"https://sean10.github.io/tags/git/"},{"name":"版本管理","slug":"版本管理","permalink":"https://sean10.github.io/tags/%E7%89%88%E6%9C%AC%E7%AE%A1%E7%90%86/"},{"name":"svn","slug":"svn","permalink":"https://sean10.github.io/tags/svn/"},{"name":"文件系统","slug":"文件系统","permalink":"https://sean10.github.io/tags/%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/"},{"name":"diff","slug":"diff","permalink":"https://sean10.github.io/tags/diff/"},{"name":"merge","slug":"merge","permalink":"https://sean10.github.io/tags/merge/"},{"name":"typescript","slug":"typescript","permalink":"https://sean10.github.io/tags/typescript/"},{"name":"rdp","slug":"rdp","permalink":"https://sean10.github.io/tags/rdp/"},{"name":"vnc","slug":"vnc","permalink":"https://sean10.github.io/tags/vnc/"},{"name":"perf","slug":"perf","permalink":"https://sean10.github.io/tags/perf/"},{"name":"rbd","slug":"rbd","permalink":"https://sean10.github.io/tags/rbd/"},{"name":"源码","slug":"源码","permalink":"https://sean10.github.io/tags/%E6%BA%90%E7%A0%81/"},{"name":"tier","slug":"tier","permalink":"https://sean10.github.io/tags/tier/"},{"name":"编程范式","slug":"编程范式","permalink":"https://sean10.github.io/tags/%E7%BC%96%E7%A8%8B%E8%8C%83%E5%BC%8F/"},{"name":"code","slug":"code","permalink":"https://sean10.github.io/tags/code/"},{"name":"paradigm","slug":"paradigm","permalink":"https://sean10.github.io/tags/paradigm/"},{"name":"exception","slug":"exception","permalink":"https://sean10.github.io/tags/exception/"},{"name":"vs code","slug":"vs-code","permalink":"https://sean10.github.io/tags/vs-code/"},{"name":"mock","slug":"mock","permalink":"https://sean10.github.io/tags/mock/"},{"name":"unittest","slug":"unittest","permalink":"https://sean10.github.io/tags/unittest/"},{"name":"debug","slug":"debug","permalink":"https://sean10.github.io/tags/debug/"},{"name":"C++","slug":"C","permalink":"https://sean10.github.io/tags/C/"},{"name":"定时器","slug":"定时器","permalink":"https://sean10.github.io/tags/%E5%AE%9A%E6%97%B6%E5%99%A8/"},{"name":"工具","slug":"工具","permalink":"https://sean10.github.io/tags/%E5%B7%A5%E5%85%B7/"},{"name":"node-js","slug":"node-js","permalink":"https://sean10.github.io/tags/node-js/"},{"name":"pdf","slug":"pdf","permalink":"https://sean10.github.io/tags/pdf/"},{"name":"pytest","slug":"pytest","permalink":"https://sean10.github.io/tags/pytest/"},{"name":"生活","slug":"生活","permalink":"https://sean10.github.io/tags/%E7%94%9F%E6%B4%BB/"},{"name":"支付宝","slug":"支付宝","permalink":"https://sean10.github.io/tags/%E6%94%AF%E4%BB%98%E5%AE%9D/"},{"name":"C","slug":"C","permalink":"https://sean10.github.io/tags/C/"},{"name":"macro","slug":"macro","permalink":"https://sean10.github.io/tags/macro/"},{"name":"hacintosh","slug":"hacintosh","permalink":"https://sean10.github.io/tags/hacintosh/"},{"name":"AMD","slug":"AMD","permalink":"https://sean10.github.io/tags/AMD/"},{"name":"windows","slug":"windows","permalink":"https://sean10.github.io/tags/windows/"},{"name":"terminal","slug":"terminal","permalink":"https://sean10.github.io/tags/terminal/"},{"name":"tmux","slug":"tmux","permalink":"https://sean10.github.io/tags/tmux/"},{"name":"rados","slug":"rados","permalink":"https://sean10.github.io/tags/rados/"},{"name":"re","slug":"re","permalink":"https://sean10.github.io/tags/re/"},{"name":"正则表达式","slug":"正则表达式","permalink":"https://sean10.github.io/tags/%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F/"},{"name":"gcc","slug":"gcc","permalink":"https://sean10.github.io/tags/gcc/"},{"name":"Clion","slug":"Clion","permalink":"https://sean10.github.io/tags/Clion/"},{"name":"Sourcetrail","slug":"Sourcetrail","permalink":"https://sean10.github.io/tags/Sourcetrail/"},{"name":"Index","slug":"Index","permalink":"https://sean10.github.io/tags/Index/"},{"name":"动漫","slug":"动漫","permalink":"https://sean10.github.io/tags/%E5%8A%A8%E6%BC%AB/"},{"name":"罗小黑战记","slug":"罗小黑战记","permalink":"https://sean10.github.io/tags/%E7%BD%97%E5%B0%8F%E9%BB%91%E6%88%98%E8%AE%B0/"},{"name":"js","slug":"js","permalink":"https://sean10.github.io/tags/js/"},{"name":"Python","slug":"Python","permalink":"https://sean10.github.io/tags/Python/"},{"name":"script","slug":"script","permalink":"https://sean10.github.io/tags/script/"},{"name":"Qt","slug":"Qt","permalink":"https://sean10.github.io/tags/Qt/"},{"name":"sqlite3","slug":"sqlite3","permalink":"https://sean10.github.io/tags/sqlite3/"},{"name":"火灾","slug":"火灾","permalink":"https://sean10.github.io/tags/%E7%81%AB%E7%81%BE/"},{"name":"高层","slug":"高层","permalink":"https://sean10.github.io/tags/%E9%AB%98%E5%B1%82/"},{"name":"KVM","slug":"KVM","permalink":"https://sean10.github.io/tags/KVM/"},{"name":"虚拟化","slug":"虚拟化","permalink":"https://sean10.github.io/tags/%E8%99%9A%E6%8B%9F%E5%8C%96/"},{"name":"frp","slug":"frp","permalink":"https://sean10.github.io/tags/frp/"},{"name":"rsyslog","slug":"rsyslog","permalink":"https://sean10.github.io/tags/rsyslog/"},{"name":"硬件","slug":"硬件","permalink":"https://sean10.github.io/tags/%E7%A1%AC%E4%BB%B6/"},{"name":"libvirt","slug":"libvirt","permalink":"https://sean10.github.io/tags/libvirt/"},{"name":"下厨","slug":"下厨","permalink":"https://sean10.github.io/tags/%E4%B8%8B%E5%8E%A8/"},{"name":"租房","slug":"租房","permalink":"https://sean10.github.io/tags/%E7%A7%9F%E6%88%BF/"},{"name":"wiki","slug":"wiki","permalink":"https://sean10.github.io/tags/wiki/"},{"name":"centos","slug":"centos","permalink":"https://sean10.github.io/tags/centos/"},{"name":"jabref","slug":"jabref","permalink":"https://sean10.github.io/tags/jabref/"},{"name":"档案","slug":"档案","permalink":"https://sean10.github.io/tags/%E6%A1%A3%E6%A1%88/"},{"name":"信息安全","slug":"信息安全","permalink":"https://sean10.github.io/tags/%E4%BF%A1%E6%81%AF%E5%AE%89%E5%85%A8/"},{"name":"Memory","slug":"Memory","permalink":"https://sean10.github.io/tags/Memory/"},{"name":"OS","slug":"OS","permalink":"https://sean10.github.io/tags/OS/"},{"name":"VMWare","slug":"VMWare","permalink":"https://sean10.github.io/tags/VMWare/"},{"name":"jupyter","slug":"jupyter","permalink":"https://sean10.github.io/tags/jupyter/"},{"name":"LaTex","slug":"LaTex","permalink":"https://sean10.github.io/tags/LaTex/"},{"name":"github","slug":"github","permalink":"https://sean10.github.io/tags/github/"},{"name":"DNS","slug":"DNS","permalink":"https://sean10.github.io/tags/DNS/"},{"name":"算法","slug":"算法","permalink":"https://sean10.github.io/tags/%E7%AE%97%E6%B3%95/"},{"name":"广告","slug":"广告","permalink":"https://sean10.github.io/tags/%E5%B9%BF%E5%91%8A/"},{"name":"Pycharm","slug":"Pycharm","permalink":"https://sean10.github.io/tags/Pycharm/"},{"name":"快捷键","slug":"快捷键","permalink":"https://sean10.github.io/tags/%E5%BF%AB%E6%8D%B7%E9%94%AE/"},{"name":"virtualenv","slug":"virtualenv","permalink":"https://sean10.github.io/tags/virtualenv/"},{"name":"kcp","slug":"kcp","permalink":"https://sean10.github.io/tags/kcp/"},{"name":"tcp","slug":"tcp","permalink":"https://sean10.github.io/tags/tcp/"},{"name":"automate","slug":"automate","permalink":"https://sean10.github.io/tags/automate/"},{"name":"travis","slug":"travis","permalink":"https://sean10.github.io/tags/travis/"},{"name":"Docker","slug":"Docker","permalink":"https://sean10.github.io/tags/Docker/"},{"name":"iTerm","slug":"iTerm","permalink":"https://sean10.github.io/tags/iTerm/"},{"name":"科幻","slug":"科幻","permalink":"https://sean10.github.io/tags/%E7%A7%91%E5%B9%BB/"},{"name":"刘慈欣","slug":"刘慈欣","permalink":"https://sean10.github.io/tags/%E5%88%98%E6%85%88%E6%AC%A3/"},{"name":"评论","slug":"评论","permalink":"https://sean10.github.io/tags/%E8%AF%84%E8%AE%BA/"},{"name":"凯文","slug":"凯文","permalink":"https://sean10.github.io/tags/%E5%87%AF%E6%96%87/"},{"name":"失控","slug":"失控","permalink":"https://sean10.github.io/tags/%E5%A4%B1%E6%8E%A7/"},{"name":"韩松","slug":"韩松","permalink":"https://sean10.github.io/tags/%E9%9F%A9%E6%9D%BE/"},{"name":"爬虫","slug":"爬虫","permalink":"https://sean10.github.io/tags/%E7%88%AC%E8%99%AB/"},{"name":"Spider","slug":"Spider","permalink":"https://sean10.github.io/tags/Spider/"},{"name":"死亡","slug":"死亡","permalink":"https://sean10.github.io/tags/%E6%AD%BB%E4%BA%A1/"},{"name":"衰老","slug":"衰老","permalink":"https://sean10.github.io/tags/%E8%A1%B0%E8%80%81/"},{"name":"微信","slug":"微信","permalink":"https://sean10.github.io/tags/%E5%BE%AE%E4%BF%A1/"},{"name":"数独","slug":"数独","permalink":"https://sean10.github.io/tags/%E6%95%B0%E7%8B%AC/"},{"name":"sudoku","slug":"sudoku","permalink":"https://sean10.github.io/tags/sudoku/"},{"name":"TensorFlow","slug":"TensorFlow","permalink":"https://sean10.github.io/tags/TensorFlow/"},{"name":"node","slug":"node","permalink":"https://sean10.github.io/tags/node/"},{"name":"shell","slug":"shell","permalink":"https://sean10.github.io/tags/shell/"},{"name":"影评","slug":"影评","permalink":"https://sean10.github.io/tags/%E5%BD%B1%E8%AF%84/"},{"name":"尼采","slug":"尼采","permalink":"https://sean10.github.io/tags/%E5%B0%BC%E9%87%87/"},{"name":"周国平","slug":"周国平","permalink":"https://sean10.github.io/tags/%E5%91%A8%E5%9B%BD%E5%B9%B3/"},{"name":"读后感","slug":"读后感","permalink":"https://sean10.github.io/tags/%E8%AF%BB%E5%90%8E%E6%84%9F/"},{"name":"哲学","slug":"哲学","permalink":"https://sean10.github.io/tags/%E5%93%B2%E5%AD%A6/"},{"name":"读书笔记","slug":"读书笔记","permalink":"https://sean10.github.io/tags/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/"},{"name":"东野圭吾","slug":"东野圭吾","permalink":"https://sean10.github.io/tags/%E4%B8%9C%E9%87%8E%E5%9C%AD%E5%90%BE/"},{"name":"推理","slug":"推理","permalink":"https://sean10.github.io/tags/%E6%8E%A8%E7%90%86/"},{"name":"小说","slug":"小说","permalink":"https://sean10.github.io/tags/%E5%B0%8F%E8%AF%B4/"},{"name":"来自深渊","slug":"来自深渊","permalink":"https://sean10.github.io/tags/%E6%9D%A5%E8%87%AA%E6%B7%B1%E6%B8%8A/"},{"name":"吉卜力","slug":"吉卜力","permalink":"https://sean10.github.io/tags/%E5%90%89%E5%8D%9C%E5%8A%9B/"},{"name":"奇幻","slug":"奇幻","permalink":"https://sean10.github.io/tags/%E5%A5%87%E5%B9%BB/"},{"name":"全部成为F","slug":"全部成为F","permalink":"https://sean10.github.io/tags/%E5%85%A8%E9%83%A8%E6%88%90%E4%B8%BAF/"},{"name":"真贺田四季","slug":"真贺田四季","permalink":"https://sean10.github.io/tags/%E7%9C%9F%E8%B4%BA%E7%94%B0%E5%9B%9B%E5%AD%A3/"},{"name":"刀剑神域","slug":"刀剑神域","permalink":"https://sean10.github.io/tags/%E5%88%80%E5%89%91%E7%A5%9E%E5%9F%9F/"},{"name":"考研","slug":"考研","permalink":"https://sean10.github.io/tags/%E8%80%83%E7%A0%94/"},{"name":"克苏鲁","slug":"克苏鲁","permalink":"https://sean10.github.io/tags/%E5%85%8B%E8%8B%8F%E9%B2%81/"},{"name":"系统结构","slug":"系统结构","permalink":"https://sean10.github.io/tags/%E7%B3%BB%E7%BB%9F%E7%BB%93%E6%9E%84/"},{"name":"Unix","slug":"Unix","permalink":"https://sean10.github.io/tags/Unix/"},{"name":"Linux","slug":"Linux","permalink":"https://sean10.github.io/tags/Linux/"},{"name":"图形学","slug":"图形学","permalink":"https://sean10.github.io/tags/%E5%9B%BE%E5%BD%A2%E5%AD%A6/"},{"name":"openGL","slug":"openGL","permalink":"https://sean10.github.io/tags/openGL/"},{"name":"日本","slug":"日本","permalink":"https://sean10.github.io/tags/%E6%97%A5%E6%9C%AC/"},{"name":"吸血鬼","slug":"吸血鬼","permalink":"https://sean10.github.io/tags/%E5%90%B8%E8%A1%80%E9%AC%BC/"},{"name":"爱的艺术","slug":"爱的艺术","permalink":"https://sean10.github.io/tags/%E7%88%B1%E7%9A%84%E8%89%BA%E6%9C%AF/"},{"name":"爱情","slug":"爱情","permalink":"https://sean10.github.io/tags/%E7%88%B1%E6%83%85/"},{"name":"综述","slug":"综述","permalink":"https://sean10.github.io/tags/%E7%BB%BC%E8%BF%B0/"},{"name":"暮省","slug":"暮省","permalink":"https://sean10.github.io/tags/%E6%9A%AE%E7%9C%81/"},{"name":"青春","slug":"青春","permalink":"https://sean10.github.io/tags/%E9%9D%92%E6%98%A5/"},{"name":"轻小说","slug":"轻小说","permalink":"https://sean10.github.io/tags/%E8%BD%BB%E5%B0%8F%E8%AF%B4/"},{"name":"书评","slug":"书评","permalink":"https://sean10.github.io/tags/%E4%B9%A6%E8%AF%84/"},{"name":"治愈向","slug":"治愈向","permalink":"https://sean10.github.io/tags/%E6%B2%BB%E6%84%88%E5%90%91/"},{"name":"Huffman","slug":"Huffman","permalink":"https://sean10.github.io/tags/Huffman/"},{"name":"压缩","slug":"压缩","permalink":"https://sean10.github.io/tags/%E5%8E%8B%E7%BC%A9/"},{"name":"离散数学","slug":"离散数学","permalink":"https://sean10.github.io/tags/%E7%A6%BB%E6%95%A3%E6%95%B0%E5%AD%A6/"},{"name":"概率","slug":"概率","permalink":"https://sean10.github.io/tags/%E6%A6%82%E7%8E%87/"},{"name":"物理","slug":"物理","permalink":"https://sean10.github.io/tags/%E7%89%A9%E7%90%86/"},{"name":"王小波","slug":"王小波","permalink":"https://sean10.github.io/tags/%E7%8E%8B%E5%B0%8F%E6%B3%A2/"},{"name":"思考","slug":"思考","permalink":"https://sean10.github.io/tags/%E6%80%9D%E8%80%83/"},{"name":"校验码","slug":"校验码","permalink":"https://sean10.github.io/tags/%E6%A0%A1%E9%AA%8C%E7%A0%81/"},{"name":"小记","slug":"小记","permalink":"https://sean10.github.io/tags/%E5%B0%8F%E8%AE%B0/"},{"name":"梦","slug":"梦","permalink":"https://sean10.github.io/tags/%E6%A2%A6/"},{"name":"群论","slug":"群论","permalink":"https://sean10.github.io/tags/%E7%BE%A4%E8%AE%BA/"},{"name":"勇气","slug":"勇气","permalink":"https://sean10.github.io/tags/%E5%8B%87%E6%B0%94/"},{"name":"关系","slug":"关系","permalink":"https://sean10.github.io/tags/%E5%85%B3%E7%B3%BB/"},{"name":"app","slug":"app","permalink":"https://sean10.github.io/tags/app/"},{"name":"App","slug":"App","permalink":"https://sean10.github.io/tags/App/"}]}